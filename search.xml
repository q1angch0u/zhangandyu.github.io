<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive 中的窗口函数]]></title>
    <url>%2F2020%2F04%2F02%2F%E6%8A%80%E8%83%BD-Hive%E4%B8%AD%E7%9A%84%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[row_number函数1 语法1row_number()over(partition by a order by b DESC) partition by : 类似hive的建表，分区的意思 order by : 排序，DESC 降序 按a进行分区，对b进行降序排列 2 案例 取各省uv排名前10的按钮 2.1 思路 求出 省、按钮 和 uv 对uv按照 city进行从大到小排序 限定序列小于等于10，取出省份和按钮。 2.2 SQL语句 1234567891011121314151617181920212223242526select province, nbtn_namefrom (select province, nbtn_name, uv, row_number()over(partition by province order by uv DESC) as ranfrom (select province, nbtn_name, count(distinct user_account) as uvfrom apache_computer_view.client_android_log where nbtn_name is not null and hit_date = '2020-03-10'group by province, nbtn_name))where ran &lt;= 10 3 注意 rank、dense_rank、row_number 区别 rank函数，排名相等的会留下空位，如1、2、2、4 dense_rank函数，排名相等的不会留下空位，如1、2、2、3 row_number 函数， 排名不管数据是否相等，如1、2、3、4 concat函数1 语法1concat(string A, stringB) 案例将省份和城市进行拼接 2.1 SQL语句12345678910111213select concat(province,&apos;-&apos;, city), uv from (select province, city, count(distinct user_account) as uv from apache_computer_viewwhere hit_date = &apos;2020-03-01&apos;group by province, city) concat_ws函数 语法 2.案例将城市和省份进行拼接 2.1 sql语句12345678910111213select concat_ws(&apos;-&apos;,province, city), uv from (select province, city, count(distinct user_account) as uv from apache_computer_view.client_android_log where hit_date = &apos;2020-03-01&apos;group by province, city) collect_set函数在hive中求出一个数据表中在某天内首次登陆的人；可以借助collect_set来处理sql: sql中的多行合并函数collect_set、collect_list 、concat_ws https://analyticshut.com/pivot-rows-to-columns-hive/ https://analyticshut.com/hive-collect-set-vs-collect-list/ http://leanote.com/blog/post/5b336f08ab64416e23001ace http://leanote.com/blog/post/5b30cf4aab64413846001ac9]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客主题更换]]></title>
    <url>%2F2020%2F03%2F20%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[最近把自己的个人博客主题由 fluid 换成了 maupassant,个人感觉 maupassant 主题简洁明了，更加符合自己的胃口。 这篇文章把自己在更换主题的流程和遇到的问题总结一下： 博客登陆 12345git config --global.name&apos;zhang&apos;git config --global.email &apos;zhang@qq.com&apos;cd E:/zy_bloghexo ghexo d 下载主题到本地 1git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassant 安装插件-安装一直显示错误，于是自己换成了镜像安装。 1$ npm install hexo-renderer-pug --save 镜像安装 12345# 安装镜像npm install -g cnpm --registry=https://registry.npm.taobao.org# 安装后用定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm:安装插件cnpm install hexo-renderer-sass --save 按照文档对主题进行配置大道至简——Hexo简洁主题推荐 常见错误 错误1：自从修改完主题进行上传，就一直报这样的错误，折腾了半天终于解决了。 12345678910111213141516171819错误： $ hexo dINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...warning: could not open directory &apos;2018/02/17/《刻意学习》读书笔记 /&apos;: No such file or directorywarning: could not open directory &apos;2018/02/17/读书笔记-《刻意学习》读书笔记 /&apos;: No such file or directorywarning: could not open directory &apos;2019/02/17/《刻意学习》读书笔记 /&apos;: No such file or directoryOn branch masterUntracked files:(use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) 2018/02/ &quot;2019/02/17/\343\200\212\345\210\273\346\204\217\345\255\246\344\271\240\343\200\213\350\257\273\344\271\246\347\254\224\350\256\260 /&quot;nothing added to commit but untracked files present (use &quot;git add&quot; to track)Everything up-to-dateBranch &apos;master&apos; set up to track remote branch &apos;master&apos; from &apos;git@github.com:zhangandyu/zhangandyu.github.io.git&apos;.INFO Deploy done: git 解法方法： 下载插件 1cnpm install hexo-deployer-git -save 删除原文件 .deploy_git 123456789101112# 删除时，文件显示找不到该项目--https://zhuanlan.zhihu.com/p/55077318去桌面新建一个文本文件，并输入如下内容:DEL /F /A /Q \\?\%1RD /S /Q \\?\%1保存该文本，将文件后缀名修改为.bat，文件名随意。我们将需要删除的文件直接拖到这个.bat文件上即可删除。 重新生成和部署 123rm -rf .deploy_githexo ghexo d 错误2： 123ERROR Process failed: 备份/文章备份/python/数据分析技能-git学习笔记.mdYAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 6, column 11: categories: 解决方法： 1仔细看了看是因为创建的md文件头部声明中没有加空格。 错误3： 12FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlTypeError: Cannot set property &apos;lastIndex&apos; of undefined 解决方法： 1在配置文件_config.yml中将highlight选项的auto_detect设为false 其他错误及解决方案： Hexo常见问题解决方案 https://xuanwo.io/2014/08/14/hexo-usual-problem/]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>博客主题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据异常分析方法]]></title>
    <url>%2F2019%2F08%2F03%2F%E6%96%B9%E6%B3%95-%E6%95%B0%E6%8D%AE%E5%BC%82%E5%B8%B8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[如何针对异常数据进行分析作为一名数据分析师， 在工作中我们经常要对异常数据进行原因分析， 那么异常排查的方法都有哪些， 今天我们就来谈一谈。 首先，在进行分析前，我们需要做到以下几点： 对此数据的业务理解是否准确。 比如：APP的日活是如何定义的， 是用户只要启动APP，还是用户必须在APP中有点击行为。 数据的指标口径是否统一。 比如：某活动页面的 uv，是通过统计用户的手机号，还是统计用户 tracking_id 。不同的统计口径会导致数据出现差异。 数据的产出过程是否明确。 比如：数据是如何从日志中进行清洗，是否会存在多发或漏发数据情况。 寻找相关运营或产品人员进行沟通。询问运营人员关于此数据异常的见解，往往能够提高我们的分析效率。 接下来就是对异常原因的排查，常见的影响因素和方法有： 外部因素：时间因素、节假日活动、热点事件、政策影响等。 内部因素： 部门运营活动、产品功能上线、大盘整体趋势、页面性能、SQL逻辑错误、数据指标口径调整等。 多维度拆解法。从各个维度进行细分拆解，定位问题。比如：某产品活跃用户下降，那我们可以把活跃用户拆分成新用户、老用户、回流用户，然后针对不同的用户再进行细拆分析。 在查找出异常原因之后，我们还需要做到以下两点： 持续跟踪后续数据是否再次异常。在排查出原因并采取相应措施之后，我们需要持续跟踪数据，如果数据再次异常，那么说明给出的异常原因可能是错误的。 对异常原因进行梳理，文档化。 问题描述：什么时间、什么指标异常、异常幅度 主要结论：异常因素有哪些，各自的影响程度如何 后续跟进：后续的解决方案是什么，解决时间，再次验证是否异常。 具体分析过程：分析过程与详细分析数据 以上就是自己总结的数据异常原因分析，你还有哪些好用的分析方法，欢迎留言交流。 参考资料： 数据异常求生指南数据分析之数据异常分析日思619.数据异常了，如何分析？ 工作中存在的分析问题本周 话费账单组kpi考核同比突降67万， 领导让我分析数据异常的原因。 在分析的过程中，自己主要犯了三个错误： 自己一开始就对所有统计的按钮进行细拆， 而没有分功能模块进行细拆， 导致自己一开始只是看到 话费余额页面 和月账单页面下降， 而没有找到电子发票页面下降。 如果自己在细拆的对比中细心的话，自己也是可以找到的， 但是自己没有耐心做对比。 如果自己按照功能模块进行细拆对比， 就不会出现这样的情况。 自己从一开始就没有搭建出一个整体的分析体系， 导致自己分析时，一会跑这个数据， 一会跑那个数据，从而使自己得出的结论没有说服力。比如： 一开始，自己就跑话费余额数据， 但是跑着跑着发现口径有问题， 自己之前得出的结论竟然是错误的， 自己是先有了结论， 然后自己再找数据的， 这样会让自己再推翻自己的结论， 重新跑数据，特别的浪费时间。 数据的准确性不能保证， 自己跑的数据， 存在着比较明显的不合理之处， 口径不够明确， 给别人解释口径时不能够解释清楚。 如何分析业务数据问题陈述、产生假设、收集数据、分析数据、获取结论、采取行动 评估和定位问题 在深入研究任何类型的数据之前，应该快速找到你需要解决的真正问题，并用最简单的话定义它 如果无法用简单的语言解释你要解决的业务问题，那么任何数据分析都无法解决问题。 快速评估和定位问题的三问： 这是否是系统异常导致的问题？ 下载量下跌，但激活量没有，也许是下载数据没有埋点或埋点错误？ 这是更大问题的预兆吗？ 注册号码的下降是网站故障的指示吗？ 你在看一个重要的度量指标吗？ 如果网站的转化率下降，但原始注册量没有下降， 那么就从一个紧急事件变成了一个谜团待揭开 确定潜在原因 经验检索，快速寻找原因根据经验，寻找任何明显的可能原因或问题的答案, 当你检查显示问题的来源或报告后，是否有任何异常原因立即浮现在脑海中？ 例如，你的电子商务网站的ssl认证可能过期，导致浏览器弹窗窗口警告数据不安全，从而显著降低购物车转化率 询问相关人员原因这个问题会影响和涉及其他团队吗？如果是这样，他们是否对可能的原因有任何了解？即使问题与其他团队之间没有明显的联系，也有必要咨询一下。 营销经理可能会问客户支持： 我注意到注册数据下降了，你能否想一想过去几周你发现过什么相关的变化吗？ 创建假设一个假设知识一个尚未得到证实的有根据的猜测。 在分析数据之前，清楚地说明问题的几个可能原因非常重要，这有助于防止常见的数据分析误区。 导致注册量突然下降的假设： 某些地区的公众假期 最近对营销网站的更改 星期一网站中断导致注册过程中出现错误 转换率下降减少了注册量 产品页面在某搜索排名下降到搜索结果的第二页 技术思维的方法——科学假设需具备的条件： 涉及一个自变量和一个因变量 它是可测试的 它是可证伪的 有时查看数据可能会产生一个新的假设，需要再次测试。最终，我们的假设会在下一步通过数据分析得到证实或反驳。 分析数据 分割并确定相关数据指标根据你的假设，你需要查看哪些数据？哪些指标可以帮助你证明或者反驳假设？ 你可以按国家/地区， 渠道和网络会话持续时间细分注册次数，以测试你的假设 注意你的数据基于你已知的业务指标，你可以判断数据是否出现异常？如果无基准线，请用历史数据作为起点。 app注册量同比下降20% 评估异常或趋势的影响经过前两个步骤，你要查看发现的趋势/异常是否足以解释问题 在寻找数据中的异常或趋势时，要注意这些异常或趋势不仅要具有统计意义，也要具有实际意义。我们需要弄清楚是什么会对我们发现的问题产生实际影响。 统计显著性检验用于确定你注意到的异常是由于抽样误差还是适用于所有对象。 在上篇我们说到了如何对数据异常进行分析，这次我们来一道具体的数据分析面试问题。 以下是一家公司APP一周每天的活跃率，如何你是分析师： 从数据中你看到了什么问题？你觉得背后的原因是什么？ 如果你的老板要求你提一个运营运营改进计划，你会怎么做？ 分析答案： 数据质量数据采集， 数据接口， 数据存储 产品质量版本更新， 版本BUG 渠道质量渠道买量造假 活动质量是否有重大活动 政策问题 –&gt; 数据异常排查清楚以下三点： 业务理解 指标口径 当前数据产出过程 数据异常原因分析： 数据有问题 将时间轴拉长，看数据是近期异常还是历史异常，对比近三个月数据。 查看和该指标关联的其他核心指标是否也异常，如果异常，也要一并查看。 核查埋点是否有问题， 数据是否存在多发情况。 业务口径是否有问题， 取的数据是不是真正需要的数据。 写的sql逻辑是否有误， 或者android 和 ios 数据没有相加。 业务发生了变化 同口径下，同比环比数据是否异常， 在长时间轴的条件下进行对比 进行细拆， 看到底是哪个指标的数据出现了异常， 将该指标和相关的指标一起进行对比 与负责此指标的负责人进行沟通， 询问他们近期是否做了推广活动。 产品最近是否发布了新版本，或者某个功能改版存在缺陷问题。 其他因素影响 假期效应： 开学季， 暑期， 四大节日，当地节日 热点事件：常规热点如运动会，世界杯，其他热点事件 活动影响： 双11， 618， 支付宝送红包 政策影响： 金融监管 底层系统故障： 服务器迁移导致数据丢失 存在外部刷量作弊情况 统计口径： 业务逻辑进行了更改， 之前某业务有统计， 但现在不统计了。 数据计算方式改变 要对异常排查进行闭环 持续跟踪后期数据是否再次异常比如7.0版本数据存在多发现象， 但7.1版本开发说已更改， 当7.1版本发布之后， 要及时去查看数据是否再次异常。 对数据异常一定要记录， 对异常口径要留文档。 邮件化， 当数据异常排查原因查明， 并且确认更改之后， 发邮件给相关方， 描述数据异常的影响范围和主要结论。 作为一名数据分析师， 一定要经常去看这三种报表，培养自己的数据敏感度，了解业务的各种核心指标。]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>异常分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用环境来辅助自己进步]]></title>
    <url>%2F2019%2F08%2F02%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E5%88%A9%E7%94%A8%E7%8E%AF%E5%A2%83%E6%9D%A5%E8%BE%85%E5%8A%A9%E8%87%AA%E5%B7%B1%E7%9A%84%E8%BF%9B%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[自己下班或者周末在房间，总是把大量的时间用来刷微博或者刷剧。虽然一直刷一直爽，但自己总是有一种虚度时间的空虚感，如何改变自己下班和周末的状态，成了自己最近在思考的问题。 最近在学习陈海贤的《自我发展心理学》，刚好说到了自己的这种现象，并给出了一种利用环境来促使改变的方法，对自己启发很大，今天就来介绍一下这种方法。 首先是融入到积极的环境中去。要想学习就去图书馆、自习室，要想锻炼就去体育场、健身房。我们心中其实都有一个关于“特定空间”的假设，在假设中，对于公司、图书馆这样的空间就是用来工作学习，对于自己寝室的假设肯定是用来休息娱乐的。如果你要让自己在宿舍这样的空间中好好学习工作，就得付出比在图书馆多几倍的努力才行，还不一定能学进去。所以，周末能去图书馆上自习就绝不在家办公， 让自己融入到特定的环境中去。 当然，如果要学习就要去图书馆，那也不现实。如何在自己的房间中也能被环境所带动呢，文中介绍了第二种方法，那就是在某个特定的环境中只做一件事情。 比如：你可以要求自己在这张书桌上只作跟工作学习有关的事情， 如果想刷微博，看电视，那就换个地方，可以坐沙发上。 背后其实也是利用了我们心中对“特定空间”的假设，如果你在这个书桌上进行娱乐活动，那么这个书桌作为你心中假设的环境就会破坏掉。平常在一个特定的空间里只做这一件事情， 慢慢这个习惯会形成稳定的心理预期，会给自己一种强烈的心理暗示，从而帮助自己进行改变。 这促使了我对之前行为的理解，当自己上完班回家之后，本身意志力就消磨的七七八八了，再要用所剩无几的意志力抵抗娱乐去学习，自己的大脑肯定不干。周末在房子里大脑肯定也是怎么舒服怎么来。 我自己针对性的采取了以下几种方法： 最近下班回家之后，先休息一个小时左右，恢复一下意志力，再起来学习工作，感觉效率到提升了不少。 指定特定的桌子只用来办公和学习， 如果自己想刷微博或者刷剧， 不要在这张桌子上进行。 （还在努力实践中） 周末能去石景山图书馆就尽量不要在房子呆着。 以上就是自己最近关于如何促进改变的一些小方法，你还有哪些好用的方法，欢迎留言交流。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>心理</tag>
        <tag>方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何用数据说话]]></title>
    <url>%2F2019%2F07%2F29%2F%E6%96%B9%E6%B3%95-%E5%A6%82%E4%BD%95%E7%94%A8%E6%95%B0%E6%8D%AE%E8%AF%B4%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[如何用数据说话背景-冲突-疑问-回答 作为一名数据分析师， 经常要写很多的运营分析报告， 但我发现自己写完的分析报告交给领导看， 总是被领导指正说报告的说服力不够。经过这一段时间的磨练， 我也思考了如何才能增加报告的说服力。 一份运营分析报告， 看似简单，描述自己通过数据观察到的现象， 暴露公司运营中存在的问题， 但你揭露公司的问题， 同时也对相应的运营人员的结果的拷问， 人家肯定会质疑你报告的准确性， 如何才能让别人心服口服呢， 在最近的工作中，我总结出以下三点： 要用数据说话。 能用数据说明的，绝对不要用莫能两可的语言。 比如：本周活跃用户数比上周好。 这样的语言让人感觉很空洞， 就不如写成本周活跃用户较上周增长了20万用户， 增长表现良好。 要给出一个结论， 一定要有数据的支撑才行。 对复杂的数据口径进行说明。 不要以为运营人员能够能够很容易理解你的统计指标与口径， 要把他们当小白一样去对待才行。比如留存率是如何计算的， 有时你不必特意的去强调， 但是必要的标注还是得有。免得运营人员多次询问。 对数据进行多维比较，佐证结论。 有时你通过一个维度的数据比较很难将问题说明清楚，需要多维比较。 比如， 本周用户环比上周下降了20%， 那么这能说明本周比上周运营的差吗， 会不会存在月初月末周期的影响。如果要排除这些因素的话， 其实还需要求上月同时间段的环比数据。 如果上月同时间段用户比上周只下降了5%， 那证明可能不是时间的原因。 对于别人给出的原因你也需要数据验证。 有时我们发现某个数据下降，然后去问运营的负责人情况， 在他说完情况之后， 我们应该再根据他的情况进行数据验证， 而不是轻信别人，直接将这个原因写到报告中去。 报告要有结论和建议。 一份分析报告中， 最难的部分就是分析的结论和建议， 很多时候，我们只是简单的描述统计，而要做到逻辑和建议， 其实是一件很难的事情。 报告的内容和布局要有逻辑性。 首先，对于分析的内容， 要保证逻辑正确，避免给出引导运营错误的结论。 比如：一个用户的行为路径分析， 必须保证一个路径下转化率必须是同一个口径。 而不能与第二个目的进行对比。避免引导运营错误。 其次，报告的整体排版必须遵循一定的逻辑， 不能说用户行为，突然就跳到用户充值了。 最后， 把自己写好的分析报告给领导看下， 有时他们的建议能够弥补我们在思维视角上的缺陷， 更快的提高我们的分析撰写能力。 当然， 以上步骤只是我工作中的一点总结，仅供参考。每个公司，每个团队不一样， 要求的分析报告的侧重点不一样，但我们撰写分析报告的目的都是一样的：希望能够指出部门运营中的不足，说服运营人员进行迭代改进。 你还有哪些能够增加分析报告说服力的技巧， 欢迎一起分享交流。]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>报告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[培养数据敏感度]]></title>
    <url>%2F2019%2F07%2F01%2F%E6%8A%80%E8%83%BD-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%9F%B9%E5%85%BB%E6%95%B0%E6%8D%AE%E6%95%8F%E6%84%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[对于数据分析师来说，培养数据敏感度是需要长期经验积累的，更需要通过刻意练习来提高，那么有哪些好的方法呢，今天我们就来谈一谈。 熟记业务关键指标 一些日常运营的关键数据：日活、月活、消息推送每天的量、常用的口径，能够做到随问随答。这有利于自己迅速判断及反应，也能够让同事认为你对数据非常敏感，懂得用数据说话。 多去记录一些行业当中比较重要的指标，比如游戏行业，你能通过次日留存、7日留存等数据，迅速判断这个游戏属于哪一个评级。 多做报表，多画思维导图 通过日报、周报、月报的制作来加深自己对业务的理解，有时根据自己的业务需求有目的的创造一些报表。 多进行一些项目类型的业务分析，做报表之前将自己的思路利用思维导图整理下，做到逻辑清楚，结构紧凑。 强迫自己用数据说话 在平时的沟通中， 多引用相关数据去表达，能够非常有力的辅助你要表达的观点， 也会让人觉得你说话比较靠谱，增强说服力。 在日常的数据报告中， 多用数据说话，能才让别人信服。 多玩一些数据游戏 24点，根据一闪而过的汽车牌照玩24点 数独类APP游戏 学会质疑， 善于找茬 对于身边的新闻数据， 报道数据，学会质疑，养成独立思维的习惯。 看到一个业绩报告后，不断去问自己背后的更多的数字，考验自己或别人数据的广度。 多看财经类的新闻报道，当看到数据的时候可以通过搜索、查证、思考，逻辑判断等来证明这个数据是正确还是错误。 多做案例分析题 判断是否正确：iDATA公司业务员大数有24个客户，7月不重复客户购买率为78%。（注：不重复客户购买比例=有订单的客户总数/总客户数，重复购买的客户只算一次） 判断是否正确：我国城镇住房建设较快发展，人均住宅建筑面积升至26.11平方米，（北京市为32.68平方米）户均住宅建筑面积为82.2平方米。同时城镇住宅建筑面积达到历史最高的300.16亿平方米 判断是否正确：某学校200名学生全部参加了优秀学生干部的选举活动，最后大数同学以88.8%的投票支持率当选（注：共5名候选者，每位同学只能选择支持一位，候选者也可以参加投票） 填空：3 4 6 10 (?) 解答：要求将3，5，7，8 这4位数字组合，计算结果=24，并要求使用2种方法。 以上就是自己总结的培养数据敏感度的方法，你还有哪些好的建议，欢迎留言交流。]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据敏感度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[改版分析]]></title>
    <url>%2F2019%2F06%2F22%2F%E6%96%B9%E6%B3%95-%E6%94%B9%E7%89%88%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[频道改版分析1.分析目的 新频道的效果怎么样？ 2.分析方向 新频道整体改版效果分析。 新频道各部分细拆分析新频道各主要区域细拆，看各区域数据是上升还是下降。 新频道重点问题分析主要功能点流量入口修改后，流量如何分布。 3. 分析思路3.1 新版本整体改版效果分析 改版后，新频道是否受欢迎。衡量参数： 页面访问uv占比大盘 日均访问uv点击转化率 日均点击uv占比大盘 日均点击uv人均点击次数 次1日留存 次3日留存 次7日留存 说明: 频道访问uv占比大盘，数据提升，说明频道改版后，用户更喜欢访问此频道。（用户访问此频道后，并不一定会在频道内产生点击） 转化宽度： 日均访问uv点击转化率 = 频道内点击uv / 频道内访问uv，点击转化率提升，说明用户查看此频道后，频道内功能点改版后对访问此频道的用户更有吸引力。 日均点击uv占比大盘，数据提升，说明改版后吸引了更多的用户来进行点击。 转化深度：日均点击uv人均点击次数，数据提升，说明改版后，用户的点击频率也有所增加。 用户粘度：频道访问留存率提升， 说明改版后，此频道的用户粘性也在增加。 改版后，频道留存率上升原因分析主要为说明是某功能点使频道整体留存率上升。 公式： 频道留存率 = A用户数 A留存率 + 其他用户数 其他留存率 举例： 旧版次7日留存率 = 26.8%签到用户 46.7%留存率 + 73.2%其他用户 24.7%留存率 = 30.6% 新版次7日留存率 = 17.5%签到用户 48.8%留存率 + 82.5%其他用户 24.9留存率 = 29.1% 说明：新版本频道次7日留存率下降1.5，主要是由于9.3%的用户次7日留存率从46.7%下降到24.9% 3.2 新频道各坑位细拆分析 对频道中相同功能点进行新旧版本对比, 衡量参数： 各个坑位点击uv占比访问uv 各个坑位次7日留存率细拆 对1中数据差异较大坑位进行具体原因分析 对各模块坑位具体原因进行分析说明 3.3 对改版后的某主要功能点的流量结构变化进行分析 对新旧不同版本的流量结构进行梳理，找出主要流量入口变化，并进行说明。 用户究竟是如何使用产品新功能的，是否符合你预期设想的那样，还是说用户自己创造出了新的玩法 3.4 对产品流程转化率是否有提升 去观察整个产品的流程转化率是否因为产品迭代改版而有所提升。 查看转化漏斗，改变前后，流程的转化数据是否发生变化，每个小环节的漏斗转化率有什么变化]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>改版分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建业务运营指标]]></title>
    <url>%2F2019%2F05%2F12%2F%E6%96%B9%E6%B3%95-%E5%B8%B8%E7%94%A8%E6%8C%87%E6%A0%87%2F</url>
    <content type="text"><![CDATA[作为一名数据分析师，在工作中通常需要一些指标来衡量数据发展的好坏，毕竟，如果你不能衡量它，那么你就不能增长它。 那么数据分析中常见的指标都有哪些，如何在工作中制定业务指标呢，今天的文章来详细探讨一下。 指标划分的整体思路1. 明确公司目前的核心指标 这也是一级指标，用来指引公司的战略目标。 明确我们需要研究公司目前都有哪些业务， 这些业务在行业中有没有一些标准的指标？ 如大目标是营收， 那么更多的付费用户能带来营收，更长的生命周期能带来营收，更高的客单价能带来营收，将一级级指标分配个多个团队或多个时间段来执行。 2. 明确部门的核心指标 根据公司的一级指标进行拆解，明确公司各个部门的二级指标。 我们要根据具体的职责来确定指标。 比如销售部门， 则gmv,客单价，客复购率等，都是我们需要追踪的指标。 认知阶段，很多都是市场部、品牌部、渠道从部负责，那么这样指标有问题，你就知道找谁背锅了。 3. 明确到个人的核心指标 根据对部门二级指标的拆解，明确部门个人的三级指标. 比如某人负责推广，则推广的流量， 转化率则就需要进行追踪， 对于数据异常，则能够追踪到某个员工具体的行为。 4. 明确每个业务动作的指标 每一个业务动作都话一个方框，注明什么动作，再补充这个动作需要哪些指标，使业务和指标之间的关系明确。 5. 学会跨部门背指标 很多部门的指标比较单一，比如渠道部只负责拉点击，不负责注册，那么就需要通过指标的表现和系统性，考虑跨部门背指标，或者用权重的方式去解决，让领导去拍板。 6 . 指标追踪 通过日报、周报、月报的数据汇报，来说明业务运营的问题，促进公司业务更好的发展。 对具体运营指标进行拆解-AARRR模型获取用户 核心： 找到获客成本较低且用户质量较高的渠道，通过砸钱让产品在某渠道进行曝光，并将用户转化成产品用户 常见的指标： 安装用户数 激活用户数 一次会话用户数 新用户下载完APP， 仅打开过产品一次，且该次使用时长在2分钟以内。（避免机器刷单） CPM - 每千人成本 广告展示时就向广告主收费，以曝光为目的，不强调实际获客效果。 倾向于保护流量主利益。 CAC - 每点击成本 用户发生点击行为时向广告主收费。 CAC = 新增用户总投入 / 新增用户总数 CPA - 每行动成本 以后端收费为主，也就是用户看到广告并点击后，有进一步了解的欲望，完成某些特定行为， 如下载APP、预约报名或购买了产品。 倾向于保护广告主利益。 CPPC - 每付费用户的获取成本 CPS - 以实际销售额换算广告金额 类似销售提成 CPD - 每下载成本 CPT - 每时间段成本 例如： 这个位置一个星期多少钱 ROI - 投资回报率 ROI = 销售所得利润 / 广告成本 * 100% 提高用户活跃度 提高产品使用粘性，提升用户使用深度。 DNU - 日新增用户数 DAU - 日活跃用户数 WAU - 周活跃用户数量 MAU - 月活跃用户数 ACU - 平均同时在线用户数 PCU - 最高同时在线用户数 UV - 访问用户数 PV - 点击量 人均点击次数 = 访问量/ 点击量 CTR - 点击率 点击量 / 曝光量 TS - 用户平均在线时长 人均启动次数 N次操作占比 用户行为路径 用户访问频次 跳出率 用户打开网站的某个网页， 然后直接退出网站。跳出率是直接衡量网页（网站）对“新用户”吸引力的重要指标 例如： 100个人进入该页面，5个人直接从该页面离开该网站，则跳出率为5%。 退出率 从该页面离开网站的次数占该网页总浏览次数的比例。退出率则是综合衡量用户离开网站行为的重要指标（也可能满足需求了就离开了） 例如： 20个人从该页面离开网站，该页面的总浏览量为200次，则退出率为10%。 用户会话次数 用户在时间窗口的所有行为集合。 例如：用户打开APP， 搜索商品，浏览商品，下单并支付，最后退出，整个算一次会话。 会话时间，网页端用户超过30分钟再次操作，算第二次会话。 移动端的时间窗口为5分钟。 功能渗透率 功能使用用户数 占 总活跃用户数 新老访客占比：衡量网站的生命力 访客时间： 衡量内容质量 访客平均访问页数：衡量网站对访客的吸引力，访问深度 访客来源： 访客从哪里来 用户行为转化率 首页访客占比：衡量网页结构，对新用户导航是否友好 TGI ： [目标群体中具有某一特征的群体所占比例 / 总体中具有相同特征的群体所占比例] * 100例如，在15-24岁的人群中，有8.9%的人过去一年内服用过斯达舒，而在总体人群中，服用过斯达舒的人数比例为6.6%，则斯达舒在15-24岁人群中的TGI指数是134.9，这说明，斯达舒主要定位在15-24岁的人群中。TGI指数表征不同特征用户关注问题的差异情况，其中TGI指数等于100表示平均水平，高于100，代表该类用户对某类问题的关注程度高于整体水平 提高留存率 如何让用户不断的使用我们的产品， 减少用户的流失，提升用户的粘性。 次日留存率 次3日留存率 次7日留存率 30日留存率 回流率 用户在使用该App离开的N天/周/月之后，再次使用该App的比例 用户流失率 用户生命周期（周期/(1-周期内新增留存率)) 功能使用率 衡量产品功能是否受用户欢迎 用户忠诚指数 忠诚指数是对活跃留存的再量化。活跃仅是产品的使用与否，A用户和B用户都是天天打开App，但是B产生了消费，那么B比A更忠诚。 提高收入 pu 付费用户 CR 付费转化率 注册用户到付费用户的转化率 ARPU 平均每用户收入 ARPPU 平均每付费用户收入 APA 活跃付费用户 PUR 用户付费率 APA / AU LTV 生命周期价值 如果我们获取到1万个用户需要花10万元，那么，如果这1万个用户从安装到卸载能够给公司带来大于10万元的收益，则这个产品就是可盈利的。 PBP 回收期 当我们预测到产品是可盈利的之后，所付出的成本需要多久才能收回，产品才能开始真正地盈利，这个时间就是回收期PBP，为了保证公司资金链不出问题，一般认为PBP能够在一年以内是最好的。 GMV 网站成交金额 拍下订单的总金额，包含付款和未付款两部分 支付uv 支付pv 访购率 人均订单数 客单价 总收入/订单数 复购率 单位时间内，消费两次以上的用户数占购买总用户数 退货率 消费次数 消费频率 订单量 购买间隔 APPU 每个用户的平均利润 用户推荐 通过提升产品的竞争力， 使用户给其他人推荐此产品。 分享率 分享次数 K因子 即每一个用户能够带来几个新用户 病毒传播周期 假设1000位种子用户在10天邀请了1500位用户，那么传播周期为10天，K因子为1.5。 NPS净推荐值 计量某个客户将会向其他人推荐某个企业或服务可能性的指数 净推荐值(NPS)=(推荐者数/总样本数)×100%-(贬损者数/总样本数)×100% 其他缩写 PP —— 英文percent point的简称，意思为百分比 UGC —— 用户原创内容 SEO —— 搜索引擎优化 CR —— 转化率 ： 衡量转化环节的好坏 visit —— 用户访问次数 ： 用户来到网站-关闭网站页面 Landing Page —— 着陆页 ： 用户从外部链接直接跳转到的第一个页面 Bounce Rate —— 跳出率 ： 用户来到网站，没有做任何行为就指标离开网站。 Referrer —— 引荐流量 PR —— 公众关系， 组织机构与公众环境之间的沟通与传播关系。 参考资料： 学习数据分析，从了解方法论开始万字干货总结：最全的运营数据指标解读]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>常用指标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive 进阶查询]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%8A%80%E8%83%BD-Hive%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Hive查询性能优化-避免数据倾斜 数据倾斜：当我们在Hive上进行查询时，因为数据的分散度不够， 导致大量数据集中在一台或者几台服务器上， 导致数据的计算速度远远低于平均计算速度， 计算过程特别耗时。 数据倾斜的表现：任务进度长时间维持在99%，查看任务监控页面，发现只有少量子任务未完成。 如何避免数据倾斜 sql优化与业务逻辑优化 方法1： 在查询中， 避免使用 select *, 使用条件限制取需要的列。 方法2： 当数据量特别大时，用 group by 代替 count(distinct) count(distinct ),在数据量特别大的情况下，效率较低, 可以用先 group by 再 count 的方式进行代替。 因为count(distinct)是按group by 字段分组，按distinct字段排序 123456789select hit_date, count(distinct user_account) as uvfromwhere hit_date between '2018-10-01' and '2018-10-02'group by hit_date 可以转换成： 123456789101112131415select hit_date, count(user_account) as uvfrom(select hit_date, user_accountfrom computer_view.datawhere hit_date between '2018-10-01' and '2018-10-02'group by hit_date, user_account) agroup by hit_date 方法3：join 优化 在使用 Join 进行外关联时， 将副表的过滤条件写在 where 后面，会先全表关联， 再进行过滤， 这样会耗费资源。 123456SELECT a.price_close, b.price_closeFROM b JOIN a ON b.ymd = a.ymd AND b.symbol = a.symbolWHERE s.symbol = 'APPLE' 正确的写法是将 where 条件写在 on 后面 1234SELECT a.price_close, b.price_closeFROM b JOIN a ON ( b.ymd = a.ymd AND b.symbol = a.symbol and s.symbol = 'APPLE') 方法4： 避免 union all 子查询中使用 group by 【替换 count(distinct) 除外】、count(distinct)、max、min等。 123456789101112131415161718192021222324252627with a1 as ( select user_account, hit_date from data where hit_date between '2018-12-01' and '2018-12-13' and nbtn_name like "%支付宝%" union all select user_account, hit_date from data where hit_date between '2018-12-01' and '2018-12-13' and nbtn_name like "%支付宝%")select hit_date, count(user_account) as pvfrom a1group by hit_date 方法5： 避免不同数据类型进行关联 使用CAST函数对数据类型进行转换，语法为cast(value AS TYPE)123456789select a.price_close, b.price_closefrom a join b on a.user_id = cast(b.user_id as string)where hit_date between &apos;2018-11-01&apos; and &apos;2018-11-02&apos; and a.symbol = &apos;apple&apos; 方法6： 无效ID在关联时的数据倾斜问题 把空值的 key 变成一个字符串加上随机数，就能把倾斜的数据分到不同的 reduce 上 ,解决数据倾斜问题。 需要用到Case When … Else…End语法 写法1： 123456789101112131415Select *From a Join bOn a.user_id is not nullAnd a.user_id = b.user_idUnion allSelect * from awhere a.user_id is null 写法2： 1234567891011Select *From a left out Join bOn Case when a.user_id is null then concat(‘dp_hive’,rand() ) else a.user_id = b.user_id end; Hive的查询注意事项以及优化总结： 尽量尽早过滤数据，减少每个阶段的数据量。对于分区表要加分区，同时只选择需要使用到的字段 对历史库的计算经验 尽量原子化操作，尽量避免一个SQL包含复杂逻辑，可以使用中间表来完成复杂的逻辑 join操作 小表要注意放在join的左边，否则会引起磁盘和内存的大量消耗 如果union all的部分个数大于2，或者每个union部分数据量大，应该拆成多个insert into语句，实际测试过程中，执行时间能提升50% 本质是让服务器尽量少做事情，走最优的路径，以资源消耗最少为目标 参考资料： https://blog.csdn.net/yu0_zhang0/article/details/81776459 https://blog.csdn.net/young_0609/article/details/84593316 https://blog.csdn.net/qq_29232943/article/details/79644614 http://lxw1234.com/archives/2015/06/317.htm https://zenoh.iteye.com/blog/1748592 http://www.lwyyyyyy.cn/getArticleDetailInfo?articleId=89 rlike 与 like 如何区分 like : 常用通配符：% 、_ 、escape 12345% : 匹配0个或任意多个字符_ : 匹配任意一个字符escape ： 转义字符，可匹配%和_。如SELECT * FROM table_name WHERE column_name LIKE &apos;/%/_%_&apos; ESCAPE&apos;/&apos; rlike和REGEXP : 常用通配符：. 、* 、 [] 、 ^ 、 $ 、{n} 1234567891011. : 匹配任意单个字符* ： 匹配0个或多个前一个得到的字符[] : 匹配任意一个[]内的字符，[ab]*可匹配空串、a、b、或者由任意个a和b组成的字符串。^ : 匹配开头，如^s匹配以s或者S开头的字符串。$ : 匹配结尾，如s$匹配以s结尾的字符串。&#123;n&#125; : 匹配前一个字符反复n次。 注意事项： like是完全匹配。rlike和regexp是不完全匹配，只要不同时匹配^和 $， 其他的包含即可。如 ^ba可以匹配baaa和baab，a也可以匹配baaa和baab，但是^bab$不能匹配baab。 求两组数据的交集， 并集， 差集并集-union 与 union allunion 与 union all 的不同： union, 结果包含所有行， 并删除重复行 unoin all, 结果包含所有行， 但不删除重复行 写法1：12345678910111213141516171819202122232425use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" union select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1-- 点击支付宝或者手淘活动的人数总共有 435499 人 写法2：123456789101112131415161718192021222324use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" union all select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 -- 点击支付宝或者手淘活动的次数为 665935 交集-instersect写法1：123456789101112131415161718192021222324use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" intersect select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1-- 点击支付宝又点击手淘活动的人数为 66174 差集-except写法1：1234567891011121314151617181920212223use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%支付宝%" except select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 写法2：1234567891011121314151617181920212223242526272829use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%支付宝%"),a2 as ( select user_account from data where hit_date between '2018-12-20' and '2018-12-25' and nbtn_name like "%支付宝%")select count(distinct a1.user_account) as pvfrom a1 left outer join a2 on a1.user_account = a2.user_account and a2.user_account is null -- 只参加支付宝活动， 没有参加手淘活动的人数为 369325--在求差集时， 需要注意前后顺序， 否则会出现逻辑错误-- 可以发现， 差集 + 交集 =并集， 369325 + 66174 = 435499 写法3： 1234567891011121314151617181920212223242526272829303132333435--详细列出差集的版本号with a1 as(select distinct two as user_accountfrom test.data_csvexcept (select distinct user_accountfrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-03' union all select distinct user_accountfrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-03'))select a2.six , COUNT(a2.two) as uv, count(a1.user_account) as uv_1froma1, test.data_csv as a2WHERE a1.user_account = a2.twogroup by a2.sixlimit 100 业务问题计算留存率方法1： 一次性求次1日，次3日， 次7日留存 12345678910111213141516171819202122232425262728with a1 as (select hit_date, user_accountfrom computer_view.datawhere hit_date between '2019-04-25' and '2019-05-13' and btn_information is not null),a2 as (select hit_date, user_accountfrom computer_view.datawhere hit_date between '2019-04-25' and '2019-05-13' and btn_information is not null)select a1.hit_date,count(distinct a1.user_account) uv,count(distinct case when datediff(a2.hit_date, a1.hit_date) = 1 then a1.user_account else null end ) next_day,count(distinct case when datediff(a2.hit_date, a1.hit_date) = 3 then a1.user_account else null end ) three_day,count(distinct case when datediff(a2.hit_date, a1.hit_date) = 7 then a1.user_account else null end ) seven_dayfrom a1 join a2 on a1.user_account = a2.user_accountgroup by a1.hit_dateorder by a1.hit_datelimit 100 方法2： 步骤1：统计每天的uv 123456789101112-- 统计10-15号每天uvSELECT hit_date, count(distinct user_account) as uvFROM computer_view.dataWHERE hit_date between '2018-11-10' and '2018-11-15'group BY hit_dateorder BY hit_date 步骤2：使用date_add 函数， 一次性求出10-15号每一天的次1、3、7日留存123456789101112131415161718192021222324252627282930-- 统计10-15号每天的次日留存数， 统计次3、7日留存只需将1换为3、7with a1 as ( select user_account, hit_date from computer_view.data where hit_date between '2018-11-10' and '2018-11-15'),a2 as ( select user_account, hit_date from computer_view.data where hit_date between '2018-11-10' and '2018-11-25')select a1.hit_date, count(distinct a1.user_account) as uvfrom a1 join a2 on a1.user_account = a2.user_accountWHERE a2.hit_date = date_add(a1.hit_date, 1) group by a1.hit_dateorder BY a1.hit_date 步骤3： 算出留存率 方法3： (迷神) 123456789101112131415161718192021222324252627-- 留存sql优化select count(1)from( select userid, count(1) from( select t1.userid, t1.statdate from table1 t1 where t1.statdate = $&#123;上30天日期&#125; and t1.statdate &lt;= $&#123;上一天日期&#125; group by t1.userid, t1.statdate ) s1 group by userid having count(1) 2 ) R1--此sql为一个样例，计算连续跟任意都适用，至于计算第N天，只需要更改下日期过滤条件，变成=$[上N天日期]，=$&#123;上一天日期&#125;。 --另外，这种方式适合跑当前周期数据，如果跑历史数据，可以写个循环。当然，最暴力还是直接用userid 关联。--这种写法，更多是针对现在大部分分布式处理平台的特性，尽可能将数据合理均匀分片，每台服务器各自运算自己的，最后汇总。 尽可能少用 count distinct 这种写法，因为无法利用分片的特性。 方法4： 计算月留存率的简单方法 12345678910111213141516171819202122232425with a1 as ( select user_account, count(distinct month(hit_date)) as c from data_an where hit_date between &apos;2019-01-01&apos; and &apos;2019-02-31&apos; group by user_account having c = 2 union select user_account, count(distinct month(hit_date)) as c from data_ios where hit_date between &apos;2019-01-01&apos; and &apos;2019-02-31&apos; group by user_account having c = 2) 计算上一步需求1： 求点击【确认充值】按钮的上一步点击的名称 1234567891011121314151617181920212223242526use default;with a as (select user_account, btn_name, lag(btn_name, 1) over (partition by user_account order by create_timestamp) as previous_btn_namefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-01' and btn_name is not nullhaving btn_name like '确认支付')select previous_btn_name, count(distinct user_account) as cfrom agroup by previous_btn_nameorder by c desclimit 1000 需求2：上一步点击的名称我已经知道了， 现在要想 之前通过上一步点击这些条件之后， 再点击【确认支付】按钮的 去重uv 123456789101112131415161718192021222324252627282930use default;with a as (select user_account, btn_name, lag(btn_name, 1) over (partition by user_account order by create_timestamp) as previous_btn_namefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-01' and btn_name is not nullhaving btn_name like '确认支付')select count(distinct user_account) as cfrom awhere (previous_btn_name like "%10元%" or previous_btn_name like "%30元%" or previous_btn_name like "%50元%" or previous_btn_name like "%10元%" or previous_btn_name like "%30元%" or previous_btn_name like "%50元%" or previous_btn_name like "%100元%" or previous_btn_name like "%200元%" or previous_btn_name like "%300元%" )-- 125752 创建临时表12345678910111213141516use default;create table test.nine_android_user_version_10select user_account, app_versionfrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-30' and user_account is not null and app_version is not nullgroup by user_account, app_version 原始日志中取数12345678910111213141516use default;create table test.nine_user_version_10select url_par(url_query,'account') as user_account, split(url_par(url_query,'AppID'),' ')[1] as app_versionfrom apache_log.client_ios_sensorwhere dt between '2018-10-01' and '2018-10-20' and url_par(url_query,'account') is not null and url_par(url_query,'AppID') is not nullgroup by url_par(url_query,'account'), split(url_par(url_query,'AppID'),' ')[1] 取 pv &gt; 3 的用户量12345678910111213141516171819202122232425262728293031with a1 as (SELECTuser_accountFROMcomputer_view.dataWHEREnbtn_name is not null andhit_date between '&#123;&#125;' and '&#123;&#125;'union all SELECTuser_accountFROMcomputer_view.dataWHEREnbtn_name is not null andhit_date between '&#123;&#125;' and '&#123;&#125;'),a2 as (SELECT user_account,count(user_account) as pvfrom a1group by user_accounthavingcount(user_account) &gt; 3)SELECT count(distinct user_account) as uvfrom a2 求连续4个月活跃的用户数需求1：1月活跃的用户数， 在2月、3月、4月一直活跃的用户有多少？ 12345678910111213141516171819with a1 as(select user_account , month(hit_date) as monthfrom compu_view.ios_log_viewwhere hit_date between '2019-01-01' and '2019-04-30'group by user_account, month(hit_date) ),a2 as ( select user_account,a1.month, row_number() over(partition by user_account order by a1.month) as pxfrom a1) select count(distinct user_account) as uvfrom a2where a2.px = 4 常用函数 聚合函数 函数名 定义 count() 个数统计函数 count(distinct ) 统计去重之后的个数 sum() 求和 sum(distinct ) 去重之后的和 avg() 平均值 avg(distinct) 去重之后的平均值 min() 最小值 max() 最大值 corr(A, B) 相关系数 var_pop() 方差 var_samp() 样本方差 stddev_pop() 标准偏差 stddev_samp() 标准样本偏差 covar_pop(A, B) 协方差 covar_samp(A, B) 样本协方差 RAND() 随机数 时间函数 函数名 定义 语句 NOW ( ) 当前时间 select now() extract() 抽取具体的年、月、日 date() 返回时间的日期部分 year() 返回时间的年份 month() 返回时间的月份 day() 返回日期的天 hour() 返回时间的小时 minute() 返回时间的分钟 second() 返回时间的秒 week () 第几周 dayofweek() 返回星期几，1为星期天 dayofyear() 一年中的第几天 sec_to_time ( ) 秒数转成时间 dateadd() 时间相加 date_add(dt,interval 1 day ) date_sub() 时间相减 datediff() 时间的差值 date_format() 输出指定时间格式 date_format(hit_date, “%Y-%m-%d) datename() 返回日期部分的参数 datepart() 返回日期、时间的单独部分 窗口函数 函数名 定义 rank() 排名相等的会留下空位 dense_rank() 排名相等的不会留下空位 row_number() 排名不管数据是否相等 lag() 访问相同结果集的先前行中的数据 lead() 访问相同结果集的后续行中的数据 first_value() 返回组中数据窗口的第一个值 last_value() 返回组中数据窗口的最后一个值 if() 条件判断函数 case…when…else…end 判断各个元素是否满足了某种条件的集合 over() 与聚合函数sum(), count(), avg()等结合使用， 实现分组聚合的功能 split() hive字符串分割函数 intersect 交集 except 差集 union all 并集 round 把数值字段舍入为指定的小数位数 difference 衡量两个值之间的差异 coalesce 1、将控制替换成其他值；2、返回第一个非空值 pivot 行转换列 over 函数详解 语法： over(partition by ….) 作用： 与聚合函数sum(), count(), avg()等结合使用， 实现分组聚合的功能 123456789# 根据日期 和 mac_id 进行分组求每组的数量和， 并按日期排序select hit_date, mac_id, mac_color, day_num, sum(day_num) over(partition by hit_date, mac_id order by hit_date) as sum_numfrom test.datas hit_date mac_id mac_color day_num sum_num 20171011 1292 金色 11 89 20171011 1292 黑色 19 89 20171011 1292 粉金 58 89 20171011 1292 金色 1 89 20171011 2013 金色 9 22 20171011 2013 金色 3 22 20171012 1292 金色 5 18 20171012 1292 粉金 1 18 20171012 2013 粉金 1 7 20171012 2013 金色 6 7 20171013 1292 黑色 1 1 20171013 2013 粉金 2 2 123456789101112# group by 语句select hit_date, mac_id, sum(day_num) from test.datagroup by hit_date, mac_idorder by hit_date day_id mac_id sum_num 20171011 124609 1 20171011 20130 22 20171011 12922 89 20171012 12922 18 20171012 20130 7 20171013 12922 1 20171013 20130 2 over(partition by) 与 group by 的区别： grou by 字段只能显示与分组聚合相关的字段， 而 over(partition by) 可以显示所有字段 LAG 和 LEAD 函数详解 语法： LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值; LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值 123456789101112131415161718192021# 计算11月1-10号， 不同日期同一用户登陆客户端 pv 量对比with a1 as (select user_account, count(user_account) as pv, hit_datefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-10'group by user_account, hit_date)select user_account, a1.hit_date, a1.pv, lag(a1.pv, 1) over (partition by user_account order by user_account, a1.hit_date) as pv1, lead(a1.pv, 1) over(partition by user_account order by user_account, a1.hit_date) as pv2from a1limit 100 first_value() 和 last_value() 函数详解 first_value() ：比较每个用户浏览次数与第一天浏览次数进行比较，查询返回当前浏览次数以及第一天浏览次数 last_value() ： 比较每个用户浏览次数与最新一天浏览次数进行比较，查询返回当前浏览次数以及最新一天浏览次数 12345678910111213141516171819with a1 as (select distinct user_account, count(user_account) as pv, hit_datefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-10'group by user_account, hit_date)select distinct user_account, a1.hit_date, a1.pv, first_value(a1.pv) over (partition by user_account order by user_account, a1.hit_date) as pv1, last_value(a1.pv) over(partition by user_account order by user_account, a1.hit_date) as pv2from a1limit 100 rank、dense_rank、 row_number 排序函数详解 rank函数， 返回数据项在分组中的排名， 排名相等的会留下空位， 如1、2、2、4 dense_rank函数， 返回数据项在分组中的排名， 排名相等的不会留下空位， 如1、2、2、3 row_number函数， 返回数据项在分组中的排名， 排名不管数据是否相等， 如1、2、3、4 row_number函数说明 1234567select a, row_number() over(order by b) row_number, rank() over(order by b) rank, dense_rank() over(order by b) dense_rank from lijie.test_rank a row_number rank dense_rank A 1 1 1 C 2 2 2 D 3 3 3 B 4 3 3 E 5 5 4 F 6 6 5 G 7 7 6 if 函数 12345678910select city, count(distinct user_account) as uv from an_log_viewwhere hit_date = &apos;2019-06-10&apos;group by cityhavingcount(if( nbtn_name like &quot;发现&quot;, 1, null)) = 20 123456789select city,count(1),count(if( nbtn_name like &quot;发现&quot;, 1, null)),count(if(nbtn_name like &quot;发现&quot;， 1， null)) / count(1)froma1group by city lateral view 函数 lateral view 用于和 split、explode、collect_set 函数 等一起使用， 能够将一行数据拆成多行数据，在此基础上对拆分后的数据进行聚合。 需求1： 将 表 table 中的 adid_list 转换为单独的行。 12345SELECT pageid, adidFROM tablelateral view explode(adid_list) adTable as adid 表-table： pageid adid_list front_page [1,2,3] contact_page [3,4] 输出结果为： pageid adid_list front_page 1 front_page 2 front_page 3 contact_page 3 contact_page 4 需求2： 计算特定广告的展现次数 1234567SELECT adid, count(1)FROM tablelateral view explode(adid_list) adTable as adidGROUP BY adid 输出结果为： adid count(1) 1 1 2 1 3 2 4 1 需求3： 多个 lateral view 查询 123456SELECT myCol1, myCol2FROM baseTableLATERAL VIEW explode(col1) myTable1 AS myCol1LATERAL VIEW explode(col2) myTable2 AS myCol2 表： table2 array col2 [1,2] [“a”，”b”] [3,4] [“c”, “d”] 输出结果为： myCol1 myCol2 1 “a” 1 “b” 2 “a” 2 “b” 3 “c” 3 “d” 4 “c” 4 “d” 字符串函数 函数名 定义 concat() 拼接字符串 length() 计算字符串的长度，一个汉字算三个字符 instr (A ,B ) 返回字符B首次在A中出现的位置,不存在返回0 lcase() 转换成小写 left(string2 ,length ) 从string2中的左边起取length个字符 lower() 将字串转化为小写 upper() 将字符转化为大写 replace() 替换字符 substr() 返回字符串A从start位置开始，长度为len的字符串 substring() 截取字符串 substring_index() 通过截取获取不同索引位的字符 LTRIM (string2 ) 去除前端空格 RTRIM (string2 ) 去除后端空格 字符串截取函数：substr,substring, substring_index 语法: substr(string A, int start, int len),substring(string A, int start, int len) 返回值: string 说明：返回字符串A从start位置开始，长度为len的字符串 举例1： 12345678910use computer_view;select substring(charge_products,2,30)from datawhere hit_date between '2018-10-01' and '2018-10-05'group by charge_productslimit 15 举例2：1234567891011121314select substring(a2.charge_products,2,80), a1.namefrom lookup.products_lookup as a1 join computer_view.data as a2 on a1.product = substring(a2.charge_products,2,80)where hit_date between '2018-10-07' and '2018-10-13' and mall_events is not nullgroup by substring(a2.charge_products,2,80), a1.name 举例3： 123456789101112131415--打断selectsubstring_index(page_url, '?', 1),count(distinct user_tracking_id) as uv,count(page_url) as pv from computer_viewwherehit_date between '2019-04-09' and '2019-04-09' and campaign like "%scjh-scep-tcnr-9yuanka%"group by substring_index(page_url, '?', 1)order by uv DESC CASE 表达式case when 的用法123456789101112131415161718192021222324selectcase when phone_province like &apos;ah&apos; then &apos;安徽&apos; when phone_province like &apos;fj&apos; then &apos;福建&apos; when phone_province like &apos;gd&apos; then &apos;广东&apos; else &apos;m&apos; end as phone_province , count(distinct user_account) uv,count(page_name) pvfrom client_android_logwhere hit_date between &apos;&#123;&#125;&apos; and &apos;&#123;&#125;&apos;and page_name like &apos;%Kefujh%&apos;group by case when phone_province like &apos;ah&apos; then &apos;安徽&apos; when phone_province like &apos;fj&apos; then &apos;福建&apos; when phone_province like &apos;gd&apos; then &apos;广东&apos; else &apos;m&apos; end order by case when phone_province like &apos;ah&apos; then &apos;安徽&apos; when phone_province like &apos;fj&apos; then &apos;福建&apos; when phone_province like &apos;gd&apos; then &apos;广东&apos; else &apos;m&apos; end limit 1000 ALTER TABLE 语句123--清楚表中数据,删除掉指定分区ALTER TABLE shphonefeature DROP IF EXISTS PARTITION(year = 2015, month = 10, day = 1);---lter table test.mon_mau_list drop partition (hit_mon = '&#123;0&#125;') 对用户进行标注1234567891011121314151617181920212223242526272829303132333435with a1 as(select hit_date, user_account, hit_mon, first_loginfrom test.day_dauwhere hit_date between &apos;&#123;0&#125;-01&apos; and &apos;&#123;0&#125;-31&apos;),a2 as(select user_accountfrom test.mon_new_userwhere hit_mon = &apos;&#123;0&#125;&apos;),a3 as(select a1.hit_date, a1.user_account, a1.hit_mon, a1.first_login, a2.user_account as if_newfrom a1 left join a2 on a1.user_account = a2.user_account)insert into table test.dau_ifnewselect user_account, (case when if_new is not null and hit_date = first_login then &apos;new&apos; else &apos;old&apos; end) as user_label, hit_date, hit_monfrom a3]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[营销活动分析]]></title>
    <url>%2F2019%2F04%2F22%2F%E6%96%B9%E6%B3%95-%E8%90%A5%E9%94%80%E6%B4%BB%E5%8A%A8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[营销活动分析营销活动分析介绍互联网公司经常会做一些运营活动，比如比如当当网的限时优惠活动，春节期间支付宝的集五福活动等。这些活动花费了公司大量的人力与财力， 那么活动的效果该如何评估呢？这就需要用数据来说话。 数据分析在营销活动中的任务，不仅是在活动后对数据进行分析， 更要在活动前、活动中、活动后三个方面来都进行跟踪。 活动前期： 目的 和运营人员商定好本次活动的目标，这次活动主要是为了：拉新、促活还是品牌推广，没有目标的活动不是好的运营活动。 埋点 和运营人员商定好这次活动都需要了解哪些数据，针对需要采集的页面位置，写好埋点方案：字段名、埋点位置、上报方式 和研发人员沟通埋点方案，数据埋点完成后，测试采集数据是否准确， 避免采集数据有误。 搭建指标体系 写出这次活动自己都需要哪些指标，如何计算， 提前搭建好指标体系 提前订好这次活动自己需要输出哪些数据，用什么形式来进行展现， 定好数据的输出格式。 活动中期 观察活动前3天的数据 观察活动第1天的数据， 详细查看各指标体系的报表数据是否有异常，对于发现的问题做到及时修改。 观察1-3天的数据趋势， 预估活动目标的完成度， 考虑活动目标是否需要调整。 活动数据及时数据 定时输出活动战报，及时发现数据异常波动， 让运营人员和项目领导知道数据的实时动态。 对于长期活动，第一周后需要进行一次复盘，将结论同步给管理层， 让更高视野的人给建议。 活动后期 活动的效果 短期效果活动对大盘的影响 参与活动uv 打开APP， 首次进入活动uv 大盘的日环比、周同比 新增用户拉动低活跃用户重新活跃数目标完成度品牌传播指数 长期效果 新增用户留存率低活用户留存率 活动优化 活动主漏斗数据转化率 活动功能模块渗透率 用户反馈 活动报告 在活动结束1-2周内输出，要有时效性。 活动与活动之前的数据对比更能说明问题 思考每次活动的本质和意义。 敢于暴露问题， 把已知的事实告诉上级，邮件同步给运营负责人 涉及到钱的问题， 需要让业务方给， 邮件说明情况，钱问题比较敏感。 案例分析支付宝集五福活动 带来新增用户，提升用户的活跃度，品牌传播量 在活动开始之前应该确定一个重点提升的核心数据。 这样的数据包括新用户注册、用户活跃度、用户付费转化、产品交易额、品牌知名度（百度指数、新浪指数等）等等。 非商品交易类的互动性活动，需要关注： 产品核心数据（日活、新用户) 的提升效果。 专题页面的uv、pv, 活动产生的用户互动量和人均互动次数、分享次数 老用户和新用户的互动比例 交易类产品的促销活动： 互动为平台带来的总交易额、购买人数、人均客单价（关键指标） 活动页面商品的 uv、pv、进入活动页面的人数占比（活动吸引力） 浏览-加入购物车-下单的转化率，分析潜在用户流失原因。 优惠券核销量/ 优惠券发放量 不同渠道用户的付费比例，单价，留存]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>活动分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive 基础查询]]></title>
    <url>%2F2019%2F04%2F18%2F%E6%8A%80%E8%83%BD-Hive%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[什么是 HiveHive 是一种建立在Hadoop系统上的数据仓库架构, 并对存储的数据进行分析和管理，这样就使得数据开发和分析人员很方便的使用 SQL 来完成海量数据的统计和分析。 Hive 擅长的是非实时的、离线的、对响应及时性要求不高的海量数据批量计算，统计分析。 Hive 不适用于在线交易处理 Hive 的常见查询语句 Hive 中的 SELECT 基础语法和标准 SQL 语法基本一致，支持 WHERE、DISTINCT、GROUP BY、ORDER BY、HAVING、LIMIT、子查询等 Hive 脚本如何注释可以用 - - 开头的字符串来表示注释， 也可以将需要注释的 sql 选中， 然后用 ctrl + ? 快捷键来进行注释。 切换数据库 1use android; 123# 查看当前数据库select current_database() 12# 重置默认数据库use default; 查看表 查看当前使用的数据库中有哪些表 1show tables; 查看非当前使用的数据库中有哪些表 1show tables in myhive; 查看数据库中以 android 开头的表 12use android;show tables like 'android*' 查看表的详细信息 1desc formatted android select…from 语句 基本查询 12# 查询 employee 表中的 name 和 salary。select name, salary from employee; 加入表中一列含有多个元素， 我们可以只查找此列的第一个元素 1select name, subord[0] from employees; 使用键值进行索引 1234567select name, deductions["state taxes"] from employees;# 可以使用 "点" 符号， 类似：表的别名 . 列名 这样的用法select name, address.city from employees; 使用列值进行计算 1234567select upper(name), salary, deductions["Federal Taxes"], rount(salary * (1 - salary, deductions["Federal Taxes"]))from employees;# ZHANGYU 100000.0 0.2 80000 使用正则表达式 12345# 选出所有列名以 price 作为前缀的列select 'price.*' from stocks; 常用的关系运算 12345678910111213 等值比较: = 等值比较:&lt;=&gt; 不等值比较: &lt;&gt;和!= 小于比较: &lt;小于等于比较: &lt;= 大于比较: &gt; 大于等于比较: &gt;= 区间比较 空值判断: IS NULL 非空判断: IS NOT NULL LIKE比较: LIKE JAVA的LIKE操作: RLIKE REGEXP操作: REGEXP 数学运算 123456789加法操作: +减法操作: –乘法操作: *除法操作: /取余操作: %与操作: &amp;或操作: |异或操作: ^取反操作: ~ 常用的聚合函数 1234567891011121314151617count(*) # 个数统计函数count(distinct col) # 统计去重之后的个数sum(col) # 求和sum(distinct col) #去重之后的和avg(col) # 平均值avg(distinct col) # 去重之后的平均值min(col) # 最小值max(col) # 最大值corr(col1, col2) # 相关系数var_pop(clo) # 方差var_samp(col) # 样本方差stddev_pop(col) # 标准偏差stddev_samp(col) # 标准样本偏差covar_pop(col1, col2) # 协方差covar_samp(col1, col2) # 样本协方差select count(distinct account), avg(salary) form employees; 使用别名 1234select count(distinct acount) as uv from employees; 使用limit语句限制返回的行数 123456# 只显示 10 行select count(distinct account) as uvform employees limit 10; 嵌套 select 语句 12345678910select e.name, e.salaryfrom( select upper(name) from employees) as ewhere e.salary &gt; 500; case…when..then句式 123456select name , salary, case when salary &lt; 5000 then 'low' when salary &gt; = 5000 and salary &lt; 70000 then 'middle' else 'high' end as bracket from employees; where 语句, 添加条件 常见用法 1select * from employees where country = 'us' and state = 'ca'; 可以在where条件下计算 12345678select name , salary, deductions['first taxes'], salary * (1-deductions['first taxes'])from employeeswhere round(salary * (1-deductions['first taxes']) ) &gt; 70000;# zhangyu 100000.0 0.2 80000 对上式进行优化 1234567891011select e.* from ( select name , salary, deductions['first taxes'], salary * (1-deductions['first taxes']) from employees ) ewhere round(salary * (1-deductions['first taxes']) ) &gt; 70000; 条件中有浮点数 12345678# 对浮点数进行比较select name, salary, duductions['first taxes']from employees where duductions['first taxes'] &gt; 0.2; --出现的结果中会有 0.2， 因为 DOUBL 和 FLOAT 类型不同 1234567select name, salary, duductions['first taxes']from employees where duductions['first taxes'] &gt; cast (0.2 as float); --&gt; 出现的结果中不会有0.2 like 和 rlike rlike 子句是Hive功能的一个扩展， 可以通过Java的正则表达式来指定匹配条件 12345678select name, address.streetfrom employees where address.street rlikt '.*(beijing|shanghai).*';# 用likeselect name, address from employeeswhere address.street like '%beijing%' or address.street like '%shanghai%'; group by 语句, order by, 与 having 分类并排序 12345678910select year(ymd), avg(price_close) from stockswhere exchange = 'nasdaq' and symbol = 'aapl'group by year(ymd)order by year(ymd) desc; having 子句来限制输出结果 123456789# 例子1select year(ymd), avg(price_close) from stockswhere exchange = 'nasdaq' and symbol = 'aapl'group by year(ymd)having avg(price_close) &gt; 50.0 ; 123456789# 例子2select col1from t1group by col1having sum(col2) &gt; 10 123456789101112131415# 如果没有having， 将要使用嵌套select子查询# 例子1select s2.year, s2.avg from( select year(ymd) as year, avg(price_close) as avg from stocks where exchange = 'nasdaq' and symbol = 'aapl' group by year(ymd)) s2where s2.avg &gt; 50.0 12345678910111213# 例子2select col1 from (select col1, sum(col2) as col2sum from t1 group by col1 ) as t2where t2.col2sum &gt; 10 having 与 where 的区别 Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。 Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。 123456789# 查找平均工资大于3000的部门select deparment, avg(salary) as average from salary_info group by deparment having average &gt; 3000 123456789#查询每个部门工资大于3000的员工个数select deparment, count(*) as c from salary_info where salary &gt; 3000 group by deparment join 语句 Hive中Join的关联键必须在ON ()中指定，不能在Where中指定,ON 子句指定了两个表间数据进行连接的条件。 内连接 只有进行连接的两个表中都存在与连接标准相匹配的数据才会被保留下来。 123456SELECT a.ymd, a.price_close, b.price_closeFROM a JOIN b ON a.ymd = b.ymdWHERE a.symbol = 'Apple' and b.symbol = 'Ibm' 对于多张表进行连接查询 12345678---为什么条件内不加表 b 和表 c 进行连接操作， 因为 Hive总是按照从左到右的顺序来执行SELECT a.ymd, a.price_close, b.price_close, c.price_closeFROM a JOIN b ON a.ymd = b.ymd JOIN c ON a.ymd = c.ymdWHERE a. symbol = 'Apple' AND b.symbol = 'Ibm' AND c.symbol = 'Google' Join 优化 Hive 会假定查询中最后一个表是最大的表， 在对每行记录进行连续操作时， 它会尝试将其他表缓存起来，然后扫描最后那个表进行计算。 因此， 我们在查询时， 要保证连续查询中的表的大小从左到右依次是增加的。 假如，在 a, b 两个表中，b表最小， 则 sql 需要修改为： 123456SELECT a.price_close, b.price_closeFROM b JOIN a ON b.ymd = a.ymd AND b.symbol = a.symbolWHERE a.symbol = 'APPLE' 使用 “标记” 来指定哪张表是大表， 不需要排序 123456SELECT /*+Streamtable(a)*/ a.price_close, b.price_closeFROM a JOIN B on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 左外连接左边表符合 WHERE 条件的全部返回，右表不符合 ON 条件的返回 NULL 123456SELECT a.price_close, b.price_closeFROM a LEFT OUTER JOIN b on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 完全外链接返回所有表中符合 WHERE 语句条件的所有记录，Hive 不支持右半开连接 123456SELECT a.price_close, b.price_closeFROM a FULL OUTER JOIN b on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 8. 排序 ORDER BY Order by 对查询的所有结果进行排序可在字段加 DESC 关键字， 进行降序排序。 （默认 ASC， 升序） 1234567891011SELECT a.price_close,FROM a WHERE a.symbol = 'Apple'GROUP BY a.price_closeORDER BY A.PRICE_close DESCLIMIT 10; 9. 子查询 Hive中如果是从一个子查询进行SELECT查询，那么子查询必须设置一个别名 From 子句进行子查询 1234567891011121314151617181920212223242526select dt, count(distinct account) as uv, count(1) as pvfrom (select dt, count(distinct account) as uv, count(1) as pv from client.android_log_viewUNION ALL select dt, count(distinct account) as uv, count(1) as pv from client.ios_log_view ) group by dtorder by dt Hive 0.13 开始， Where 子句也支持子查询 1234567SELECT *FROM AWHERE A.a IN (SELECT foo FROM B); SELECT AFROM T1WHERE EXISTS (SELECT B FROM T2 WHERE T1.X = T2.Y) 将子查询作为一个表的语法，叫做Common Table Expression（CTE） 如果用 distinct, select 后面必须直接跟 distinct 1234567891011121314151617181920212223242526272829with a1 as (select distinct user_account, provincefrom computer_viedatawhere hit_date between '2018-09-01' and '2018-09-30'union allselect distinct user_account, provincefrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-30')select province, count(distinct user_account) as uvfrom a1group by provinceorder by uv DESC 刷新数据表 1refresh table computer_log.client_ios_log 用python脚本连接数据库作为一名数据分析师，日报、周报、月报数据一个也不能少。 相应的， 就要在数据库中提取大量的数据， 并处理大量的Excel表格。 在提取和处理数据的过程中， 对于一些重复性的劳动， 写个Python脚本来实现半自动化， 能够大幅提高自己的工作效率。 以下是自己工作中的一点总结经验。 首先， 用Python连接数据库 对于数据库的ip地址，用户名，密码等， 如果不清楚，或数据库连接不上， 需要和开发人员对接 12345678from pyhive import hive import timeconn = hive.Connection(host='ip地址', port=10000, username='用户名', database = 'default', auth='NOSASL')cursor = conn.cursor()# 获得连接的游标 设置开始和结束时间可以用python中的time函数设置时间 12startdate = '2018-09-01'enddate = '2018-09-19' 用Python中的format函数将日期传入{}中 python中写sql脚本时， 需要用\来进行换行符的转换, \后面不能有空格。 日期用两个{}来代替， 用format函数将开始日期与结束日期传入 123456789101112131415161718192021222324# 提取积分类uv,pv数据sql_jifenxinxi_an = """select count(distinct user_account) as uv, count(1) as pv from computer_view.data where hit_date between "&#123;&#125;" and "&#123;&#125;" and (btn_position like "服务-查询-积分信息%" or btn_home = "积分-扇形左" ) limit 1000""".format(startdate,enddate)# format 插入时间cursor.execute(sql_jifenxinxi_an)# 运行此语句cursor.fetchall()#fetchall():接收全部的返回结果行. 我们可以按照这个格式写工作中需要运行的多个SQL语句。 这样， 当脚本运行的时候， 我们可以腾出时间来去干其他工作， 等过一段时间，所有的SQL语句都跑完了， 我们再进行统一的整理。 参考资料：Hive 编程指南Hive的那些事Hive 官网一起学HiveHive性能优化上的一些总结过往记忆——hive]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类比汇总]]></title>
    <url>%2F2019%2F03%2F30%2F%E9%80%9A%E7%94%A8-%E6%B2%9F%E9%80%9A%E8%83%BD%E5%8A%9B-%E7%B1%BB%E6%AF%94%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[类比论证： 一个论证用两件事物之间熟知的相似点作为基础，推导出关于其中一件事物的一个相对未知特征的结论，这样的论证叫做类比论证。 类比有好有坏，需要区别。 学习一门技能，你需要知道最少必要知识。 这就好像你拿着一张地图，不可能一下子掌握其中所有的细节，但花几分钟搞清楚 “图例”（Legend）部分总是可以的，知道什么样的线标示的是公交车，什么样的线标示的是地铁，什么样的线标示的是桥梁，然后知道上北下南左西右东 —— 这之后，就可以开始慢慢研究地图了…… 在我们使用函数的过程中，我们常常有意忽略它的内部如何完成从输入到输出之间的处理过程 —— 这就好像我们平日里用灯泡一样，大多数情况下，我们只要知道开关的使用方法就够了 —— 至于为什么按到这个方向上灯会亮，为什么按到另外一个方向上灯会灭，并不是我们作为用户必须关心的事情……当然，如果你是设计开关的人就不一样了，你必须知道其中的运作原理；但是，最终，你还是希望你的用户用最简单方便的操作界面，而不是必须搞懂所有原理才能够使用你所设计的产品…… 在任何一本编程书籍之中，关于字符串的内容总是很长 —— 就好像每本英语语法书中，关于动词的内容总是占全部内容的至少三分之二。 教育就像一副眼镜。戴上眼镜之前和之后，我们看到的其实是同样的世界；但是戴上眼镜之后，我们就看得更清楚。 我们是这样一台计算机，厂商（我们的父母）并没有为我们提供详尽的说明书，也不负责定期升级我们的操作系统——即使他们并非故意。 人与人之间很不一样，就好像计算机和计算机之间也很不一样，有些中央处理器（头脑）更强大一些，有些人的内存容量（记忆力）更大一些，有些人的硬盘空间（笔记与藏书）更大一些，有些人显示器（外表）更漂亮一些。 很多人的处理器是落伍的，输入和输出设备常常残缺不全，内存小到没法用的底部，硬盘甚至根本就没有……至于连网设备么，真的很差，甚至真的还不如没有，因为即使连着网也因为缺乏通讯协议而完全无法使用… 科学是由信息构成的，正如房子是用砖头盖的一样，可问题在于，正如仅仅一堆砖头放在那里的时候，我们不能称其为房子一样，一堆信息放在一块就叫科学，有点不像话…… 学习电脑编程的函数时，我把函数想象成铅笔刀，钝铅笔进去，锐利的铅笔出来，这个模型不依赖于图像，但是过程类似。 两个自我： 大象和骑象人 人的感性面就是一头大象，而理智面就是一个骑象人。 骑象人骑在大象背上，手里握着缰绳，好像是他在指挥大象，但实际上，他的力量微不足道。一旦和大象发生冲突，他想往左，而大象想往右。那他通常是拗不过大象的。 就像人有一套生理免疫系统来排斥不属于身体的微生物一样，人的心理也有一套免疫系统，它会排斥我们采取新的行为方式，以此来维持心理结构的平衡和稳定。 我们要验证这些假设对不对，什么时候成立，什么时候不成立。 这就像学习游泳，我们既不能只在岸上熟读《怎么学游泳》的书，也不能一下子要求自己跳到深水区，这样就被淹死了。 同一辆车， 在公路上开， 和在泥地上开， 要达到相同的速度， 付出的努力是不同的。 同理， 不同的工作环境和内容， 带来不同的难度， 对采用的技术和努力程度也有不同的要求。 所以只衡量结果却不考虑过程， 有失公平。 考虑过程， 就包括了对工作暖色、环境因素带来的工作复杂度的度量， 也体现了对个人技能、态度的衡量。 中国人是椰子文化，擅长熟人社会的交往规则，不擅长与陌生人打交道。西方人是桃子文化， 擅长与陌生人打交道。 闭环原则是工作中最常用也是最有效的原则，但很少有人能够一直做到。这就像“运动和良好的饮食可以帮助我们保持健康和身材”一样，几乎所有人都知道， 但很少有人能够做到。 “回音壁”效应： 基于数据算法的产品就像是一个回音壁，你发出声音后，应用反馈给你的是与你自己声音相似的回音。你认为自己的“声音”得到了印证，所以你会对自己“声音”的正确性更加坚定不移。由此，你的信息、知识圈层只会更加固话，视野越发狭窄。 爱因斯坦：事情不会在出现问题的那个层面得到解决，只有上升到更高的层面才会得到解决。这就像你家的羊被狼叼走了一只，你往里面补了一只羊，表面上看这个问题解决了。过些天，又有羊被叼走了，你又得不断的补羊。可出是有一天你登高望远，发现原来是羊圈出现了破损，那么你只要把破损的地方补好就可以了。 用大海捞针的方式穷举各种可能进行试验，这其实是一种受限于无法利用更高潜能的“笨方法”。如果人自己可以提升视野和维度，去“补羊圈”，问题往往迎刃而解，并不需要无穷次的实验。 只要改变的策略和知识得当，以前看似不可能的事情会变得完全可能，而且简单明了，这就好比要打开一扇锁着的门一样–只有拿对钥匙才能轻松打开。 建立习惯就好像骑自行车上陡坡： 爬坡，到顶，下坡。 刚开始，你必须用双腿的最大力量蹬自行车，之后会渐渐变得轻松，但是你必须一直蹬到山顶，否则就会倒退回原地，让之前所有的进步付诸东流。 你有没有开过不带转向助力装置的汽车？ 方向盘转了好几圈，车的反应却很小。 大脑对改变的反应就像不带转向装置的汽车一样。 每次重复产生的作用可以忽略不计，可是如果不断重复下去，这些微小的变化会给大脑和生活带来巨大的改变。 任何事物能成为基础的第一原则就是它必须牢固可靠，而“激发动力”侧率就像是在液体上盖房子。 我不喜欢动力不是因为它不好。例如，为了写出这些文字，我需要最基本的动力，但动力论到处都是， 人们将其伪装成个人成长的秘方，虽然这不是它本身的错。 这就好像我告诉你胡萝卜能治愈癌症一样，胡萝卜的确对你有益，但它不可能治好任何得癌症的人，于是这个好东西-胡萝卜，已经被塑造成了真理的敌人，在导出招摇撞骗。这么看来，动力是一根邪恶的胡萝卜。 动力偶尔才会产生效果，所以很难评估，对动力策略的长远结果做一番审视，你可能会发现它并不是每次都会奏效。动力也不会轻易改善，因为如果你的狗病死了，你会情绪崩溃，或者你累了或者情绪很差时也会不想锻炼。与此相反的是， 你却能提高克服可能来自感情创伤、缺乏自信、情绪糟糕或者精力不足的抵触情绪，进而采取行动的能力，这种能力就是意志力。 相反，他在脑中植入了一个观点，有点像你在DVD播放器里插入了一张DVD. 当你努力理解一个人的时候，你的任务在很多方面都好像没有亲眼观看魔术师魔术表演的每个步骤就自己动手去做那个魔术。 你眼看着手帕放进了帽子里，出来的却是一只兔子，而你压根就不知道魔术师暗地里玩的到底是什么把戏。要理解这个魔术，你就得搞清楚魔术师暗地里的那些把戏。同样，在论证当中，你也得找到那些暗藏的把戏。实际上，这些把戏就是没有明说出来的想法。我们把这些没有明说出来的想法称为假设。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>类比</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的分析思维方法]]></title>
    <url>%2F2019%2F03%2F26%2F%E6%96%B9%E6%B3%95-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[数据分析方法 使用频率按照顺序排列 1.对比分析法 对比分析是给单独的数据一个参考系， 否则孤立的数据毫无意义。 时间上的同比环比 环比、环比增长率 同比、同比增长率 竞争对手对比 与其他维度结合，进行对比 活动促销前后的对比 细拆维度之间的对比 各渠道之间的对比等 2.多维度拆解法 多维分解是指从业务需求出发，将指标从多个维度进行拆分。 说明： 为什么需要进行多维拆解? 有时候一个非常笼统或者最终的指标你是看不出什么问题来的，但是进行拆分之后，很多细节问题就会浮现出来。 举个例子，某网站的跳出率是0.47、平均访问深度是4.39、平均访问时长是0.55分钟。如果你要提升用户的参与度，显然这样的数据会让你无从下手;但是你对这些指标进行拆解之后就会发现很多思路。 补充：维度拆解不够， 容易导致辛普森悖论 3. 漏斗分析法漏斗分析法， 还原用户转化的路径， 分析每一步的转化率， 针对性的优化和改善 说明：漏斗分析是一套流程式数据分析，它能够科学反映用户行为状态以及从起点到终点各阶段用户转化率情况的重要分析模型。 漏斗分析模型已经广泛应用于网站用户行为分析和APP用户行为分析的流量监控、产品目标转化等日常数据运营与数据分析的工作中 漏斗分析要注意的两个要点： 不但要看总体的转化率，还要关注转化过程每一步的转化率; 漏斗分析也需要进行多维度拆解，拆解之后可能会发现不同维度下的转化率也有很大差异。 4. 留存分析 留存分析是一种用来分析用户参与情况/活跃程度的分析模型，考察进行初始行为的用户中，有多少人会进行后续行为。 衡量留存的常见指标有：次日留存率、7日留存率、30日留存率等等 说明： 这是用来衡量产品对用户价值高低的重要方法 留存分析可以帮助回答以下问题： 一个新客户在未来的一段时间内是否完成了您期许用户完成的行为？如支付订单等； 某个社交产品改进了新注册用户的引导流程，期待改善用户注册后的参与程度，如何验证？ 想判断某项产品改动是否奏效，如新增了一个邀请好友的功能，观察是否有人因新增功能而多使用产品几个月？ 5. 趋势分析通常我们在数据分析产品中建立一张数据指标的线图或者柱状图，然后持续观察，重点关注异常值。 说明： 在这个过程中，我们要选定第一关键指标，而不要被虚荣指标所迷惑。 以社交类APP为例，如果我们将下载量作为第一关键指标，可能就会走偏;因为用户下载APP并不代表他使用了你的产品。在这种情况下，建议将DAU(Daily Active Users，日活跃用户)作为第一关键指标，而且是启动并且执行了某个操作的用户才能算上去;这样的指标才有实际意义，运营人员要核心关注这类指标。 6.用户分群用户分群主要有两种分法：维度和行为组合。 第一种根据用户的维度进行分群，比如从地区维度分，有北京、上海、广州、杭州等地的用户;从用户登录平台进行分群，有PC端、平板端和手机移动端用户。 第二种根据用户行为组合进行分群，比如说每周在社区签到3次的用户与每周在社区签到少于3次的用户的区别. 7.公式法 将一切问题皆可量化，拆解成最小的维度，通过 +、-、*、/ 进行计算 8.用户细查用户行为数据是观察用户在你产品内的行为路径是一种非常直观的分析方法。 在用户分群的基础上，一般抽取3-5个用户进行细查，即可覆盖分群用户大部分行为规律。 绝大多数产品都或多或少存在一些反人类的设计或者BUG，通过用户细查可以很好地发现产品中存在的问题并且及时解决。 9.A/B测试与A/A测试 A/B测试是为了达到一个目标，采取了两套方案，一组用户采用A方案，一组用户采用B方案。通过实验观察两组方案的数据效果，判断两组方案的好坏。 说明： 在A/B测试方面，谷歌是不遗余力地尝试;对于搜索结果的显示，谷歌会制定多种不同的方案(包括文案标题，字体大小，颜色等等)，不断来优化搜索结果中广告的点击率。 这里需要注意的一点，A/B测试之前最好有A/A测试或者类似准备。什么是A/A测试?A/A测试是评估两个实验组是否是处于相同的水平，这样A/B测试才有意义。其实这和学校里面的控制变量法、实验组与对照组、双盲试验本质一样的。 10.假设法 假设-验证-判断。 当没有直观数据时， 以假设先行的方式进行推断。 说明： 例如： 如果商品提价后， 公司收益会不会变化？ 假设流量不会发生变化， 那么商品价格会影响转化率，确定转化率的下降。 计算日常的转化率， 针对不同的用户，如：忠诚用户、普通用户、羊毛用户， 预估各类别用户提价后的转化率变化。 11.指数法指定一个标准， 解决衡量的问题 线性加权： 反比例： 1-1/n， 范围为0-1 log指数法 热度公式： log(uv+ 5*评论,2) +(time -初始时间) / 10 参考资料： 数据分析的基本方法论]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL面试题]]></title>
    <url>%2F2019%2F03%2F24%2F%E6%8A%80%E8%83%BD-Hive%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[结合两个表 问题描述： 表1：Preson Column Name Type PersonId int FirstName varchar LastName varchar 表2： Address Column Name Type AddressId int PersonId int City varchar State varchar 要求： 为Person表中的每个人提供以下信息，无论每个人都有一个地址：1FirstName, LastName, City, State 答案： 12345678SELECT Person.FirstName, Person.LastName, Address.City, Address.StateFROM Person LEFT join Address on Person.PersonId = Address.PersonId; 考查点： 使用 join 对两表进行连接查询。 取出排名第 2 高的数据 问题描述 表： Employee Id Salary 1 100 2 200 3 300 要求： 根据上面的 Employee 表，查询返回 薪水工资第二高的数据：200, 如果没有第二高的薪水， 返回Null。 SecondHighestSalary 200 答案 答案1 解法： 在除过第一名薪水中，找出最高的薪水，也就是第二名。 123456SELECT MAX(Salary) as SecondHighestSalaryFROM EmployeeWHERE Salary &lt; (SELECT MAX(Salary) FROM Employee); 答案2 解法： 跳过排名第一的数据， 并取出1条数据，即读取第2条数据。 123456789SELECT DISTINCT Salary as SecondHighestSalaryFROM Employeeorder by Salary DESC limit 1 offset 1-- 可缩写为limit 1,1 但上式写法错误， 因为如果表中没有第二薪水的话，那sql运行报错，而不是返回Null。 我们将其作为临时表可解决此问题： 12345678SELECT (SELECT DISTINCT Salary FROM Employeeorder by Salary DESClimit 1 offset 1) AS SecondHighestSalary 或者使用 IFNULL 1234567891011SELECT IFNULL( (SELECT DISTINCT Salary FROM Employeeorder by Salary DESClimit 1,1), NULL ) AS SecondHighestSalary 延伸 找出排名第三的薪水 1234567891011SELECT IFNULL( (SELECT DISTINCT Salary FROM Employeeorder by Salary DESClimit 2 offset 1), NULL ) AS SecondHighestSalary 对数据进行排序 问题： 表： Scores Id Score 1 3.50 2 3.65 3 4.00 4 3.85 5 4.00 6 3.65 要求： 对以下 Scores 表中的分数进行排名，如果两数相同，则有相同的排名， 排名相等的不会留下空位。 输出结果为： Score Rank 4.00 1 4.00 1 3.85 2 3.65 3 3.65 3 3.50 4 答案 答案1： 步骤1： 返回不同的成绩 1Select Distinct Score from Scores 步骤2： 统计并计算排名 1Select Count(1) + 1 From (Select Distinct Score from Scores) as uniqeScores where Score &gt; sc.Score 步骤3： 汇总 12345678910Select sc.Score, (Select Count(1) + 1 From ( Select Distinct Score from Scores) as uniqeScores where Score &gt; sc.Score) as rank From Scores sc Order by sc.Score Desc; 答案2： 123456select s1.Score, COUNT(DISTINCT s2.Score) Rankfrom Scores s1 inner join Scores s2 on s1.Score &lt;= s2.Scoregroup by s1.Idorder by s1.Score desc 答案3： 12345select Score, dense_rank() over(order by Score) as Rankfrom Scores 延伸 rank、dense_rank、 row_number 的区别 rank函数， 返回数据项在分组中的排名， 排名相等的会留下空位。 如1、2、2、4 dense_rank函数， 返回数据项在分组中的排名， 排名相等的不会留下空位。 如1、2、2、3 row_number函数， 返回数据项在分组中的排名， 排名不管数据是否相等。 如1、2、3、4 留存率 问题： 写出6月5-10号每日客户端活跃用户的次1日、次3日、次7日留存 答案 答案1：123456789101112131415161718192021222324with a1 as (select dt, user_accountfrom computerwhere dt between '2019-06-01' and '2019-06-17'),a2 as (select dt, user_accountfrom computerwhere dt between '2019-06-01' and '2019-06-17')select a1.dt,count(distinct a1.user_account) uv,count(distinct case when datediff(a2.dt, a1.dt) = 1 then a1.user_account else null end ) next_day,count(distinct case when datediff(a2.dt, a1.dt) = 3 then a1.user_account else null end ) three_day,count(distinct case when datediff(a2.dt, a1.dt) = 7 then a1.user_account else null end ) seven_dayfrom a1 join a2 on a1.user_account = a2.user_accountgroup by a1.dtorder by a1.dtlimit 100 输出结果为： 日期 uv 次1日 次3日 次7日 2019/6/1 50231 6578 6642 5154 2019/6/2 42000 6293 5027 4304 2019/6/3 44312 6760 8331 5042 2019/6/4 37852 5298 7133 0 2019/6/5 30678 6082 4648 0 2019/6/6 39405 8173 4972 0 2019/6/7 31267 5352 4920 0 2019/6/8 25614 4451 0 0 2019/6/9 24113 4568 0 0 2019/6/10 26242 0 0 0 答案2：步骤1：1234567891011SELECT dt, count(distinct user_account) as uvFROM computerWHERE dt between '2019-06-01' and '2019-06-17'group BY dtorder BY dt 步骤2：123456789101112131415161718192021222324252627282930-- 统计10-15号每天的次日留存数， 统计次3、7日留存只需将1换为3、7with a1 as ( select user_account, dt from computer where dt between '2019-06-01' and '2019-06-17'),a2 as ( select user_account, dt from computer_view.client_android_log_view where dt between '2019-06-01' and '2019-06-17')select a1.dt, count(distinct a1.user_account) as uvfrom a1 join a2 on a1.user_account = a2.user_accountWHERE a2.dt = date_add(a1.dt, 1) group by a1.dtorder BY a1.dt 步骤3：1留存率 = 用步骤2结果/ 步骤1 结果 连续出现三次的数字 问题： 查找出连续出现至少三次的所有数字 表 Logs 如下： Id Num 1 1 2 1 3 1 4 2 5 1 6 2 7 2 得到如下结果： ConsecutiveNums 1 答案 答案1： 12345678910select distinct a1.Num as ConsecutiveNumsfrom Logs as a1left join Logs as a2 on a1.Id = a2.Id-1left join Logs as a3 on a1.Id = a3.Id -2where a1.Num = a2.Num and a2.Num = a3.Num 答案2： 1234567891011121314select distinct a1.Num as ConsecutiveNumsfrom Logs a1, Logs a2, Logs a3where a1.Id = a2.Id -1 and a2.Id = a3.Id -1 and a1.Num = a2.Num and a2.Num = a3.Num 答案3：1234567891011121314---连续 N 次出现， 则将 3 改为 N 即可。SELECT distinct num as ConsecutiveNumsFROM(SELECT id, num, @pre := @cur, @cur := num, @rep_ct := IF(@pre = @cur, @rep_ct + 1, 1) as rep_ctFROM `Logs` l, (SELECT @pre := null, @cur := 0, @rep_ct := 1) init) temp WHERE rep_ct &gt;= 3 连续 4 个月活跃的用户明细 问题：求出 1-4 月每月连续登陆客户端的用户数 思路 将用户登录的月份按从小到大排序， 找出排序等于 4 的用户 答案 1234567891011121314151617181920212223242526with a1 as(select id, month(dt) as monthfrom datawhere dt between '2019-01-01' and '2019-04-30'group by id, month(dt) ),a2 as ( select id, a1.month, row_number() over(partition by id order by a1.month) as numfrom a1) select count(distinct id) as uvfrom a2where a2.num= 4 查询比经理薪资高的员工姓名 问题 表：Employee 包含员工和经理的Id 与薪水 Id Name Salary ManagerId 1 Joe 70000 3 2 Henry 80000 4 3 Sam 60000 NULL 4 Max 90000 NULL 要求： 查找收入高于经理的员工，得到如下结果： Employee Joe 前3列 来自a1, 后两列来自a2 答案 答案1： 利用 join 对表进行合并前3列 来自a1, 后两列来自a2 Name Salary ManagerId Id Salary Joe 70000 3 3 60000 Henry 80000 4 4 90000 1234567select a1.name as Employeefrom Employee as a1 join employee as a2 on a1.ManagerId = a2.Idwhere a1.Salary &gt; a2.Salary 答案2： 123456789101112131415161718with a1 as ( select name,salary, ManagerId from Employee),a2 as ( select managerid, Id from Employee)select a1.namefrom a1 join a2 on a1.ManagerId = a2.Idwhere a1.Salary &gt; a2.Salary 答案3： 步骤1： 12SELECT *FROM Employee AS a1, Employee AS a2 此步骤输出结果为： 结果将获得这两个标的笛卡尔积，输出结果将使 4*4 = 16条记录， 我们对输出结果进行过滤。 12345678SELECT a.Name AS 'Employee'FROM Employee AS a, Employee AS bWHERE a.ManagerId = b.Id AND a.Salary &gt; b.Salary 找出重复邮件 问题 表： Person Id Email 1 a@b.com 2 c@d.com 3 a@b.com 要求： 找出Person 表中所有重复电子邮件，得到如下结果： Email a@b.com 答案 答案1： 123456789101112select a1.Emailfrom(select Email, count(Email) as numfrom Persongroup by Email) as a1where a1.num !=1 答案2： 12345678select Emailfrom Persongroup by Emailhaving count(Email) !=1 5月中连续7天登陆的用户数 问题:根据用户登录表 data，取出连续登录了K天的用户uid id dt A 2019-06-01 B 2019-06-03 B 2019-06-04 B 2019-06-05 B 2019-06-06 C 2019-06-05 C 2019-06-06 C 2019-06-07 答案： 将用户按照电话号进行排序 id dt num A 2019-05-01 1 B 2019-05-03 1 B 2019-05-04 2 B 2019-05-05 3 B 2019-05-06 4 C 2019-05-05 1 C 2019-05-06 2 C 2019-05-07 3 1234567891011select id, dt, row_number() over(partition by id order by dt) as numfrom Datawhere dt between '2019-05-01' and '2019-05-07'group by id, dt 将日期与排序进行相减 id dt num diff A 2019-05-01 1 2019-04-30 B 2019-05-03 1 2019-05-02 B 2019-05-04 2 2019-05-02 B 2019-05-05 3 2019-05-02 B 2019-05-06 4 2019-05-02 C 2019-05-05 1 2019-05-04 C 2019-05-06 2 2019-05-04 C 2019-05-07 3 2019-05-04 12345678910111213141516171819202122232425with a1 as ( select id, dt, row_number() over(partition by id order by dt) as num from computer_view.client_android_log_view where dt between '2019-06-01' and '2019-06-03' group by id, dt)select id, dt, num, (DATE_SUB(dt, num )) as diff from a1group by id, dt, numlimit 100 统计差值相同的数字个数，并大于等于3 1234567891011121314151617181920212223242526272829303132333435with a1 as ( select user_account, hit_date, row_number() over(partition by user_account order by hit_date) as num from computer_view.client_android_log_view where hit_date between '2019-06-01' and '2019-06-05' group by user_account, hit_date),a2 as (select user_account, hit_date, num, (DATE_SUB(hit_date, num )) as diff from a1group by user_account, hit_date, num)select diff, max(num), count(distinct user_account)from a2group by diffhaving max(num) &gt;= 1limit 100 找出连续登录4天以上的用户数 123456789101112131415161718192021222324252627282930313233343536with a1 as ( select id, dt, row_number() over(partition by id order by dt) as num from computer_view.client_android_log_view where dt between '2019-06-01' and '2019-06-05' group by id, dt),a2 as (select id, dt, num, (DATE_SUB(dt, num )) as diff from a1group by id, dt, num)select id, diff, count(diff) from a2group by id, diff having count(diff) &gt;= 4limit 100 id diff count(diff) B 2019-05-02 4 C 2019-05-04 3 求连续任意天数的用户数 sql分三层第一层：根据条件查询一个时间区间的数据 cha_day 统一计算出一个时间差，然后和当前行数相减。连续的天数和行数相减，结果是一样的第二层：分组求出每个用户的连续天数， rows:排序找出一个用户最大连续天数第三层：连续天数分组，求出人数。 分组天数总人数，应该等于总人数 1234567891011121314151617181920212223242526272829303132333435363738select lx_day, count(user_account)from( select user_account, cha_day, count(cha_day) as lx_day, row_number() over(partition by user_account order by count(cha_day) desc) as rows from ( select datediff(hit_date,'2000-01-01')-row_number() over(partition by user_account order by hit_date) as cha_day, hit_date, user_account from apache_computer_view.client_ios_log where hit_date between '2019-10-15' and '2019-10-20' and nbtn_name = '签到有礼' group by hit_date, user_account )v group by user_account, cha_day)vwhere rows = 1group by lx_dayorder by lx_daylimit 1000 找出未订购任何内容的用户 问题： 表： Customers Id Name 1 Joe 2 Henry 3 Sam 4 Max 表： Orders Id CustomerId 1 3 2 1 要求： 根据上面两个表，找出从未订购任何内容的所有客户。输出结果如下： Customers Henry Max 答案 答案1： 123456SELECT Name as CustomersFROM Customers left JOIN Orders on Customers.Id = Orders.CustomerIdwhere Orders.CustomerId is NULL 答案2： 12345678910select customers.name as Customersfrom customerswhere customers.Id not in (select CustomerId from Orders) 找出各部门薪水最高的员工 问题： 表： Employee Id Name Salary DepartmentId 1 Joe 70000 1 2 Jim 90000 1 3 Henry 80000 2 4 Sam 60000 2 5 Max 90000 1 表： Department Id Name 1 IT 2 Sales 要求：找出各部门薪水最高的员工 Department Employee Salary IT Max 90000 IT Jim 90000 Sales Henry 80000 答案 步骤1： 查出各部门最高薪水 1234567SELECT DepartmentId, MAX(Salary)from Employeegroup by DepartmentId 步骤2： 12345678910111213141516171819selectEmployee.Name as Department,Department.Name as Employee,Salary from Employee join Department on Employee.DepartmentId= Department.Idwhere ((Employee.DepartmentId, Salary) in (SELECT DepartmentId, MAX(Salary)from Employeegroup by DepartmentId))group by Department,Employee,Salary 获取每个部门中薪水前三名的员工 问题： 表：Employee Id Name Salary DepartmentId 1 Joe 85000 1 2 Henry 80000 2 3 Sam 60000 2 4 Max 90000 1 5 Janet 69000 1 6 Randy 85000 1 7 Will 70000 1 表： Department Id Name 1 IT 2 Sales 要求： 找出各部门薪水前三的员工， 输出结果如下： Department Employee Salary IT Max 90000 IT Randy 85000 IT Joe 85000 IT Will 70000 Sales Henry 80000 Sales Sam 60000 答案 步骤1：对各部门薪水进行排序 合并12345678910select Employee.Name AS Employee, Employee.Salary AS Salary, Department.Name AS Department from Employee join Department on Employee.DepartmentId = Department.Id group by Employee, Salary, Department Employee Salary Department Joe 85000 IT Henry 80000 Sales Sam 60000 Sales Max 90000 IT Janet 69000 IT Randy 85000 IT Will 70000 IT 步骤2 ： 找出排名前三的 思路： 再添加一张Employee 表，与步骤1中的 A 表进行对比， 令 B 表中的 salary 大于 A 表中的 salary 条件限制：B表中 salary 大于 A 表中salary 的个数小于3 123456789101112131415select A.Name AS Employee, A.Salary AS Salary, Department.Name AS Department from Employee as A join Department on A.DepartmentId = Department.Id WHERE (select count(distinct B.Salary) from Employee as B WHERE B.Salary &gt; A.Salary and B.DepartmentId = A.DepartmentId) &lt;3 sql题 学生-课程-成绩案例 内容：表： student id name 1 zy 2 hz 3 zy 4 lx 5 lx 表： course id name 1 match 2 python 3 java 表: student_course sid cid score 1 1 60 1 2 50 2 2 80 4 3 90 2 2 80 3 3 50 问题 问题1： 查询 student表中重名的学生， 结果包含id 和name, 按 name 升序 12345678910select name, idfrom studentwhere name in (select name from student group by name having count(name) &gt; 1)order by name 问题2： 查询 student_course 表中的平均份不及格的学生， 列出学生的 id 和平均分 123456789select sid, avg(score) as avg_scorefrom student_coursegroup by sidhaving avg_score &lt; 60 问题3： 查询每门课成绩都不低于80的学生id 123456789101112select distinct sidfrom student_coursewhere sid not in (select score from student_course where score &lt;80) 问题4： 查询每个学生的总成绩，列出学生名称和总成绩 12345select student.name, sum(student_course.score)from student left join student_course on student.id = student_course.sid 问题5：查出总成绩最高的学生 123456789select sid, sum(score)from student_coursegroup by sidorder by sum(score) desclimit 1; 问题6： 查询课程1,成绩第二高的学生 方法1：123456789101112---在除过第一高的成绩中，找出最高的成绩select cid, max(score)from stuent_scorewhere cid =1 and score &lt; (select max(score) from student_score) 方法2： 12345678910111213---跳过排名第一的数据， 取1条数据select max(score)from stuent_scorewhere cid = 1 group by score order by score desc limit 1 offset 1 --limit 1,1 问题7： 查看各科成绩最高的学生id与课程id 1234567891011121314select cid, sid, scorefrom student_course as a1where score &gt;= (select max(score) from stuent_score as a2 where a1.id = ax.id) 错误写法： 12345678select sid, cid, max(score)from student_scoregroup by cid 问题8： 在student_course 表中查询每门课的前2名，结果按照课程id 升序， 同一课程按照成绩降序。 123456789101112131415select *from student_course xwhere 2 &gt;( select count(*) from student_course y where y.cid = x.cid and y.score &gt; x.score)order by cid, score DESC 对每季度数据进行汇总 问题： 表： sales 年 季度 销售 1991 1 11 1991 2 12 1991 3 13 1991 4 14 1992 1 21 1992 2 22 1992 3 23 1992 4 24 要求： 通过 SQL 语句显示以下结果： 年 一季度 二季度 三季度 四季度 1991 11 12 13 14 1992 21 22 23 24 答案： 123456select 年, sum(case when 季度=1 then 销售量 else 0 end) as 一季度, sum(case when 季度=2 then 销售量 else 0 end) as 二季度, sum(case when 季度=3 then 销售量 else 0 end) as 三季度, sum(case when 季度=4 then 销售量 else 0 end) as 四季度 from sales group by 年 解释 lateral view 函数 描述： lateral view 用于和 split、explode、collect_set 函数 等一起使用， 能够将一行数据拆成多行数据，在此基础上对拆分后的数据进行聚合。 问题1：将 表 table 中的 adid_list 转换为单独的行。 表： table pageid adid_list front_page [1,2,3] contact_page [3,4] 答案： 12345SELECT pageid, adidFROM tablelateral view explode(adid_list) adTable as adid 输出结果为： pageid adid_list front_page 1 front_page 2 front_page 3 contact_page 3 contact_page 4 问题2：要求： 计算特定广告的展现次数 答案： 1234567SELECT adid, count(1)FROM tablelateral view explode(adid_list) adTable as adidGROUP BY adid 输出结果为： adid count(1) 1 1 2 1 3 2 4 1 问题3： 多个 lateral view 查询 表： table2 array col2 [1,2] [“a”，”b”] [3,4] [“c”, “d”] 答案： 123456SELECT myCol1, myCol2FROM baseTableLATERAL VIEW explode(col1) myTable1 AS myCol1LATERAL VIEW explode(col2) myTable2 AS myCol2 输出结果为： myCol1 myCol2 1 “a” 1 “b” 2 “a” 2 “b” 3 “c” 3 “d” 4 “c” 4 “d” 删除重复的电子邮箱 问题 表：Person Id Email 1 zhang@qq.com 2 yu@gmailc.om 3 zhang@qq.com 要求: 删除 Person 表中所有重复的电子邮箱，只保留 Id 最小的那个。 Id Email 1 zhang@qq.com 2 yu@gmailc.om 答案： 答案1： 步骤1：找出 Id 大的重复邮箱 1234567select a1.*from Person a1 join Person a2 on a1.Email = a2. Emailwhere a1. Id &gt; a2.Id 步骤2： 删除 Id 较大的重复邮箱。 123456DELETE a1FROM Person a1 join Person a2 on a1.Email = a2. Emailwhere a1. Id &gt; a2.Id 答案2： 123456DELETE a1FROM Person a1, Person a2 where a1.Email = a2. Email and a1. Id &gt; a2.Id 上升的温度 问题 表： Weather Id(INT) RecordDate(DATE) Temperature(INT) 1 2015-01-01 10 2 2015-01-02 25 3 2015-01-03 20 4 2015-01-04 30 要求：查找与昨天日期相比温度更高的所有日期的 Id, 返回结果如下： Id 2 4 答案： 答案1： datediff 函数 123456SELECT a1.Idfrom Weather a1 join Weather a2 on datediff(a1.RecordDate, a2.RecordDate) = 1 and a1.Temperature &gt; a2.Temperature 答案2： ADDDATE 函数 123456SELECT a1.Idfrom Weather a1 join Weather a2 on a1.RecordDate= date_add(a2.RecordDate,1) and a1.Temperature &gt; a2.Temperature 游戏玩家分析1此表显示某些游戏玩家的活动。每一行都是某天用某些设备登陆并玩多个游戏的玩家记录。 表： Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-05-02 6 2 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 显示每个玩家的第一次登陆日期， 输出如下结果 player_id first_login 1 2016-03-01 2 2017-06-25 3 2016-03-02 答案： 123SELECT a1.player_id, a1.event_date as first_loginFROM activity a1 left join activity a2 on a1.player_id=a2.player_id and a1.event_date&gt;a2.event_dateWHERE a2.event_date is NULL 12345678910select player_id, to_char(event_date, 'yyyy-mm-dd') as first_loginfrom (select player_id, event_date, row_number() over (partition by player_id order by event_date asc) rn from Activity)where rn = 1 https://codeday.me/bug/20190309/737795.html 游戏玩家分析2表： Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-05-02 6 2 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 写取出每个玩家第一次玩游戏的设备号 输出结果如下： player_id device_id 1 2 2 3 3 1 答案： 123456789SELECT a1.player_id, a1.device_idFROM activity a1 left join activity a2 on a1.player_id=a2.player_id and a1.event_date&gt;a2.event_dateWHERE a2.event_date is NULL 12345678select player_id, device_id from ( select * from Activity where (player_id,event_date) in (select player_id, min(event_date) from Activity group by player_id) ) as t 123456789select player_id, device_idfrom (select player_id, device_id, row_number() over(partition by player_id order by event_date asc) rn from Activity)where rn = 1 游戏分析3表：Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-05-02 6 1 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 取出每个玩家在不同日期下的累积玩游戏次数。 例如： 玩家 id 为 1 的玩家， 在 2016-05-02 时，玩游戏的总次数为 5+6=11， 在2017-06-25 时，玩游戏的总次数为 5+6+1=12。 输出结果如下： player_id event_date games_played_so_far 1 2016-03-01 5 1 2016-05-02 11 1 2017-06-25 12 3 2016-03-02 0 3 2018-07-03 5 答案： 12345select player_id, to_char(event_date, 'yyyy-mm-dd') as event_date, sum(games_played) over(partition by player_id order by event_date) games_played_so_farfrom activity 1select a.player_id ,a.event_date,(case when @player_id=a.player_id then @value:=@value+a.games_played when @player_id:=a.player_id then @value:=a.games_played end ) as games_played_so_far from (select * from Activity order by player_id,event_date) a, (select @player_id:=Null,@value:=0)s 游戏分析4表： Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-03-02 6 2 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 查询在首次登陆后第二天再次登陆的玩家比例， 四舍五入到小数点后两位。 换句话说： 你需要计算从首次登陆日期开始至少连续两天登陆的玩家数量， 然后将该数量除以玩家总数。 输出结果如下： fraction 0.33 12345678--- 错误select CAST( count(b.player_id) / count(distinct a.player_id) as decimal(38, 2)) as fractionfrom Activity as aleft join Activity as b on a.player_id = b.player_id and a.event_date = b.event_date+1 123456789101112131415select round(count(if(datediff(a2.event_date ,a1.event_date )=1,1,null))/count(distinct a1.player_id ),2) as fractionfrom Activity a1, Activity a2where a1.player_id =a2.player_id and (a1.player_id,a1.event_date) in ( select player_id , min(event_date) event_date from Activity a3 group by player_id ) 求中位数表： Employee Id Company Salary 1 A 2341 2 A 341 3 A 15 4 A 15314 5 A 451 6 A 513 7 B 15 8 B 13 9 B 1154 10 B 1345 11 B 1221 12 B 234 13 C 2345 14 C 2645 15 C 2645 16 C 2652 17 C 65 要求：查找每个公司的薪水中位数 Id Company Salary 5 A 451 6 A 513 12 B 234 9 B 1154 14 C 2645 答案：https://www.cnblogs.com/jxlwqq/p/5868206.htmlhttps://www.oschina.net/translate/how-to-calculate-median-value-in-mysql-using-a-simple-sql-query 进行排序123456789select Id, Company, Salary, ROW_NUMBER ( ) OVER (PARTITION BY Company order by Salary) as rank_name, count(1) over (partition by company) as numfrom Employee Id Company Salary rank_name num 3 A 15 1 6 2 A 341 2 6 5 A 451 3 6 6 A 513 4 6 1 A 2341 5 6 4 A 15314 6 6 8 B 13 1 6 7 B 15 2 6 12 B 234 3 6 9 B 1154 4 6 11 B 1221 5 6 10 B 1345 6 6 17 C 65 1 6 13 C 2345 2 6 14 C 2645 3 6 15 C 2645 4 6 16 C 2652 5 6 找到中位数 12345678910select id, company, salaryfrom (select id, company, salary, row_number() over (partition by company order by salary) as rank_name, count(1) over (partition by company) as num from employee )where abs(rank_name - (num+1)/2) &lt; 1 -- 顺序编号在公司薪水记录数中间的，即为中位数 查找至少有5名直接下属的经理表：Employee Id Name Department ManagerId 101 John A null 102 Dan A 101 103 James A 101 104 Amy A 101 105 Anne A 101 106 Ron B 101 要求： 查询来查找至少有5名直接下属的经理 输出结果为： Name John 答案： 123456789select a2.Namefrom Employee a1 join Employee a2on a1.ManagerId = a2.Idgroup by a1.ManagerIdhaving count(*) &gt;=5 给定数字的频率查中位数表： Numbers Number Frequency 0 7 1 1 2 3 3 1 要求： 数字为 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3，所以中位数是 (0 + 0) / 2 = 0，输出结果如下 median 0.0000 答案： 1234567891011121314151617181920select avg(n2.number) medianfrom (select min(n.number) numberfrom (select number, frequency, (@cumsum:=@cumsum+frequency) 'cumsum'from numbers ,(select @cumsum:=0) temp order by number) nwhere n.cumsum &gt;= (floor(((SELECT SUM(frequency) FROM numbers) +1 ) / 2))union select min(n1.number) numberfrom (select number, frequency, (@cumsum1:=@cumsum1+frequency) 'cumsum'from numbers ,(select @cumsum1:=0) temp order by number) n1where n1.cumsum &gt;= (ceil(((SELECT SUM(frequency) FROM numbers) +1 ) / 2))) n2; 找出当选最多的人名称表： Candidate id Name 1 A 2 B 3 C 4 D 5 E 表： Vote id CandidateId 1 2 2 4 3 3 4 2 5 5 表 Candidate 为候选人名称表， 表 Vote 中CandidateId 是 Candidate表中的 id。 要求： 找出当选者的名称，返回结果为当选者B。输出结果如下：| Name ||——|| B | 答案：12345678910111213141516select Namefrom Candidatewhere id = ( select CandidateId from Vote group by CandidateId order by count(*) DESC LIMIT 1 ) 选出所有 bonus &lt; 1000的员工的 name 以及 bonus表：Employee empId name supervisor salary 1 John 3 1000 2 Dan 3 2000 3 Brad null 4000 4 Thomas 3 4000 表：Bonus empId bonus 2 500 4 2000 要求： 选出所有 bonus &lt; 1000的员工的 name 以及 bonus。输出结果如下 name bonus John null Dan 500 Brad null 答案： 123456789select a1.name, a2.bonusfrom Employee as a1 left join Bonus as a2 on a1.empid = a2.empid where ifnull (bonus, 0) &lt; 1000 12345678910select a1.name, a2.bonusfrom Employee as a1 left join Bonus as a2 on a1.empid = a2.empid where nvl (bonus, 0) &lt; 1000 谁有最多的好友表： request_accepted 表中存储了所有好友申请通过的数据记录，其中，requester_id 和 accepter_id 都是用户的编号。 requester_id accepter_id accept_date 1 2 2016_06-03 1 3 2016-06-08 2 3 2016-06-08 3 4 2016-06-09 要求： 求出谁拥有最多的好友和他拥有的好友数目。输出结果如下 id num 3 3 答案： 1234567891011121314select id as id, ucnt as numfrom( select id, count(1) as ucnt from ( select requester_id as id from request_accepted union all select accepter_id as id from request_accepted ) group by id order by ucnt desc)where rownum = 1 找出人流量的高峰期表：stadium id visit_date people 1 2017-01-01 10 2 2017-01-02 109 3 2017-01-03 150 4 2017-01-04 99 5 2017-01-05 145 6 2017-01-06 1455 7 2017-01-07 199 8 2017-01-08 188 要求： 找出人流量的高峰期。高峰期时， 至少连续三行记录中的人流量不少于100。得出结果如下 id visit_date people 5 2017-01-05 145 6 2017-01-06 1455 7 2017-01-07 199 8 2017-01-08 188 答案： 1234567SELECT distinct a.*FROM stadium as a,stadium as b,stadium as cwhere ((a.id = b.id-1 and b.id+1 = c.id) or (a.id-1 = b.id and a.id+1 = c.id) or (a.id-1 = c.id and c.id-1 = b.id)) and (a.people&gt;=100 and b.people&gt;=100 and c.people&gt;=100)order by a.id; 12345678910111213141516select id, to_char(visit_date, 'yyyy-mm-dd') as visit_date, peoplefrom (select id, visit_date, people, count(1) over (partition by offset) cnt from (select id, visit_date, people, (row_number() over (order by id) - id) offset from stadium where people &gt;= 100 ) )where cnt &gt;= 3 -- 连续 3 天（及以上）order by id 预约连续空余座位表：cinema seat_id free 1 1 2 0 3 1 4 1 5 1 要求：获取所有空余座位，并将它们按照 seat_id 排序。输出结果如下 连续空余座位的定义是大于等于 2 个连续空余的座位。1 表示空余，0 表示已被占据。 seat_id 3 4 5 答案： 1234567891011121314151617181920select seat_idfrom(select seat_id, count(1) over (partition by num) as cumfrom( select seat_id, (row_number() over (order by seat_id) - seat_id) as numfrom cinemawhere free = 1))where cum &gt;= 2order by seat_id 找出符合条件的电影表：cinema id movie description rating 1 War great 3D 8.9 2 Science fiction 8.5 3 irish boring 6.2 4 Ice song Fantacy 8.6 5 House card Interesting 9.1 要求： 找出所有影片描述为非 boring (不无聊) 的并且 id 为奇数 的影片，结果请按等级 rating 排列。输出结果如下 id movie description rating 5 House card Interesting 9.1 1 War great 3D 8.9 答案1：12345678910select *from cinemawhere mod(id, 2) = 1 and description != 'boring'order by rating DESC 答案2：12345678910select *from cinemawhere description != 'boring' and id % 2 !=0order by rating DESC 表：Sales sale_id product_id year quantity price 1 100 2008 10 5000 2 100 2009 12 5000 7 200 2011 15 9000 表：Product product_id product_name 100 Nokia 200 Apple 300 Samsung 要求： 编写sql查询， 选择每个销售产品的第一年的数据， 输出结果如下 product_id first_year quantity price 100 2008 10 5000 200 2011 15 9000 答案：123456789101112131415select product_id, year as first_year, quantity, pricefrom ( select product_id, year, quantity,price, rank() over(partition by product_id order by year) rn from sales)where rn=1 找到购买所有产品的顾客表1： customer customer_id product_key 1 5 2 6 3 5 3 6 1 6 表2： product | product_key |+————-+| 5 || 6 | 要求： 找出从 customer 表中购买了 product 表所有产品的客户id。 输出结果如下 customer_id 1 3 答案：123456789101112select customer_idfrom customergroup by customer_idhaving count(distinct product_key) = (select count(distinct product_key) from product ) 12345678910111213141516select customer_idfrom (select customer_id, count(distinct product_key) as num from customer group by customer_id) as a1join ( select count(product_key) as num from product) as a2on a1.num = a2.num 查询关注者的关注数据表：follow followee (博主) follower(关注者) A B B C B D D E 要求： 查询每个关注者， 被多少人关注。 输出结果如下： follower num B 2 D 1 B 和 D 都在在 follower 字段中出现，作为博主，B 被 C 和 D 关注，D 被 E 关注。A 不在 follower 字段内，所以A不在输出列表中。 答案： 123456789101112select f1.follower, count(distinct f2.follower) as numfrom follow f1inner join follow f2 on f1.follower = f2.followeegroup by f1.followerorder by f1.follower 如何用python操作mysql步骤 安装 mysql-connector 1pip install mysql-connector 连接数据库 通过 connection 对数据库的连接进行管理， 通过 cursor 创建游标对数据库中的数据进行操作。 12345678910111213import mysql.connector# 创建数据库连接db = mysql.connector.connect( host='ip地址', user = "root", passwd = "1234", # 数据库密码 database = 'default', # 连接的数据库 auth_plugin = 'mysql_native_password" )# 获取操作游标cursor = db.cursor() 编写sql语句 123456789# 输出sql 语句sql = """select btn_namefrom cinemawhere hit_date = "2019-07-26" """ 执行sql语句并返回结果 1234567891011121314# 执行sql语句cursor.execute(sql)# 获取数据集中的所有行cursor.fetchall()# 获取数据中的第一行# cursor.fetchone()# 获取数据集中的n条数据# cursor.fetchmany(n)# 返回数据集中中的行数# cursor.rowcount 关闭游标和数据库连接 12345# 关闭游标cursor.close()# 关闭数据连接db.close() 延伸： 捕获异常信息。 在对数据进行增加、删除和修改时， 可能会出现异常，需要对异常数据进行捕获。 123456789101112131415161718import tracebacktry: sql = """INSER INTO player (team_id, player_name, height) VALUES (%s, %s, %s)""" val = (1000, "zhangyu", 1.95) # 执行sql语句 cursor.execute(sql, val) # 进行提交 db.commit() print(cursor.rowcount, "记录插入成功。")except Exception as e: # 打印异常信息 traceback.print_exc() # 回滚 db.rollback()finally: # 关闭数据库连接 db.close() 参考资料： 极客时间-sql必知必会 求出每个项目中经验最丰富的员工表：Project table project_id employee_id 1 1 1 2 1 3 2 1 2 4 表：Employee table employee_id name experience_years 1 Khaled 3 2 Ali 2 3 John 3 4 Doe 2 要求： 求出每个项目中经验最丰富的员工， 输出结果如下 ID为1和3的员工，在第一个项目中拥有最丰富的经验， 对于第二个项目， ID为1的员工拥有最丰富的经验 project_id employee_id 1 1 1 3 2 1 答案： 1234567891011select project_id, employee_idfrom (select p.project_id, e.employee_id, rank() over(partition by p.project_id order by e.experience_years desc) rn from project p, employee e where p.employee_id = e.employee_id)where rn = 1 求所有员工的平均工作经验，保留2位小数。表： Project project_id employee_id 1 1 1 2 1 3 2 1 2 4 +————-+————-+ 表：Employee employee_id name experience_years 1 Khaled 3 2 Ali 2 3 John 1 4 Doe 2 要求： 求每个部门所有员工的平均工作年限， 保留两位小数。输出结果如下 第一个项目的平均工作年限为（3+2+1）/ 3 = 2.00第二个项目的平均工作年限为（3+2）/ 2 = 2.50 project_id average_years 1 2.00 2 2.50 答案1：123456789select project_id, round(avg(experience_years),2) as average_yearsfrom Project, Employeewhere Project.employee_id = Employee.employee_idgroup by project_id 查询每个专业的学生人数 一所大学有 2 个数据表，分别是 student 和 department ，这两个表保存着每个专业的学生数据和院系数据。 表：student student_id student_name gender dept_id 1 Jack M 1 2 Jane F 1 3 Mark M 2 表：department dept_id dept_name 1 Engineering 2 Science 3 Law 要求： 查询 department 表中每个专业的学生人数 （即使没有学生的专业也需列出）。将你的查询结果按照学生人数降序排列。 如果有两个或两个以上专业有相同的学生数目，将这些部门按照部门名字的字典序从小到大排列。输出结果如下 dept_name student_number Engineering 2 Science 1 Law 0 答案1： 1234567891011SELECT a1.dept_name, COUNT(student_id) AS student_number FROM department a1 LEFT JOIN student a2 ON a1.dept_id = a2.dept_id GROUP BY a1.dept_nameORDER BY student_number DESC, a1.dept_name 答案2：12345678910111213141516select dept_name, (case when student_num is null then 0 else student_num end) student_numberfrom(select dept_id, count(*) student_numfrom studentgroup by dept_id) t1right join department t2 on t1.dept_id=t2.dept_idorder by student_number desc, dept_name asc 表：salesperson 表 salesperson 存储了所有销售员的信息。每个销售员都有一个销售员编号 sales_id 和他的名字 name 。 sales_id name salary commission_rate hire_date 1 John 100000 6 4/1/2006 2 Amy 120000 5 5/1/2010 3 Mark 65000 12 12/25/2008 4 Pam 25000 25 1/1/2005 5 Alex 50000 10 2/3/2007 表：company 表 company 存储了所有公司的信息。每个公司都有一个公司编号 com_id 和它的名字 name 。 com_id name city 1 RED Boston 2 ORANGE New York 3 YELLOW Boston 4 GREEN Austin 表： orders 表 orders 存储了所有的销售数据，包括销售员编号 sales_id 和公司编号 com_id 。| order_id | order_date | com_id | sales_id | amount ||———-|————|———|———-|——–|| 1 | 1/1/2014 | 3 | 4 | 100000 || 2 | 2/1/2014 | 4 | 5 | 5000 || 3 | 3/1/2014 | 1 | 1 | 50000 || 4 | 4/1/2014 | 1 | 4 | 25000 | 要求： 根据给定的三个表，salesperson， company， orders。输出所有表 salesperson 中，没有向公司 ‘RED’ 销售任何东西的销售员。 根据表 orders 中的订单 ‘3’ 和 ‘4’ ，容易看出只有 ‘John’ 和 ‘Pam’ 两个销售员曾经向公司 ‘RED’ 销售过。所以我们需要输出表 salesperson 中所有其他人的名字。 输出： name Amy Mark Alex 答案1： 1234567891011121314SELECT a1.nameFROM salesperson a1 LEFT JOIN orders a2 ON a1.sales_id = a2.sales_id LEFT JOIN company a3 ON a2.com_id = a3.com_idGROUP BY a1.nameHAVING SUM(IF(a3.name = 'RED', 1, 0)) = 0ORDER BY a1.sales_id 答案2： 12345678910111213select a1.namefrom salesperson a1where not exists (select * from orders a2 join company a3 on a2.com_id=a3.com_id where a3.name='RED' and a1.sales_id=a2.sales_id) 答案3：123456789101112SELECT name FROM salesperson WHERE sales_id not in (SELECT DISTINCT a1.sales_id FROM orders a1 LEFT JOIN company a2 ON a1.com_id = a2.com_id WHERE a2.name = 'RED') LeetCodeAnimation https://github.com/MisterBooo/LeetCodeAnimation leetcode 题解 https://github.com/azl397985856/leetcode LeetCode所有题目 http://leetcode.liangjiateng.cn/leetcode/game-play-analysis-ii/description SQL语句数据分析面试必备 https://mp.weixin.qq.com/s/ol-jheA3TTv0qqtFtEt_ow]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的分析思维模型]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%96%B9%E6%B3%95-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[分析思维模型 使用频率按顺序排列 1.AARRR 模型 2.基于用户生命周期的数据分析体系 对应的关键指标 3. 5W2H 分析法 什么原因 (why) 导致 什么事情 (what), 需要哪些人 (who) 在什么时间完成 (when),在什么地点 (where) 用什么方法 (how)完成, 预算是多少 (how much)? 4. 象限法 通过象限法， 找到问题的共同原因， 从而建立分组优化策略。 内外因素分解法 用户分群 RFM 用户分群 5. 二八法则 / 帕累托法则 将对象分为重要和不重要两类， 20%的用户贡献了80%的销售额。 数据中， 20% 的变量将直接产生 80% 的效果，数据分析应该围绕这20%的变量来进行。 和业务和KPI紧密相关，花费很少的精力就能达到不错的效果。 在条件允许的状况下， 依旧不能放弃全局，否则会让思维变得狭隘。补充： 升级版本： ABC 分析法 与之对应： 长尾理论 6. SWOT方法指定发展战略前，对自身进行全面的分析及竞争优势定位。 对自己进行解析 指定相应的对策 7.麦肯锡七步分析法 界定问题 将问题分解成议题 去除不重要的议题（优先排序） 制定详细工作计划 分析重要议题 汇总研究成果 准备你的故事 8.SMART原则 意义：人们在制定工作目标或者任务目标时，考虑一下目标与计划是不是SMART化的。只有具备SMART化的计划才是具有良好可实施性的，也才能指导保证计划得以实现。 说明： S代表具体(Specific)，指绩效考核要切中特定的工作指标，不能笼统； M代表可度量(Measurable)，指绩效指标是数量化或者行为化的，验证这些绩效指标的数据或者信息是可以获得的； A代表可实现(Attainable)，指绩效指标在付出努力的情况下可以实现，避免设立过高或过低的目标； R代表现实性(realistic)，指绩效指标是实实在在的，可以证明和观察； T代表有时限(time bound)，注重完成绩效指标的特定期限。 9.4P 与 STP 理论市场营销与市场定位 4P 理论 STP 理论 10.PEST分析方法企业的战略外部环境分析。 11. PDCA模型 12.时间管理 A、重要且紧急 紧急状况迫切的问题限期完成的工作你不做其他人也不能做 B、重要不紧急准备工作预防措施价值观的澄清计划人际关系的建立真正的再创造增进自己的能力 C、紧急不重要造成干扰的事、电话、信件、报告会议许多迫在眉捷的急事符合别人期望的事 D、不重要不紧急忙碌琐碎的事广告函件电话逃避性活动等待时间 13. 任务分解法 目标→任务→工作→活动。 WBS分解的原则：将主体目标逐步细化分解，最底层的任务活动可直接分派到个人去完成；每个任务原则上要求分解到不能再细分为止。 WBS分解的方法：至上而下与至下而上的充分沟通；一对一个别交流；小组讨论。 WBS分解的标准：分解后的活动结构清晰；逻辑上形成一个大的活动；集成了所有的关键因素包含临时的里程碑和监控点；所有活动全部定义清楚 14. AISAS-用户行为决策分析模型 注意- 兴趣-搜索-行动-分享 15. 延伸： 个人IPO模型 16. 波特五种竞争力分析模型 17. KANO模型 对用户需求分类和优先排序 将影响用户满意度的因素划分为五个类型，包括： 魅力因素：用户意想不到的，如果不提供此需求，用户满意度不会降低，但当提供此需求，用户满意度会有很大提升; 期望因素(一维因素)：当提供此需求，用户满意度会提升，当不提供此需求，用户满意度会降低; 必备因素：当优化此需求，用户满意度不会提升，当不提供此需求，用户满意度会大幅降低; 无差异因素：无论提供或不提供此需求，用户满意度都不会有改变，用户根本不在意; 反向因素：用户根本都没有此需求，提供后用户满意度反而会下降; 18. SCP模型 分析在行业或者企业收到表面冲击时，可能的战略调整及行为变化。 19. SPACE-战略地位与行动评价矩阵 企业的内部因素与外部因素 参考资料 分析和解决问题的7种武器]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书档案]]></title>
    <url>%2F2019%2F02%2F20%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E6%88%90%E9%95%BF%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[读书档案《麦肯锡精英高效阅读法》 2020年1月11日 阅读这本书的目的是什么阅读这本书的目的是想找到一种读书方法，能够把自己看过的书中知识运用到自己的生活中去， 给自己带来真正的改变。 读完这本书的感受是什么读完这本书的感受是书的前半段挺唠叨的，但后面介绍的建立读书档案和看完记录自己的想法，还是对自己挺有启发性的。 阅读这本书之后， 自己会采取哪些行动读完这本书之后，自己会建立自己的读书档案， 对于自己看过的有价值的书籍， 自己会写读书感想，并且经常来反复读，直到自己真正把书中的知识运用到自己的生活中去 3个月之后，自己会有什么样的改变？3个月之后，自己能够把自己的阅读习惯建立起来，对于自己看过的书，自己都能够确实把书中的知识运用到自己的生活中， 建立了自己的读书档案， 对于自己读书笔记与感想自己都能够及时复习更新。 需读书籍数据分析： 《网站分析实战》 《精益数据分析》 《运营之光》 《计算广告》 《新零售：低价高效的数据赋能之路》 《增长黑客》 《女士品茶》 《数据化管理》 《流量池》 麦肯锡： 《麦肯锡教我的思考武器》 《麦肯锡教我的写作武器》 《麦肯锡意识》 《麦肯锡方法》 《麦肯锡图表工作法》 《麦肯锡教我的谈判武器》 《麦肯锡笔记思考法》 《麦肯锡精英高效阅读法》 批判思维与逻辑思维： 《批判性思维工具》 《学会提问》 《金字塔原理》 《零秒思考》； 已写文章 行动： 每天问自己的10个问题 如何学习： 《学习之道》 《如何学习》 《刻意练习》；已写文章 《刻意学习》；读书笔记 《好好学习-个人成长指南》 ；已写文章 ； 读书笔记行动： 反思日记 《好好思考-如何链接高超学习力 如何生活： 《基本穿搭-适用一生的穿衣法则》 《奇特的一生》 《我是个怪圈》 《习惯的力量-原版》 《医治受伤的自信》 《智能时代》 《微习惯》 职场技能： 《精准表达：让你的方案在最短的时间内打动人心》 《小强升职记》 《像外行一样思考，像专家一样实践》 《你凭什么做好互联网》 《关键沟通》 《关键对话》 如何思考： 《系统之美》 《思考-快与慢》 《原则》 《怎样解题》 《第五项修炼》 《穷查理宝典》 《改变》 《万万没想到-用理工科思维理解世界》； 已写文章 适合产品经理的十本书 - 俞军入门必读 《社会心理学》 阿伦森 插图第七版：特别好，适合成为“产品经理的第一本书” 《第一本经济学》 经济学帮助人们洞察世事 《学会提问》 学习辨别信息和言论的真假对错 以上三本都是既可以当做产品经理的入门书读，又可以在职业生涯反复读的书。 思维： 《认知心理学及其启示》 人类认知和思维的基本机制 《 思考快与慢》 人如何有缺陷地思考 《 超越智商》 如何克服缺陷做理性决策 《思维与决策》 第四版 系统介绍思维与决策领域的研究 学习深度思考和决策需要的书籍，以上四本够用很久了，因为仅仅阅读多是没用的，最终还是阅读、思考、实践的最短板决定决策水平。 经济学： 《经济学原理》 曼昆版 微观分册 最通用的经济学教材 《错误的行为》 行为经济学离PM最近，但尚无好教材，先用这一本占坑 《新制度经济学 一个交易费用分析范式》 学习交易费用思考商业模式 《魔鬼经济学》 史蒂芬.列维特 《统计数据会撒谎》 统计陷阱 《超级数字天才》 《女士品茶》 其他推荐阳志平：双十一买书指南认知科学入门书单 专栏]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何整理大脑思绪]]></title>
    <url>%2F2019%2F01%2F20%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E3%80%8A%E9%9B%B6%E7%A7%92%E6%80%9D%E8%80%83%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[自己时常有这种感觉，总觉得自己的大脑反应很迟钝，思绪比较混乱，看一个问题想法很模糊，有时心情急躁却找不到问题的解决方法。工作中和别人沟通时，有时词不达意，表达不够清晰，导致工作中出现很多问题。自己也明白自己需要更加深入的思考，但总是没有找到好的办法。 最近在看《零秒思考》这本书，书中作者提供了一个解决此类问题的方法：时刻写下自己的想法。 我们每天会接受不同的信息，在脑海中会产生大量的想法与感觉。很多时候，这些想法还没有转换成语言之前，便在含混朦胧、内心纠结的状态下消失了。虽然想法会暂时忘记，但是那种纠结的感觉并没有消解，会导致自己的心情消极的，产生精神上的压力，进而让大脑变得迟钝。 时刻记录自己想法的好处是，写下来能够将纠结于心的情绪发泄出来，在写的过程中对大脑的思绪进行整理，也能更准确的表达自己的想法。这个方法的关键是：在1分钟的时间限制内，迅速写出大量自己的原始感受。 具体的做法是这样： 写标题： 写出有关大脑中思绪的一个疑问句。 写内容：写4-6行文字来写下自己的原始想法。 字数限制：每行文字字数在10-15字之间。 时间限制：在2分钟之内完成。 数量限制：每天写10条。 每个做法对应的原理是这样： 标题，用疑问句可以让自己更有写下去的冲动。 内容，写4-6行文字，能够将自己大脑中浮现的想法基本都写下来，而不至于重复。 字数，10-15字，让自己不至于写的太短而不能充分表达想法，也不会字数太长在规定时间内写不完。 时间，限制时间，避免大脑受环境和周围状况的影响。 数量，每天写10条，不会过多占用时间，更容易坚持。 书中作者要求在A4纸上写，个人感觉不是很方便，自己目前习惯于通过手机自带的【闪念胶囊】软件来进行记录。记录想法的方法与写反思日记有些相似，两者都要求把自己的想法写下来，不同之处在于，反思日记是对自己这一天做的事情进行反思记录，而记笔记是对你时刻产生的想法进行记录。 目前自己按照这个方法写了10天左右，感觉自己一个很大的变化就是下班回家走在路上，可以通过自问自答的方式来对一个问题进行深入的思考。虽然有时也想着想着就跑偏了，但是自己对于思考这件事情，不再有抵触的情绪。 书中作者还提供了通过回顾记录来挖掘价值的方法： 回顾自己的笔记， 然后再把笔记的内容当做标题， 每个标题再写4-6行。 这样自己对这类问题的思考会更加的深入。 多角度的写一个标题。 让自己对带有个人情感的内容作出更冷静的判断， 能够站在别人的角度去看问题。 将笔记按照不同领域来进行分类整理。 每三个月回顾一次笔记，了解自己面临的问题，探寻自己的成长轨迹。 最后，想说的是，看到一个方法论，我们常常会怀疑这样的方法真的有用吗，但问题本质是看你选择先相信再看见，还是先看见再相信。 我相信时刻记录想法是一个看似简单却对个人成长大有裨益的方法，所以准备践行100天再看看效果。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>思维方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反思日记]]></title>
    <url>%2F2019%2F01%2F13%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E3%80%8A%E5%A5%BD%E5%A5%BD%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[“我应该不会拒绝从头到尾把生活再过一遍，只是希望能够获得唯有作家才有的特权——在‘再版’的生活中修正‘初版’的错误，生活的悲哀之处在于我们总是老得太快而又聪明得太晚，等你不再修正的时候，你也就不再了” ——西塞罗《论老年》 在18年下半年，自己有一种感觉特别的强烈，就是总感觉时间过得飞快，而自己还什么都没有做，一周就完了，甚至自己想不到自己上周主要做了哪些事情。于是，自己想了一个办法，来抵抗这种感觉，就是每天写日记。 开始的时候，自己主要是记录自己这一天都干了什么，写了一个月之后，自己总感觉自己是在记流水账，刚好那时候，在看一本书《好好学习：个人知识精力管理指南》，里面提到了通过写反思日记的方法来掌握知识，自己按照里面的方法写了 100 多天，感觉还是非常有用的。 反思日记主要分为两个部分，反思与日记。反思就是对自己做的事进行思考，对产生结果的原因进行分析。日记则是要每天都要去写，每天都要对自己的生活进行记录。自己现在更加深刻的认识到， 一个人的变化不是突然发生的， 而是发生在每一天做的事情中的。 根据自己的实际情况，我给自己制定了反思模板，每天日记的任务主要是回答自己这7个问题。 今天自己做的不好的事情是什么？ 自己当时是怎么想的， 身体是如何反应的 如果自己再重新来一次， 自己会如何做 自己今天做的很好的事情是什么 自己目前最主要的目标是什么 自己今天任务的完成情况。 自己明天的计划是什么 这7个问题背后的原理是这样的： 问题1-3，是对自己思考方式的反思。我们平时做一件事情，是基于 假设-行动-结果 这样的过程。 而反思，就是通过 观察结果-研究原来假设-反思校正假设 这样的顺序对自己思考的再思考。 问题4， 是为了提高自己的自信心。个人认为自己在生活中不够自信，通过每天记录自己做的事情，来让自己增加自信心。 问题5，提醒自己时刻盯住自己的目标，为了自己的目标而努力。 问题6，对比昨天的计划，监督自己今天任务的完成情况。 问题7，是为明天的事情，做出一个良好的计划。 有时候，翻看自己之前的记录，会发现自己当时会面临这样的问题，回过头来再看也是比较有意思的事情，比如, 翻看自己18年10月22号的日记，发现自己是这样想的： 通过写反思日记，自己发现了一些自己反复会犯的问题。比如： 自己下班一回到房子就什么也不想干，总是在刷微博、看美剧，但是自己在看完之后，自己并没有产生放松的愉悦感，在写反思日记的时候，自己总是懊恼自己为什么这样浪费时间，这实际上是自己的精力管理方面出了问题，认识到这个问题之后，现在自己也在尝试各种方式来恢复自己的精力。 个人认为培养出记反思日记的习惯还是很有必要的，通过记录自己的生活并不断反思， 能够让我更清醒的认识到自己的不足，从而尝试做出改变。 作者在《好好学习-个人知识精力管理指南》这本书中还提到了通过写反思日记来进行对标管理，把一本书中的知识进行每日的反思等方法。大家可以根据书中的内容，指定自己的个人反思模板。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>思考方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[麦肯锡精英高效阅读法]]></title>
    <url>%2F2019%2F01%2F11%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E3%80%8A%E9%BA%A6%E8%82%AF%E9%94%A1%E7%B2%BE%E8%8B%B1%E9%AB%98%E6%95%88%E9%98%85%E8%AF%BB%E6%B3%95%E3%80%8B%2F</url>
    <content type="text"><![CDATA[2020年1月11日更新 为什么要读这本书自己常常有这种感觉，就是自己读了一本书，但是自己并没有真正的把这本书中的内容运用到自己的生活中去。 也就导致了自己明白了很多的道理， 但是还是过不好这一生。 自己最近比较喜欢这本书的作者， 我是从《零秒思考》这本书认识这位作者的，-赤羽雄二， 开始看他的《零秒思考》感觉方法比较亲民，而且感觉比较好用，就喜欢上了这位作者。 找他写过的书来看，就发现了他的这本阅读法。 看完之后，发现书中还是有什么方法自己可以用的， 于是就有了这篇读书笔记。 这本书讲了一个什么观点，自己觉得非常有用书中给自己最启发的一点，就是建立一个阅读档案，每次阅读完一本书， 自己都要写下自己从这本书中获得了什么知识， 然后自己期望自己在三个月后会有什么样的改变，等到过了三个月自己再来查看是否真的像自己想想的那样，生活发生了改变。 这让我明确了一个很好的道理， 就是你看完书之后， 一定要把书中的知识运用到自己的生活中才行， 让自己的生活真正的发生改变，否则，你看了书和没有看是一个样子的。 只有把书中的知识熟练的运用到自己的生活中去， 才是真正的读书了。 阅读完这本书，自己有什么收获读完这本书， 我准备建设自己的读书文档，真正的去记录自己的收获与自己期待的改变，并且把知识真正的运用到自己的生活中去， 而不仅仅是看过就完了。 好的书读一遍是不够的， 你可以在第一次的时候， 把自己认为重要的知识点画出来， 然后在后面再读的时候， 只看自己画的重点， 这样会更好。 读完一本书， 要把自己的感触， 自己学到的知识写写来，不是去做摘抄，而是自己真实的感触，自己的语言，不要去用别人的语言与内容。 等到三个月的时候，再来看自己的思想内容。 读书前，先思考自己为什么要读这本书， 自己想从这本书中获得什么知识。 自己后面会怎么去做，如何把书中的知识运用到生活中去记录自己的生活，形成文档，形成记录。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>思考方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析师-岗位与具备能力介绍]]></title>
    <url>%2F2018%2F12%2F22%2F%E6%96%B9%E6%B3%95-%E5%B2%97%E4%BD%8D%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[超级菜鸟如何入门数据分析 1. 数据分析师岗位介绍 什么是数据分析师？ 数据分析师， 就是专门从事数据收集、研究分析，并依据数据来指导业务决策的人员。 岗位分类 其中的数据收集、研究分析、业务指导刚好可以将数据分析的岗位分为三个大的部分： 数据收集——数据研发工程师 主要职能是搭建数据处理的基础设置，让大数据的存储、处理、计算能按要求完成，包括数据仓库搭建、数据存储、计算处理、报表开发等。 数据挖掘、算法工程师 主要是应用机器学习和数据挖掘算法，进行用户行为分析和用户属性挖掘，建立模型，预测、用户画像等为业务场景提供支持。 业务数据分析师 分析业务数据， 发现问题，分析问题，得出分析结论，为决策提供支持，主要支持市场运营部门。 如需详细了解数据分析师的岗位划分，可以参考秦路老师的文章：数据分析的职业规划 业务数据分析师的日常工作有哪些? 业务前期： 建立业务数据指标， 梳理业务数据口径， 确定数据埋点方案， 进行埋点测试，确保数据采集的准确性。 日常工作： 公司的日报、周报、月报数据支持，业务方临时性数据支持， 数据异常原因分析， 业务专题分析。 业务数据分析师的技能要求 数据分析思维和对公司业务的理解程度， 是业务数据分析的主要核心技能。 必备技能有： Excel, Hive/Sql, 统计学，PPT 软技能有： 逻辑思维能力，分析方法论， 数据敏感度， 沟通协调能力 加分技能： Python, R, 机器学习算法 业务数据分析的发展方向 业务数据分析是入门相对容易， 但要精通比较困难， 在公司属于比较基础的岗位。如果专精于业务方向， 可以往管理方面发展， 如数据运营经理/总监。也可往数据挖掘工程师方面发展， 需要进一步掌握Python和机器学习算法等知识，后面也可以往数据产品经理的方向发展。 对于我自己来说，目前的职业发展方向是业务数据分析师， 主要任务是不断学习和完善业务数据分析的所有技能， 加强互联网运营的业务理解能力，打好职业发展的基础，未来的期望是往数据挖掘方面发展。 业务数据分析师的考量标准 产品理解能力： 熟悉业务的各种核心数据，明白用户从哪里来，进来之后做了什么，了解用户反馈最多的问题是什么。 了解产品功能渗透率和关键路径，再以这些数据为切入点，思考当前产品有哪些问题，并与产品经理沟通如何优化，同时看竞品数据和行业数据，深入了解业务数据。 深入了解： 要有自己的洞见，对于整个行业，各个不同阶段的领头羊是谁，他们靠什么成为领头羊，又因为什么出现增长瓶颈，当前各自的大法测试什么，对我们自身的app有什么借鉴，后续我们要监控哪些数据。 分析方法论： 能够快速从一个较全面、逻辑性、价值性的角度去分析，而不是单点无架构分析。所有方法论都是通过不断提炼、总结、实践得出来的。 指标体系方法论 流量分析方法论 路径分析方法论 产品分析方法论 营销活动分析方法论 用户流失分析方法论 A/B 测试 可视化能力： PPT 制作能力 PPT专题报告之间的逻辑性 内容是否符合金字塔原理 数据可视化内容美观性 演讲能力： 表达能力 讲故事能力 形象化能力 协作沟通能力： 跟产品、业务、研发沟通时的软技能 如何在团队中定义好自己的位置并让其他人感到舒服 逻辑思维能力： 分析推导过程的全面性、合理性、价值型 技术能力： excel的常规操作 统计知识是否能够熟练应用 hive、sql的熟练程度 python 中常用的数据分析库能否熟练应用 算法模型是否熟练搭建并知道有哪些坑。 对数据进行分析的最佳途径： 业务梳理——了解业务需求 确定业务目标——弄清产品目标以及当下的首要问题 事件设计——记录和目标相关的用户行为，并定义为相应事件 数据采集——保证采集质量，确定好事件采集时机，和开发进行沟通 构建指标体系——确定想要看的指标，想要达到的分析粒度，建立产品的第一关键指标 数据分析——业务人员根据自己的经验，进行数据分析，迭代优化 2. 如何避免数据分析中的坑要避开哪些坑？ 不要重复无意义的工作。许多刚入行的小伙伴喜欢把清理数据作为主要工作，纪敏认为这只是让你接触数据的一种方法，每天重复地提出需求、整理表格，会磨灭掉许多对于分析师岗位的热情。 不要“全手动”，要寻找代替的工具。既然不能重复地做无意义的工作，那么就要学会用工具去代替人工，选择合适的用户行为模型和工具，能把分析师的主要精力放在规律和策略的探索上，才能充分发挥一名数据分析师应有的价值。 数据分析只是一种辅佐手段，它无法从根本上改变产品方向、功能价值，主要辅佐和支持的产品，探索更有价值的数据意义。 https://www.sensorsdata.cn/blog/20181107/ 避免数据偏见在分析数据时受个人偏见和动机的影响，即仅选择支持你声明的数据，同时丢弃不支持声明的部分。“数据偏见”将让数据的客观性荡然无存。 避免这种谬误的方法是在分析数据时，尽可能收集相关数据，并询问他人意见 避免数据疏浚数据疏浚（Data Dredging）是指未能确认相关性，实际上是偶然的结果。 在寻找问题的原因时，很容易被数据蒙蔽。乍一看，这些数据可能具有统计学意义，但进一步测试（例如，检查趋势是否持续，查看相关指标等）可能会发现只是偶然结果。 避免这种谬误的方法是在分析数据时，从假设开始检查相关指标和观察数据变化趋势。 区分因果关系和相关性 在数据分析时很容易将两个事件同时发生（相关），判断为因果关系。 避免这种谬误的方法是，收集更多数据并查看可能的第三方原因，有时会发现他们的相关关系可能与第三个独立因子相关，而不是彼此相关。 例如，我们发现放弃其在线购物车的潜在客户往往具有较低的总购物车价值（放弃时购物车中物品的总成本）。此时，我们没有足够的数据来确定这是一致的相关性，是偶然结果，还是由其他因素引起的。深入挖掘我们可能会发现运输成本导致购物车到下单的流失率上升，因为免费送货仅适用于超过特定最低购物车价值的订单。 解决问题，做出明智的决定在找到数据支持的结论后，你需要记下一个简短的摘要（包括问题，数据显示的内容以及由此产生的决策 / 行动），这样做有两个目的： 1.将你所分析的数据和结论告知可能涉及或受影响的任何其他团队，为其他人提供有价值的背景信息。 2.这个记录也将使你在将来出现类似情况时更容易参考和以防其他人想要查看数据本身。 最终，问题解决了，也总结了有价值的经验。 https://www.sensorsdata.cn/blog/20180929/ https://www.geckoboard.com/learn/data-literacy/basic-data-analysis-guide/ 一个提升用户体验的绝好方法：触点管理]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>岗位介绍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学学习]]></title>
    <url>%2F2018%2F10%2F20%2F%E6%8A%80%E8%83%BD-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前言：为什么应该学点统计学 统计学是人类发明用来研究我们自身的科学，它与我们的生活息息相关。 小到支付宝根据用户个人消费数据判断其消费水平，从而有针对性进行限额借贷。大到国家通过国民生产总值这样的统计数据分析，来研究国家经济发展趋势等， 都需要用到统计学知识。 我们可以从统计大师 Hans Rolling 的演讲中， 来看下 1960 年到 2003 年的世界各国出生率与经济发展是如何变化的。 Hans Rolling —— 统计的魅力 有人会问，统计学那么多高深的概念和复杂的算术， 在平时的生活中自己也应用不到。 这种想法其实是错误的。我们学习统计学， 不光是学习怎么对数据进行统计计算，更重要的是学会运用统计思维去更理性地看待周围的事物。 比如， 最近报道的一名美国公民在 10 月 23 号中了 16 亿美元的彩票， 看到这则消息，你会不会也有点心动， 也想去买个彩票。其实， 关于是否要买彩票，统计学有一个重要的概念来衡量：期望值 即同一种行为多次重复之后，所能得到的平均收益 举例来说， 假如某彩票规则为：每次买张彩票需要 2 元，假设 200 次抽奖可以中奖一次，奖金为 300 元。 期望值 = 300 (1/200) + 0 (199/200) = 1.5。 期望值是 1.5 元， 但是每次抽奖成本为 2 元， 于是每次净亏损 0.5 元。如果你偶尔买一次就算了， 但如果你长期买彩票，就肯定会亏很多钱。 况且现实生活中，中奖的概率远远低于 1/200 你可能会觉得，概率那么低， 那我怎么感觉天天有人中奖呢， 这背后其实是媒体的选择性报道， 也就是统计学中的幸存者偏差问题。 例如：二战期间，盟军为减少飞机在敌人防空炮火中的损失，军方决定为飞机加装防护，多数人认为，应该在机身中弹多的地方加强防护。但统计学家沃德认为，应该给那些没有中弹的油箱和驾驶部位进行防护，因为这些部位中弹的飞机根本没有机会飞回来。 现实生活中，也往往会存在一些幸存者偏差的数据，我们生活中接触的数据越来越多， 解读数据背后的信息， 辨析数据真伪就显得非常的重要，这则视频对此有更深入的讲解。 成功学有用吗？幸存者偏差，一个活着就该明白的事！李永乐老师 那么统计学到底要学什么呢？统计学主要学习两个方面: 描述统计， 描述数据的基本情况 通过研究数据的平均值，中位数，标准差等指标， 来了解数据的整体分布状况，从杂乱的数据中得出有用的信息 推理统计，根据样本数据来对总体进行估计 通过对样本数据的研究， 来对总体数据进行估计，评估推理数据的准确度，统计学中就会通过置信度， 卡方分布等来对总体进行估计。 统计学是我们将客观数据转化成有用信息的一把钥匙， 运用统计概念对一些更为广泛而大致的信息及规律进行思考， 可以改善我们做出的判断和决定。我们当然不能指望这些判断不出错误， 但每一个好的决策都会帮助你更有效的利用这些信息，积少成多，把事情做成的概率会大很多。 视频资料补充：Hans Rolling —— 东方崛起 为什么应该学点统计学 数据的乐趣 描述统计 平均数将所有数据进行平均分配 1234import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]# 均值np.mean(a) 中位数n个数据由大到小排列时，位于正中间的那个数 1234import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]# 中位数np.median(a) 众数n个数据中，出现次数最多的那个数。 12345678import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]#方法1# np.bincount, 计算非负的int数组中，每个值出现的次数counts = np.bincount(a)#[0 1 0 2 1 1 0 2 0 0 0 0 0 0 0 3]#返回沿轴最大值的索引np.argmax(counts) 12345import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]# 方法2from scipy import statsstats.mode(a)[0][0] 极差n个数据中，最大数与最小数之差 123import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]b = max(a) - min(a) 四分位数将数据从小到大排列并分成4等份后，处于3个分割点上的数。箱型图 123456import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]# 中位数np.median(a)# 45%分位数np.percentile(a, 45) 方差度量随机变量与期望值（平均值）之间的偏离程度。 公式：$\sigma ^{2} = \frac{ \sum_{i=1}^{N}(x_{i}-\mu)^{2}}{N}$ 计算步骤： 求平均值 求 (各数值 - 平均值) 的值 以 (各数值 - 平均值) 的平均数为标准，无法看出以平均数为基准数据的离散程度。因为两数相减结果有正有负，相加之后会互相抵消。 为使 (各数值 - 平均值) 的差值即使为负也能显示出差值，可以将 (各数值 - 平均值)的值平方之后，再取平均值。 求 (各数值 - 平均值)² 的值 求 (各数值 - 平均值)² 的平均值 方差问题： 数值时有会过大 单位为原先单位的平方 123import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]np.var(a) 标准差标准差越小，说明数据大多数集中于平均值附近，偏差不大。公式：$\sigma = \sqrt{\sigma ^{2}} =\sqrt{\frac{ \sum_{i=1}^{N}(x_{i}-\mu)^{2}}{N}} $计算步骤： 计算出方差后开根号 123import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15]np.std(a) 常见的因果关系 某个原因导致的结果唯一，导致某个结果的原因也是唯一的。 某个原因导致的结果唯一，导致某个结果的原因不唯一。 某个原因导致的结果不唯一，导致某个结果的原因唯一。 某个原因导致的结果不唯一，导致某个结果的原因也不唯一。 相关系数表示相关关系的正负与强弱的系数相关系数r的范围是-1≤r≤1判断相关关系强弱的标准： 123456789101112131415# 写法1a = [1,2,3,4]b = [2,4, 6,9]import numpy as npnp.corrcoef([a,b])# 写法2import scipy.stats as statsstats.pearsonr(a,b)# 结果的第一个数为相关系数# 写法3import pandas as pddf= pd.DataFrame()df['a'] = [1,2,3,4]df['b'] = [2,4, 6,9]df.corr() 概率 排列从N项中任取n项，并进行排列，决策的顺序的结果有影响。公式：$P_{n}^{N} = \frac{N!}{(N-n)!}$ 12from scipy.special import comb, permperm(5,2) 组合从N项中任取n项,不考虑顺序。公式：$c_{n}^{N} = \frac{N!}{n!(N-n)!}$ 12from scipy.special import comb, permcomb(5,2) 补充资料： 5分钟彻底了解排列组合 事件 事件的补: $P(A) = 1 - P (A^{c})$ 事件的并：$P(A\bigcup B ) = P(A) + P(A) - P(A\bigcap B )$ 互斥事件：$P(A\bigcup B ) = P(A) + P(B)$ 独立事件：$P(A\bigcap B) = P(A) * P(B)$ 条件概率在事件B发生的条件下， A条件发生的概率公式： $P(A|B ) = \frac{P(A\bigcap B)}{P(B)}$ $P(A\bigcup B) = P(B) P(A|B) = P(A) P(B|A)$ 二项分布概念： 成功率为P的实验，独立重复 n 次后的成功次数为 x 的概率分布。 公式： 案例：在各类促销活动中， 抽奖是一种常见的促销方式。现在希望运营方设计一个抽奖模式。用户能够抽10次，中奖概率是10%。如果用户抽中了3次及以上， 则公司会亏本。那么公司亏本的概率是多少？ 正态分布性质： 均值 = 中位数 = 众数 沿中心线对称，一半在平均值左侧，一半在平均值右侧。 特点： 69%的数值在离平均值一个标准差之内 95%的数值在离平均值2个标准差之内 99.7%的数值在离平均值3个标准差之内 补充资料： 正态分布为什么常见？ 正态分布 数据标准化-Z-Score公式： z = (x - u) / 方差目的：消除指标之间的量纲和取值范围差异的影响 补充资料：数据规范化（归一化）、及Z-score标准化 切比雪夫定理 至少有75%的数据在两个标准差之内 至少有89%的数据在三个标准差之内 至少有95%的数据在5个标准差之内 举例： 若一班有36个学生，而在一次考试中，平均分是80分，标准差是10分，我们便可得出结论：少于50分（与平均相差3个标准差以上）的人，数目不多于4个（=36*1/9） 作用： 用于异常值检测 贝叶斯定理 如何判断她喜欢你的概率贝叶斯定理计算方法： 先假定一个概率， 然后根据样本获得新的信息， 根据这些信息对 原先假设的概率进行修正， 得到准确的概率。公式：$P(A|B) = \frac{P(A) * P(B|A)}{P(B)}$ 假设 你是一名女生， 在情人节这天， 一名男生送给你一盒巧克力， 你可能会有疑问，他是不是喜欢你， 他喜欢你的概率是多大？ 因为你没有证据来说明你就是他喜欢的类型， 所以， 我们假设 你或者是他喜欢的类型， 或者是一名路人。 假设各有50%的概率。 通过调查， 我们发现 一个男生对心意女生送出巧克力的概率为 45% 对路人送出巧克力的概率 为 20%， 那他现在送给你一盒巧克力， 在他已经送你巧克力的这件事情已经确定了， 所以他们现在是一个整体。他喜欢你的概率是多少呢。 45% / (45% + 20%) = 69.2%当他送你巧克力时，大概有69、2%的概率会喜欢你 当然， 贝叶斯概率 能够计算出这个概率， 但是否要继续， 取决与你。 贝叶斯概率在我们生活中的应用是非常广泛的， 常见的， 比如 在邮件中的反垃圾邮件。 这是一种贝叶斯概率非常好的使用案例。 在上面的推理中， 我们总会觉得贝叶斯定理有些“牵强”,牵强的原因主要是因为先验概率。 这种主观上假定或者大概的概率， 会让人感觉牵强。 但也正是由于设定了先验概率， 贝叶斯定理才会有即是只有少量信息， 也能够进行推理。 当然， 贝叶斯定理有另一学习功能， 就是信息越多， 推理结果就越精确。 快速理解贝叶斯定理 假设一家商城， 顾客分为： 想买商品的顾客，和随便逛逛的顾客。 假设， 随机走进来一个顾客，他为有意愿度的顾客占20%， 为随便逛逛的顾客占80%。 现在增加了一个主动询问店员的动作。 假设有意愿度购买的顾客， 向店员询问的概率为70%， 不询问的概率为30%。 随便逛逛的客户， 主动询问店员的购买概率为 10%， 不询问的概率为 90%。 现在问 如果一顾客主动向店员询问， 那么他是有意愿购买的顾客的概率是多少。 有意向且询问的概率为 14%。 有意向不询问的概率为 6% 无意向且询问的概率为 8%， 无意向且不询问的概率为 72% 现在 主动询问这个动作已经做出了， 所以总体为两部分： 有意向且询问， 和无意向且询问 14:8 = 7:4。 所以她有意向且愿意购买的概率为 7/11 63.6% 贝叶斯： 通过结果来反推原因 参加活动的人群中，女性只占30%， 是否说明女性不喜欢参加此类活动？ 某种疾病的发病率为千分之一。现在有一种试纸，它在患者得病的情况下，有99%的准确率判断患者得病，在患者没有得病的情况下，有5%的可能误判患者得病。现在试纸说一个患者得了病，那么患者真的患病的概率是多少？ 某城市有两种颜色的出租车，蓝车和绿车市场比率为15:85。 一辆出租车肇事逃逸，当时有一位目击者证人，这位证人认定肇事的出租车是蓝色的。但是他的目击未必可信，公安人员经过在相同环境下对该目击者进行“蓝绿”测试得到：80%的情况下识别正确，20%的情况下不正确。那么实际为蓝车的可能性是多少？ 我们经常会受到垃圾短信，假设1000条正常短信中，包含【澳门赌场】的短信有2条，而在垃圾短信中，包含澳门短信的短信有400条。现在我们接受到了一条新短信，在不浏览内容的情况下，假定它的正常几率是50%。现在对短信内容进行解析，发现澳门赌场这个词，那么它是垃圾短信的概率有多高。 补充资料： 数学之美番外篇：平凡而又神奇的贝叶斯方法 《统计学关我什么事》 贝叶斯推断及其互联网应用（一）：定理简介 贝叶斯学习与未来人工智能 统计学网站 看见统计学 数学很好玩 数据可视化-博客 数学公式转换为markdown格式 《写给所有人的极简统计学》]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《beyond feelings》]]></title>
    <url>%2F2018%2F10%2F14%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E3%80%8ABeyond%20Feelings%E3%80%8B%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[Part one the contextPrefacewhen the first edition of this book appeared in 1975, the dominant intellectual focus was still subjectivity, feelings. 当这本书的第一版于1975年问世时，主要的思想重点仍然是主观性，_感觉_。 that focus, the legacy of the 1960s, was originally a necessary reaction to the rationalism and behaviorism that preceded it. 这种关注是20世纪60年代遗留下来的，最初是对之前的理性主义和行为主义的必然反应。 it declared, in effect:”people are not robots. they are more than the sum total of their physiology. they have hopes, dreams, emotions. 它实际上宣称:“人不是机器人。它们比它们生理机能的总和还要多。他们有希望、梦想和情感。 No tow humans are alike-each has a special perspective, a unique way of perceiving the world. And any view of humanity that ignores this subjective side is a distortion.” 没有两个人是相似的——每个人都有独特的视角，独特的感知世界的方式。任何忽视这一主观方面的人性观都是一种扭曲 Yet, desplite its value, the focus on feelings went too far. 然而，抛开它的价值不谈，对情感的关注太过了。 like many other movements, what began as a reaction against an extreme view became an extreme view itself. 和其他许多运动一样，一开始是对极端观点的反对，后来变成了极端观点本身。 The result of that extremism was the neglect of thinking. The book was designed to answer that neglect. 这种极端主义的结果是对思考的忽视。 这本书就是为回答这种忽视而写的。 The introduction to the first edition explained its rationaale as follows. 第一版的导言解释了它的原理如下： The emphasis on subjectivity served to correct a dangerous oversimplification. 强调主观性有助于纠正一种危险的过分简单化。 But it is the kind of reaction that connot be sustained for long without causing an even worse situation - the neglect of thinking. 但是这种反应不可能持续很长时间，而不引起更糟糕的情况-忽略思考。 Worse for two reasons. First, because we live in an age of manipulation. 更糟糕有两个原因。 首先，因为我们生活在一个被操控的时代。 Armies of hucksters and demagogues stand ready with the rich resources of psychology to play upon our emotions and subconscious needs to persuade us that superficial is profound, harmful is beneficial, evil is virtuous. 成群结队的小贩 和蛊惑人心的政客 随时准备利用丰富的心理学知识来利用我们的情绪，潜意识里需要说服我们，肤浅是深刻的，有害是有益的，邪恶是善良的。 And feelings are especially vulnerable to such manipulation. 感觉尤其容易受到这种操纵。 Secondly, because in virtually every important area of modern life - law, medicine, government, education, science, business, and community affairs - we are beset with serious problems and complex issues that demand careful gathering and weighing of facts and informed opinions, thoughtful consideration of various conclusions or actions, and judicious selection of the best conclusion or most appropriate action …. 第二， 因为在现在生活的每一个重要领域-法律，医学，政府，教育，科技，商业和社区事务等- 我们面临严重和复杂的问题，需要认真收集和权衡事实和知情意见，对各种结论和行动进行深思熟虑，并且明智的选择最佳结论和适当的行动…. Today’s college student has been conditioned not to undervalue subjectivity, but to overvalue it. 如今的大学生已经不会低估主观性，而是高估它。 Rather, he needs to be taught how to sort out his feelings, decide to what extent they have been shaped by external influences, and evaluate them carefully when they conflict among themselves or with the feelings of others. 相反， 他需要思考如何理清他自己的感受，决定他们在多大程度上受到外部的影响的影响，并在它们之间与他人的感受发生冲突时仔细评估他们。 In short, he needs to be taught to think critically. 简而言之，他需要学会批判性思考。 there is an unfortunate tendency among many to view feeling and thought as mutually exclusive, to force a choice between them. 很多人有一种不幸的倾向，认为情感和思想是互斥的，要在两者之间做出选择。 If we focus on one, then in their view we must reject the other. 如果我们只关注其中的一个， 在他们看来， 我们必须抛弃另一个。 But this is mistaken.Feeling and thought are perfectly complementary. 但这时错误的。 感觉和思想是完全互补的。 Feeling, being more spontaneous, is an excellent beginning to the developement of conclusions. 感觉，更自然，是结论发展的良好开端。 And thought, being more deliberate, provides a way to identify the best and most appropriate feeling. Both are natural. 而思考，更为深思熟虑，提供了一种确定最佳和最合适感觉的方法。两者都是自然的。 Thinking, however, is less automatic than feeling. To do it well demands a systematic approach and guided practice. 然而，思考不如感觉那么自然。做好这项工作需要有系统的方法和引导的练习。 The general attitude toward thinking has changed confiderably since the mid-1970s. 自20年代中期以来，人们对思维的普遍态度发生了根本性的改变。 The view that critical thinking is an important skill to which education should give prominence is no longer a minority view. 批判性思维是教育应该重视的一项重要技能，这一观点不再是少数人的观点。 Hundreds of voices have joined the chorus calling for the addition of critical thinking objectives to existing courses and even the creation of special courses in thinking. 数以百计的声音要求在现有的课程中加入批判性思维目标， 甚至要求开设专门的思想课程。 There is little disagreement that the challenges of the newmillennium demand minds that can move beyond feelings to clear,impartial, critical problem solving and decision making. 毫无疑问，新千年的挑战要求我们的大脑能够超越情感，去清晰地、公平的，关键的问题解决和决策。 Features of This Edition 本版特色This edition of Beyond Feelings retains the basic organization of previous editons. 这版《超越感觉》 保持了以前版本的基本结构。 The first section explains the psychological, philosophical, and social context in which critical thinking takes place and describes the habits and attitudes that enhance such thinking. 第一节解释了批判性思维发生的心理学、哲学、和社会背景并且描述了促进这种思维的习惯和态度。 The second section helps students recognize and overcome common errors in thinking. 第二节帮助学生认识并克服思维中的常见错误。 The third section provides a step-by-step strategy for dealing with issues. 第三节提供了一个逐步的策略去处理这种错误。 Within the overall design, however, I have made a number of changes, most in response to the helpful suggestions of reviewers. 然而，在总体设计范围内，我做了一系列的改变，大部分是为了回应评论者的有益建议。 In Chapter 1, a new section - “The influence of ideas” - has been added. 在第一章，增加了一个新的章节：思考的影响。 In Chapter 3, a new section - “Understanding Cause and Effect” - has been added. 在第三章， 增加了一个新的章节：了解因果关系 In chapter 15, new examples of the value of observation have been added. 在第15章，增加了观察价值的新例子。 In Chapter 17, the subsection “Evaluate your information sources” has been expanded. 在第17章，”评估你的信息源“部分被扩展。 A number of new “Difference of Opinion” exercises have been added. 添加了一些新的“意见分歧”练习 As in the past, I have attempted to follow George Orwell’s sage advice:” Never use a foreign phrase, a scientific word, or a jargon word if you can think of an everyday English equivalent.” 和过去一样，我也试着遵循乔治.奥威尔的明智建议：如果你能够想到一个日常英语的对等词，就不要使用外来词、科学词或行话。 This is not always easy. When logicians are taught terms such as argumentum as hominem, non sequitur, and “affirming the consequent,” they naturally want to use them. 这并不容易做到。 这并不总是容易的。当逻辑学家被教授诸如“论证是人”、“非推理”、“肯定结果”等术语时，他们自然想要使用它们。 Arguments for doing so urge themselves upon us: for example, “These are the most preise terms. Don’t join the ranks of the coddlers and deprive students of them.” 这样做的理由不断地在我们面前出现:例如，“这些是最具说服力的术语。”不要加入娇生惯养的行列，剥夺学生的权利。” In weak moments i succumb to this appeal.(Until the previous edition, for example, i included the term enthymeme. Mea culpa… there i go again.) 在脆弱的时刻，我屈服于这样的吸引力。(例如，在上一版之前，我一直使用“推理论证”这个词。认错……我又来了) But is the precision of such terms the real reason for my wanting to use them? 但是这些术语的精确性是我想要使用它们的真正原因吗? Is it not possible that we professors enjoy parading our knowledge or that we are reluctant to spare our students the struggle we were forced to undergo(“We suffered, so they should too”)? 难道我们教授不喜欢炫耀我们的知识吗?难道我们更愿意让我们的学生去经历我们被迫经历的斗争吗? It seems to me that modern culture already provides too many impediments to critical thinking for us to add more. 在我看来，我们的现代化思维已经给批判性思维提供了太多的阻碍。 Is it possible to carry this plain language commitment too far? 有没有可能把这种直白的承诺说得太过了? Yes, and some will think i have done so in avoiding the term inferences and speaking instead of conclusions.But i respectfully disagree. 是的，有些人会认为我这样做是为了避免使用“推论”一词，是为了避免得出结论。 但我不同意 Lexicographers point out that the distinction between these thems is extremely subtle, so it seems more reasonable not to devote time to it. 词典编纂者指出，这两个词之间的区别极其细微，所以不花时间研究它们似乎更有道理。 Also, i avoid using the term values whenever possible for a somewhat different reason. 此外，出于某种不同的原因，我尽量避免使用术语值 The word value is so associated with relativism that its use in this contest can undermine the crucial idea that arguments differ in quality. “价值”这个词与相对主义联系如此紧密，以至于它在这场辩论中的使用可能会破坏争论质量不同这一关键观点。 For many students, the word value triggers the thought, “Everyone has a right to his or her values; mine are right for me, and though they may need ‘clarification’ from time to time, they are never to be questioned.” this thought impedes critical thinking. 对许多学生来说，“价值”这个词引发了这样一种想法:“每个人都有权拥有自己的价值;我的想法对我来说是正确的，虽然他们可能需要不时的‘澄清’，但他们永远不会被质疑。这种想法阻碍了批判性思维 Introduction 介绍 Beyond Feeling is designed to introduce you to the subject of critical thinking. 《超越感觉》 主要向你介绍批判性思维的主题。 The subject may be new to you because it has not been emphasized in most elementary and secondary schools. 这个主题或许对你来说是新的，因它在大多数小学和中学并没有被强调。 In fact, until fairly recently, most colleges gave it little attention. 事实上，直到最近，大多数大学都很少关注批判性思维。 For the past four decades, the dominant emphasis has been on subjectivity rather than objectivity, on feeling rather than on thought. 在过去的四十年里， 主要强调的是主观性而不是客观性，强调的是感觉而不是思考。 Over the past several decades, however, a number of studies of Ameirca’s schools have criticized the neglect of critical thinking, and a growing number of educators and leaders in business, industry, and the professions have urged the development of new courses and teaching materials to overcome that neglect. 然而，在过去的几十年里， 许多对美国大学教育的研究，批评了对批判性思维的忽视，越来越多的教育工作者和商业、工业和专业领域的领导者敦促开发新的课程和教材来克服这种忽视。 It is no exaggeration to say that critical thinking is one of the most important subjects you will study in college regardless of your academic major. 毫不夸张的说，无论你在大学里主修的是什么课程，批判性思维都是一门非常重要的学科。 The quality of your schoolwork, your efforts in your career, your contributions to community life, your conduct of personal affairs-all will depend to your ability to solve problems and make decision. 你学业的质量，你在事业上的努力， 你对社会生活的贡献，你处理个人事务的方式，都依赖于你解决问题和做决定的能力。 The book has three main sections.The first, “The Contest,” will help you understand such important concepts as individuality, critical thinking, truth, knowledge, opinion, evidence, and argument and overcome attitudes and ideas that obstruct critical thinking. 这本书主要分为三部分。 第一部分“竞赛”，将帮助你理解一些非常重要的概念，例如：个性、批判性思考，真理， 知识，观点，证据和论证，克服阻碍批判性思维的态度和方法。 The second section, “The Pitfalls,” will teach you to recogize and avoid the most common errors in thinking. 第二部分“陷阱”， 将教会你认识并且避免思考中一些常见的错误。 The third section,”A Strategy,” will help you acquire the various skills used in addressing problems and issues. 第三部分“策略”， 将帮助你获得处理问题时使用的各种技能。 This section includes tips on identifying and overcoming your personal intellectual weaknesses as well as techniques for becoming more observant, clarifying issues, conducting inquires, evaluating evidence, analyzing other people’s views, and making sound judgments. 本节包括识别和克服个人智力上弱点的技巧，以及变得更善于观察、澄清问题、进行调查、评估证据、分析他人观点和做出合理判断的技巧。 At the end of each chapter, you will find a number of applications to challenge your critical thinking and help you exercise your skills. 在每一章的最后， 你都会发现一些应用程序来挑战你的批判性思维并且帮助你训练你的技能。 These applications cover problems and issues both timely and timeless. 这些应用程序涵盖了及时和永恒的问题。 The final application in each of the first thirteen chapters invites you to examine an especially important issue about which informed opinion is divided. 在前13章的每一章的最后应用邀请你检查一个特别重要的问题，关于它的明智的意见是有分歧的。 Students sometimes get the idea that a textbook must be read page by page and that reading ahead violates some unwritten rule. 学生有时会有这样的想法： 书本必须逐页逐页的去阅读，提前阅读违反了一些不成文的规定。 This notion is mistaken. Student’s background knowledge varies widely; what one student knows very well, another knows only vaguely and a third is totally unfamiliar with. 这种观念是错误的。学生们的知识背景差别很大。一个学生知道的很清楚， 另一个知道的很模糊，剩下的三分之一的学生一点都不清楚。 Any time you need or want to look ahead to an explanation in a later chapter, by all means do so. 任何时候，你需要或者想在后面的章节中看到一个解释，一定要这样做，去跳跃的阅读。 Let’s say you make a statement and a friend says, “That’s relativism, pure and simple.” IF your aren’t sure exactly waht she means, go to the index, look up “relativism,” proceed to the appropriate page, and find out. 假设你做了一个陈述， 一个朋友说：这是相对论， 纯粹且简单。如果你不能准确理解他的含义， 查看索引，查看“相对论”， 转到相应的页面，并且找到答案。 Looking ahead is especially prudent in the case of concepts and procedures relevant to the end-of-chapter applications. 在与本章结尾应用程序相关的概念和程序方面，向前看是特别谨慎的。 One such concept is plagiarism. If yor are not completely clear on what constitutes plagiarism, why it is unacceptable, and how to avoid it, take a few minutes right now to learn. 其中的一个概念就是剽窃. 如果你完全不清楚什么是剽窃，为什么是不可接受的，以及如何避免，现在就花几分钟来学习。 Look for the section “Avoiding Plagiarism” toward the end of the Chapter 2. z在第二章末尾找到“避免剽窃”的章节。 Similarly, if yor are not as skilled as you would like to be doing library or Internet research, it would be a good idea to read Chapter 17 now. 同样的，如果你不像你想做的图书馆或互联网研究那样熟练，现在读第17章是个好主意。 Doing so could save you a great deal of time and effort completing homework assignments. 这样做可以节省你完成家庭作业的大量时间和精力。 The Context 上下文Anyone who wishes to master an activity must first understand its tools and rules. 任何想要掌握一项活动的人都必须首先知道他的工具和规则。 This is as true of critical thinking as it is of golf, carpentry, flying a plane, or brain surgery. 就像和掌握高尔夫、木工、开飞机、或脑部手术一样，批判性思维也是如此。 In critical thinking, however, the tools are not material objects but concepts, and the rules govern mental rather than physical performance. 然而，在批判性思维里， 工具并不是物品而是概念，这些规则支配着精神上的表现而不是身体上的表现。 This first section explores seven important concepts - individuality, critical thinking, truth, knowledge, opinion, evidence, and argument - with a chapter devoted to each. 第一节探讨了七个重要的概念：个性、批判性思维、真理、知识、观点、证据、论点，每一章都有专门的论述。 Most of these concepts are so familiar that you may be inclined to wonder whether there is any point to examining them. The answer is yes, for three reasons. 这些概念中大多都是如此的熟悉，以至于你可能怀疑是否有必要对它们进行研究。答案是肯定的，原因有三。 First, much of what is commonly believed about these concepts is mistaken. 首先，人们对这些概念的普遍看法是错误的。 Second, who ever examines them carefully is always rewarded wiht fresh insights. 第二，凡是仔细研究的人，总是能获得新的见解。 Third, the more thorough your knowledge of these concepts, the more proficient you will be in your thinking. 第三，你对这些概念的了解越透彻，你的思维就越熟练。 who are you?Suppose someone asked, “Who are you?.” It would be simple enough to respond with your name. 假设有人问： 你是谁。用你的名字来回答可能足够简单。 But if the person wanted to know the entire story about who you are, thequestion would be more difficult to answer. 但是如果那个人如果想知道你是谁，这个问题可能有更多的答案。 You’d also have to include all your sentiments and preferences, even the secret ones you’ve never shared with anyone-your affection for your loved ones; 你还必须包括你所有的情感和喜好，即是是那些你从未和别人分享过你对你所爱的人的爱的秘密。 your desire to please the people you associate with; your dislike of your older sister’s husband; your allegiance to your favorite beverage, brand of clothing, and music. 你想取悦与你交往的人；你不喜欢你姐姐的丈夫；你对你最喜欢的饮料、服装品牌和音乐的忠诚。 Your attitudes couldn’t be overlooked either - your impatience when an issue gets complex, your aversion to certain courses, your fear of high places and dogs and speaking in public. 你的态度也不容忽视， 当一个问题变得复杂时，你的不耐烦，你对某些课程的厌恶， 你害怕高处和狗，害怕在公众面前说话。 The list would go on. To be complete, it would have to include all your characteristics - not only the physical also the emotional and intellectual. 这样的例子不胜枚举.为了完整，它必须包括你所有的特征- 不只是身体部分， 还包括情感和智力上的。 To provide all then information would be quite a chore. 提供所有这些信息是一件很麻烦的事情。 But suppose the questioner was still curious and asked, “How did you get the way you are?” 但假设提问者仍然很好奇，问道:“你是怎么变成现在这个样子的?” If your patience were not yet exhausted, chances are you’d answer something like this: “I’m this way because i choose to be, because I’ve considered other sentiments and preferences and attitudes and have made my selections. 如果你的耐心没有被耗尽， 你可能会回答这样的问题：我这样做是因为我选择这样做。 因为我考虑了其他的情感、偏好和态度，并做出了我的选择。 The ones i have chosen fit my style and personality best.” 我选择的那些最适合我的个性和风格。 That answer is natural enough, and in part it’s true.But in a larger sense, it’s not true. 这个答案很自然， 在一定程度上是正确的， 但在更大的意义上，它是不正确的。 The impact of the world on all of us is much greater than most of us realize. 世界对我们所有人的影响比我们认识的要多得多。 The influence of Time and Place Not only are you a member of a particular species.Homo sapiens, but you also exist at a particular time in the history of that species and in a particular place on the planet. 你不仅是一个特定物种的成员。智人，但你也存在于那个物种历史上的某个特定时期，存在于地球上某个特定的地方。 That time and place are defined by specific circumstances, understandings, beliefs, and customs, all of which limit your experience and influence your thought patterns. 时间和底单是由特定的额环境、理解、信仰和习俗来定义的，所有这些都限制了你的经验并影响了你的思维模式。 If you had lived in America in colonial times, you likely would have had no objection to the practice of barring women from serving on a jury, entering into a legal contract, owning property, or voting. 如果你生活在美国殖民时期， 你可能不会反对禁止女性担任陪审团成员，签订法律合同、拥有财产或投票的做法。 If you had lived in the nineteenth century, you would have had no objection to young children being denied an education and being hired out by their parents to work sixteen hours a day, nor would you have given and thought to the special needs of adolescence.(The concept of adolescence was not invented until 1904) 如果你生活在19世纪， 你可能不会反对剥夺年轻的孩子受教育的权利，并且雇佣他们的父母一天工作16个小时，你也不会考虑到青少年的特殊需要。 如果你生活在19世纪，你就不会反对剥夺孩子受教育的权利，让他们的父母每天工作16个小时，你也不会考虑和考虑青少年的特殊需要。（青春期的概念直到1904年才被提出） If you had been raised in the Middle East, you would stand muchcloser to people you converse with than you do in America. 如果你在美国中东长大，你会站得比离你交谈的人更近。 If you had been raised in India, you might be perfectly comfortable having your parents choose your spouse for you. 如果你在印度长大， 你或许会对你父母替你选择伴侣的行为感到享受。 If your native language were Spanish and your knowledge of English modest, you probably would be confused by some Englishcolloquialisms. 如果你的母语是西班牙语，而你的英语水平一般，你可能会被一些英语口语混淆。 James Henslin offers two amusing examples of such confusion: Chevrolet Novas initially sold very poorly in Mexico because no va in Spanish means “it doesn’t work”; and Perdue chickens were regarded with a certain suspicion (or worse) because the company’s slogan - “It takes a tough man to make a tender chicken” - became in Spanish “It takes an aroused man to make a chicken affectionate.” 詹姆斯·亨斯林举了两个有趣的例子来说明这种困惑: 雪佛兰Novas一开始在墨西哥卖得很差，因为“no va”在西班牙语中的意思是“不行”,并且人们对普度鸡有一定的怀疑(或者更糟)，因为公司的口号是：坚强的人做不出嫩鸡。这在西班牙语中的含义是： 在西班牙语中变成了“需要一个被唤起的男人使一只鸡充满深情。” People who grow up in Europe, Asia, or South America have very different ideas of punctuality. 在欧洲、亚洲或南美长大的人对守时有非常不同的看法。 As Daniel Goleman explains, “Five minutes is late but permissible for a business appointment in the U.S, but thirty minutes is normal in Arab countries. 丹尼尔·戈尔曼解释说： 在美国，商业约会迟到5分钟是语序的， 但在五分钟内的迟到是被允许的， 但在阿拉伯国家，30分钟是正常的。 In England five to fifteen minutes is the ‘correct’ lateness for one invited to dinner; an Italian might come two hours late, an Ethiopian still later, a Javanese not at all, having accepted only to prevent his host’s losing face.” 在英国，晚餐邀请迟到5-15分钟是正常的迟到，意大利人或许能迟到2个小时。埃塞俄比亚人可以一直迟到，而瓜哇人则可能根本不会来，他们接受邀请只是为了不让主人丢脸。 A different ethnic origin would also mean different tastes in food. 不同的人种起源意味着对食物有不同的味觉。 Instead of craving a New York Strip steak and french fries, you might crave “raw monkey brains” or “ camel’s milk cheese pattties cured in dry camel’s dung” and washed down with “warm camel’s blood.” 你可能会想吃“生猴脑”或“用干骆驼粪腌制的骆驼奶芝士饼”，并蘸着“温暖的骆驼血”吞下去，而不是想吃纽约的牛排和炸薯条。 Sociologist Ian Robertson summed up the rang of global dietary differences succinctly: “ Americans eat oysters but not snails. 社会学家伊恩·罗伯逊简明扼要地总结了全球饮食差异的范围:“美国人吃牡蛎，但不吃蜗牛。 The French eat snails but not locusts. The Zulus eat locusts but not fish. The Jews eat fish but not pork. 法国人吃蜗牛，不吃蝗虫。祖鲁人吃蝗虫，不吃鱼。犹太人吃鱼，不吃猪肉。 The Hindus eat pork but not beef. The Russians eat beef but not snakes. The Chines eat snakes but not people. The Jale of New Guinea find people delicious.” [Note: The reference to Hidus is mistaken]印度教徒吃猪肉而不是牛肉。俄国人吃牛肉，但不吃蛇。中国人吃蛇，但不吃人。新几内亚人发现人很好吃。[注:对印度教徒的引用是错误的。] To sum up, living in a difference age or culture would make you a different person. 总结， 生活在不同的岁月和文化中造就了你是一个不同的人。 Even if you rebelled against the values of your time and place, they still would represent the context of your life - in other worlds, they still would influence your responses. 即使你违背了你当前时间和地点的价值观，它们仍然会代表你的生活背景——换句话说，它们仍然会影响你的反应。 The Influence of Ideas 思维的影响 When one idea is expressed, closely related ideas are simultaneously conveyed, logically and inescapably. 当一个想法被表达出来时，同时相关的有逻辑性的，密不可分的想法也会表达出来。 In logic, this kinship is expressed by the term sequitur, Lation for “it follows”.(The converse is non sequitur, “it does not follow.”) 在逻辑上，这种亲缘关系是由推理这个术语来表达的，推理是“它跟随”的缩写。(反之则是不合逻辑的，“它不遵循”。) Consider, for example, the idea that many teachers and parents express to young children as a way of encouraging them:” If you believe in yourself, you can succeed at anything.” 例如： 想一想需要老师和家长为鼓励孩子们所说的一句话：“如果你相信你自己，你做任何事情都能够成功的。” From this it follows that nothing else but belief-neither talent nor hard work - is necessary for sucess. 由此可见，天赋和努力都不是成功的必要条件，只有相信才是。 The reason the two ideas are equivalent is that their meanings are inseparably linked. 这两种思想之所以是相同的， 是因为他们的概念密不可分。 Similarly, research has shown that human memory can be manipulated. 同样的，研究表明人类的记忆能够被操控。 The way a question is aksed can change the details in a person’s memory and even make a person remember something that never happened! 提问的方式可以改变一个人记忆的细节，甚至让一个人记起从未发生过的事情。 Of course, advertisers and people with political or social agendas are not content to stimulate emotions and/or plant ideas in our minds. 当然，广告商和有政治或社会议程的人不满足于刺激我们的情绪更希望在我们的头脑中植入想法。 They also seek to reinforce those impressions by repeating them again and again. 他们还通过一次次的重复来加强这些印象。 The more people hear a slogan or talking point, the more familiar it becomes. 人们听到一个口号或话题越多，就会越熟悉。 Before long, it becomes indistinguishable form ideas developed through careful thought. 没过多久，它就变成了经过仔细思考而形成的难以辨别的思想。 Sadly, “the packaging is often done so effectively that the viewer, listener, or reader does not make up his own mind at all. 可悲的是， 这种包装通常是有效的， 以至于观众、听众、读者根本无法做出自己的决定。 Instead, he inserts a packaged opinion into his mind, somewhat like inserting a DVD into a DVD player. 相反，他在脑中植入了一个观点，有点像你在DVD播放器里插入了一张DVD. He then pushes a button and ‘plays back’ the opinion whenever it seems appropriate to do so. 然后他按下一个按钮，在适当的时候“回放”这个观点。 He has performed acceptably without having had to think.” 他不用思考，表现的很好 Many of the beliefs we hold dearest and defend most vigorously may have been planted in our minds in just this way. 我们最珍视、最积极捍卫的许多信念可能就是这样在我们的头脑中扎根的。 Many years ago, Harry A.Overstreet noted that “a climate of opinion, like a physical climate, is so pervasive a thing that those who live within it and know no other take it for granted.” 许多年前，哈里。奥弗斯特里特指出，“一种意见的气候，就像一种物理气候，是如此普遍，以至于那些生活在其中，不知道其他事物存在的人都认为它是理所当然的。 TH Influence of Psychology The social and psychological theories of our time also have an impact on our beliefs. 我们这个时代的社会和心理理论也会对我们的信念产生影响。 Before the past few decades, people were urged to be self-disciplined, self-critical, and self-effacing. 在过去的几十年之前，人们被要求自律、自我批评、谦逊。 They were urged to practice self-denial, to aspire to self-knowledge, to behave in a manner that ensured they maintained self-respect. 他们被敦促进行自我否定，渴望自知，以确保他们保持自尊的方式行事。 Self-centeredness was considered a vice. 以自我为中心被认为是一种恶习 “Hard work”, they were told,”Leads to achievement, and that in turn produces satisfaction and self-confidence.” 他们被告知，努力工作会带来成就，这反过来又会产生满足感和自信。 By and large, our grandparents internalized those teachings. 总的来说，我们的祖父母把这些教义内化了。 When they honored them in their behavior, they felt proud; when they dishonored them, they felt ashamed. 当他们尊敬他们的行为时，他们感觉骄傲，当他们羞辱他们，他们感到羞愧。 Today the theories have been changed-indeed, almost exactly reversed. 今天，理论发生了变化，几乎完全相反 Self-esteem, which nineteenth-century satirist Ambrose Biercedefined as “an erroneous appraisement,” is now considered an imperative. 19世纪的讽刺作家安布罗斯·比尔斯(Ambrose Bierce)将自尊定义为“一种错误的评价”，如今自尊被认为是一种必要条件。 Self-centeredness has been transformed from vice into virtue, and people who devote their lives to helping others, people once considered heroic and saintlike, are now said to be afflicted with “a disease to please.” 以自我为中心已经从邪恶变成了美德，那些致力于帮助他人的人，那些曾经被认为是英雄和圣人的人，现在被认为是“一种疾病”。 The formula for success and happiness begins with feeling good about ourselves. 成功和幸福的公式是从对自我良好的感觉开始 Students who do poorly in school,workers who don’t measure up to the challenges of their jobs, substance abusers, lawbreakers - all are typically diagnosed as deficient in self-esteem. 在学校表现不佳的学生， 无法胜任工作挑战的工人，滥用药物者、违法者-都被诊断为缺乏自尊。 In addition, just as our grandparents internalized the social and psychological theories of their time, so most contemporary Americans have internalized the message of self-esteem. 此外，正如我们的祖父母内化了他们那个时代的社会和心理理论一样，大多数当代美国人也内化了自尊的信息。 We hear people speak of it over coffee; we hear it endlessly invoked on talk shows. 我们听到人们在喝咖啡时谈论它，我们在脱口秀节目中听到它不断的被调用。 Challenges to its precepts are usually met with disapproval. 对其戒律的挑战通常会遭到反对。 But isn’t the theory of self-esteem self-evident？ NO. A negative perception of our abilities will, of course, handicap our performance. 但自尊理论不是不言自明的吗? 不是的，当然，对我们能力的负面认知会阻碍我们的表现。 Dr.Maxwell Maltz explains the amazing results one educator had in improving the grades of schoolchildren by changing their self-images. 马克斯韦尔·马尔茨博士解释了一位教育家通过改变学生的自我形象来提高他们的成绩的惊人结果。 The educator had observed that when the children saw themselves as stupid in a particular subject (or stupid in general), they unconsciously acted to confirm their self-images. 这位教育家曾观察到，当孩子们认为自己在某一特定主题上是愚蠢的(或总体上是愚蠢的)时，他们会无意识地采取行动来确认他们的自我形象。 They believed they were stupid, so they acted that way. 他们认为自己很蠢，所以他们就这么做了。 Reasoning that it was their defeatist attitude rather than any lack of ability that was undermining their efforts, the educator set out to change their self-images. 教育家认为削弱他们努力的并不是能力的缺乏而是他们的失败主义态度，于是开始改变他们的自我形象。 He found that when he accomplished that, they no longer behaved stupidly! 他发现，当他做到这一点时，他们就不再表现得愚蠢了! Maltz concludes from this and other examples that our experiences can work a kind of self-hypnotism on us, suggesting a conclusion about ourselves and then urging us to make it come true. 马尔茨从这个例子和其他例子中得出结论，我们的经历可以对我们产生一种自我催眠，暗示一个关于我们自己的结论，然后敦促我们去实现它。 Many proponents of self-esteem went far beyond Maltz’s demonstration that self-confidence is an important ingredient in success. 许多自尊的支持者远远超出了马尔兹的论证，即自信是成功的一个重要因素。 They claimed that there is no such thing as too much self-esteem. 他们声称他们没有太多的自尊。 Research does not support that claim. 研究并不支持这项声明 For example, Martin Seligman, an eminent research psychologist and founder of the movement known as positive psychology, cites significant evidence that, rather than solving personal and social problems, including depression, the modern emphasis on self-esteem causes them. 例如： 马丁·塞利格曼。一个著名的心理学研究者和积极心理学运动的创始人， 引用了大量的证据表明，现代社会对自尊的重视并没有解决包括抑郁症在内的个人和社会问题，反而导致了这些问题。 Maltz’s research documents that lack of confidence impedes performance, a valuable insight, But such research doesn’t explain why the more global concept of self-esteem has become so dominant. 马尔茨的研究文件指出，缺乏自信会阻碍表现，这是一种有价值的洞察力，但这样的研究并不能解释为什么更加全球化的自尊概念会变得如此主导。 The answer to that question lies in the popularization of the work of humanistic psychologists such as Abraham Maslow. 这个问题的答案在于像亚伯拉罕·马斯洛这样的人本主义心理学家工作的普及。 Maslow described what he called the hierarchy of human needs in the from of a pyramid, with physiological needs (food and drink) at the foundation. 马斯洛描述了他所谓的金字塔中的人类需求层次，以生理需求(食物和饮料)为基础。 Above them, in ascending order , are safety needs, the need for belongingness and love, the need for esteem, and approval, and aesthetic and cognitive needs(knowledge, understanding, etc.). 之后向上依次是： 安全需要， 归属感和爱的需要， 尊重和认可的需要，审美和认知的需要（知识、理解等) At the pinnacle is the need for self-actualization, or fulfillment of our potential. 在金字塔的顶端， 是自我实现的需要或者我们的潜能被实现。 In Maslow’s view, the lower needs must be fulfilled before the higher ones. 在马斯洛的观点中，必须先满足较低的需要，再满足较高的需求。 It’s easy to see how the idea that self-esteem must precede achievement was derived from Maslow’s theory. 从马斯洛的理论中不难看出，自尊必须先于成就。 Other theories might have been adopted, however.然而，其他理论可能也被采纳了。 A notable one is Austrian psychiatrist Viktor Frankl’s, which was advanced at roughly the same time as Maslow’s and was based on both Frankl’s professional practice and hit experiences in Hitler’s concentration camps. 一个著名的例子是奥地利精神病学家维克多·弗兰克的学说，它与马斯洛的学说几乎是同时发展起来的，它是基于弗兰克的专业实践和他在希特勒集中营的亲身经历。 Frankl argues that one human need is higher than self-actualization: self-transcendence, the need to rise above narrow absorption with self. 弗兰克认为，一个人的需要高于自我实现:自我超越，超越狭隘的自我吸收的需要。 According to Frankl, “the primordial anthropological fact that being human is being always directed, and pointing to something or someone other than oneself: to a meaning to fulfill or another human being to encounter, a cause to serve or a person to love.” 根据弗拉克的观点，“最原始的人类学事实是，人类总是被指引着，并且指向某些东西或其他人而不是自我:去实现一个意义或者去遇见另一个人，去服务一个事业或者去爱一个人。” A person becomes fully human “by forgetting himself and giving himself, overlooking himself and focusing outward.” 一个人通过“忘记自己、奉献自己、忽视自己、关注外部”而成为完全的人。 Making self-actualization(or happiness) the direct object of our pursuit, in Frankl’s view, is ultimately self-defeating; 在弗兰克看来，把自我实现(或幸福)作为我们追求的直接目标，最终会弄巧成拙; such fulfillment can occur only as “the unintended effect of self-transcendence.” 这种满足只能以“自我超越的意外效果”的形式出现。 The proper perspective on life, Frankl believes, is not what it can give to us, but what it expects from us; 弗兰克尔认为，正确的人生观不是它能给我们什么，而是它对我们的期望； life is daily-even hourly- questioning us, challenging us to accept “the responsibility to find the right answer to its problems and to fulfill the tasks which it constantly sets for [each of us].” 生活每天甚至每小时都在质问我们，要求我们承担责任，找到问题的正确答案，完成它为我们每个人设定的任务。 Finding meaning, according to Frankl’s theory, involves “perceiving a possibility embedded in reality” and searching for challenging tasks “whose completion might add meaning to [one’s] existence.” 根据弗兰克的理论，寻找意义包括“感知一种根植于现实中的可能性”和寻找具有挑战性的任务，这些任务的完成可能会增加一个人存在的意义。 But such perceiving and searching are frustrated by the focus on self:” As long as modern literature confines itself to, and contents itself with, self-expression - not to say self-exhibition - it reflects its author’s sense of futility and absurdity. 但这种感知和探索却被对自我的关注所挫败:“只要现代文学将自身局限于自我表达——更不要说自我展示——并以此为内容，它就反映了作者的徒劳和荒诞感。 This is understandable in light of the fact that meaning must be discovered, it cannot be invented. 这是可以理解的，因为意义必须被发现，而不能被发明。 Sense cannot be created, but what may well be created is nonsense.” 理智是无法创造的，但很可能被创造出来的东西却是毫无意义的。” Whether we agree completely with Frankl, one thing is clear: Contemporary American culture would be markedly different if the emphasis over the past several decades had been on Frankl’s theory rather than on the theories of Maslow and the other humanistic psychologists. 无论我们是否完全同意弗兰克的观点，有一件事是清楚的:如果过去几十年的重点放在弗兰克的理论上，而不是马斯洛和其他人本主义心理学家的理论上，当代美国文化将会显著不同。 Becoming an Individual 成为一个个体In light of what we have discussed, we should regard individuality not as something we are born with but rather as something acquired - or, more precisely, earned. 根据我们所讨论的，我们不应该把个体性看作是与生俱来的，而应该看作是后天获得的，或者更确切地说，是挣来的。 Individuality begins in the realization that it is impossible to escape being influenced by other people and by circumstance. 个性是从意识到不可能逃避他人和环境的影响开始的 The essence of individuality is vigilance. The following guidelines will help you achieve this: 个性的本质是警惕。以下指导原则将帮助您实现这一目标： Treat your first reaction to any person, issue, or situation as tentative.No matter how appealing it may be, refuse to embrace it until you have examined it. 把你对任何人、问题或情况的第一反应看做是暂时的。不管它有多吸引人，在你审视它之前，拒绝接受它。 Decide why you reacted as you did.Consider whether you borrowed the reaction from someone else - a parent or friend, perhaps, or a celebrity or fictional character on television. If possible, determine what specific experiences conditioned you to react this way. 你为什么会做出那样的反应考虑一下你是从其他人那里借来的反应——也许是父母或朋友，或者是电视上的名人或虚构人物。如果有可能的话，确定是什么特殊的经历人你做出那样的反应 *Think of other possible reactions you might have had to the person, issue, or situation. 思考你对于一个人，问题或者情况， 你可不是可能会有其他的反应。 Ask yourself whether one of the other reactions is more appropriate than your first reaction. And when you answer, resist the influence of your conditioning. 问问你自己， 其他的反应是否比你的第一反应更适合你自己。当你回答时，要抵制你的条件反射影响。 To ensure that you will really be an individual and not merely claim to be one, apply these guidelines throughout your work in this book, as well as in your everyday life. 为了确保你是一个真正的个体， 而不仅仅是声称自己是一个个体。在你的工作中， 在你的日常生活中，应用书中的这些指导方针。 ApplicationsNote: ONe of the best ways to develop your thinking (and writing) skills is to record your observations, questions, and ideas in a journal and then, as time permits, to reflect on what you have recorded-considering the meaning and application of the observations, answering the questions, elaborating on the ideas (and, where appropriate , challenging them), and recording your insights. 注意：培养你的思考（和写作）技能最好的方式之一就是在日记中记录你的观察、问题和想法， 然后，在时间允许的情况下， 考虑到观察的意义和应用，思考你所记录的内容，回答问题，阐述想法（并且在适当的情况下，挑战他们），并记录你的见解。 An inexpensive bound notebook or spiral notebook will serve the purpose. 一个便宜的笔记本或者螺旋式笔记本就可以了。 A good approach is to record your initial observations, questions, and ideas on the left side of the page, leaving the right side blank for your later analysis and commentary. 一个好的方法是在页面的左侧记录你最初的观察、问题和想法，在右边留下空白供你以后分析和评论。 The value of this reflective process is so great that you should consider keeping such a journal even if your instructor does not make it a formal part of the course. 这个反思过程的价值是如此之大，以至于你应该考虑写这样一本日记，即是你的老师没有把它作为课程的一个正式部分。 Do a brief study of attention shifts such as the one described in the chapter. 对注意力转移做一个简短的研究，如本章所述。 Record a half-hour show. Then play the show back twice, the first time counting the number of shifts within the program, excluding commercials, and the second time counting only those within commercials. 对注意力转移做一个简短的研究，如本章所述。录半个小时的节目。将节目回放两次，第一次计算节目内的轮班次数(不包括广告)，第二次只计算广告内的轮班次数。 Complete the necessary arithmetic and be prepared to share your results in class. 完成必要的算术，准备在课堂上分享你的成果。 Reflect on your finding in application 1. Writer several paragraphs discussing the implications of those findings for education, business, and family life. 反思你在1中发现。 作者写了几段讨论这些发现对教育、商业和家庭生活的影响。 Many people cheerfully pay $6 or $7 a gallon for designer drinking water but moan and groan when they have to pay $3 a gallon for gasoline.Does anything you read in this chapter help you understand why this is so? 许多人乐意为设计师设计的饮用水支付每加仑6或7美元，但当他们不得不为汽油支付每加仑3美元时，他们就会抱怨。你在这一章里读到的东西能帮助你理解为什么会这样吗? Imagine how different America might be if Frankl’s emphasis on self-transcendence and personal responsibility, rather than Maslow’s emphasis on self-actualization and popular culture’s emphasis on self-esteem, had been dominant for the past fifty years. 想象一下，如果弗兰克尔对自我超越和个人责任的强调，而不是马斯洛对自我实现的强调和大众文化对自尊的强调，在过去的五十年里占据主导地位，那么美国可能会有多大的不同。 List as many ways as you can in which our society might be different today and comment on whether each would be beneficial or harmful. 尽可能多地列出当今社会可能不同的方式，并评论每一种方式是有益的还是有害的。 Be prepared to explain your views in class discussion. 准备在课堂讨论上解释你的观点 Watch one of the music video channels - MTV,VH1,CMT,BET - for at least an hour. 观看一个音乐频道最少一小时： MTV,VH1,CMT,BET Analyze how men and women are depicted in the videos.No significant details. 分析女生和男生分别是如何描述这个视频的, 不要注重细节。 For example, observe whether men are depicted in power roles more than women and whether women are portrayed as objects of male desire. 例如，观察男性是否比女性更具有权力角色，以及女性是否被描绘成男性欲望的对象。 Decide what attitudes and values are conveyed. 你觉得你会传递什么样的态度和价值观 (You might want to record as you are watching so that you can review what you have seen, freeze significant frames for closer analysis, and keep your observations for later reference or class viewing and discussion.) (您可能希望在观看时录制，以便可以查看所看到的内容，冻结重要帧以进行更深入的分析，并保留观察结果以供以后参考或课堂查看和讨论。) Suppose you asked a friend, “How did you acquire your particular identity - your sentiments and preferences and attitudes?” Then suppose the friend responded, “I’m as individual. No one else influences me. I do my own thing, and I select the sentiments and preferences and attitudes that suit me.” How would you explain to your friend what you learned in this chapter? 假设你问一个朋友：“你是如何确定你是一个特别的人呢？你的观点、偏好和态度吗？” 假设你的朋友回答：“ 我就是我，没有人能够影响我。 我做我自己的事情，并且我选择适合我的观点、偏好态度。 你如何向你的朋友解释在这一章学到了什么？ Ask yourself the question? Who am I? Write down then answers to this question, each on a separate slip of paper. 问你自己一个问题， 我是谁。写下对于这个问题的十个答案， 每一个答案写一个独立的行。 Use the first three paragraphs of this chapter to help you frame your answers. 使用本章的前三段帮助你确定你的答案。 Arrange the pieces of paper in order of their importance to you. Then explain the arrangement - that is , which self-descriptions are most important to you, and why? 把这几张纸按它们对你的重要性排列好。然后解释这个安排——也就是说，哪些自我描述对你来说最重要，为什么？ Identify the various positive and negative influences that have shaped you. 找出塑造你的各种积极和消极的影响。 Be sure to include the particular as well as the general and the subtle as well as the obvious influences. 一定要包括特殊的以及一般的， 微妙的以及明显的影响。 Which of those influences have had the greatest effect on you? Explain the effects as precisely as you can. 这些影响中，对你最大的影响是什么？ 尽可能准确的解释效果。 Note your immediate reaction to each of the following statements. Then apply the four guidelines given in this chapter for achieving individuality. 注意你对以下每一个陈述的即时反应。然后应用本章中给出的四个准则来实现个性化。 a. Health care workers should be required to be tested for HIV/AIDS. 卫生保健工作者应该接受艾滋病毒检测。 b. Beauty contests and talent competitions for children should be banned. 禁止举办儿童选美比赛和才艺比赛。 c. Extremist groups like the Ku Klux Klan should be allowed to hold rallies on public property or be issued permits to hold parades on city streets. 像三k党这样的极端组织应该被允许在公共场所举行集会，或者被允许在城市街道上举行游行。 d. Freshman composition should be a required course for all students. 大一作文应该是所有学生的必修课。 e. High school and college athletes should be tested for anabolic steroid use. 高中和大学运动员应接受合成代谢类固醇使用测试 f. Creationism should be taught in high school biology classes. 神创论应该在高中生物课上教授 g. Polygamy should be legalized. 多个配偶应该是合法的。 h. The voting age should be lowered to sixteen. 低于16岁的年轻人应该被允许投票 i. The prison system should give greater emphasis to the punishment of inmates than to their rehabilitation. 监狱系统应该更加重视对犯人的惩罚，而不是他们的改造。 j. Doctors and clinics should be required to notify parents of minors when they prescribe birth control devices or facilitate abortions for the minors. 医生和诊所在为未成年人开节育器或者为未成年人堕胎提供便利时，应当通知未成年人的父母。 k. A man’s self-esteem is severely injured if his wife makes more money than he makes. 一个男人的自尊心会受到严重的伤害，当他的妻子比他挣得钱多得多 l. Women like being dependent on men. 女人喜欢依赖男人。 Group discussion exercise: Discuss several of statements in application 9 with two or three of your classmates, applying the four guidelines presented in this chapter for developing individuality. Be prepared to share your group’s ideas with the class. 小组讨论练习:与2 - 3名同学讨论应用程序9中的几个陈述，运用本章中提出的四个发展个性的指导原则。准备好与全班同学分享你们小组的想法。 A Difference of OpinionTHe following passage summarizes an important difference of opinion. 下面的段落总结了一个重要的意见分歧。 After reading the statement, use the library and / or the Internet and find what knowledgeablepeople have said about the issue. 在阅读完陈述后，使用图书馆和/或互联网，找到有知识的人们已经谈论过这个问题。 Be sure to cover the entire range of views. Then assess the strengths and weaknesses of each. 一定要覆盖整个范围的观点。然后评估各自的优缺点 If you conclude that one view is entirely correct and the othes are mistaken, explain how you reached that conclusion. 如果你认为一种观点是完全正确的，而其他观点是错误的，请解释你是如何得出这个结论的。 IF, as is more likely, you find that one view is more insightful than the others but that they all make some valid points, construct a view of your own that combines insights from all views and explain why that view is the most reasonable of all. 更有可能的是，如果你发现一种观点比另一种更有洞察力，但它们都提出了一些有效的观点，那么构建一个你自己的观点，结合所有观点的见解，并解释为什么那个观点是最合理的。 what is critical thinking?what is truth?what does it mean to know?how good are you opinions？what is evidence?what is argument?]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>逻辑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[思考系统]]></title>
    <url>%2F2018%2F10%2F14%2F%E9%80%9A%E7%94%A8-%E6%80%9D%E8%80%83%E8%83%BD%E5%8A%9B-%E6%80%9D%E8%80%83%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[批判性思维图尔敏模型 举例： 小明出生在北京，所以小明是中国人。 论题： 小明出生在北京 前提： 在北京出生的是中国人 支撑： 现有法律规定 逻辑推理： 在北京出生的是中国人，小明在北京出生，所以小明是中国人。 反例：小明后来移民加拿大。 对推理的限定： 小明并非一定就是中国人 结论：因为小明出生在北京，所以小明可能是中国人。 对各个模块进行解释 论题论题是要讨论的问题或争议。 论题分为两种形式： 一种是对事实的讨论，比如：服用中药 是不是 能治好疾病，杨教授的学术研究水平 怎么样？ 人口出生率下降的原因 是什么？ 另一种是对价值主张的讨论， 比如：大学生 应不应该 读研， 对全民医疗 应该 采取什么样的态度？ 不同类型的论题，做出的评价是不同的，我们在讨论一件事情时，要检查两点： 我们是在讨论某个事实，还是讨论价值主张。 我有没有正面回答问题。 结论结论是要让你相信的观点和信息, 必须是有论证支撑的观点。 没有论据支撑的观点不能叫结论。 当某人说出他的观点时， 我们应该马上问：你这个看法有什么依据？ 注意问题： 偷换结论用一个相关性很强的结论来换掉正面回答问题的结论。原理：默认预设，认为结论只能二选一。 鱼和熊掌不可兼得，我拿不到鱼，所以我会拿到熊掌。 年轻人不愿意生孩子，所以养猫的人会越来越多。 先有结论，再证明合理人先作了决定，然后给出的理由并不是来推导这个决定，而是想办法维护这个决定。 在作一些决定和选择时，要先问自己：影响决策的是理性判断还是情绪等影响。 论证前应明确的两个问题明确对方是在进行论证，还是在进行解释。 解释并没有证明论证确实成立，而是把结论变成了默认前提。论证是指：我还没有相信或者认同你，你得证明你的判断。 将 因为 用 根据…、基于…、理由是… 来进行替换， 将 所以 用 得出…、推断…、证明… 来进行替换，看语句是否通顺。 我在吃饭，因为我往嘴里塞食物。 解释是指：我们已经承认了事实，视图说明为什么事实是这样的。 将 因为 用 归因于… 来进行替换， 将 所以 用 导致… 来进行替换，看语句是否通顺。 我在吃饭，因为我饿了。 识别概念的定义区别 在论题、论证和结论中出现的概念是一致的吗,这些观念会误导别人吗？ 关键概念的定义准确吗？ 在思考和论证的过程中，把一件事定义清楚。参考：《学会提问》第4章 挖掘论证中两种隐藏假设 事实判断型的假设， 这个世界是什么样的？一个理由是否能证实结论，主要取决于我们能否找到没有明说出来的想法，将理由和结论从逻辑上联系起来。比如：每天一个鸡蛋，能补充蛋白质。假定：鸡蛋是富含蛋白质的。 如何找出描述性假设 不断思考理由和结论之间的关系，寻找支持理由的想法、 把自己放到相反立场 价值判断型的假设， 这个世界应该如何选择？价值观假设是认为某些价值观中一个比另一个更重要，并且选择的价值观会对结论产生重大影响，同时也影响他捍卫结论的方式，但是这种价值取向并没有说明。比如价值观冲突： 忠诚-诚实、竞争-合作、媒体自由-国家安全、平等-个人主义、秩序-言论自由、理性-冲动。 如何找出价值观假设 言论者的背景是什么，他代表了哪方的利益？ 注意作者用来证实结论的各种理由，然后判断哪些价值取向会导致作者认为这些理由比另一些理由更可取，而另一些理由其实可以从论题的另一方面进行论证。 如果我和作者站在相反的立场，我会如何反驳 判断假设 这个假设和我的个人经验冲突不？ 这个假设是来自哪里的，消息来源可靠吗？ 我自己想法，背后的隐藏假设是什么？ 支撑 支撑是双方都公认的法则或常识。 法律法规 经检验的科学研究 注意类比的质量。 反例 对相反观点的论证，以达到论证的全面性。 常见谬误：参考下文：常见谬误详解 用图尔敏模型进行议论文写作 对文章主题进行介绍 介绍能够引起读者注意的内容 对要表述的问题进行陈述 表达你的结论，并给出使用范围。 提出证据来支撑论证 证据1、2 提供支撑保证的理由和事实，根据个人实践和理论来说明保证的合理性。 支撑1、2 回答反驳 反驳1 对反驳1的回答… 结论 概括论证和结论的要点，指出论证的意义，能够让读者印象深刻。 用图尔敏模型进行分析性写作对某一文章质量进行评判 理解主题论点，澄清概念的意义。 审查理由质量，挖掘潜在的假设。 分析论证结构，评估推理的强弱。 考虑替代论证， 提出完善的建议。 学习资料 课程-中国青年政治学院：批判性思维（谷振诣教授） Toulmin method 《逻辑新引.怎样辨别是非》 《beyond feelings》 《简单的逻辑学》 《学会提问》 《蔡钰-批判性思维15讲》 Justice – What’s the right thing to do? 结构化思维 对信息进行识别、归纳、概括、总结和表达。 识别信息 纵向上的总分结构 识别结论 识别理由 识别事实参考:上文批判性思维 归纳信息 横向上的分类结构 MECE 分类法： 不重不漏 二分法 过程法： 发展时间、运作流程 要素法：从上到下、从外到内、从整体到局部 公式法：按照公式的要素去分类。 矩阵法 特定场景模型：常见的分析思维模型 总结概括信息 归纳法 根据许多个别事物的特殊性来概括出同类事物的特性。 描述性概括 找出事物属性上的共同点。 行动性概括 最终结果是什么，找出事物结果的共性。 演绎法 将某一事实与对应的某个规律联系再一起，得出结论。 注意事项： 大前提一定要无可争议，避免主观判断，并且罗列不能过长。 小前提是一个已经发生的事实。 清晰表达1.结论先行 表达时先说结论 2.以上统下 上一层次要点必须是下一层次的概括 3.归类分组 每一组要点必须属于同一范畴 4.逻辑递进 每个要点必须按照一定的逻辑顺序排列。 演绎推理 时间/步骤顺序 空间顺序 重要性顺序 注意事项： 结论先行，重要的理由说三点。 参考资料 《得到-有效训练你的结构化思维》 《金字塔原理》 如何解决问题1. 明确和理解问题 明确问题的本质到底是什么 跟领导确认希望达到的目标 明确可以利用的资源 2.拆分和定位问题 用公式思维拆解问题 逻辑树-金字塔原理（mece法则) 假设驱动-假设问题可能出现在某个细分的问题点上。 3.提出解决方案并总结 结论先行参考上文：结构化思维 4. 工作中解决问题的方法 快速按照理解去做拆解，去做思维导图， 能想到多少是多少 拿着拆解思维导图去跟业务方的人去请教，一定要找到业务方真正关心的点 结合业务方给出的具体建议， 修改第一步的思维框架， 做完后，请教你的领导 再改一次， 回报给业务方领导 遇到坑之后， 一定要文档详细记录下来。 让团队中其他人知道， 节省团队时间。 知道自己在哪块花了大量时间，为后续分析节省时间。 5. 生活中问题解决的4个层次 有没有找到真正的问题， 人都是有逃避心理的。 想到了问题的第几层 想到了最后一层， 并且去执行解决问题 做到了，并且分享帮助别人 常见谬误详解1.幸存偏误 在生活中更容易看到成功者的故事，看不到失败， 你会系统性地高估成功的概率。 2.游泳选手身材错觉 你看到游泳选手的身材好，因此你觉得游泳就可以练就这样的身材。你觉得用这个护肤品的模特都好漂亮， 因此你觉得用了这个护肤品自己也可以变漂亮。 其实是因为他们有这样的好身材， 所以他们才能被选为游泳运动员。 和游泳能够练就这样的身材没有直接的关系。 用这个护肤品的模特好看， 是因为这个模特好看， 所以她才能被选做拍这个护肤品的广告， 和这个护肤品可以让自己更漂亮没有直接关系。 3.过度自信效应 系统性地高估自己的学识和能力 过度自信会令你忽视你真正掌握的能力与你已知的知识之间的区别 这个怎么理解呢， 就是你很多知识， 你只是了解， 而并非已经内化成你的能力， 而你会错误的把它归为你能力的一部分。 比如你说你会python, 但当你真正写的时候， 你却写不出来， 其实你没有掌握 4.诉诸结果 依据某观点成立所产生的结果好坏，来判断一个观点是否正确。 5.稻草人谬误 有意地模仿他人观点，以达到攻击模仿出来的观点而非实际论点的目的。 6.诉诸无关权威 诉诸不是问题专家的人， 其观点更可能是错误的。 例如：信仰中医，而不相信现代医学 7.虚假两难 给出一个有两种范畴组成的有限集合， 并假设讨论范围内的一切事物都必须属于该集合。因此 若拒绝其中一个范畴，便只好接受另一个。 例如： 世界上只有两种人，男人和女人， 你既然不是女人， 那么你一定是男人。 8.人身攻击 通过攻击一个人本身，而不是攻击其论点，以转移讨论话题，最终达到诋毁其论点的目的。 “侮辱性人身攻击” ： 你又不是专家， 你有什么资格发言 “处境类人身攻击” ： 对他们的动机作出判断。 你又不是真正关心降低城市犯罪率， 你只是想要人们投票给你。 9.循环论证 你完全错了， 因为你说得没有道理。 你应该相信上帝， 否则你会下地狱。 10.从众心理 11.纠缠于沉迷成本 我已经买了电影票了， 电影再烂也要看完。 我已经在这段恋情中投入了那么多感情， 现在离开她是不明智的。 我已经在这支股票中投了那么多钱了， 现在就收手会亏本的， 说不定以后会涨的。 你应该看的是现在的形势以及你对未来的评估。 12.互惠偏误 先送你一束花， 然后让你捐赠。 诉诸公众 诉诸感情 滑坡谬误 偷换概念 转移话题 因果混淆：相关并不能证明因果。 事后归因参考资料： 《简单的逻辑学》第5章 《有用的逻辑学》]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>逻辑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-Pandas库学习]]></title>
    <url>%2F2018%2F09%2F27%2F%E6%8A%80%E8%83%BD-pandas%E5%BA%93%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Pandas简介 Pandas是python数据分析中一个非常核心的数据库， 在日常的工作中经常需要使用Pandas库来对数据进行处理分析。Pandas的核心为两大数据结构， Series和DataFrame，Series用于存储一维数据， 而DataFrame存储多维数据。 常用的软件-Anaconda是数据分析中运行python的一款利器， 安装教程可参考Anaconda入门使用指南 读取与写入Excel数据 相对路径与绝对路径 读取文件夹内容 r（转义符）避免路径中的\被转义。路径中不加 \ 则需要把所有的\写成/。 1234567891011import pandas as pdimport numpy as npfrom pandas import Series, DataFrameimport osfile_list = os.listdir(r'E:\工作文件\周报\周数据\测试\0902-0908')print(file_list, '\t')# 读取当前文件夹地址os.getcwd() 读取xls格式Excel表 123df = pd.read_excel('E:/工作文件/an-商品汇总-uv.xls')df = pd.read_excel(r'E:\工作文件\an-商品汇总-uv.xls') 读取csv格式Excel表 1234567df = pd.read_csv('E:/工作文件/周报/周数据/测试/0902-0908/商品汇总.csv')# 读取csv文件，并用 分隔符分割df = pd.read_csv(r'E:\商品汇总.csv', sep = " ")# 只读取文件前两行df = pd.read_csv(r'E:\商品汇总.csv', nrows = 2) 读取显示编码错误 123456789101112131415# 显示错误为：# UnicodeDecodeError: 'utf-8' codec can not decode byte 0xb5 in position 0: invalid start byte# 修改方式df = pd.read_csv(path + '登记用户 20191127.csv',encoding="gbk" )# 当文件路径包含中文解析错误时，设置 engine 参数来消除这个错误# 错误原因， 当调用read_csv方法时，默认使用C语言作为解析语言，只需要将默认值c语言更改为python# 如果文件格式是 csv usf-8, 那么编码也改为 utf-8-sig# 如果文件格式是 csv格式， 则编码格式为 gbkdf = pd.read_csv('登记用户 20191127.csv', engine = 'python', encoding = 'utf-8-sig') 读取txt格式数据 123456df = pd.read_table(r'C:\Users\Administrator\Desktop\haha.txt', sep = ' ')with open(r'C:\Users\Administrator\Desktop\haha.txt', 'r') as f: df = f.readlines() df = np.loadtxt(r'C:\Users\Administrator\Desktop\haha.txt') # 将txt文件存为numpy数组 读取excel中的sheet名称 12345678910111213141516171819202122232425262728df = pd.read_Excel(r'E:\工作文件\an-商品汇总-uv.xlsx', sheet_name = 'sheet1')# 传入sheet的顺序，从0开始计数df = pd.read_Excel(r'E:\工作文件\an-商品汇总-uv.xlsx', sheet_name = 0)# 读取sheet,并制定文件中的第几行做行索引df = pd.read_Excel(r'E:\工作文件\an-商品汇总-uv.xlsx', sheet_name = 0, index_col = 0)# 读取sheet文件， 并制定文件中的第几列做列索引df = pd.read_Excel(r'E:\工作文件\商品汇总.xlsx', sheet_name = 0, head = 1)# 当本地文件过多时，可以通过设定 usecols 参数来指定要导入的列df = pd.read_Excel(r'E:\商品汇总.xlsx', usecols = 0)# uescols = [0,2]# 读取excel中所有sheet，并进行合并rbook = []kong_data = os.listdir(r'F:\省资源位')for file_name in kong_data: data_excel = pd.ExcelFile(r'F:\省资源位\\'+file_name) sheet = data_excel.sheet_names for i in sheet: data_button_rest = pd.read_excel(r'F:\省资源位\\'+file_name, sheet_name= i ) rbook.append(data_button_rest) result_df =pd.concat(rbook)datas_excel = pd.DataFrame(result_df) 将运行的所有数据都展现出来， 而不是只展现最后一条 12from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all" 将数据写入Excel表， 并输出 1234567891011121314151617181920212223242526# 写入数据df.to_excel('C:/Users/Administrator/Desktop/'+'商品分类.xlsx')df.to_excel(r'C:\Users\Administrator\Desktop\\'+'商品分类.xlsx')df.to_excel(r'C:\Users\Administrator\Desktop/'+'商品分类.xlsx')# 写入数据，且不带索引df.to_excel('C:/Users/商品分类.xlsx', sheet_name = '首页', index = False)# 设置要导出的列df.to_excel('C:/Users/商品分类.xlsx', sheet_name = '首页', index = False, columns = ['ID', '销量’])# 设置编码格式df.to_excel('C:/Users/商品分类.xlsx', sheet_name = '首页', index = False, encoding = 'utf-8')# 缺失值、无穷值处理df.to_excel('C:/Users/商品分类.xlsx', sheet_name = '首页', index = False, na_rep = 0, # 缺失值用0填充 inf_rep = 0 # 无穷之用0填充 )# 导出csv文件，设置分隔符df.to_excel('C:/Users/商品分类.xlsx', sheet_name = '首页', index = False, sep = ',' ) 将求出的数据存储在excel中的多个sheet中 123456789import pandas as pdfrom openpyxl import load_workbook writer = pd.ExcelWriter('F:/notebooks/zhoushuju.xlsx')btn_navigation.to_excel(writer, sheet_name = '底部导航')shouye_top20.to_excel(writer, sheet_name = '首页top20')writer.save()writer.close() 其他数据格式 12345678910111213141516171819# 从SQL表/库导入数据 import pymysqleng = pymysql.connet(host= '100.129', user = 'root', password = '1234', df = 'db', charset = 'ugf8')query = """select * from android_log """df = pd.read_sql(query, eng)# 导出数据到SQL表 df.to_sql(table_name, eng)``` 8. 常见问题* 当文件有中文时， 可能会出现错误：Initializing from file failed 有中文， 可以用此方法解决```pythonf = open(‘我的文件.csv’)res = pd.read_csv(f) 查看大文件有多少列 1234data = open('E:/用户明细.csv')data1 = pd.read_csv(data, iterator=True)data2 = data1.get_chunk(5)print(data2) 迭代器 对输出数据进行处理pandas的数据输出显示设置 对表中某一列元素进行相同操作 123df[&apos;金额&apos;].apply(lambda x:x+1)df[&apos;金额&apos;] +2 对表中每一个元素进行相同操作 1df.applymap(lambda x:x+1) 123456789101112131415import numpy as npimport pandas as pddf = pd.DataFrame(np.random.randn(150, 150))# pd.set_option('expand_frame_repr', False) #数据超过总宽度后，是否折叠显示pd.set_option('display.width', 100) #数据显示总宽度pd.set_option('max_rows', 100) #显示最多行数，超出该数以省略号表示pd.set_option('max_columns', 100) #显示最多列数，超出该数以省略号表示pd.set_option('max_colwidth', 16) #设置单列的宽度，用字符个数表示，单个数据长度超出该数时以省略号表示pd.set_option('large_repr', 'truncate') #数据超过设置显示最大行列数时，带省略号显示/若是info则是统计信息显示pd.set_option('show_dimensions', True) #当数据带省略号显示时，是否在最后显示数据的维度print(df)pd.set_option('max_info_columns', 100) #当列数超过这个值时，调用df.info()函数时不会统计每列的非空值。print(df.info()) 将数据变成小数形式12345678910import pandas as pd inputfile = '../data/electricity_data.xls'outputfile = './electricity_data_analyze1.xls' data = pd.read_excel(inputfile)data[u'线损率'] = (data[u'供入电量']-data[u'供出电量'])/data[u'供入电量'] #data[u'线损率']的类型为series； data[u'线损率']为小数data[u'线损率'] = data[u'线损率'].apply(lambda x: format(x, '.2%')) #Series.apply()让序列的值依次在lambda函数中执行； data['线损率']由小数转化为百分数 data.to_excel(outputfile, index=False) 描述数据 表信息 1df.info() 显示数据的行列数 1df.shape 查看数据格式dtpyes 1df.dtypes 显示列名、元素 12df.columnsdf.values 添加默认列名 12# 如果数据没有标题行，可用pandas添加默认的列名df = pd.read_excel('x.xlsx', header = None) 显示前数据前5行 12df.head(5)df[['标题', '客户端uv']].head() 显示数据后5行 1df.tail(5) 值 1df.values 读取a列 1df['a'] 找到重复值 1df.duplicated() 显示数据唯一值（unique函数） 12# 数据有0， 是因对缺失值进行了填充df['经纪人级别'].unique() 对第几行数据不读取 12#不读取哪里数据，可用skiprows=[i]，跳过文件的第i行不读取df = pd.read_excel('x.xlsx',skiprows=[2] ) 对缺失值进行识别 12# 所有缺失值显示为Truepd.insull(df) # df.isnull() 计算 1234567891011#计算此data的数量df['data'].value_counts()# 升序计数df['data'].value_counts(ascending = True)# 升序计数并分组df['data'].value_counts(ascending = True, bins = 2)# 计数df['data'].count() 字符和数值之间的转化 1234int() # 转化成整数float() # 转化成浮点数str() # 转化成字符type() # 查看格式 获取数据分布情况 1data.describe() 数据清晰 删除空值 （dropna函数） DataFrame中的空值处理 1234df.dropna(how='any')df.dropna(how = 'all') 123456789用法：DataFrame.drop(labels=None,axis=0, index=None, columns=None, inplace=False)参数说明：labels 就是要删除的行列的名字，用列表给定axis 默认为0，指删除行，因此删除columns时要指定axis=1；index 直接指定要删除的行columns 直接指定要删除的列inplace=False，默认该删除操作不改变原数据，而是返回一个执行删除操作后的新dataframe；inplace=True，则会直接在原数据上进行删除操作，删除后无法返回。 123# 删除包含 集团 二字 的行read_data = df[- df[&apos;所属省份名称&apos;].isin([&apos;集团&apos;])] 数值删除 删除列 1234567# 删除列, axis=1表示删除列df.drop(["销售额", "ID"], axis = 1)df.drop(columns = ["销售额", "ID"])# 传入列位置df.drop(df.columns[[4,5]], axis =1) 删除行 1234567891011# 删除行，筛选行名df.drop([&apos;一&apos;,&apos;二&apos;], axis = 0)df.drop(index = [&apos;一&apos;, &apos;二&apos;])# 删除行，筛选行索引df.drop(df.index[[0,1]], axis = 0)# 只要年龄小于40的用户df[df[&apos;ID&apos;] &lt; 40] 填充（fillna函数） 123456789# 空值用0填充df.fillna(value=0)df.replace(np.NaN, 0)# 用均值对空值进行填充df['时长'].fillna(df['时长'].mean())# 按照不同列进行填充df.fillna(&#123;'性别' : '男'&#125;) 更改数据格式，更改数据类型 123# 将数据格式int64,改为float格式df['大区'].astype('float64') 更改列名称, 修改列名。 123df.columns = [['导航','uv', 'pv','户均点击']]df.rename(columns=&#123;'IM渠道': '渠道'&#125;) 添加修改索引 12345678# 添加索引df.index = [1,2,3,4]# 修改索引,重新设置df = df.set_index['标题']# 重命名索引df.rename (index = &#123;1: '一'&#125;) 重置索引 12345678910DataFrame.reset_index(level=None, drop=False, inplace=False)# 默认将所有index转化成columnsdf.reset_index()#将第0级索引转化为 columnsdf.reset_index(level=0)# 将原索引删除，不加入columnsdf.reset_index(drop = True) 删除重复值 Pandas删除数据的几种情况 12345678# 默认第一次出现的保留，其余删除df['门店'].drop_duplicates()# 最后一次出现的保留，其余删除df['门店'].drop_duplicates(keep = 'last')# 多列去重df.drop_duplicates(subset = ['姓名', '唯一识别码']) 对列表内的值进行替换 123456789# 一对一替换df['ID'].replace('1053', '110')# 多对一替换df['ID'].replace(&#123;'1053': '110', '230': '33'&#125;)df.columns.str.replace(' ', '_') 对数据进行处理 对两个数据进行合并- merge, join, concat函数 merge 123456789101112131415161718192021222324252627# 按照轴把多个对象拼接起来pd.concat(df1, df2)# join函数适合根据索引进行合并，合并索引相同但列不同的对象# merge函数，根据一个或多个键连接多行, 相当于excel中的vlookup# 将left和right进行合并pd.merge(left, right)# 指定以key为键进行合并pd.merge(left, right, on = 'key') pd.merge(name_3, name_1, left_on = ['ming'], right_on = ['标记'])# key2列不相同的部分会直接舍弃掉pd.merge(left, right, on = ['key', 'key2'])# 保留key2列不相同的部分pd.merge(left, right, on = ['key', 'key2'], how = 'outer')# 不相同的部分指定以左表为基准pd.merge(left, right, on = ['key', 'key2'], how = 'left')# 重复列名处理# pd.merge()会自动给这些重复名添加后缀_x、_y，也可以自己命名。pd.merge(df1,df2, on = 'id', suffixes= ['_L', '_R']) concat函数, 按照标题进行拼接 12345678# 普通合并pd.concat([df1, df2])# 索引设置pd.concat([df1, df2], ignore_index= True)# 合并后删除重复值pd.concat([df1, df2], ignore_index = True).drop_duplicates() 对数据进行排序 12345678910111213# 按照ID进行升序排列# 按照ID进行降序排列df.sort_values(by = ['ID'], ascending = False)# 在保证销售额列降序的情况下，对ID列进行升序处理data.sort_values(by = ['销售额', 'ID'],ascending = [False, True], inplace = True)# 默认将ID是缺失值的列显示在最后面df.sort_values(by = ['ID'])# 将ID是缺失值的列显示在最前面df.sort_values(by = ['ID'], na_position = 'first') 对数值进行排名 1234567891011# 对应Excel中的 rank.avg函数df['ID'].rank(method= 'average')# 按值在所有的排列数据中出现的先后顺序排名df['ID'].rank(method = 'first')# 与Excel中rank.eq 函数的功能一样df['ID'].rank(method = 'min')# 与min相反，取重复值对应的最大排名df['ID'].rank(method = 'max') 对数据进行分组 123456789# 如果price列的值&gt;3000，group列显示high，否则显示lowdf[&apos;group&apos;] = np.where(df[&apos;客户当天发送消息数&apos;] &gt; 5,&apos;high&apos;,&apos;low&apos;)# 对符合多个条件进行分组# 符合经纪人级别为A1且经纪人响应时长&gt;24的在sign列显示为1df.loc[(df[&apos;经纪人级别&apos;] == &apos;A1&apos;) &amp; (df[&apos;经纪人响应时长&apos;]&gt;= 24.0), &apos;sign&apos;]=1 对数据进行分列 12345678pd.DataFrame((x.split('网') for x in df['客户注册渠道']), index=df.index,columns=['客户注册渠道','size'])&lt;!-- df = pd.DataFrame((x.split('.') for x in 首页jhrj_1['所属省份编码']), index=df.index,columns=['客户注册渠道','size']) --&gt;# 分列完对数据进行合并df1 = pd.merge(首页jhrj_1, df, left_index = True, right_index = True) 新增一列 123data = data.assign(ration = [4, 2, 5, 6, 7, 8, 2, 9, 4])data[&apos;rations&apos;] = [5, 2, 5, 6, 7, 8, 2, 9, 4] 对数据进行切分 123456# 指明切分区间pd.cut(df[&apos;年龄&apos;], bins = [0,3,6,10])# 将数据切成3份pd.qcut(df[&apos;年龄&apos;],3 ) 取出的数据， 指定取到小数点几位数？ 123456# 取到小数点后3位for i in a : print(&quot;%.3f&quot;%c)# 设置小数点位数，四舍五入df[&apos;cnts&apos;].round( decimals = 2) 将 list 格式转化成 DataFrame 格式 1df = pd.DataFrame(data, columns = [&apos;省份&apos;, &apos;按钮名称&apos;, &apos;uv&apos;, &apos;pv&apos;] ) 数据选择 选择某一列/ 某几列 123456789101112# 普通索引- 根据名称进行选择df['客户端uv']df[['标题', '客户端uv']]# 位置索引 / 切片索引， 根据所在第几列进行选择# : 表示选择所有的行， 逗号后面表示要选择列的位置区域df.iloc[:, [0,2]] # 获取第1列和第3列的数值 选择某一行/某几行 12345678910111213# 普通索引-locdf.loc['第一行']df.log[['第一行', '第二行']]# 位置索引，切片索引 # 选择第一行df.iloc[0]# 选择第一行和第二行df.iloc[[0,1]] 根据指定条件进行筛选 123456789101112131415161718# 选择年龄小于200的数据df[df['年龄'] &lt; 200] #年龄小于200，且id小于300df[(df['年龄'] &lt; 200) &amp; (df['id'] &lt; 300)]df[np.logical_and(df['年龄'] &gt; 10, df['id'] &gt; 5)]# A列值大于10，或 B列值大于5df[(df['A'] &gt; 10) | (df['C'] &gt;20)]df[np.logical_or(df['A'] &gt; 10, df['C'] &gt; 20)]# 当 A列的值大于13时， 显示B，c列的值df[['B','C']][df['A']&gt;13] 行列同时选择 普通索引+普通索引选择指定的行和列 1df.loc[['第一行', '第三行'], ['订单号’, 'ID']] 位置索引 + 位置索引选择指定的行和列 123df.iloc[[0,1], [0,2]]df.iloc[0:2, 1:2] 布尔索引+ 普通索引 1df[df['年龄']&lt; 200][['订单编号', 'ID']] 切片索引+ 普通索引 1df.ix[0:2, ['订单变化', 'ID']] 按条件进行提取 12345678910111213# 用isin函数进行判断# 使用isin函数根据特定值筛选记录。筛选A值等于10或者13的记录df[df.A.isin((10, 13))]# 查看这一列是否包含某个值df['级别'].isin(['A3']) # 先判断是否包含，然后将符合条件的数据提取出来。df.loc[df['级别'].isin(['A3','M4'])] 数据汇总 对数据进行分类 - group by函数 12345678# 按照某列分组求和df.groupby('渠道').sum()# 按照多列分组求和df.groupby(['渠道', 'ID']).sum()# 对分组后的结果进行重新索引df.groupby('渠道').sum().reset_index() aggregate方法 12345678# 对同一列 先做计数汇总运算，再做汇总运算df.group('渠道').aggregate(['count', 'sum'])# 针对不同的列做不同的汇总运算df.groupby('渠道').aggregate(&#123;'ID' : 'count', '销量' : 'sum'&#125;) pivot_table-数据透视表 123# 为方便处理， 一般需要对结果进行重置索引pd.pivot_table(df, values = 'ID', columns = '渠道', index = '客户分类', aggfun = 'count').reset_index() pd.pivot_table(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name = ‘All’) data: 数据values: 对应的值index: 对应的行columns: 对应的列aggfunc : 对values的计算类型fill_value : 对空值的填充值margins: 是否显示合计列dropna: 是否删除缺失值，如果为真，则一整行全删除margins_name: 合计列的列名 对数据进行映射 12# 用map函数对字典进行映射， 新加一列data[&apos;upper&apos;] = data[&apos;group&apos;].map(dataUpper) 数据采样 12345678910111213# 简单随机抽取sampledf.sample(n=3)# 设置采样权重# 需要对每一行进行权重设置，列表行数少可行，过多不可行# 假设有4行数据，设置采样权重weights = [0, 0, 0.5, 0.5]df.sample(n=4, weights=weights)## 确定采样后是否放回# 采样后放回，Truedf.sample(n=6, replace=True) 统计计算 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 计算每一列的个数df.count()# 计算每一行的个数df.count(axis = 1)# 求和df.sum()df.sum(axis = 1)# 中位数df.median()# 求和df.sum()# 求最大值df.max()# 求最小值df.min()# 求众数df.mode()# 求方差df.var()# 求标准差df.std()# 求分位数df.quantile(0.75, axis = 1)# 描述统计 describe函数#自动生成数据的数量，均值，标准差等数据#round（2）,显示小数点后面2位数，T转置df.describe().round(2).T# 标准差std()df['经纪人响应时长'].std()# 协方差covdf['经纪人当天发送消息数'].cov(df['客户当天发送消息数']# 相关性分析corrdf['客户当天发送消息数'].corr(df['经纪人当天发送消息数']) 数值计数 123456789# 查看不同值出现的次数， #默认进行排列df['ID'].value_counts()# 查看不同值出现的占比, #默认进行排列df['ID'].value_counts(normalize = True)# 查看不同值出现的占比， 不进行排列df['ID'].value_counts(normalize = True, sort = False) 插入数据 12# 在 insert方法中，指明要插入的位置、插入新列的列名，以及要插入的数据df.insert(2, '销售品id', ['01', '02']) 对数据进行转置 1df.T 索引重塑 12345# 将表格型数据转化成树形数据df.stack()# 将树形数据转化成表格型数据df.stack().unstack() 长宽表转换 宽表 长表 将长表转化成宽表,对数据进行透视, 相当于Excel中的数据透视表功能。 1df.pivot_table(index = ['computer','name'], columns = 'year', values = 'sale') 将宽表转换成长表 12# 方法1： melt()df.melt(id_vars = ['company', 'name'], var_name = 'year', value_name = 'sale') 12# 方法1： stack()# 在保持行索引不变的前提下，将列索引转化成行索引 对字符串进行操作 大小写 12a.lower()a.upper() 长度 12# 长度a.len() 去除空格 123a.strip()a.lstrip()alrstrip() 切分与分列、 合并 123456789101112131415161718192021222324252627282930313233343536#切分a.split('_')# 切分， 且成为新列a.split('_', expand = True)# 对切分进行限制, 只切1次a.split('_', expand = True, n=1)# 查看是否包含a.str.contains('A')# 分列s.str.get_dummies(sep= '|')df = 首页jhrj_1['所属省份编码'].str.split('.') # expand=True 可以把用分割的内容直接分列首页jhrj_1["所属省份编码1"]=df[0]# 切分并在原表中进行合并首页jhrj_2 = pd.merge(首页jhrj_1, pd.DataFrame(首页jhrj_1['所属省份编码'].str.split('.', expand = True) ), how = 'left', left_index = True, right_index = True)# pandas对dataframe中的某一列使用split做字符串切割：# words = df['col'].split()# 报错：# AttributeError: 'Series' object has no attribute 'split'# 原因是df['col']返回的是一个Series对象，需要先把Series对象转换为字符串：pandas.Series.str.split# words = df['col'].str.split()对两列数据进行合并df['省份_名称'] = df['省份'].str.cat(df['名称'],sep = '_')首页jdt_1['省份_标题'] = 首页jdt_1['所属省份编码'].astype(str).str.cat(首页jdt_1['标题'],sep = '_') 日期-时间 当前日期 123456789101112131415161718192021import timefrom datetime import datetime, time, timedelta# 返回当前日期和时间datetime.now()# 返回当前时间的年datetime.now().year# 返回当前时间的月份datetime.now().month# 返回当前日期的日期datetime.now().day# 返回当前时刻在周几# python周几默认是从0开始的datatime.now.weekeday() + 1# 返回当前时间所在周的周数datatime.now.isocalendar()[1] 返回指定日期 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 只展现日期datetime.now.date()# 只展示时间datetime.now.time()# 显示当前日期datetime.now().strftime('%Y-%m-%d')#2018-12-22datetime.now.strftime('%Y-%m-%d %H:%M:%S")# 将时间格式转化成字符串格式now=str( datetime.now())# 将字符串格式转化为时间格式parse(str_now) # 往后推一天date+ Day(1)# 往后推一个小时date + Hour(1)# 往前推一天date - Day(1)# 昨天ysd = now - timedelta(days = 1)#本月第一天ysd = now.replace(day = now.day-1)# 上月最后一天lastmonth_end = now.replace(day = now.day-1) - timedelta(days=1)# 上月第一天lastmonth_first = now.replace(month = now.month-1, day =1)lastmonth_first = lastmonth_end.replace(day=1)#提取2016年11月2号的数据df['2016-11-02' : '2016-11-02']dt_time = dt.datetime(year = 2018, month=9, day = 17, hour = 22, minute = 43)# 构造时间序列， 构造十个日期， 每12分钟一次pd.Series(pd.date_range(start = '2018-09-17 22:43:00', periods = 10, freq = '12min'))# 取所有8点到12点之间的数据, 不包含8点和12点data[(data.index.hour &gt; 8) &amp; (data.index.hour &lt; 12)]# 包含8点到12点data.between_time('08:00', '12:00')import datetimefrom dateutil.relativedelta import relativedelta begin = datetime.date(2019,1,1)end = datetime.date(2019,1,31)for i in range(1,10): first = d + relativedelta(months=i) last = end + relativedelta(months=i) 处理月与月之间时间不连续问题 1234567891011121314151617181920212223import time from datetime import datetime, time,timedelta# 指定昨天df = datetime.now() - timedelta(days = 1)# 月初第一天startdates = (df.replace(day = 1)).strftime('%Y-%m-%d')# 昨天enddates = (df - timedelta(days = num)).strftime('%Y-%m-%d')# 上月第一天last_moth_f = df.replace(month =df.month-1, day=1).__format__("%Y-%m-%d")# 上月最后一天last_moth_e = df.replace(month = df.month-1, day =1).strftime('%Y-%m-31')# 目标值月份mubiao_dates = startdates[0:7]# 将字符串转换为日期df = datetime.now() - timedelta(days = 1)day1 = (df.replace(day = 1)).strftime('2019-11-%d')first = datetime.strptime(day1, "%Y-%m-%d") 自动发送邮件12import smtplibfrom email import encoders]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个好用的插件]]></title>
    <url>%2F2018%2F09%2F25%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E5%A5%BD%E7%94%A8%E7%9A%84%E6%8F%92%E4%BB%B6%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[一个好用的插件神器最近发现了一个特别能够提高生活幸福感的插件：Tampermonkey, 中文翻译过来叫做油猴。 安装好这个插件最大的作用， 就是我们可以从Greasy Fork这个网站来安装我们需要的脚本， 从而极大的提高浏览器的使用效率。 比如：我们在Greasy Fork网站找到智能划词翻译这个脚本， 然后点击安装脚本即可。安装完成脚本之后， 我们打开一个英文网页，对需要翻译的段落进行框选，点击翻译按钮，就可实现在原网页查看中文翻译， 对于我这种英语不好的人来说， 有很大的帮助。 我们还可以安装微博过滤设置脚本，来对微博页面进行个性化设置， 自己设置完成后的微博页面是这个样，相对于原版网页来说简洁了不少。 也可安装微博浮图脚本， 查看微博图片也比较方便， 只需把鼠标光标放在图片上即可 如果想找资料或电影资源的话， 也可以下载豆瓣资源下载大师, 或百度网盘直接下载助手等脚本， 当然，有能力还是要支持正版。 例如：安装豆瓣资源下载大师脚本后， 打开豆瓣电影网页， 页面是这个样子。 在Greasy Fork这个网站还有很多别人写好的脚本， 比如百度文库文字复制、购物党自动比价工具、 Download Youtube videos and subtitles等好用的脚本， 可以根据自己的需要进行安装。]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人资料收集]]></title>
    <url>%2F2018%2F08%2F05%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[互联网工具 指数类 百度指数 http://index.baidu.com/v2/index.html#/ 微博指数 https://data.weibo.com/index/ 各种数据指数 http://data.chongbuluo.com/ 企业类 企业信用信息公示系统 http://www.gsxt.gov.cn/index.html 国家统计局 http://data.stats.gov.cn/ 企查查 财报类 上交所http://www.sse.com.cn/ 深交所http://www.szse.cn/ 港交所https://www.hkexnews.hk/ 美国上市公司https://www.sec.gov/ 同花顺财经http://data.10jqka.com.cn/ 分析工具 语义分析系统http://ictclas.nlpir.org/nlpir/ 腾讯文智 https://nlp.qq.com/semantic.cgi#page2 echarts https://echarts.baidu.com/ 在线图片识别文字 https://ocr.wdku.net/ 问卷调查 https://www.wjx.cn/ 视频： 科普-计算机科学速成课 纪录片-设计的艺术 纪录片-小兵小赵 访谈-子夜.大学之殇 月球视频 最后的演讲 性，死亡与生命的意义 统计学：statistics —— CrashCourse 锵锵行天下 蓝色星球 风味人间 成功的原则 youtube视频：Rachel’s English 纪录片-生门 电影-生门 纪录片-人生果实 《人类星球》梦与狂想的王国《尘与雪》《人生七年》《身份的焦虑》 《铁西区》《和凤鸣》《原油》 书： The Non-Designer’s Design Book (4th Edition) 英文原版免费编程书籍 网站： RSS收集网站 知笔墨 微软海底机房摄像头直播 全球免费摄像头直播 设计类网站 漫画-海报 Our the in World 中国知网 统计学可视化 各种书籍下载 cnki免费下载文献：账号：hqwytsg015 密码：cnki015 北京值得去的地方 纪录片——AlphaGo youtube最受欢迎的频道 写作网站 颜色选择 博客 TED:阅读全世界 阮一峰的个人网站 追求对知识概念和原理进行更合适的描述 《用数据讲故事》作者博客 万维钢的博客 w4lle’s Notes = android技术博客 stormzhang 廖祜秋的博客 最好的数据分析博客汇总 what’s up - The Longest Way 数据分析类网站 Kaggle 统计之都 纪杨的网站数据分析笔记 蓝鲸的网站分析笔记 Cloga的互联网笔记 陈老师的天善智能博客文章 秦路-文章 数据可视化网站 一起大数据 数据分析问答 数学公式转换MD格式 信息图制作 简历制作网站 多人协同任务清单 GA小站-一个Google Analytics 和Adobe Analytics 经验分享平台 数据可视化网站 https://datavizcatalogue.com/ZH/%E6%90%9C%E7%B4%A2.html https://plot.ly/python/ https://datavizproject.com/# TED 如何掌控你的自由时间 —— 时间=选择 提升自信的技巧 —— 除非你做到了，否则没有人相信你 【TED】科技公司如何控制你的注意力 我从生活和写作中学到了12个真理 - 一个一个写，改初稿， 如果不知道写什么，就写你自己经历的事情 收入如何影响人们的生活方式——世界各国， 收入水平导致的生活条件改变都差不多官方网站 图表的魔力——图表能够让人更快的理解信息 如何利用大数据做出正确的判断-用大量数据去做分析， 去深入了解， 但要想成功， 就需要冒一定的风险 大数据时代：如何避免数据迷信？-不光要依靠大数据， 也要依靠厚数据，让解决问题的方法更加多元化 李开复：人工智能如何拯救人类-ai让我们明白我们为何为人 开启情绪识别的大门-用算法来识别人类情绪 有趣的故事 盗醉猴 植物修炼成精之后还有没有细胞壁？ NBA 感人的比赛或者画面有哪些？ 有没有一部电影让你在深夜中痛哭？ 为什么法海要阻止白素贞和许仙在一起？ What are some amazing pictures one has to see twice to understand? 21世界100部伟大的电影 世界运行的潜在规律 这个世界要改变你，会潜移默化的改变你，如果你这一天不去努力，那么你两年之后再看回头看你自己，会发现自己并没有取得什么成就。 如果你要理解某些知识，你就要结合你自己的情况去理解学习，不管你觉得作者说的怎么好，你都要切合你自己的实际情况，不管你的实际情况是多么的烂。 人类的进化是有一定的规律的，你要认清这些规律，并利用好它。 比如： 人的大脑是有适应性的，你每天去刻苦练习就是会进步。 人都是有恐惧心理的。 人都是要吃饭穿衣服的。 人都是善于遗忘的。 人就是佩服逻辑清晰的人，逻辑清晰的人就是能两三句让你理解到事物的本质。 人都是喜欢有自己主见的人，而不是人云亦云的人，不是只会复述别人话的人。 让你坚持每天都做一件事情的时候，人们就是会对你产生佩服之情。 当你去学习，去面对的时候，你就不会感受到那么的恐惧与难受。 你一直拖延下去，你自己只会更加的难受。 人就是喜欢整洁，干净有序的环境，因为潜意识里人是向往健康的。 人的身体总体是喜欢稳定的， 你一运动就会心跳加速，一读书就会让脑细胞大量活跃，这些是身体尽量避免的， 但正因为身体有稳定性，所以你坚持一段时间，突破了临界点，人的身体会变得更加强壮，以便达到一个新的舒适区。]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础学习]]></title>
    <url>%2F2018%2F07%2F25%2F%E6%8A%80%E8%83%BD-python%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[数 整数-int 123i = 1# 查看变量的类型type(i) 浮点数-float 12340.2 * 0.10.020000000000000004 浮点数在计算机中表输入的十进制浮点数仅由实际存储在计算机中的近似的二进制浮点数表示,二进制来表达 1/10 是一个无限循环小数:0.0001100110011001100110011001100110011001100110011…,Python 只打印机器中存储的二进制值的十进制近似值。 如何限制显示的小数点个数 1print(&quot;&#123;:.4f&#125;&quot;.format(0.1*0.4)) 字符串-str 字符串的表示方式： python中有3种表示字符串的方式——单引号，双引号，三引号。 单引号和双引号的作用是相同的, 但双引号中可以将包含的特殊字符单引号输出，而单引号要输出’需要/转义 123456str = &apos; \&apos;hello world\&apos; &apos;print(str)str = &quot;&apos;hello python&apos;&quot;print(str) 三引号的用法特殊，三引号中可以输入单引号、双引号或换行符等字符,也可用作制作文档字符串 123str = &apos;&apos;&apos;&apos;hello&apos;/&quot;world&quot;&apos;&apos;&apos;print(str) 常用的字符串处理方法 1234# 重复字符串sta = &apos;hi&apos;print (sta * 2) 1234# 切片sta = &apos;1234567890&apos;print(sta[2:9:2]) 123456789#去除空格name = &apos; zhang yu &apos;# 去除左侧空格print(name.lstrip())# 去除右侧空格print(name.rstrip())# 去除两侧空格print(name.strip()) 123456789101112# 分割字符串#split()函数通过制定分隔符对字符串进行切片name = &quot;zhang and yu and han&quot;print(name.split())print(name.split(&apos; &apos;,2))print(name.split(&apos; and &apos;))# partition()函数将目标字符串分割为两个部分，返回一个三元元组（head,sep,tail），包含分割符url = &quot;https://zhangandyu.github.io//2018&quot;print( url.partition(&quot;//&quot;))print(url.rpartition(&quot;//&quot;)) 1234567# 替换字符串#str.replace(old, new,max)# max 可选字符串不能超过max次str = &quot;this is a apple&quot;print (str.replace(&quot;is&quot;, &quot;was&quot;)) print (str.replace(&quot;is&quot;, &quot;was&quot;, 1)) 1234# 拼接字符串a = &apos;_&apos;name = (&apos;zhang&apos;, &apos;and&apos;, &apos;yu&apos;)print(a.join(name)) 12345678910#查找字符串是否包含子字符串#str.find(str, beg=0, end=len(string))a = &apos; this is a apple&apos;b = &apos;is&apos;#从下标3开始，查找在字符串里第一个出现的子串，返回结果：3print(a.find(b,2)) #从下标5开始，查找在字符串里第一个出现的子串，返回结果：6print(a.find(b,5)) 12345678910111213#判断字符串是否以指定的前后缀结尾# str.startswith(str, beg=0,end=len(string))a = &apos;this is a apple&apos;b = &apos;th&apos;c = &apos;is&apos;print(a.startswith(b))print(a.startswith(c,2))a = &apos;this is a apple&apos;b = &apos;le&apos;c = &apos;app&apos;print(a.endswith(b))print(a.endswith(b,10)) 1234567891011121314151617181920212223#其他函数# 检测数字str.isdigit() # 检测字符串是否只由数字组成str.isnumeric() # 检测字符串是否只由数字组成,这种方法是只针对unicode对象str.isdecimal() # 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象# 检测字母str.isalpha() # 检测字符串是否只由字母组成# 检测字母和数字str.isalnum() # 检测字符串是否由字母和数字组成# 检测其他str.isspace() # 检测字符串是否只由空格组成str.islower() # 检测字符串是否由小写字母组成str.isupper() # 检测字符串中所有的字母是否都为大写str.istitle() # 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写str.capitalize() # 将字符串的第一个字母变成大写,其他字母变小写str.lower() # 转换字符串中所有大写字符为小写str.upper() # 将字符串中的小写字母转为大写字母str.swapcase() # 对字符串的大小写字母进行转换max(str) # 返回字符串 str 中最大的字母min(str) # 返回字符串 str 中最小的字母len(str) # 返回字符串的长度str(arg) # 将 arg 转换为 string 布尔值 and-逻辑与 or-逻辑或 not-逻辑非 not的优先级大于and和or的优先级，而and和or的优先级相等。 逻辑运算符的优先级低于关系运算符，必须先计算关系运算符，再计算逻辑运算符。 变量命名规则 只能包含字母、数字和下划线 不能包含空格 不能将python关键字和函数名用作变量名 变量名应简短又具有描述性 慎用小写字母l和大写字母O 序列 什么是序列 序列是Python中最基本的数据结构。 python中有6个序列的内置类型,包括列表、元组、字符串、Unicode字符串、buffer对象和xrange对象。 对于序列，都可以使用一下操作： 索引 切片 加 乘 成员检查in和not in 计算序列的长度len() 取序列中的最大、最小值max()和min() 列表 列表是最常用的Python数据类型，它可以作为一个方括号内的逗号分隔值出现 列表适合用于存储在程序运行期间可能变化的数据集。 列表是可以修改的， 这对处理网站的用户列表或游戏中的角色列表至关重要。 列表对象方法 12 list.append(x)# 把一个元素添加到列表的结尾 12 list.extend(x)# 将一个给定列表中的所有元素都添加到另一个列表中 12 list.insert(i,x)# 在指定位置插入一个元素 12list.remove(x)# 删除列表中值为 x 的第一个元素 12list.pop(i)# 从列表的指定位置删除元素，并将其返回 12 list.clear()# 从列表中删除所有元素 12list.index(x)# 返回列表中第一个值为 x 的元素的索引 12list.count(x)# 返回 x 在列表中出现的次数 12 list.sort()# 对列表中的元素进行排序 12list.sorted()# 对列表中的元素进行临时排序 12list.reverse()# 倒排列表中的元素 12list.copy()# 返回列表的一个浅拷贝 12list.len(x)#返回列表的长度 用列表实现栈和列队 栈是一种后进先出的数据结构，我们可以使用列表的append()和pop()方法了实现 123a = [1,2]a.append(3) #入栈a.pop() # 最后一个元素出栈 队列是一种先进先出的数据结构，我们可以使用列表的append()和pop(0)方法了实现 123a = [2,1]a.append(1) # 入队列a.pop(0) # 第0个元素出队列 列表推导式 为从序列中创建列表提供了一个简单的方法。 普通方法 12345a = []for i in range(20): a.append(i ** 2)print(a)# i 依然存在 123456b = []for x in [1,2,3,4]: for y in [2,3,4]: if x !=y: b.append((x,y))print(b) 推导式 12a = [i**2 for i in range(20)]print(a) 1[(x,y) for x in [1,2,3,4] for y in [2,3,4] if x !=y] 12from math import pi[str(round(pi, i)) for i in range(1, 16)] 12345matrix = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]][[row[i] for row in matrix] for i in range(4)] 元组 元组为不可变得列表， 在需要创建一系列不可修改的元素时使用。 只有一个元素元组中只包含一个元素时， 需要在元素后面添加逗号，否则括号会被当做运算符使用 12zy = (2,)zy[0] 修改元组 对元组进行连接组合 1234na = (&apos;z&apos;, &apos;y&apos;)me = (&apos;y&apos;, &apos;u&apos;)name = na + meprint(name) 给元组变量赋值 123na = (&apos;zy&apos;, &apos;yu&apos;)na = (&apos;y&apos;, &apos;u&apos;)print(na) 元组运算符 123456789101112# 计算元组个数len((2,45, 67, 8, 9))# 连接(1,2,3, 4) + (4, 5, 6)# 复制(1,2,3, 4)* 3#迭代 for i in (12, 3,4 , 5): print(i) 将列表转换为元组 123list = [ &apos;z&apos;, 1, 2, 3, 4, &apos;u&apos;]tup = tuple(list)print(tup) 映射和集合字典 字典：将相关信息关联起来 访问字典 12man = &#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;xingbie&apos;:&apos;man&apos;, &apos;hige&apos;:165&#125;print(man[&apos;name&apos;]) 添加键-值对 12man[&apos;home&apos;] = &apos;xian&apos;man 修改字典中的值 123man = &#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;xingbie&apos;:&apos;man&apos;, &apos;hige&apos;:165&#125;man[&apos;hige&apos;] = 170man 删除键-值对 123man = &#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;xingbie&apos;:&apos;man&apos;, &apos;hige&apos;:165&#125;del man[&apos;xingbie&apos;]man 遍历所有的键-值对 1234man = &#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;home&apos;:&apos;xian&apos;, &apos;hige&apos;:165, &apos;girfriend&apos;:&apos;null&apos;&#125;for key, value in man.items(): print( key,&quot;:&quot; , value) 分别遍历所有的键-值 1234567man = &#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;home&apos;:&apos;xian&apos;, &apos;hige&apos;:165, &apos;girfriend&apos;:&apos;null&apos;&#125;for key in man.keys(): print( key) for value in man.values(): print(value) 按倒序顺序遍历分别遍历所有的键-值 12for key in sorted(man.keys()): print( key) 字典列表 12345678man = &#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;home&apos;:&apos;xian&apos;, &apos;hige&apos;:165, &apos;girfriend&apos;:&apos;null&apos;&#125;alien = &#123;&apos;color&apos;:&apos;green&apos;, &apos;points&apos;:5&#125;computer = &#123;&apos;name&apos;:&apos;wangzhou&apos;, &apos;num&apos;: 40&#125;alients = [man, alien, computer]for i in alients: print(i) 在字典中存储列表 12345678910province = &#123; &apos;name&apos;:[&apos;zhangyu&apos;, &apos;han&apos;, &apos;dou&apos;], &apos;home&apos;:[&apos;xian&apos;, &apos;beijing&apos;], &apos;hige&apos;:[165, 170, 370, 2389]&#125;for na, las in province.items(): for la in las: print(na, la) 在字典中存储字典 12345678province = &#123; &apos;man&apos; :&#123;&apos;name&apos;:&apos;zhangyu&apos;, &apos;home&apos;:&apos;xian&apos;, &apos;hige&apos;:165, &apos;girfriend&apos;:&apos;null&apos;&#125;, &apos;alien&apos; : &#123;&apos;color&apos;:&apos;green&apos;, &apos;points&apos;: 5&#125;, &apos;computer&apos; : &#123;&apos;name&apos;:&apos;wangzhou&apos;, &apos;num&apos;: 10&#125;&#125;for i, a in province.items(): print(i, a) 字典键的特性 不允许同一键出现两次，创建时如果同一键被赋值两次， 后一个值会被记住。键必须不可变， 可以用数字，字符串，或元组充当，但不能用列表 12dict = &#123;&apos;name&apos;: &apos;zhang&apos;, &apos;name&apos;:&apos;yu&apos;&#125;dict python中关于字典的函数 1234567891011121314151617181920212223242526272829303132333435# 删除字典内所有元素dict.clear()#返回一个字典的浅复制dict.copy()# 创建字典seq = (&apos;Google&apos;, &apos;Runoob&apos;, &apos;Taobao&apos;)dict = dict.fromkeys(seq,10)dict#返回指定键的值，如果值不在字典中返回设定值dict1.get(&apos;Google&apos;, 40)#和get()类似, 但如果键不存在于字典中，将会添加键并将值设为设定值dict1.setdefault(&apos;google&apos;, &apos;20&apos;)dict1#把字典dict2的键/值对更新到dict里dict1=&#123;&apos;Google&apos;: 10, &apos;Runoob&apos;: 10, &apos;Taobao&apos;: 10&#125;dict2 =&#123;&apos;na&apos;: &apos;zhang&apos;, &apos;name&apos;:&apos;yu&apos;&#125;dict1.update(dict2)dict1#以列表返回可遍历的(键, 值) 元组数组dict.items()#以列表返回一个字典所有的键dict.keys()#以列表返回字典中的所有值dict.values() 集合类型 集合是一个无序的，不重复的数据集合。集合作用有以下两点： 去重： 把一个还有重复元素的列表或元组等数据类型变成集合， 其中的重复元素只出现一次，用set()方法 1234567891011121314#使用大括号之间创建集合f = &#123;1, 2, 2, 2, &apos;a&apos;&#125;print(f)print(type(f))# 用set()方法a = [1, 2, 2, &apos;a&apos;, &apos;a&apos;]b = (1,2,2, &apos;a&apos;, &apos;a&apos;)c = set(a)d = set(b)e = set()print(c)print(d)print(e) 进行关系测试：测试两组数据之间的交集，差集，并集等数据关系 12345678910111213141516171819202122232425262728293031323334# 查看集合的相关函数help(set)a = [1,2,2,&apos;a&apos;,&apos;a&apos;,&apos;d&apos;,&apos;e&apos;]b = [1,2,2,&apos;a&apos;,&apos;a&apos;,&apos;b&apos;,&apos;b&apos;]c = set(a)d = set(b)# 取交集e = c.intersection(d)print(e)# 取并集f = c.union(d)print(f)# 取差集（无重复）g = c.difference(d)print(g)#对称差集&quot;（不同时在c,d中存在）h = c.symmetric_difference(d)print(h)#判读是否为子集i = c.issubset(d)print(i)# &quot;判读是否为超集&quot;j = c.issuperset(d) #检查是否有相同元素,没有返回Truek = c.isdisjoint(d) 条件和循环if语句 if-else语句 12345age = 17if age &gt;= 18: print( &quot;you can seee six video&quot;)else: print(&quot; you should study&quot;) if-elif-else 语句 1234567age = 18if age == 18: print( &quot;you should find girlfriend&quot;)elif age&gt; 18: print(&quot;you can see six video&quot;) else: print(&quot; you should study&quot;) 多个elif 1234567891011age = 80if age == 18: print( &quot;you should find girlfriend&quot;)elif 18&lt;age&lt;30: print(&quot;you can see six video&quot;) elif 30&lt; age &lt; 60: print( &quot;you should go to work&quot;)elif age&gt; 60: print(&quot;you should go to tourism&quot;)else: print(&quot; you should study&quot;) if语句中的and和or 1234567num = 9if num &gt;= 0 and num &lt;= 10: print (&apos;hello&apos;)num = 10if num &lt;= 0 or num &gt;= 10: print(&apos;zy&apos;) while语句 for循环主要用于遍历迭代的对象， while循环主要用于条件判断 1234567891011numbers = [12, 21, 48, 8, 1230, 5, 7]even =[]odd = []while len(numbers) &gt; 0 : number = numbers.pop() if(number % 2 == 0): even.append(number) else: odd.append(number) print(even) continue 用于跳过该次循环 123456789101112numbers = [12, 21, 48, 8, 1230, 5, 7]even =[]odd = []while len(numbers) &gt; 0 : number = numbers.pop() if(number % 2 == 0): even.append(number) else: odd.append(number) continue print(even) break 用于退出循环 12345678910111213numbers = [12, 21, 48, 8, 1230, 5, 7]even =[]odd = []while len(numbers) &gt; 0 : number = numbers.pop() if(number % 2 == 0): even.append(number) else: odd.append(number) continue print(even) break 循环使用 else 语句 123456count = 0while count &lt; 5: print (count, &quot; is less than 5&quot;) count = count + 1else: print (count,&quot; is not less than 5&quot; ) for语句for 循环可以遍历任何序列的项目 12for letter in &apos;python&apos;: print(letter) 函数 函数是组织好， 可重复使用的，用来实现有关功能的代码段。函数能提高应用的模块行，和代码的重复利用率。 定义函数123456def zhangyu(): &quot;&quot;&quot;显示名称&quot;&quot;&quot; print(&quot;zhangandyu&quot;) # return[&apos;a&apos;] zhangyu() 向函数传入参数 1234567def zy(name): print(&apos;Hello, &apos; + name.title() + &apos;!&apos;)zy(&apos;zhangyu&apos;)# name 为形参#&apos;zhangyu&apos;为实参 位置实参 1234567def describe_pet(animal_type, name): print(&apos;I have a &apos; + animal_type) print(&apos;My &apos; + animal_type + &apos;is name is &apos; + name.title() + &apos;.&apos;)describe_pet(&apos;dog&apos;, &apos;huabao&apos;)# 警惕位置混淆describe_pet(&apos;huabao&apos;, &apos;dog&apos;) 关键字实参 123456def describe_pet(animal_type, name): print(&apos;I have a &apos; + animal_type) print(&apos;My &apos; + animal_type + &apos;is name is &apos; + name.title() + &apos;.&apos;)describe_pet(name = &apos;huabao&apos;, animal_type = &apos;dog&apos;)# 位置混淆也没有关系 设置默认值 12345678910def describe_pet(name,animal_type=&apos;dog&apos;): &quot;&quot;&quot;设置animal_type的默认参数是dog&quot;&quot;&quot; print(&apos;I have a &apos; + animal_type) print(&apos;My &apos; + animal_type + &apos;is name is &apos; + name.title() + &apos;.&apos;)# 默认参数不改变describe_pet(name = &apos;huabao&apos;)# 默认参数改变describe_pet(&apos;huxbao&apos;, &apos;cat&apos;) 返回值函数返回的值可以使用return语句将值返回到调用函数的代码行中。从而将程序的大部分繁重工作移到函数中取完成。 12345def zy_name(first_name, last_name): name = first_name + last_name return name.title()zy_name(&apos;zhang&apos;, &apos;yu&apos;) 让实参变成可选的 12345678910def zy_name(first_name, last_name, middle_name =&apos; &apos;): if middle_name: name = first_name +&apos; &apos;+ last_name +&apos; &apos; + middle_name else: name = first_name + &apos; &apos; + last_name return name.title()zy_name(&apos;zhang&apos;, &apos;yu&apos;)zy_name(&apos;zhang&apos;, &apos;and&apos;, &apos;yu&apos;) 返回字典 1234567def build_person(first_name, last_name, age=&apos;&apos;): person = &#123;&apos;first&apos; : first_name, &apos;last&apos;: last_name&#125; if age: person[&apos;age&apos;] = age return personbuild_person(&apos;zhang&apos;, &apos;yu&apos;, age=25) 传递列表 12345def get_user(names): for name in names: print(name.title())zy = [&apos;a&apos;, &apos;b&apos;, &apos;v&apos;]get_user(zy) 传递任意数据的实参 12345def get_world(* names): for i in names: print(i)get_world(&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;) 使用位置实参和任意数量实参 必须将接纳任意数量实参的形参放到最后 1234def get_world(size, *names): for i in names: print(str(size) + i)get_world( 1,&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;) 使用任意数量的关键字实参 1234567def get_user(**user_info): profile = &#123;&#125; for key, value in user_info.items(): profile[key] = value return profileuser_profile = get_user(location = &apos;princeton&apos;, field = &apos;physics&apos;, home = &apos;xian&apos;)print(user_profile) 递归函数如果一个函数在函数内部，调用自己本身，这个函数就是递归函数。 12345def fan(n): if n == 1: return 1 else: return n * fan (n-1) 但递归函数在数特别大的情况下会导致栈溢出， 例如： 1fan(10000) 变量的作用域 局部作用域 1234def func(): name = &quot;zhangyu&quot;print(name) 运行报错， 因为name变量只在func()函数中生效，而在全局无法调用。 作用域链 12345678name = &quot;lzl&quot;def f1(): name = &quot;Eric&quot; def f2(): name = &quot;Snor&quot; print(name) f2()f1() f1()函数执行，最后输出snor，Python中有作用域链， 变量会由内到外找，先去自己作用域找，自己没有再去上级找，直到找不到报错。 终极作用域 1234567891011name = &apos;zhang&apos;def f1(): print(name)def f2(): name = &apos;yu&apos; return f1 ret = f2()ret() 输出结果为zhang, 分析可知， f2()函数执行结果为函数f1的内存地址。执行ret()就是执行f1()，name =’zhang’与fi()在一个作用域链。 12345678910# 新浪面试题li = [lambda : x for x in range(10)]print(type(li))print(type(li[0]))#lambada 面试题 li = [lambda :x for x in range(10)]res = li[0]()print(res) Numpy库 Numpy是科学计算库,特点是有N维数组对象ndarray，是Scipy、Pandas等的基础 array结构 1234567891011121314151617181920212223import numpy as np# 给列表每个元素增加1zy = [1, 2, 3, 4, 5]zy = zy + 1# 错误， 因为列表不支持这样的错误# 用array函数zy = np.array(zy)zy += 1zy# 计算by = np.array([ 2, 3, 4, 5, 6])zy + byzy * byzy ** by# 取值zy[0] zy[2:] 底层为创建ndarray对象，有丰富的可选参数 12345zy.shape # 多维数组的形状type(zy) # 类型zy.dtype # 数组中元素的类型, array内部必须为同一类型， 不同类型会默认进行转换zy.size # 数组中元素个数zy.ndim # 数组的维度 索引 12345678tang_array = np.array([[1, 2, 3], [3, 4, 5], [6, 7, 8]])tang_array[1]tang_array[1, 1]tang_array[:,1]tang_array[1,0:2] 1234567891011tang_array2 = tang_arraytang_array2# 将tang_array2中的4 改为10tang_array2[1,1] = 10tang_array2tang_array# tang_array 中的4也改为了10， 修改tang_array2,实际是指向了tang_array中的内存# 要想修改tang_array2 而不改tang_arra, 需要用copy() 巧用布尔类型 1234567891011121314# 构造等差数组zy = np.arange(0, 100, 10)zy# array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])# 构造布尔类型by = np.array([0, 0, 1, 0, 1, 1, 1, 0, 1, 0], dtype=bool)by# array([False, False, True, False, True, True, True, False, True,False])zy[by]# array([20, 40, 50, 60, 80]) array数组的数值计算 123456789101112131415161718192021222324252627282930313233343536373839404142zy = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])#所有数据求和 np.sum(zy)# 指定要按什么维度进行计算np.sum(zy,axis = 0)np.sum(zy,axis = 1)# 所有数据乘积zy.prod()zy.prod(axis = 0)zy.prod(axis = -1)# 最小最大值zy.min(axis = 0)zy.max()# 最大值的索引zy.argmax()# 均值zy.mean()zy.mean(axis = 0)# 标准差zy.std(axis = 1)# 方差zy.var()# 进行限制， 小于3的值都变成3， 大于7的值都变成7zy.clip(3, 7)# 进行四舍五入zy.round()# 进行四舍五入到第一个小数点zy.round(decimals = 1) 排序 12345678import numpy as nptang_array = np.array([[1.1, 4.3, 5.2 , 5.1], [5.2, 6.4, 2.3, 4.6]])# 排序np.sort(tang_array)np.sort(tang_array, axis = 0) 数组形状操作 123456789101112zy_num = np.arange(10)zy_num# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])zy_num.shape = 2, 5zy_num# array([[0, 1, 2, 3, 4],[5, 6, 7, 8, 9]])zy_num.reshape(1,10)#array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 增加维度zy_num = np.arange(10)zy_num.shape#(10,)zy_num = zy_num[np.newaxis, :]zy_num.shape#(1, 10)zy_num = zy_num[ :, np.newaxis]zy_num.shape#(10, 1)# 压缩维度zy_num = zy_num.squeeze()zy_num#array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])zy_num.shape#(10,)# 转置zy_num.shape = 2,5zy_num#array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])zy_num.transpose() # zy_num.T#array([[0, 5],[1, 6], [2, 7], [3, 8], [4, 9]])# 数组的连接a = np.array([[1,2, 3, 4], [5, 6, 7, 8]])b = np.array([[0, 3, 5, 7], [8, 0, 10, 21]])c = np.concatenate((a, b))c# array([[ 1, 2, 3, 4], [ 5, 6, 7, 8],[ 0, 3, 5, 7], [ 8, 0, 10, 21]])c = np.confatenate((a, b), axis = 1)cnp.vstack((a,b))# array([[ 1, 2, 3, 4],[ 5, 6, 7, 8],[ 0, 3, 5, 7],[ 8, 0, 10, 21]])np.hstack((a,b))# array([[ 1, 2, 3, 4, 0, 3, 5, 7],[ 5, 6, 7, 8, 8, 0, 10, 21]])a# array([[1, 2, 3, 4],[5, 6, 7, 8]])a.flatten()a.ravel()# array([1, 2, 3, 4, 5, 6, 7, 8]) 生成数组 123456789101112131415161718192021222324252627282930np.arange(10)np.arange(2,20,2)# array([ 2, 4, 6, 8, 10, 12, 14, 16, 18])np.arange(2,20,2, dtype= np.float32)# array([ 2., 4., 6., 8., 10., 12., 14., 16., 18.], dtype=float32)# 构造等距数组np.linspace(0, 10, 5)# array([ 0. , 2.5, 5. , 7.5, 10. ])# 构造行向量，列向量np.r_[0:10:1]np.c_[0:10:1]np.zeros(3)# array([0., 0., 0.])np.zeros((3,3))np.ones(3)# array([1., 1., 1.])np.ones((3,3)) * 8zy_num = np.array([1,2,3, 4])np.zeros_like(zy_num)# array([0, 0, 0, 0]) 运算 12345678910111213141516171819202122232425# 乘法x = np.array([5,5])y = np.array([2,3])np.multiply(x,y)# array([10, 15])np.dot(x,y)# array([10, 15])x = np.array([1, 1, 1])y = np.array([[1, 2, 3],[4, 5, 6]])print(x * y)#[[1 2 3] [4 5 6]]x = np.array([1, 1, 2])y = np.array([1, 1, 1])x == y# array([ True, True, False])np.logical_and(x,y)np.logical_or(x,y)np.logical_not(x,y) 随机模块 123456789101112131415161718192021222324252627282930# 随机浮点数np.random.rand(3,2)# 随机整数np.random.randint(10, size = (2,4))# array([[4, 6, 7, 8], [7, 6, 2, 3]])# 随机数np.random.rand()np.random.random_sample()# 0-10中随机找三个数np.random.randint(0, 10, 3)# array([8, 6, 9])# 随机高斯分布mu, sigma = 0, 0.2np.random.normal(mu, sigma, 5)# 设置数字精度, 输出数精度为小数点后3位np.set_printoptions(precision = 3 )# 洗牌， 打乱排列顺序zy_num = np.arange(15)zy_num# array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])np.random.shuffle(zy_num)zy_num# array([ 1, 5, 4, 11, 14, 9, 8, 6, 7, 3, 0, 2, 10, 12, 13]) 读取写入文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 写一个名为tang的txt文件%%writefile tang.txt1 2 3 4 5 6 2 3 4 5 5 7# 读取tang文件data = np.loadtxt(&apos;tang.txt&apos;)data# array([[1., 2., 3., 4., 5., 6.],[2., 3., 4., 5., 5., 7.]])%%writefile tang.txt1, 2, 3, 4, 5, 6 2, 3, 4, 5, 5, 7data = np.loadtxt(&apos;tang.txt&apos;, delimiter = &apos;,&apos;)%%writefile tang.txta, b, c, d, e, f1, 2, 3, 4, 5, 6 2, 3, 4, 5, 5, 7# 不读取第一行data = np.loadtxt(&apos;tang.txt&apos;, delimiter = &apos;,&apos;, skiprows =1)# 指定使用哪几列data = np.loadtxt(&apos;tang.txt&apos;, delimiter = &apos;,&apos;, skiprows =1, usecols = (0,1, 4))# 写入数组文件zy_num = np.array([[1, 2, 3], [4, 5, 6]])np.savetxt(&apos;tang.txt&apos;, zy_num)# 保存成指定格式np.savetxt(&apos;tang.txt&apos;, zy_num, fmt= &apos;%d&apos;)np.savetxt(&apos;tang.txt&apos;, zy_num, fmt= &apos;%.2f&apos;)# 指定分隔符np.savetxt(&apos;tang.txt&apos;, zy_num, fmt= &apos;%d&apos;, delimiter = &apos;,&apos;)# 读写文件zy_num = np.array([[1, 2, 3], [4, 5, 6]])np.save(&apos;zy_num.npy&apos;, zy_num)zy_num = np.load(&apos;zy_num.npy&apos;)# 将两个文件保存在同一文件夹，并进行读写zy_num2 = np.arange(10)np.savez(&apos;zy_npz&apos;, a = zy_num, b = zy_num2)data = np.load(&apos;zy.npz&apos;)data.keys()# [&apos;a&apos;, &apos;b&apos;]data[&apos;a&apos;]# array([[1, 2, 3],[4, 5, 6]])]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫学习]]></title>
    <url>%2F2018%2F07%2F12%2F%E6%8A%80%E8%83%BD-python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[爬取英雄联盟-英雄皮肤图片 前言 最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。 过程 分析过程 找到皮肤图片链接， 研究规律。 在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。 打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。 123456789# 英雄1http://ossweb-img.qq.com/images/lol/web201310/skin/small266000.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small266001.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small266002.jpg# 英雄2http://ossweb-img.qq.com/images/lol/web201310/skin/small103000.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small103001.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small103002.jp 从以上的链接中，我们可以知道英雄皮肤的链接规律为： 1&quot;http://ossweb-img.qq.com/images/lol/web201310/skin/small&quot; + &quot;英雄代号&quot; + &quot;0&quot; + &quot;01-10&quot; 找到每个英雄对应的数字代号 那么我们需要解决的问题就变成了到每个英雄对应的代号是多少？ 通过搜索，我们发现每个英雄对应的代号存在champion.js文件中 从Headers中， 我们可以看到champion.js 对应的url为： 12345678&gt;&gt;我们通过正则表达式， 把js中对应的英雄代号提取出来。&gt;&gt; 通过以上把链接拼凑起来，我们就可以把链接对应的图片皮肤下载到本地了。3. 代码&gt; import requestsimport reimport jsonimport urlliburl = “http://lol.qq.com/biz/hero/champion.js&quot;hd ={‘User-Agent’:”Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0”}data = requests.get(url,headers = hd).contentdatas = data.decode()pat = ‘“keys”:(.*?),”data”‘imglist = re.findall(pat,datas)datass = json.loads(imglist[0])for i in datass: try: for j in range(12): try: num = str(j) # print(num) if len(num) == 1: hero_num = &quot;00&quot; + num elif len(num) ==2: hero_num = &quot;0&quot; + num numstr = i + hero_num urls = &apos;http://ossweb-img.qq.com/images/lol/web201310/skin/big&apos;+ numstr +&apos;.jpg&apos; localfile = &quot;E:/张宇个人文件/英雄联盟/&quot; + str(i) + str(num) + &quot;.jpg&quot; urllib.request.urlretrieve(urls, filename = localfile) except Exception as err: pass except Exception as err: pass 12345678---# 爬取王者荣耀-英雄图片1. 代码&gt; 用python爬取王者荣耀皮肤import requestsimport reimport urllib url = “http://pvp.qq.com/web201605/herolist.shtml&quot;hd ={‘User-Agent’:”Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0”}data = requests.get(url,headers = hd)pat = ‘a href=”herodetail/(.*?).shtml’imglist = re.compile(pat, re.S).findall(data.text) for i in imglist: # print(i) try: for j in [1,2,3,4,5,6]: try: numstr = str(i)+&apos;/&apos; +str(i)+&apos;-mobileskin-&apos;+ str(j) # print(numstr) urls = &apos;https://game.gtimg.cn/images/yxzj/img201606/heroimg/&apos;+numstr+&apos;.jpg&apos; print(urls) localfile = &quot;E:/张宇个人文件/官网图片/&quot; + str(i)+ str(j)+ &quot;.jpg&quot; urllib.request.urlretrieve(urls, filename = localfile) except Exception as err: pass except Exception as err: pass 1234567------# 爬取网站图片1. 代码* 构建用户代理池&gt; 这里可以随意加多个浏览器uapools = [ “Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)”, “Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)”, “Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko”, “Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 920)”, “Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0.2) Gecko/20100101 Firefox/6.0.2”, “Opera/9.80 (Windows NT 6.1; WOW64) Presto/2.12.388 Version/12.12”, “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0 Safari/537.36 OPR/15.0”, “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.57 Safari/537.17”, “Mozilla/5.0 (X11; CrOS armv7l 3428.193.0) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.126 Safari/537.22”, “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2”, “Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/533.9 (KHTML, like Gecko) Maxthon/3.0 Safari/533.9”,] 1232. 爬取并下载图片&gt; import reimport requestsimport urllib.request uapools 如上所示for ua in uapools: hd ={‘User-Agent’:ua} i = uapools.index(ua) # 限制爬取页数， 我们爬取前10页 if i &gt; 10: break try: url = &quot;http://www.iyuanqi.com/home/funimg/fun_list/m/Home/cp_uid/all/sort/30hot/p/&quot;+str(i)+&quot;.html&quot; data = requests.get(url, headers = hd) pat = &apos;class=&quot;lazy-img&quot; src=&quot;(.*?)&quot; data-original=&quot;&apos; imglist = re.compile(pat, re.S).findall(data.text) for j in range(0, len(imglist)): try: thisimg = imglist[j] thisimgurl = thisimg localfile = &quot;E:/张宇个人文件/网络图片/&quot; + str(i) + str(j) + &quot;.jpg&quot; urllib.request.urlretrieve(thisimgurl, filename = localfile) except Exception as err: pass except Exception as err: pass 12345678910111213141516-----------------# 爬取天善课程数据表存储到MYSQL1. 前言&gt; 天善智能是一个商业智能与大数据在线社区，有很多很好的学习课程。我们用爬虫来爬取网站的所有课程并存储到MYSQL数据库中， 以便于进一步的分析。2. 用python在MYSQL中创建名为zhanhyu的数据库 * 用python连接MYSQL数据库&gt; import pymysql 因为本地mysql没有设置密码， 所以没有加password参数db = pymysql.connect(host = ‘localhost’, user = ‘root’, port = 3306) 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句cursor = db.cursor() 123 * 创建一个新的数据库， 名字叫做zhangyu&gt; cursor.execute 执行真正的sql语句, DEFAULT 指定默认值cursor.execute(“CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8”)123453. 在zhangyu库中创建tianshan2_datas的数据表 * 指定在zhangyu这个数据库中运行&gt; db = pymysql.connect(host = ‘localhost’, user = ‘root’, port = 3306, db=’zhangyu’)cursor = db.cursor()123* 用sql语句创建名为tianshan2_datas的表&gt; sql = ‘CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))’ curosr.exectute(sql) db.close() 12344. 爬取天善智能网站的数据&gt; import reimport requests for i in range(1,5): # 观察天善课程链接， 找出规律 thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1) # 用requests库抓取数据 hd ={&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;} data = requests.get(thisurl, headers = hd) #用正则表达式进行解析 title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos; price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos; numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos; title = re.compile(title_pat, re.S).findall(data.text) if(len(title)&gt;0): title = title[0] else: continue price = re.compile(price_pat, re.S).findall(data.text) if(len(price)&gt;0): price = price[0] else: price = &apos;免费&apos; numb = re.compile(numb_pat, re.S).findall(data.text) if(len(numb)&gt;0): numb = numb[0] else: numb = &apos;缺失&apos; 1235. 将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中&gt; con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;) cursor = con.cursor() sql = &apos;insert into tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos; try: cursor.execute(sql, (title, price, numb)) con.commit() except: con.rollback() con.close() 12345----&gt; 这样，我们就成功的把爬取的数据保存到mysql数据库中，方便我们查询使用。6. 完整代码&gt; import pymysql 因为本地mysql没有设置密码， 所以没有加password参数db = pymysql.connect(host = ‘localhost’, user = ‘root’, port = 3306) 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句cursor = db.cursor() cursor.execute 执行真正的sql语句, DEFAULT 指定默认值cursor.execute(“CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8”) db = pymysql.connect(host = ‘localhost’, user = ‘root’, port = 3306, db=’zhangyu’)cursor = db.cursor()sql = ‘CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))’cursor.execute(sql)db.close() import reimport pymysqlimport requests for i in range(0,284): thisurl = “https://edu.hellobi.com/course/&quot; + str(i+1) hd ={“user-agent”: “Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36”} data = requests.get(thisurl, headers = hd) title_pat = ‘(.?)‘ price_pat = ‘class=”price-expense”&gt;￥(.?)‘ numb_pat = ‘class=”course-view”&gt;(.*?)‘ title = re.compile(title_pat, re.S).findall(data.text) if(len(title)&gt;0): title = title[0] else: continue price = re.compile(price_pat, re.S).findall(data.text) if(len(price)&gt;0): price = price[0] else: price = ‘免费’ numb = re.compile(numb_pat, re.S).findall(data.text) if(len(numb)&gt;0): numb = numb[0] else: numb = ‘缺失’ con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;) cursor = con.cursor() sql = &apos;insert into tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos; try: cursor.execute(sql, (title, price, numb)) con.commit() except: con.rollback() con.close() `]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音乐]]></title>
    <url>%2F2018%2F04%2F23%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E9%9F%B3%E4%B9%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[李志-回答 卑鄙是卑鄙者的通行证，高尚是高尚者的墓志铭。看吧，在那镀金的天空中，飘满了死者弯曲的倒影。冰川季过去了，为什么到处都是冰棱？好望角发现了，为什么死海里千帆向竞？ 我来到这个世界上，只带着纸、绳索和背影，为了在审判之前，宣读那些被判决了的声音：告诉你吧，世界，我不相信！纵使你脚下有一千名挑战者，那就把我算作那第一千零一名。 我不相信天是蓝的，我不相信雷的回声；我不相信梦是假的，我不相信死无报应。如果海洋注定要决堤，就让所有的苦水都注入我心中；如果陆地注定要上升，就让人类重新选择生存的峰顶。新的转机和闪闪的星斗，正在缀满没有遮拦的天空，那是五千年的象形文字，那是未来人们凝视的眼睛。 李志-忽然 李志-这个世界会好吗？ 李志-热河 李志-黑色信封 李志-梵高先生 李志-关于郑州的回忆 李志-人民不需要自由 李志-墙上的向日葵 李志-光阴路的夏天 李志-动静 李志-看见 李志-14跨年演唱会 左小祖咒/陈升-爱情的枪 Pink Floyd - Wish You Were Here Queen - Love Of My Life 轻音乐-Cello Collection with Calcifer]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刻意练习]]></title>
    <url>%2F2018%2F04%2F16%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E3%80%8A%E5%88%BB%E6%84%8F%E7%BB%83%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[读后笔记与文章–2018-04-16 1. 什么是刻意练习 刻意练习是一个在已经有明确方法论的行业内， 个人通过制定一系列明确的目标， 不断进行刚好超出他们能力范围的练习， 并通过检验反馈不断地对练习进行调整， 从而创建有效的知识晶体， 保存在长时记忆中， 以便以后遇到问题及时响应。 2. 刻意练习背后的原理是什么 利用身体偏爱稳定的倾向，进行刚好超出能力范围的练习我们人类的身体天生偏爱稳定性， 我们的身体通过各种各样的反馈机制来保持身体各项指标的稳定性。当身体系统长时间的感受到压力，原来的平衡再无法保持时， 身体便会开始响应那些变化，让那些变化更加容易， 进而达到重新的平衡。但在过长的时间内过分的逼迫自己， 可能导致倦怠和低效。 例如：对于跑步锻炼来说， 如果你短时间剧烈的运动，导致身体中的能量与氧气下降， 身体就会通过心跳加速以提高氧气供给，并将储存在不同部位的能量拿来给肌肉供给，以达到平衡状态。只要体育锻炼并未让身体平衡机制无法正常运转，就很难引起身体上的生理变化。 因此， 你需要足够努力的锻炼并保持足够长的时间，才能让身体形成新的平衡。要想要改变不断地进行下去， 你就需要不断地加码：跑的更远，更快，负重跑等。 一旦你不给自己在跑步方面施加压力， 你将停止改进的脚步，停留在新的平衡内。 但如果你一上来玩命的跑， 可能只让自己受伤。 同理，对大脑进行长时间的锻炼， 大脑也会以各种不同的方式来重新布置神经元之间的连接，以达到快速地相应。 为了创建有效的知识晶体 知识晶体就是我们思考某件事物时心理所创建的知识结构。 刻意练习的目的之一就是创建有效的知识晶体。 信息预先存在这些晶体中，并长时间保存在记忆之中，当生活中遇到类似的情况可快速地进行响应。 行业内的杰出人物正式由于他们经过多年的积累，针对行业中可能遇到的不同局面，创建了高度复杂和精密的知识晶体。反过来这些知识晶体让他们更好地在一系列事物中找到规律，更好地理解信息，指定计划，高效的学习。 比如： 你听到‘猫’这个词就会想到毛茸茸可爱的猫，它的样子，叫声等具体的内容。你在生活中对‘猫’这个词创建了包括图像， 气味，声音等一系列的晶体结构。 同理，我们要想更好地创建对某一动物的知识晶体，最好的方法就是花一点点的时间来了解它们，摸摸它的毛发，和它玩耍，并且细心地观察它的一举一动。 3. 如何在一个行业中进行刻意练习 找到一位好的导师 如果可以的话， 找到一个好的导师能够让自己的练习事半功倍。 好的导师能够了解什么样的行为会带来进步，能带来及时的反馈。 找行业中的大牛 我们在现实中很难找到一个好的导师， 但我们在互联网中可以很容易找到行业中的大牛。 我们首先确定大牛的指标都有哪些， 然后调查思考谁符合这些指标，算的上是真正的大牛。 在数据分析行业， 称为大牛的特征有：有多年的行业积累， 有大厂的工作经历。 有较大的行业影响力， 愿意传播教授 技能。 通过搜索，我们可以知道：数据挖掘与数据分析博主-邓凯是数据分析里的大牛， 他在数据分析行业工作多年， 并在京东这样的大厂担任数据负责人， 微信公众号有数十万粉丝，现在成立了爱数圈这样的学习团体。 观察大牛都做了什么 观察他们是做了什么让他们如此的杰出，运用了哪些方法让他们如此的卓越。 不断的通过工作业务磨练自己的数据分析思维，建立了良好的互联网分析能力。 他不断地写数据分析的相关文章，总结输出，让自己不断扩大影响力。这些方法途径，也是自己在进行技能学习时可以学习借鉴的方法。 学会分解目标 找到一种适合自己的练习方法，并将漫长的目标分解成一个一个的小目标，每次练习都只专注于这一个目标，当达到目标时， 给自己一个小小的奖赏 最重要的是盯紧自己的目标。 找到自己的练习规律 保证自己在短的时间内能够集中全部的注意力去练习。 一旦自己发现自己不能够保持专注力，就停下来休息。 经过自己这段时间的统计发现，自己能够保持专注学习的时间为一个小时， 超过一个小时自己就看不进去了。 这个时候，自己停下来放松10分钟再看，效果会好的多。 在工作中需要必要的反馈 给自己设计某种必要的反馈， 让自己能够随着时间的推移， 不断的纠正错误和精进技巧。 如何创建反馈， 我觉得可以通过写作来给自己提供反馈，通过输出来倒逼输入， 在写作中发现自己的问题， 比如自己在写这篇读书笔记时就发现自己有很多的概念没有理解。 创建自己对于这个技能的知识晶体 将工作中的项目经验和学到的知识相结合，构成强大的晶体结构。培养自己能够遇到问题迅速的响应能力。多培养自己遇到问题的解决思路。 隐形知识 寻求建议 当遇到停滞阶段时， 稍微给自己加强练习的强度，找出到底是在哪里让你停滞不前， 然后尝试换一种方法专门针对这个缺点来进行练习，或向大牛寻求建议。 自己的打字速度现在停滞不前 在练习的过程中保持动机 给自己制定一个专门的时间点来进行练习，并想办法把干扰你的事物控制到最小。坚定自己可以通过刻意练习可以进步的信念。有可能的话， 加入一个社区进行学习比自己单独学习更容易坚持 比如：把手机调静音，去图书馆学习防止网络对自己的影响。 保持充足的睡眠，加入一个数据分析的圈子进行学习。 保证错误是低风险的。这样自己才能敢于犯错。 练习， 试错， 反馈，修正 应用 当自己在进行学习时， 自己总是会想到刻意练习里的一个观点， 就是在学习过程中必须脱离自己的舒适区，让学习的内容稍微难一点， 这样的学习才会让自己进步。 每当这样想， 自己就不会抵触学习的过程了， 也让自己能够长久的坚持。 补充–2018-12-08 刻意练习区别与其他练习的特征是什么 有定义明确的特定目标把大目标分解成每一个小目标，制定计划，在达成每一个小目标的过程中，纠正自己的行为方式，解决面临的问题。 具有专注的练习状态尽力保持专注，集中精力，不会走神 练习包含反馈你必须知道自己做的对不对，如果不对，又错在哪里。 走出舒适区 刻意练习的原则专注、反馈、纠正、足够的重复次数 延伸： TED演讲： 《how to get better at the things you care about》 刻意练习的本质-阳志平公众号：心智工具箱网站：http://www.yangzhiping.com/ 论文：the role of Deliberate Practice in the Acquisition of Expert Performance 第二次读书笔记–2020年2月26 在2018年自己就看完了此书，但是自己并没有按照书中的内容践行过，自己也没有任何质的改变。这也让我明白了一个深刻的道理：读书不应该把读完作为目标，而应该能把书中的知识真正应用到生活中为目标。 要不读也是白读。 那么在书中讲的刻意练习的方法是什么呢，总结如下： 自己应该找到和行业大牛的差距，从而给自己设立清晰的目标。 将目标拆解成 N 个可完成的小目标，每次只盯住一个目标练习。 在练习时跳出舒适区，在短时间内注意力高度集中， 完成目标进行奖励。 每次练习时都必须有反馈，对暴露的问题进行纠正。 必须坚持去做，保持持续去做的动力。 关键词： 目标、专注、反馈、纠正、持续。 自己在技能中为什么没有进步，原因有以下三点： 自己没有一个清晰的目标，不知道自己与高手之间的差距应该怎样弥补？ 自己没有持续的动力，总是躲在自己的舒适圈里。 自己的学习不能很好的用在工作中，在工作中没有体现。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>学习方法</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双拼输入法]]></title>
    <url>%2F2017%2F09%2F17%2F%E7%94%9F%E6%B4%BB-%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93-%E5%8F%8C%E6%8B%BC%E8%BE%93%E5%85%A5%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 怎么接触到双拼的？自己第一次接触双拼，是看到李笑来老师的《把时间当朋友》第二章中的“盲打究竟是否值得学会”,里面提到了盲打与双拼帮助他快速进行记录笔记和文字。 于是自己就试着在网上找双拼的学习方法。 2. 什么是双拼？ 维基百科：双拼是汉语拼音输入法的一种编码方案。相对于全拼而言，使用双拼输入汉字时只需输入一个代表声母的字母，一个代表韵母的字母，就可以打出任意一个中文单字了。 理解起来也很简单，比如你要拼写 张 红 这两个字， 用全拼的话可能你得输入 zhang hong， 而用小鹤双拼的话， 你只需要输入vh hs 就可以显示。 v 代表zh , h 代表ang , s代表ong 双拼的语法也有很多种，比如小鹤双拼、自然码双拼、紫光拼音双拼、搜狗拼音双拼、微软拼音双拼、智能ABC双拼。 每种双拼对应的语法也都不一样。 自己学习的是小鹤双拼，语法图是这样的： 在搜狗输入法上点击 设置—— 属性设置 —— 常用 —— 特殊习惯—— 双拼 就可以使用了。 3. 学习的过程刚开始学习小鹤双拼的时候， 自己是完全不习惯的， 因为想要使用小鹤双拼进行文字输入，就得记住每个字母对应的韵母， 自己每输入一个字， 就得想一下这个字的韵母是什么， 对应到按键上的那个字母又是什么。 再去输入，说实话当时输入字的效率低下到令人发指，而且往往记不住，自己只好打印了一张语法表贴在自己的电脑旁， 忘了就在表上找。 好几次忍不住偷偷换成了全拼， 特别是在工作着急的情况下。 就这样别别扭扭用了一周之后， 才发现自己已经能够慢慢不看语法表了。 （这让我都有点怀疑自己的智商，因为网上说基本一周就可以很熟练了）一个月过后自己才做到了输入基本不卡壳，但如果旁边有人一紧张还是会忘掉如何输入了。 现在用了一年多， 自己已经能够无意识的使用双拼了。 如果你现在问我键盘上的字母在双拼中代表哪个韵母，自己可能真的答不上来，但只要自己在键盘上打字，自己就能够无意识的打出来。 4. 学习双拼的优点与缺点( 1 ). 优点 简洁，同样一个词全拼要五六下，双拼只需要两下 感觉节省了时间，更喜欢在键盘上敲字了。 （至于是否真正节省了时间，自己没有做过对比） ( 2 ). 缺点 全拼不会用了， 有时在别人的电脑上输入文字总是很别扭，老出错，总想着把输入法改成双拼 有时大脑短路会想不起来双拼的语法 5. 感悟 任何学习都是不可逆的，当你学了到了一项技能，你就不可能再像从前没学过一样生活。 最可怕的不是自己知道自己不知道，而是不知道自己不知道。 比如自己学习双拼，自己以前根本不知道还有双拼这么一种输入法，就更不会产生要学习这种输入法的冲动。 如何解决自己不知道自己不知道的知识，自己目前能够想到的方法是：多读书，多关注大牛，多了解别人是怎么工作、生活。 有些东西只有自己亲身经历过后才能有所体会，哪怕是坏的体验。 如果只是看别人推荐而不去坚持使用双拼， 我就不能体会到大脑下意识使用双拼输入的快感。当然，也许会出现这种情况， 你付出了时间，付出了精力，而这项技能对你的生活影响并不大。这就需要你前期做一些搜索调查。 延伸到生活上，要是我不来北京生活，不来北京工作，我就没有机会知道来北京到底会面临什么困难，到底对自己的职业发展是否有益。也许最后自己会失败，可那又怎么样，自己的人生自己做主。 2020年2月26：现在在北京已经呆了马上快3年了，自己虽然已经转行做数据分析了，但是现在自己的职业发展并不好，甚至犹豫自己是否还应呆在北京。 学会一项技能，不是只是了解它，而是能够在生活中无意识的使用它 一项技能，只是了解是远远不够的， 你要去不断的磨练，打磨，直到它成为你大脑的一部分。 学会的标准就是：你能否不需要专门思考就能够调用它。 要学习那些你通过短时间学会,就能够一辈子用的上的知识。 6. 延伸 总是听很多的牛人说，写作是非常重要的一项技能，对一个人清晰思考问题是非常有帮助的，然而自己却迟迟没有行动，主要还是觉得自己语言词汇匮乏， 缺乏独立思考，怕自己语无伦次。 其实又想想，写作这东西这就和自己刚开始学习双拼时一样，开始你觉得自己没有可能学会，也许过一段时间你就能够发现自己的进步， 你不去坚持写又怎么能够证明自己一定学不会呢？ 自己认为学习是一个自我验证的过程：你认为自己不可能学会，你就不会坚持去学；你不坚持去学，你就不会有进步， 从而你就不会看到到自己能够学会的结果，也就证明了自己确实学不会。相反， 你认为自己能学会，你就坚持去学，看到自己的进步，最终的确学会了，也证明了自己确实能够学会。 7. 未解决问题 如何运用心智的力量在还没有机会亲身体验的情况下，仅凭心智就可以像真实经历过一样深刻体会？ 如何解决 害怕自己付出了时间，付出了精力，而没有一个好的结果 参考资料： 《把时间当朋友》]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
</search>
