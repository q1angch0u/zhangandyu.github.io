<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive-SQL学习]]></title>
    <url>%2F2019%2F04%2F18%2FHive-SQL%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[数据库与表的增删改查数据库 create database-创建新数据库 12345--创建zhang数据库create database zhang --制定数据库的位置create database if not exists zhang location '/zhang.db' alter database-修改数据库 12---增加数据库属性alter database zhang set dbproperties("CTtime"= "2020-05-01") drop database -删除数据库 12345---数据库下无表drop database zhang;---数据库下有表，-强制删除drop database zhang cascade; 选择数据库 1use android; 12# 重置默认数据库use default android; 查看所在的数据库 123456789show databases;--模糊查询show databases like "s%"--- 查询数据库信息desc database zhang;---查询数据库扩展属性desc database extended zhang; 数据表 create table-创建新表 12345678910111213141516171819202122232425create [external] table [if not exists] table_name [(col_name data_type [comment col_comment],....)][partitioned by (col_name data_type [comment col_comment],..)][clustered by (col_name, col_name, ...)][row format row_format][stored as file_format][location hdfs_path]--- create table 创建指定名称的表，如果相同名称的表已存在，则用if not exists 选项来忽略这个异常。--extername 关键字让用户创建一个外部表---partitioned by 分区：分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过where子句的表达式来选择查询所需的指定分区，提高查询效率。--clustered by 分桶--row format 字段之间的分隔符---stored as 文件存储格式--location， 指定表在HDFS上的存储位置---在zhang库中创建test表create external table dept( deptid int, dname string, loc int) row format delimited fields terminated by '\t' update-更新数据库中的数据 1234567update 表名set 需更新的列名1= 新值1, 需更新的列名2=新值2,...where 列名 = 某个原有的值UPDATE Websites SET alexa='5000', country='USA' --更新的数据WHERE name='菜鸟教程'; insert into() -向数据库中插入新数据 12insert into 表名（列名1,列名2,列名3...)values(值1, 值2, 值3...) delete-从数据库中删除数据 12345678delete from 表名where column = value...DELETE FROM WebsitesWHERE name='Facebook' AND country='USA';--删除表中所有的行，表结果不变delete from table_name; alter table- 修改数据库表 123--清楚表中数据,删除掉指定分区ALTER TABLE shphonefeature DROP IF EXISTS PARTITION(year = 2015, month = 10, day = 1);---lter table test.mon_mau_list drop partition (hit_mon = '&#123;0&#125;') drop table - 删除表 create index -创建索引 drop index -删除索引 refresh table 表名 - 刷新数据表 1refresh table computer_log.client_ios_log 查看当前使用的数据库中有哪些表 1show tables; 查看非当前使用的数据库中有哪些表 1show tables in myhive; 查看数据库中以 android 开头的表 12use android;show tables like 'android*' 查看表的详细信息 1desc formatted android 查询分区表有多少分区 1show partitions dept_partition; 查看分区表结果 1desc formatted dept_partition 增加分区 1alter table dept_partition add partition(month=&apos;201705&apos;) partition(month=&apos;201704&apos;) 删除分区 1alter table dept_partition drop partition (month=&apos;201705&apos;) 内部表与外部表 内部表(管理表)：默认创建内部表， 删除表会删除所有数据 外部表： 删除表不会删除这份数据，不过描述表的元数据信息会被删除掉。 原始日志数据应该建立外部表（避免误删）， 用到的中间表、结果表使用内部表存储。 查看表是内部表还是外部表 12--查看表信息desc formatted table_name 内部表与外部表的相互转换 12345---内部表转换为外部表alter table student set tblproperties('EXTERNAL' = 'true') ---单引号、大小写不能变---外部表转化为内部表alter table student set tbproperties('EXTERNAL' = 'false') 查询select…from… 加入表中一列含有多个元素， 我们可以只查找此列的第一个元素 12select name, subord[0] from employees; 可以使用 “点” 符号， 类似：表的别名 . 列名 这样的用法 12select name, address.city from employees; 使用正则表达式，可以选出所有列名以 price 作为前缀的列 1select 'price.*' from stocks; 使用列值进行计算 1select count(distinct account), avg(salary) from employees; 使用别名 1select count(distinct acount) as uv from employees; 如果用 distinct, select 后面必须直接跟 distinct 1select distinct user_account, province from computer_viedata where 关系型运算符优先级高到低为：not - and - or 123select * from employees where country = 'us' and state = 'ca';select * from employees where country not in ('us', 'china') 数学运算符与关系运算符 运算符 描述 + 加法 - 减法 * 乘法 / 除法 % 取余 &amp; 与 \ 或 ^ 异或 ~ 取反 操作符 描述 A=B 如果A=B，则返回True,否则返回False A&lt;=&gt;B 如果A和B都为NULL，则返回True,其他的和等号操作结果一致，如果任意为Null,则结果为null A&lt;&gt;B,A!=B A或B为Null, 则返回Null,如果A不等于B，则返回True,否则返回False A&lt;B – A&lt;=B – A&gt;B – A&gt;=b – A[not] between B and C — A is null — A is not null — in – A [NOT] like B – A rlike B, A REGEXP B — 逻辑运算 描述 and — or – not — like、rlike 123456---like、 rlike select name, address.street from employees where address.street rlike '.*(beijing|shanghai).*';select name, address.street from employeeswhere address.street like '%beijing%' or address.street like '%shanghai%'; 通配符 含义 % 匹配0个或任意多个字符 _ 匹配任意一个字符 escape 转义字符，可匹配%和_。如SELECT * FROM table_name WHERE column_name LIKE ‘/%/_%_’ ESCAPE’/‘ — — . 匹配任意单个字 符 * 匹配0个或多个前一个得到的字符 [] 含有任意一个[]内的字符，[ab]*可匹配空串、a、b、或者由任意个a和b组成的字符串。 ^ 匹配开头，如^s匹配以s或者S开头的字符串 $ 匹配结尾，如s$匹配以s结尾的字符串。 {n} 匹配前一个字符反复n次。 group by1234567891011--- 对结果进行分类select year(ymd), avg(price_close) from stockswhere exchange = 'nasdaq' and symbol = 'aapl'group by year(ymd)order by year(ymd) desc; --desc 从高到低排列 order by1234567891011--对查询的所有结果进行排序, 可在字段加 DESC 关键字， 进行降序排序。 （默认 ASC， 升序）select year(ymd), avg(price_close) from stockswhere exchange = 'nasdaq' and symbol = 'aapl'group by year(ymd)order by year(ymd) desc; 12--先对code进行排序，然后对code里的姓名进行排序select * from a order by code, name desc; having1234567891011--- having 子句来限制输出结果--- 查找平均工资大于3000的部门select deparment, avg(salary) as average from salary_info group by deparment having average &gt; 3000 having 与 where 的区别： Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。 Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。 limit12---使用limit语句限制返回的行数，只显示 10 行select count(distinct account) as uv from employees limit 10; 表连接joinHive中Join的关联键必须在ON ()中指定，不能在Where中指定,ON 子句指定了两个表间数据进行连接的条件。 对于多张表进行连接查询12345678---为什么条件内不将表 b 和表 c 进行连接操作， 因为 Hive总是按照从左到右的顺序来执行SELECT a.ymd, a.price_close, b.price_close, c.price_closeFROM a JOIN b ON a.ymd = b.ymd JOIN c ON a.ymd = c.ymdWHERE a. symbol = 'Apple' AND b.symbol = 'Ibm' AND c.symbol = 'Google' 并集：union 与 union all12345678910111213141516171819202122with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" union select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 union 与 union all 的不同： union, 结果包含所有行， 并删除重复行 unoin all, 结果包含所有行， 但不删除重复行 交集：intersect12345678910111213141516171819202122with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" intersect select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 差集：except12345678910111213141516171819202122with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%支付宝%" except select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 函数聚合函数 函数名 定义 count() 个数统计函数 count(distinct ) 统计去重之后的个数 sum() 求和 sum(distinct ) 去重之后的和 avg() 平均值 avg(distinct) 去重之后的平均值 min() 最小值 max() 最大值 corr(A, B) 相关系数 var_pop() 方差 var_samp() 样本方差 stddev_pop() 标准偏差 stddev_samp() 标准样本偏差 covar_pop(A, B) 协方差 covar_samp(A, B) 样本协方差 RAND() 随机数 count(1)、count(*)、count(column) 之间的区别 执行效果上：count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULLcount(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULLcount(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。 执行效率上：列名为主键，count(列名)会比count(1)快列名不为主键，count(1)会比count(列名)快如果表多个列并且没有主键，则 count(1) 的执行效率优于count(*)如果有主键，则 select count(主键)的执行效率是最优的如果表只有一个字段，则 select count(*)最优。 时间函数 函数名 定义 语句 NOW ( ) 当前时间 select now() extract() 抽取具体的年、月、日 date() 返回时间的日期部分 year() 返回时间的年份 month() 返回时间的月份 day() 返回日期的天 hour() 返回时间的小时 minute() 返回时间的分钟 second() 返回时间的秒 week () 第几周 dayofweek() 返回星期几，1为星期天 dayofyear() 一年中的第几天 sec_to_time ( ) 秒数转成时间 date_add() 时间相加 date_add(dt,interval 1 day ) date_sub(date,INTERVAL expr（时间间隔） type（时间类型，天、月、年）) 时间相减 date_sub(‘2018-05-01’,interval -1 year) datediff() 时间的差值 date_format() 输出指定时间格式 date_format(hit_date, “%Y-%m-%d) datename() 返回日期部分的参数 datepart() 返回日期、时间的单独部分 求留存率 datediff-求留存率 1234567891011121314151617181920212223242526272829---一次性求次1日，次3日， 次7日留存，此方法不能计算pv，会造成笛卡尔积with a1 as (select hit_date, user_accountfrom computer_view.datawhere hit_date between '2019-04-25' and '2019-05-13' and btn_information is not null),a2 as (select hit_date, user_accountfrom computer_view.datawhere hit_date between '2019-04-25' and '2019-05-13' and btn_information is not null)select a1.hit_date,count(distinct a1.user_account) uv,count(distinct case when datediff(a2.hit_date, a1.hit_date) = 1 then a1.user_account else null end ) next_day,count(distinct case when datediff(a2.hit_date, a1.hit_date) = 3 then a1.user_account else null end ) three_day,count(distinct case when datediff(a2.hit_date, a1.hit_date) = 7 then a1.user_account else null end ) seven_dayfrom a1 join a2 on a1.user_account = a2.user_accountgroup by a1.hit_dateorder by a1.hit_datelimit 100 date_add 求留存率 12345678910111213141516171819202122232425262728293031323334---步骤1：统计每天的uv---步骤2： - 统计10-15号每天的次日留存数， 统计次3、7日留存只需将1换为3、7with a1 as ( select user_account, hit_date from computer_view.data where hit_date between '2018-11-10' and '2018-11-15'),a2 as ( select user_account, hit_date from computer_view.data where hit_date between '2018-11-10' and '2018-11-25')select a1.hit_date, count(distinct a1.user_account) as uvfrom a1 join a2 on a1.user_account = a2.user_accountWHERE a2.hit_date = date_add(a1.hit_date, 1) group by a1.hit_dateorder BY a1.hit_date--步骤3：计算留存率 计算留存率的其他写法-迷神 1234567891011121314151617181920212223242526-- 留存sql优化select count(1)from( select userid, count(1) from( select t1.userid, t1.statdate from table1 t1 where t1.statdate = $&#123;上30天日期&#125; and t1.statdate &lt;= $&#123;上一天日期&#125; group by t1.userid, t1.statdate ) s1 group by userid having count(1) 2 ) R1--此sql为一个样例，计算连续跟任意都适用，至于计算第N天，只需要更改下日期过滤条件，变成=$[上N天日期]，=$&#123;上一天日期&#125;。 --另外，这种方式适合跑当前周期数据，如果跑历史数据，可以写个循环。当然，最暴力还是直接用userid 关联。--这种写法，更多是针对现在大部分分布式处理平台的特性，尽可能将数据合理均匀分片，每台服务器各自运算自己的，最后汇总。 尽可能少用 count distinct 这种写法，因为无法利用分片的特性。 留存率的另一种写法-勇哥 123456789101112131415161718192021222324252627282930313233343536373839404142with a1 as (select hit_date, user_account, count(1) as hit_countfrom apache_computer_view.client_android_logWHERE hit_date between '2020-04-01' and '2020-04-07' and btn_navigation like "%查询办理%"group by 1,2),a2 as (select hit_date, user_account, count(1) as hit_countfrom apache_computer_view.client_android_logWHERE hit_date between '2020-04-01' and '2020-04-07' and btn_navigation like "%查询办理%"group by 1,2)select a1.hit_date as one, a2.hit_date as two, datediff(a2.hit_date, a1.hit_date) as cha, count(distinct a2.user_account), sum(a2.hit_count)from a1 left join a2 on a1.user_account = a2.user_accountgroup by 1,2having cha &gt; 0order by 1,2 计算月留存率的简单写法：筛选出在两个月份出现的用户 12345678910111213141516171819202122232425262728with a1 as (select user_account, count(distinct month (hit_date)) as cfrom apache_computer_view.client_android_log where hit_date between '2019-03-01' and '2019-04-31'group by user_accounthaving c = 2union select user_account, count(distinct month (hit_date)) as cfrom apache_computer_view.client_ios_log where hit_date between '2019-03-01' and '2019-04-31'group by user_accounthaving c = 2 )select count(distinct user_account) as uv from a1 条件判断：case when 与 if IF( expr , v1 , v2 )函数 查出班级所有学生，如果年龄小于20，就标准为少年，否则标记为青年。12345select * if(age&lt;20,'少年','青年') AS ifage from student ifnull(V1,V2)函数 如果v1不为空，则直接返回v1;如果v1为空，则返回参数v2123select ifnull(1,2), ifnull(null,10); case when 函数 对不同字母进行省份转换 12345678910111213141516171819202122232425selectcase when province like 'ah' then '安徽' when province like 'fj' then '福建' when province like 'gd' then '广东' else 'm' end as province , count(distinct user_account) uv, count(page_name) pvfrom android_logwhere hit_date between '&#123;&#125;' and '&#123;&#125;'and page_name like '%Kefujh%'group by case when province like 'ah' then '安徽' when province like 'fj' then '福建' when province like 'gd' then '广东' else 'm' end order by case when province like 'ah' then '安徽' when province like 'fj' then '福建' when province like 'gd' then '广东' else 'm' end limit 1000 统计各部门男女分别有多少人 姓名 部门 性别 甲 A 男 乙 A 男 丙 B 女 丁 A 女 张 B 男 赵 B 女 1234567select 部门， sum (case 性别 when '男' then 1 else 0 end ) as male_count, sum (case 性别 when '女' then 1 else 0 end ) as male_countfrom table1group by 部门 范围转换12345678910select case when population &lt; 250 then '1' when population = 250 and population &lt; 500 then '2' when population = 500 and population &lt; 750 then '3' when population = 750 then '4' else null end as pop_classs, count(*) as cntfrom popgroup by district; 行转列 函数 case when concat(string A/col, string B/col…) ：函数在连接字符串时，只要其中一个是NUll，则返回NUll concat_ws(separator, str1, str2,…): 函数需要指定分隔符，只能接收 string或string类型的数组，只要有一个字符串不是NUll， 则不会返回NULL。 collect_set(col): 函数值接受基本数据类型，主要作用是将某字段的值进行去重汇总，产生array类型字段。 案例 多行转多列 年 季度 销售量 1991 1 11 1991 2 12 1991 3 13 1991 4 14 1992 1 21 1992 2 22 1992 3 23 1992 4 24 查询结果如下： 年 一季度 二季度 三季度 四季度 1991 11 12 13 14 1992 21 22 23 24 12345678910select 年, sum(case when 季度=1 then 销售量 else 0 end ) as 一季度, sum(case when 季度=2 then 销售量 else 0 end ) as 二季度, sum(case when 季度=3 then 销售量 else 0 end ) as 三季度, sum(case when 季度=4 then 销售量 else 0 end ) as 四季度,from salesgroup by 年 多行转单列 省-城市 uv 河北省-保定 11189 山西省-阳泉市 13 河南省-信阳 7462 1234567891011121314select concat(province,'-', city), uv --concat_ws('-', province, city), uv from (select province, city, count(distinct user_account) as uv from apache_computer_viewwhere hit_date = '2020-03-01'group by province, city) 多行转单列-复杂 name contellation blood_type 孙悟空 白羊座 A 猪八戒 射手座 A 宋宋 白羊座 B 唐僧 白羊座 A 张帅 射手座 A 把星座和血型一样的人归类到一起： 。。。 。。。 射手座,A 猪八戒\张帅 白羊座，A 孙悟空\唐僧 白羊座，B 宋 123456789101112select t1.c_b concat_ws("\", collect_set (t1.name))from ( select concat_ws(',', constellation, blood_type) c_b, name from person_info) t1group by t1.c_b;) 求将每个省的城市列出来 12345678910111213select province, collect_set(city)from apache_computer_view.client_android_log where hit_date = '2020-03-01'and nbtn_name is not null group by province---辽宁省 ["营口市","大连","大连市","抚顺市","铁岭","盘锦","锦州","沈阳市","辽阳","鞍山","铁岭市","本溪市","丹东市","丹东","沈阳","朝阳市","锦州市","辽阳市","阜新市","鞍山市","盘锦市","葫芦岛","营口","抚顺","葫芦岛市","阜新","本溪","朝阳"] 求出一个月内活跃天数大于20天的用户数 1234567891011121314151617--先列出每个用户的所有登陆时间--选出需要的时间段select count(distinct user_account) as uv from (select user_account, collect_set(hit_date) as t from apache_computer_view.client_android_log where hit_date between '2020-03-01' and '2020-03-31' group by user_account) as awhere size(a.t) &gt;= 20--手机号对应日期长度 &gt;= 20 列转行 函数 explode(col): 将hive列中复杂的array或者map结构拆分成多行 lateral view用法： lateral view udtf(expression) tableAlias as columnAlias说明： 用户和split,explode 等UDTF一起使用，能够将一列数据拆分成多行数据， 在此基础上可以对拆分的数据进行聚合计算. 形成一个新的表，并对原来的表进行侧写 案例 需求1 movie category 《疑犯追踪》 悬疑,动作,科幻,剧情 《lie to me》 警匪,动作,心理 要求： movie category 《疑犯追踪》 悬疑 《疑犯追踪》 动作 《疑犯追踪》 科幻 《疑犯追踪》 剧情 《lie to me》 警匪 《lie to me》 动作 《lie to me》 心理 123456789select movie, category_namefrom movie_infolateral view explode(category) tmpTable as category_name---用分开的表，对要求的数据进行测写-- select movie,explode(category) from movie_info 会生成笛卡尔积，不能执行 需求2： 将 表 table 中的 adid_list 转换为单独的行。 表-table： pageid adid_list front_page [1,2,3] contact_page [3,4] 输出结果为： pageid adid_list front_page 1 front_page 2 front_page 3 contact_page 3 contact_page 4 12345SELECT pageid, adidFROM tablelateral view explode(adid_list) adTable as adid 需求3： 计算特定广告的展现次数 1234567SELECT adid, count(1)FROM tablelateral view explode(adid_list) adTable as adidGROUP BY adid 输出结果为： adid count(1) 1 1 2 1 3 2 4 1 需求4： 多个 lateral view 查询 表： table2 array col2 [1,2] [“a”，”b”] [3,4] [“c”, “d”] 输出结果为： myCol1 myCol2 1 “a” 1 “b” 2 “a” 2 “b” 3 “c” 3 “d” 4 “c” 4 “d” 123456SELECT myCol1, myCol2FROM baseTableLATERAL VIEW explode(col1) myTable1 AS myCol1LATERAL VIEW explode(col2) myTable2 AS myCol2 窗口函数 函数 函数名 定义 over() 指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化 常跟的函数 说明 — — current row 当前行 n preceding 往前n行数据 n following 往后n行数据 unbounded 起点 uvbounded preceding 表示从前面的起点开始 unbounded following 表示到后面的终点 lag(col, n) 往前第n行数据 lead(col, n) 往后第n行数据 ntile(n) 把有序分区中的行分发到指定数据的组中， 各个组有编号，编号从1开始，ntile返回此行所属组的编号 first_value() 返回组中数据窗口的第一个值 last_value() 返回组中数据窗口的最后一个值 案例 name orderdate cost jack 2017-01-01 10 tony 2017-01-02 15 jack 2017-01-03 23 tony 2017-01-04 29 jack 2017-01-05 46 jack 2017-04-06 42 tony 2017-01-07 50 jack 2017-01-08 55 mart 2017-04-08 62 mart 2017-04-09 68 neil 2017-05-10 12 mart 2017-04-11 75 neil 2017-06-12 80 mart 2017-04-13 94 查询在2017年4月购买的顾客及总人数12345678select name,count(1)over() ----over全量， 如果不加over，就会按照name来划分from businesswhere substring_index(orderdate,'-',2) = '2017-04'group by name name c1 不加over jack 2 1 mart 2 4 查询顾客的购买明细及月购买总额 123456select *, sum(cost) over (distribute by month(orderdate))--- sum(cost) over (partition by month(orderdate))from business 要将cost按照日期进行累加 12345select *, sum(cost) over(order by orderdate rows between unbounded preceding and current row)from business 按照日期进行排序，并将当前日期和前一天、后一天数据求和 12345select *, sum(cost) over(order by orderdate rows between 1 preceding and 1 following)from business 求每个人将按照日期进行累加的消费金额 12345select *, sum(cost) over (partition by name order by orderdate rows between unbounded preceding and current row )from business 要将cost按照日期进行倒序累加 12345select *, sum(cost) over (order by orderdate rows between current now and unbounded following )from business 查询顾客上次购买的时间, 与下次购买时间。相邻两个时间戳如何相减，求时间 123456select *, lag(orderdate, 1) over (partition by name order by orderdate), lead(orderdate,1) over (partition by name order by orderdate)from business 查询前20%时间的订单信息 1234567891011select * from ( select name, orderdate, cost, ntile(5) over(order by orderdate) gid from business ) twhere git =1 ntile函数详解ntile函数可以将有序数据，根据指定的组数进行分组处理。 编号从1开始，对于每一行，ntile将返回此行所属的组编号。ntile函数的分组依据： 每组包含的数据个数不能大于它上一组 包含的数据个数 计算规则：1. 检查能不能对所有满足条件的记录进行平均分组，若能则直接平均分配完成分组。2. 若不能，则会先分出一个组，此组个数为（总个数/总组数）+1。3. 分配之后系统会继续比较余下的记录数与未分配的组数能不能进行平均分配，若不能，则根据上面条件再分配。 例如：将6个记录分为4组， 不能平均分配则，第一组记录数为 （6/4)+1 = 2条记录。剩余4条记录分为3组，不能平均分配，则第二组记录数为（4/3)+1=2条记录。剩余2条记录分为2组，则剩余2组各1条记录。 排序函数 函数 SQl 中用于排序的函数有：rank、dense_rank、row_number、ntile函数,其语法为：1234567891011rank() over ([partition by A] order by B DESC)dense_rank() over ([partition by A] order by B DESC)row_number() over ([partition by A] order by B DESC )ntile() over([partition by A] order by B desc)-- partition by A 表示 按照A进行分区。-- order by B 表示按照B进行排序。-- DESC 表示 从大到小降序排列。-- 其中[partition by col1]若不需要则可省略不写。 明确各函数之间的不同点rank函数， 数值相等的排序则会留下空位： 1、2、2、4dense_rank函数，数值相等的排序不会留下空位: 1、2、2、3row_number函数，则不区分数值是否相等，默认排序为： 1、2、3、4ntile函数，对有序行进行分组处理 **2.需求 如何找出各省点击人数Top10的按钮？ 对于这个问题，首先要理清自己的思路：1. 取出 省份、按钮和 uv;2. 各省分组内，按照uv进行从大到小排序，并输出一列排序序号;3. 根据排序序号，取出排序前10的按钮和省份。 1234567891011121314151617181920212223242526select province, nbtn_name from (select province, --省份 nbtn_name, --按钮 uv, --uv dense_rank()over(partition by province order by uv DESC) as ran --排序from (select province, nbtn_name, count(distinct user_account) as uvfrom apache_computer_view.client_android_log where nbtn_name is not null and hit_date = '2020-03-10'group by province, nbtn_name))where ran &lt;= 10 求连续4个月活跃的用户数 123456789101112131415161718192021---1月活跃的用户数， 在2月、3月、4月一直活跃的用户有多少？with a1 as(select user_account , month(hit_date) as monthfrom compu_view.ios_log_viewwhere hit_date between '2019-01-01' and '2019-04-30'group by user_account, month(hit_date) ),a2 as ( select user_account,a1.month, row_number() over(partition by user_account order by a1.month) as pxfrom a1) select count(distinct user_account) as uvfrom a2where a2.px = 4 求4月连续7天进行签到的用户数 12 字符串函数 函数 函数名 定义 concat() 拼接字符串 length() 计算字符串的长度，一个汉字算三个字符 instr (A ,B ) 返回字符B首次在A中出现的位置,不存在返回0 lcase() 转换成小写 left(string2 ,length ) 从string2中的左边起取length个字符 lower() 将字串转化为小写 upper() 将字符转化为大写 replace() 替换字符 split() hive字符串分割函数 substr() 返回字符串A从start位置开始，长度为len的字符串 substring() 截取字符串 substring_index() 通过截取获取不同索引位的字符 LTRIM (string2 ) 去除前端空格 RTRIM (string2 ) 去除后端空格 函数详解 substr函数与 substring函数用法相同: 1substr/substring( A, k开始截取的位置，截取长度) 举例：1234substr(string,4): 从右第4位置截取到最后，结果为：ingsubstr(string,1,3):取左边第1位置起，3字长的字符串，结果为：strsubstr(string,-3,3):取右边第1位置起，3字长的字符串,右边第一位置往右不够3字长，结果为：gsubstr(string,-3,3):取右边第1位置起，3字长的字符串，结果为：ing substring_index函数1substring_index(A, 分割的字符,截取字符的位置) 举例：123456789substring_index(&apos;15,151,152,16&apos;,&apos;,&apos;,1)：取第一个逗号前面的字符串，结果为：15substring_index(&apos;15,151,152,16&apos;,&apos;,&apos;,2)：取第二个逗号前面部分，结果为：15,151substring_index(&apos;15,151,152,16&apos;,&apos;,&apos;,-1)：取目标字符串中最后一个含 “,” 位子的后的部分，结果为：16substring_index(substring_index(&apos;15,151,152,16&apos;,&apos;,&apos;,2),&apos;,&apos;,-1):取第二个逗号前面部分,然后最后逗号的前面部分，结果为：151substring_index(substring_index(&apos;15,151,152,16&apos;,&apos;,&apos;,-2),&apos;,&apos;,1)：取倒数第二个逗号后面部分字符串，再去这部分里第一个都号前的部分，结果为：152 split函数 1split(A, 分割的字符) 举例： 12345678910split(&apos;a,b,c,d&apos;,&apos;,&apos;):根据逗号进行分割，结果为： [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]split(&apos;a,b,c,d&apos;,&apos;,&apos;)[0]： 取结果数组中的某一项，结果为： asplit(&apos;192.168.0.1&apos;,&apos;\\.&apos;)： 点号这种特殊字符的时候需要做特殊的处理，结果为：[&quot;192&quot;,&quot;168&quot;,&quot;0&quot;,&quot;1&quot;]&quot;.... split(&apos;192.168.0.1&apos;,&apos;\\\\.&apos;) ... &quot;: split包含在 &quot;&quot; 之中时 需要加4个\,不然得到的值是null同样的 | 等特殊符号也需要做类似 处理。 3.区分函数之前的区别 substr函数与 substring函数是根据截取的位置来进行分割。 substring_index和split是根据特定的字符来进行分割。 需求 将一些字段拆解出来进行使用，比如：Syjh-sjsy-zygn-3_1字段，我们只需要Syjh-sjsy-zygn位置的所有按钮。 1234567891011select substring_index(nbtn_position, &apos;-&apos;,3) as position, count(distinct user_account) as uv from apache_computer_viewwhere hit_date = &apos;2020-03-01&apos; and nbtn_position like &apos;%Syjh%&apos;group by substring_index(nbtn_position, &apos;-&apos;,3) 空字段赋值NVL：给值为NULL的数据赋值，格式为NVL（string1, replace_with),功能为：如果string1为null，则NVL函数返回replace_with的值，否则返回string1的值，如果两个参数都为NULL，则返回NULL。1select nvl(comm, -1) from student; 查看系统内置函数 查看系统自带的函数 1show functions 显示自带的函数的用户 1desc function 函数名; 详细显示自带的函数用法 1desc function extended 函数名 Hive避免数据倾斜 数据倾斜：当我们在Hive上进行查询时，因为数据的分散度不够， 导致大量数据集中在一台或者几台服务器上， 导致数据的计算速度远远低于平均计算速度， 计算过程特别耗时。 数据倾斜的表现：任务进度长时间维持在99%，查看任务监控页面，发现只有少量子任务未完成。 小表Join大表 Hive 会假定查询中最后一个表是最大的表， 在对每行记录进行连续操作时， 它会尝试将其他表缓存起来，然后扫描最后那个表进行计算。因此，我们在查询时，要保证连续查询中的表的大小从左到右依次是增加的。 假如，在 a, b 两个表中，b表最小， 则 写sql时需让b表在左，a表在右： 123456789101112131415161718SELECT a.price_close, b.price_closeFROM b JOIN a ON b.ymd = a.ymd AND b.symbol = a.symbolWHERE a.symbol = 'APPLE'---Hive支持使用/*+STREAMTALBE*/语法指定哪张表是大表， 不需要排序SELECT /*+3`'LKLLGFG Streamtable(a)*/ a.price_close, b.price_closeFROM a JOIN B on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 大表JOIN大表 空key过滤有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在sql语句中进行过滤。 123456789101112131415Select *From a Join bOn a.user_id is not nullAnd a.user_id = b.user_idUnion allSelect * from awhere a.user_id is null 空key转换有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机值，是的数据随机均匀地分布到不同的reducer上。 把空值的 key 变成一个字符串加上随机数，就能把倾斜的数据分到不同的 reduce 上 ,解决数据倾斜问题。 需要用到Case When … Else…End语法123select n.*from nullidtable n full join bigtable o oncase when n.id is null then concat('hive', rand()) else n.id end = o.id; count(distinct) 去重统计 数据量大时，由于count distinct 操作需要用一个 reduce task 来完成， 这一个reduce 需要处理的数据量太大，会导致整个job很难完成，一般 count distinct 使用先group by 再 count的方式替换。123select count(distinct id) from bigtableselect count(id) from (select id from bigtable group by id) a 避免笛卡尔积尽量避免产生笛卡尔积，如join时不加on条件，或无效的on条件。hive只能使用1个reducer来完成笛卡尔积 行列过滤 列处理： 在查询中， 避免使用 select *, 使用条件限制取需要的列。 行处理： 在分区剪裁中，当使用join外关联时，如果将副表的过滤条件写在where后面，那么就会先全表关联，之后再过滤, 这样会耗费资源。 123456select o.id from bigtable b join ori o on.id = b.id where o.id &lt;=10;select b.id from bigtable bjoin (select id from ori where id &lt;=10) o on b.id = o.id) 12345678910111213SELECT a.price_close, b.price_closeFROM b JOIN a ON b.ymd = a.ymd AND b.symbol = a.symbolWHERE s.symbol = 'APPLE'--正确的写法是将 where 条件写在 on 后面SELECT a.price_close, b.price_closeFROM b JOIN a ON ( b.ymd = a.ymd AND b.symbol = a.symbol and s.symbol = 'APPLE' union all 子查询避免中使用 group by等 union all 子查询避免中使用 group by【替换 count(distinct) 除外】、count(distinct)、max、min等。 123456789101112131415161718192021222324252627with a1 as ( select user_account, hit_date from data where hit_date between '2018-12-01' and '2018-12-13' and nbtn_name like "%支付宝%" union all select user_account, hit_date from data where hit_date between '2018-12-01' and '2018-12-13' and nbtn_name like "%支付宝%")select hit_date, count(user_account) as pvfrom a1group by hit_date 避免不同数据类型进行关联 使用CAST函数对数据类型进行转换，语法为cast(value AS TYPE)123456789select a.price_close, b.price_closefrom a join b on a.user_id = cast(b.user_id as string)where hit_date between &apos;2018-11-01&apos; and &apos;2018-11-02&apos; and a.symbol = &apos;apple&apos; Hive的查询注意事项以及优化总结： 尽量尽早过滤数据，减少每个阶段的数据量。对于分区表要加分区，同时只选择需要使用到的字段 对历史库的计算经验 尽量原子化操作，尽量避免一个SQL包含复杂逻辑，可以使用中间表来完成复杂的逻辑 join操作 小表要注意放在join的左边，否则会引起磁盘和内存的大量消耗 如果union all的部分个数大于2，或者每个union部分数据量大，应该拆成多个insert into语句，实际测试过程中，执行时间能提升50% 用python脚本连接数据库作为一名数据分析师，日报、周报、月报数据一个也不能少。 相应的， 就要在数据库中提取大量的数据， 并处理大量的Excel表格。 在提取和处理数据的过程中， 对于一些重复性的劳动， 写个Python脚本来实现半自动化， 能够大幅提高自己的工作效率。 以下是自己工作中的一点总结经验。 首先， 用Python连接数据库 对于数据库的ip地址，用户名，密码等， 如果不清楚，或数据库连接不上， 需要和开发人员对接 12345678from pyhive import hive import timeconn = hive.Connection(host='ip地址', port=10000, username='用户名', database = 'default', auth='NOSASL')cursor = conn.cursor()# 获得连接的游标 设置开始和结束时间可以用python中的time函数设置时间 12startdate = '2018-09-01'enddate = '2018-09-19' 用Python中的format函数将日期传入{}中 python中写sql脚本时， 需要用\来进行换行符的转换, \后面不能有空格。 日期用两个{}来代替， 用format函数将开始日期与结束日期传入 123456789101112131415161718192021222324# 提取积分类uv,pv数据sql_jifenxinxi_an = """select count(distinct user_account) as uv, count(1) as pv from computer_view.data where hit_date between "&#123;&#125;" and "&#123;&#125;" and (btn_position like "服务-查询-积分信息%" or btn_home = "积分-扇形左" ) limit 1000""".format(startdate,enddate)# format 插入时间cursor.execute(sql_jifenxinxi_an)# 运行此语句cursor.fetchall()#fetchall():接收全部的返回结果行. 我们可以按照这个格式写工作中需要运行的多个SQL语句。 这样， 当脚本运行的时候， 我们可以腾出时间来去干其他工作， 等过一段时间，所有的SQL语句都跑完了， 我们再进行统一的整理。 其他拓展group by 升级版 需求背景 通过 a1 明细表，获得每个店铺，每个城市，每个省份，每个大区以及全国5月的份的成交量情况。 order_id shop city province area hit_date 1 A 西安 陕西 西北大区 2019-05-04 2 B 上海 上海 华东大区 2019-05-01 3 C 安康 陕西 西北大区 2019-05-02 4 D 北京 北京 华中大区 2019-05-21 5 E 延安 陕西 西北大区 2019-05-03 6 F 成都 四川 西南大区 2019-05-19 7 G 汉中 陕西 西北大区 2019-06-04 … … … … … … 10000 H 郑州 河南 西北大区 2019-05-29 解法1： 分别写5个sql 1234567-- 全国成交量selectcount(order_id) as salesfroma1where hit_date between '2019-05-01' and '2019-05-31' 12345678910-- 大区成交量selectarea,count(order_id) as salesfrom a1where hit_date between '2019-05-01' and '2019-05-31'group byarea 123456789101112-- 省成交量selectarea,province,count(order_id) as salesfrom a1where hit_date between '2019-05-01' and '2019-05-31'group byarea,province 1234567891011121314-- 城市成交量selectarea,province,city,count(order_id) as salesfrom a1where hit_date between '2019-05-01' and '2019-05-31'group byarea,province,city 12345678910111213141516-- 店铺成交量selectarea,province,city,shop,count(order_id) as salesfrom a1where hit_date between '2019-05-01' and '2019-05-31'group byarea,province,city,shop 这种方法太低效了， 还需要在excel中进行合并，比较麻烦。 解法2： 通过 union 和 union all 对查询结果进行纵向合并 union: 对合并后的结果进行去重处理 union all : 返回合并后的所有数据 1234567891011121314151617select null,null,null,null,count(order_id) as sales from a1 where hit_date between '2019-05-01' and '2019-05-31' union all select area, null , null ,null, count(order_id) as sales from a1 where hit_date between '2019-05-01' and '2019-05-31' group by areaunion all select area, province , null ,null, count(order_id) as sales from a1 where hit_date between '2019-05-01' and '2019-05-31' group by area, provinceunion all select area, province, city ,null, count(order_id) as sales from a1 where hit_date between '2019-05-01' and '2019-05-31' group by area, province, cityunion all select area, province, city ,shop, count(order_id) as sales from a1 where hit_date between '2019-05-01' and '2019-05-31' group by area, province, city, shop 上述式中有很多 null, 这是因为 union all 拼接的两个表的列数需要相等。 结果如下： 解法3： 利用 union all 比写出5个sql 再在 Excel 中处理简单很多，但是代码比较冗余。可以用grouping sets来进行优化。 此函数可以根据不同维度组合进行聚合。 将union all 语句用grouping sets 进行改写： 1234567891011121314151617181920212223242526select null, area, province, city, shop, count(orderid) as sales, grouping_idfrom a1where hit_date between '2019-05-01' and '2019-05-31'group by null, area, province, city, shopgrouping sets (null, area, (area,province), (area,province,city), (area,province,city,shop)order by grouping_id 得到结果与利用 union all拼接结果相同。group by后面的字段表示要分组聚合的全部字段， grouping sets后面为 group by 后面各种字段的组合。 grouping_id表示每个分组的序号。 1 表示第一个分组、2表示第二个分组。我们可以根据grouping_id 选取我们需要的组合。如果我们需要全国的成交量，则让 grouping_id = 1, 需要每个省的成交量，让 grouping_id = 3。 解法4： cube函数， 对group by的维度的所有组合进行聚合。 123456789101112131415select area, province, count(orderid) as sales, grouping_idfrom a1where hit_date between '2019-05-01' and '2019-05-31'group by area, provincewith cubeorder by grouping_id 以上代码对区域和省份进行了聚合， cube 会先对全部数据进行聚合，即 null, null， 再对area,null进行聚合，然后再对null, province进行聚合，最后再对area,province进行聚合。 解法5：rollup函数， 和cube类似，是针对 group by所有维度的部分组合。 123456789101112131415select area, province, count(orderid) as sales, grouping_idfrom a1where hit_date between '2019-05-01' and '2019-05-31'group by area, provincewith rolluporder by grouping_id 对比cube和rollup得到的结果，我们发现rollup少了null province 这个组合，rollup 是以最左侧指标为主进行组合聚合。 参考资料：讲讲 group 的plus版-张俊红]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>sql</tag>
      </tags>
  </entry>
</search>
