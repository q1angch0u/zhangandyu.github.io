<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何通过数据驱动增长]]></title>
    <url>%2F2019%2F09%2F19%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[思考用户最想要，最关注的是什么，如何满足他们的潜在需求获得增长？ 增长代表的是产品的长期价值，包括用户价值和商业价值。 增长不是绩效指标的提升，而是以用户为中心带来产品价值的提升。体验也不是你理解的要把最好的带给用户，而是把用户最想要的、最核心的给他，同时忽略其他不重要的，用最小成本触发增长。 只有回归用户价值， 才有长期持续增长的可能性，同时配合有效的增长手段， 让增长效率大幅提升，事半功倍。 以用户为中心增长，不是把提升关键数据指标当做最重要的事情， 而是通过提升用户价值提升商业价值，数据只是衡量的手段和工具而已。 以用户为中心， 通过差异性洞察找到增长的爆破点，再配合数据驱动的实验方法，最终达到持续地以最小成本创造最大价值的目标。 做增长不仅要了解用户，更要上升到“人性洞察”层面，挖掘用户的潜在需求；而不是靠主观臆想，把所谓的“最好的，最专业的”给用户。 增长的核心观点？ 以用户为中心 差异性洞察 数据驱动验证 驱动增长的步骤 差异化定位及增长战略， 确定北极星指标 公司产品战略： 产品差异性定位、核心竞争优势。定位就是打产品的差异化，并且通过营销推广等一系列手段把这个差异化植入用户心中，抢占用户心智。只要用户一遇到相关的场景需要做决策时就会想到你。 全盘考虑发现增长机会 根据公司产品战略来提出多项增长机会 打造闭环落地实施增长 选择增长方向-明确指标-提出假设-分解假设-上线实验-观察结果-再次试验 总结增长规律规模复制 积累3中的经验，摸索规律，把规律用到其他相关的项目、功能、界面中。最终带来批量的增长。 以用户为中心 有能力挖掘用户的潜在心理和真实需求。 你的用户最想要、最关注的是什么？ 如何通过满足他们的潜在需求获得增长呢？ 有没有更简单的方式？ 只要能满足核心需求，用户完全忽悠其他的小瑕疵。 比如 朋友分享的哔哩哔哩视频看10秒就会显示下载客户端查看，就是利用了用户的核心需求，能够看到想看的视频，能够和朋友愉快的沟通，大部分用户并不会在乎多下载一个APP。 但是你直接吊起视频小程序，能够看到的是整个视频， 要能够做到抓大放下，力图用最小成本获取最大价值。 差异性洞察 只有当你捕捉到别人没有发现的点，你才可能出奇制胜。洞察其实就是发现差异、发现未知的过程。只有发现差异点，你才有可能抓住增长爆破点。 差异性洞察的方法 通过百度指数分析通过百度指数，比较自己和精品的数据，看看有没有明显的差异。 分析用户留言和评论对于差评要特别关注，它往往反映了用户认为非常重要且没有被满足的核心需求。 访谈老板多跟老板聊聊天，借机会了解产品的目标、方向、核心资源及优势、用户等，可以起到事半功倍的效果。 如果十分钟能解决的问题，为什么要花上好几天呢，而且还不一定能解决。 在增长时代，我们需要注重协作，注重信息的互通，而不是单兵作战，好的人脉关系都是互相麻烦出来的。 留意行业分析及用户行为报告 如何调研目标数据收集 锁定目标用户范围 进一步明确定位的产品—-调研现有用户 增长陷入瓶颈， 需要转型或扩大规模的产品—-调研潜在用户 从0到1探索方向的新产品—–根据北极星指标定位目标人群，然后进行调研 分析全量数据 小样本数据会导致结果偏差 真实数据才能帮助决策 全量数据的结论往往出乎意料 分析数据的铁人三项 性别 年龄 地域 数据分析寻找数据差异 对比、不同维度交叉对比 各省/市/城市类型的占比 和全国或全网的平均水品对比 和同行业平均水平对比 和竞争对手的水平进行对比 解读数据差异 探寻本质 违背常理 与平均水平有出入 对差异进行深入研究 对用户进行分群 为什么要进行用户分群一个产品不可能满足所有人。我们要找到最重要的那个用户群体，在普遍特征的基础上进一步挖掘该目标群体的差异性。要找到最重要的用户群体，首先我们需要把现有用户群体进行分类，再排定优先级。 如何给用户做分群 单一维度或可以清晰定义的维度 不同类别之间应具有明显的差异性 和北极星指标相关并由此判断优先级 用户访谈 把握好用户的心理和场景 选择有代表性的用户 结合数据分析结果， 选择符合特征的人选。 寻找地域性比较远的用户进行访谈。 访谈需要深挖，不要只是按照大纲来。 关注特殊人群 比如高价值用户，高活跃用户等 特殊类型的用户可以放大各种细微的情感及体验，帮助我们得等洞察。只有亲自接触真实、有代表性的用户，才能有所发现。 访谈中得出的任何结论，都不可以作为最终定论，因为有可能只是个别现象，不代表它具有普适性。 用户画像能够帮助我们了解用户， 但是缺点是不能够落地。 要想寻找差异性， 就需要对比。 对分类人群进行对比探寻差异。 差异性提炼侧重与差异对比中体现出关键信息。 数据驱动验证数据分析如何驱动用户增长 北极星指标 公司的长远价值 如何运行增长策略 增长 ，不能单独行动。 需要获得领导的支持，在过程中拉上相关同事一起，让大家发现这个事情对公司对产品都有很大的帮助，这样才容易推行下去。 和自己的领导及相关业务同事经常沟通，一方面促进感情为后面的合作打下良好的基础，另一方面也是要及时了解领导层的方向和想法，以及其他同事都在做什么、关心什么，这样才可能助力增长。 做增长要缓慢推进，不能伤筋动骨。 先从一点小事做起，得到认可之后再慢慢延展，这样才更容易得到支持及想要的资源。 做增长需要合适的土壤和机会。 北极星指标北极星指标并不只是一个简单的数字，它代表了公司高层对于优先级的判断。判断企业在发展的过程中，什么因素是最重要的，该如何衡量。 北极星指标是对增长成果的衡量，并且为增长带来明确的方向。 衡量价值并校正方向的工具，最终通过针对性的服务用户提升企业的长远价值。 公司 商业模式 长期价值 北极星指标 摩拜单车 共享经济 自行车资源共享 月活跃用户数 阿里巴巴 电商 快速的网上购物 总销售额 电信APP 提供服务？ 更快更好的给用户提供查询充值等服务 月活跃用户数 重要指标的关系就像是天平两端，一头上去了，另一头必定会下去，导致给企业带来其他的损失。 比如，业务高了，成本自然会上升或安全隐患事故增加，我们要做的是保证企业命脉或核心价值稳定的前提下提升业绩。 设立北极星指标的要点不在于分别处理两个指标，而要寻求一组互斥的指标关系作为北极星指标。 要对业务有一定的了解：1. 知道企业的底线，比如安全、质量、体验等。要保证它们不逾越红线。第二再看企业想要追求的另一端是什么，比如营收、资本、利益等。然后设定： 在xx提升的同时，降低xx。 增长要能够把握平衡。 北极星指标要因时而变。 在产品的不同生命周期，关注点是不同的， 聚焦的指标自然也是不同的。 产品生命周期 探索期 成长期 成熟期 增长第二曲线-探索期 关注点 找到正确的产品方向 明确核心竞争优势，占领市场 提升商业价值 挖掘多元化需求发现新增长点 北极星指标 留存率/推荐意愿 新增用户/活跃用户 付费用户/客单价/成本率 新产品留存率/新增用户数/活跃用户数 需要根据自己产品的情况，先明确商业模式、长期价值、产品底线，在此基础上再看处于什么发展阶段，决定当前最合适的指标。 从公司整体价值触发， 不要受限于职能角度。不要只从数据分析的角度去看， 要从整个运营的角度去看，从整个部分发展的角度去看。 不要受限于功能角度将视野放大，多听听领导的声音，高维视角。 要明确无歧义什么算月活跃用户，只有月活用用户数可以吗? 不断培养自己的眼界和格局，避免被自己的旧有思想限制住。 北极星指标： 月活跃用户数： 启动客户端就算月活 月活跃用户增长的同时， 月交易率提升。 存量用户月交易率提升 + 新增用户月交易率提升。 当我们刚从事一项工作时，注意专业、注意细节是非常重要的；但是当我们已经熟练掌握工作技能后，就需要改变角度，从追求执行转变为追求策略。 增长强调少而精， 体现在我们工作的方方面面： 比如北极星指标、数据分析、用户分类、用户画像…..]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>用户增长</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析如何懂业务？]]></title>
    <url>%2F2019%2F08%2F14%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E5%A6%82%E4%BD%95%E6%87%82%E4%B8%9A%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据分析如何懂业务？ 背景-冲突-疑问-答案 作为一名数据分析师，有时我们会面临自己的分析结果对业务人员帮助很小， 但是却不知道如何提高的困境。 要想让自己的分析结果有价值，就需要我们数据分析师一定要懂业务。可是作为一名新手，如何才能透彻的理解业务，是自己一直以来面临的问题。今天看陈老师的《业务知识一点通》中提到的三个点，很有启发，特此分享一下。 很多时候，我们沉迷于数据分析的各种技术上应用，但是却不能 很长时间，自己都一直陷入了技术的陷阱，认为作为一名数据分析师，应该将python、sql、算法等练得如火纯青才行，将大量的时间欢喜花费在上面。 但是在实际的工作中，其实工具是最基本的要求， 更高的要求是自己如何解决业务人员的问题。 其实更重要的是分析思维的建立， 能够让自己的分析结果产生价值。 要想理解业务， 首先我们需要了解互联网公司的组织架构。 首先我们需要对整个业务的流程有一个清晰的认识 在互联网公司， 业务可能从提出想法——领导决策——确定运营方向——编写方案——设计页面——研发开发——上线推广——效果评估，可能需要很多各步骤，作为数据分析师， 我们需要清楚整体的业务流程。 开启自己的业务思路 知道业务方到底在干什么活动 知道业务方需要哪些数据， 需要什么样的分析 作为一名数据分析师， 基于公司的平台和数据资源，我可以做到些什么，能够帮到运营人员什么 如何做，才能使自己的分析结果见成效， 让业务方，让领导满意。 技术和业务上不断进行修炼 知道数据在业务方的应用让分析理论切合实际， 有经验的更受欢迎。 学习业务， 先抓思路，再看原理，案例补强 作为一名数据分析师，有时我们会面临自己的分析结果对业务人员帮助很小， 但是却不知道如何提高的困境。今天看陈老师的《业务知识一点通》中提到的三个点，很有启发，以下是做的笔记。​ 在日常的分析工作中，我们经常面临这样的的问题， 自己的分析报告不知道价值在哪里， ​也不知道该如何才能做好。 夹在技术和业务中间，上不来下不去​。要想让自己的分析结果有价值，其实是要懂业务的，那么如何才能理解业务呢，需要做到以下几点： 需要对整个业务流程有一个清晰的认识。在互联网公司，一个业务活动的运营，可能从提出想法——领导决策——确定运营方向——编写方案——设计页面——研发开发——上线推广——效果评估，可能需要很多各步骤，作为数据分析师， 我们需要清楚整体的业务流程。 需要开拓自己的业务思路，不能只是简单的接需求。 知道业务方目前都开展了哪些运营活动 知道业务方需要哪些数据， 他们有哪些分析需求。 基于公司目前的平台和数据资源，我们能够做些什么，能够产出什么样的分析报告 如何做，才能让自己的分析结果有效果，让领导和运营人员​满意。 理解公司的具体业务。 经营模式我们挣什么钱，怎样让用户买单， 你的竞争对手是谁 目标用户你的客户是谁， 他们为什么要买你的产品，他们需要什么 产品属性产品是什么，用户在使用时有什么问题， 销售渠道通过什么方式把产品卖给客户 市场策略 如何找到我们的客户 收支来源 收益是什么，成本是什么，如何扩大收益，减少成本。 商业画布 消费者关注功效，企业关注谁买单 APP上线后表现一直不佳，经过数据分析，发现是产品留存率不够所导致。即便有流量引入，但是DAU的数据也长期在低位徘徊。问题1：设计一套针对用户调查和数据模型，并通过模型分析，解答问题 难题1： 产出没有价值 不知道自己为什么做这件事情不知道如何把事情做得更好不知道做了这个有什么意义 难点2：缺乏领导进一步提升的指导 只要结果，不管过程要求进步，不说怎么做整体思路不说 困境： 夹在技术和业务中间，上不来下不去 难点3： 只懂技术，业务没工作经验第一，认知自己的价值，突破打杂的局面 懂业务，体现价值，展现自己的能力 我在电信公司，他们需要监控页面性能数据，来改善充值业务的质量，我在负责转化数据监控期间，就及时发现了页面性能不足问题。帮助业务方改善了页面性能，提高了转化率。 表不值钱，值钱的是因为这张表引发的业务动作，产生实际的价值，发现问题，提出方案，这才是这张表和这个人的价值。 业务的流程： 大老板有想法-业务部门领导定方向-业务经办做方案-竞品分析等报表-领导汇报-集体决议通过-前线执行 第二：掌握基础的业务知识，不能当小白 业务上开启思路：到底业务在干什么？业务需要什么样的数据？我可以做什么，提供什么数据？怎样做才能容易见成效 第三：技术业务双修，提升能力 要能够理解数据在业务方的应用，让研发人员变得更有针对性，更适合企业。让业务人员变得更有条理，更容易做出成绩。 如何脱颖而出，能够根据行业经验，在这个业务场景下，用我这个方案更好，因为某行业的特殊性，常规方法会被坑的。 理论最终都要服务与行业的实际情况，能够切合实际，有经验的更受欢迎。 业务和技术的差别：业务很多样，不同行业都有差别业务很多变，经常有创新的玩法业务有很多的细节。 技术只要专注于细分的一项就可以。什么叫懂业务 业务就是把产品了以合理的方式通过渠道卖给消费者赚取利润 产品特征产品的概念是什么产品是怎样销售的用户在使用的时候有什么问题为了让用户更好的使用，我需要做什么功能改善，运营配合 销售渠道运作方式通过什么方式把产品卖给客户 我从哪里挣钱我从哪里拉客 用户需求你的客户是谁， 他们为什么要买你的产品，他们需要什么 你的客户群体是谁在什么时间，什么场景下会使用我们的产品 经营模式怎样让用户买单， 你的竞争对手是谁 营销推广运营 线上怎么玩，线下怎么玩，这样的玩法能解决什么问题，达到什么结果 收支来源我们能挣多少钱，下一步要挣多少钱 收益是什么，成本是什么 如何增加收益，减少成本 把产品传递给用户，并产生价值 经营模式 目标用户 产品属性 销售渠道 市场策略 部门分工 营收情况]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>业务理解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[营销活动分析]]></title>
    <url>%2F2019%2F08%2F11%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-APP%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[背景-冲突-问题-解决方案 在日常分析工作中，某个产品功能模块修改，对数据的影响如何评判，是一个问题，那么我们该如何去评价呢? 常规分析： 功能渗透率：使用某个功能的占比 功能用户数/ 大盘用户数 功能留存率第一天使用该功能同时第二天也使用该功能的用户数 / 第一天使用该功能的用户数 功能的大盘留存率第一天使用该功能同时第二天是APP的活跃用户数 / 第一天使用该功能用户数 不使用任何功能的用户数 大盘用户数 = 所有功能用户去重 + 不使用任何功能用户数 价值分析： 功能的核心用户数符合某种要求的功能用户数， 如使用次数、使用时长、使用天数等 功能对大盘贡献度对大盘留存提升的贡献。 渗透率* 留存率 功能带来的收入对比]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>功能分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据异常分析]]></title>
    <url>%2F2019%2F08%2F03%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E5%BC%82%E5%B8%B8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[如何针对异常数据进行分析作为一名数据分析师， 在工作中我们经常要对异常数据进行原因分析， 那么异常排查的方法都有哪些， 今天我们就来谈一谈。 首先，在进行分析前，我们需要做到以下几点： 对此数据的业务理解是否准确。 比如：APP的日活是如何定义的， 是用户只要启动APP，还是用户必须在APP中有点击行为。 数据的指标口径是否统一。 比如：某活动页面的 uv，是通过统计用户的手机号，还是统计用户 tracking_id 。不同的统计口径会导致数据出现差异。 数据的产出过程是否明确。 比如：数据是如何从日志中进行清洗，是否会存在多发或漏发数据情况。 寻找相关运营或产品人员进行沟通。询问运营人员关于此数据异常的见解，往往能够提高我们的分析效率。 接下来就是对异常原因的排查，常见的影响因素和方法有： 外部因素：时间因素、节假日活动、热点事件、政策影响等。 内部因素： 部门运营活动、产品功能上线、大盘整体趋势、页面性能、SQL逻辑错误、数据指标口径调整等。 多维度拆解法。从各个维度进行细分拆解，定位问题。比如：某产品活跃用户下降，那我们可以把活跃用户拆分成新用户、老用户、回流用户，然后针对不同的用户再进行细拆分析。 在查找出异常原因之后，我们还需要做到以下两点： 持续跟踪后续数据是否再次异常。在排查出原因并采取相应措施之后，我们需要持续跟踪数据，如果数据再次异常，那么说明给出的异常原因可能是错误的。 对异常原因进行梳理，文档化。 问题描述：什么时间、什么指标异常、异常幅度 主要结论：异常因素有哪些，各自的影响程度如何 后续跟进：后续的解决方案是什么，解决时间，再次验证是否异常。 具体分析过程：分析过程与详细分析数据 以上就是自己总结的数据异常原因分析，你还有哪些好用的分析方法，欢迎留言交流。 参考资料： 数据异常求生指南数据分析之数据异常分析日思619.数据异常了，如何分析？ 工作中存在的分析问题本周 话费账单组kpi考核同比突降67万， 领导让我分析数据异常的原因。 在分析的过程中，自己主要犯了三个错误： 自己一开始就对所有统计的按钮进行细拆， 而没有分功能模块进行细拆， 导致自己一开始只是看到 话费余额页面 和月账单页面下降， 而没有找到电子发票页面下降。 如果自己在细拆的对比中细心的话，自己也是可以找到的， 但是自己没有耐心做对比。 如果自己按照功能模块进行细拆对比， 就不会出现这样的情况。 自己从一开始就没有搭建出一个整体的分析体系， 导致自己分析时，一会跑这个数据， 一会跑那个数据，从而使自己得出的结论没有说服力。比如： 一开始，自己就跑话费余额数据， 但是跑着跑着发现口径有问题， 自己之前得出的结论竟然是错误的， 自己是先有了结论， 然后自己再找数据的， 这样会让自己再推翻自己的结论， 重新跑数据，特别的浪费时间。 数据的准确性不能保证， 自己跑的数据， 存在着比较明显的不合理之处， 口径不够明确， 给别人解释口径时不能够解释清楚。 在上篇我们说到了如何对数据异常进行分析，这次我们来一道具体的数据分析面试问题。 以下是一家公司APP一周每天的活跃率，如何你是分析师： 从数据中你看到了什么问题？你觉得背后的原因是什么？ 如果你的老板要求你提一个运营运营改进计划，你会怎么做？ 分析答案： 数据质量数据采集， 数据接口， 数据存储 产品质量版本更新， 版本BUG 渠道质量渠道买量造假 活动质量是否有重大活动 政策问题 三、数据异常排查清楚以下三点： 业务理解 指标口径 当前数据产出过程 数据异常原因分析： 数据有问题 将时间轴拉长，看数据是近期异常还是历史异常，对比近三个月数据。 查看和该指标关联的其他核心指标是否也异常，如果异常，也要一并查看。 核查埋点是否有问题， 数据是否存在多发情况。 业务口径是否有问题， 取的数据是不是真正需要的数据。 写的sql逻辑是否有误， 或者android 和 ios 数据没有相加。 业务发生了变化 同口径下，同比环比数据是否异常， 在长时间轴的条件下进行对比 进行细拆， 看到底是哪个指标的数据出现了异常， 将该指标和相关的指标一起进行对比 与负责此指标的负责人进行沟通， 询问他们近期是否做了推广活动。 产品最近是否发布了新版本，或者某个功能改版存在缺陷问题。 其他因素影响 假期效应： 开学季， 暑期， 四大节日，当地节日 热点事件：常规热点如运动会，世界杯，其他热点事件 活动影响： 双11， 618， 支付宝送红包 政策影响： 金融监管 底层系统故障： 服务器迁移导致数据丢失 存在外部刷量作弊情况 统计口径： 业务逻辑进行了更改， 之前某业务有统计， 但现在不统计了。 数据计算方式改变 要对异常排查进行闭环 持续跟踪后期数据是否再次异常比如7.0版本数据存在多发现象， 但7.1版本开发说已更改， 当7.1版本发布之后， 要及时去查看数据是否再次异常。 对数据异常一定要记录， 对异常口径要留文档。 邮件化， 当数据异常排查原因查明， 并且确认更改之后， 发邮件给相关方， 描述数据异常的影响范围和主要结论。 作为一名数据分析师， 一定要经常去看这三种报表，培养自己的数据敏感度，了解业务的各种核心指标。]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>异常分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用环境来辅助自己进步]]></title>
    <url>%2F2019%2F08%2F02%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E5%BF%83%E7%90%86%E7%B3%BB%E7%BB%9F-%E5%88%A9%E7%94%A8%E7%8E%AF%E5%A2%83%E6%9D%A5%E8%BE%85%E5%8A%A9%E8%87%AA%E5%B7%B1%E7%9A%84%E8%BF%9B%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[自己下班或者周末在房间，总是把大量的时间用来刷微博或者刷剧。虽然一直刷一直爽，但自己总是有一种虚度时间的空虚感，如何改变自己下班和周末的状态，成了自己最近在思考的问题。 最近在学习陈海贤的《自我发展心理学》，刚好说到了自己的这种现象，并给出了一种利用环境来促使改变的方法，对自己启发很大，今天就来介绍一下这种方法。 首先是融入到积极的环境中去。要想学习就去图书馆、自习室，要想锻炼就去体育场、健身房。我们心中其实都有一个关于“特定空间”的假设，在假设中，对于公司、图书馆这样的空间就是用来工作学习，对于自己寝室的假设肯定是用来休息娱乐的。如果你要让自己在宿舍这样的空间中好好学习工作，就得付出比在图书馆多几倍的努力才行，还不一定能学进去。所以，周末能去图书馆上自习就绝不在家办公， 让自己融入到特定的环境中去。 当然，如果要学习就要去图书馆，那也不现实。如何在自己的房间中也能被环境所带动呢，文中介绍了第二种方法，那就是在某个特定的环境中只做一件事情。 比如：你可以要求自己在这张书桌上只作跟工作学习有关的事情， 如果想刷微博，看电视，那就换个地方，可以坐沙发上。 背后其实也是利用了我们心中对“特定空间”的假设，如果你在这个书桌上进行娱乐活动，那么这个书桌作为你心中假设的环境就会破坏掉。平常在一个特定的空间里只做这一件事情， 慢慢这个习惯会形成稳定的心理预期，会给自己一种强烈的心理暗示，从而帮助自己进行改变。 这促使了我对之前行为的理解，当自己上完班回家之后，本身意志力就消磨的七七八八了，再要用所剩无几的意志力抵抗娱乐去学习，自己的大脑肯定不干。周末在房子里大脑肯定也是怎么舒服怎么来。 我自己针对性的采取了以下几种方法： 最近下班回家之后，先休息一个小时左右，恢复一下意志力，再起来学习工作，感觉效率到提升了不少。 指定特定的桌子只用来办公和学习， 如果自己想刷微博或者刷剧， 不要在这张桌子上进行。 （还在努力实践中） 周末能去石景山图书馆就尽量不要在房子呆着。 以上就是自己最近关于如何促进改变的一些小方法，你还有哪些好用的方法，欢迎留言交流。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>心理</tag>
        <tag>方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中常用的SQL函数]]></title>
    <url>%2F2019%2F07%2F31%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84SQL%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[SQL 语言是每个数据分析师必备的技能，毕竟能否快速准确的从数据库中得到想要的数据，关系到后面的每一步分析。掌握SQL 函数可以让我们很快得到想要的结果， 以下为几类常见的 SQL 函数： 聚合函数 函数名 定义 count() 个数统计函数 count(distinct ) 统计去重之后的个数 sum() 求和 sum(distinct ) 去重之后的和 avg() 平均值 avg(distinct) 去重之后的平均值 min() 最小值 max() 最大值 corr(A, B) 相关系数 var_pop() 方差 var_samp() 样本方差 stddev_pop() 标准偏差 stddev_samp() 标准样本偏差 covar_pop(A, B) 协方差 covar_samp(A, B) 样本协方差 RAND() 随机数 字符串函数 函数名 定义 concat() 拼接字符串 length() 计算字符串的长度，一个汉字算三个字符 instr (A ,B ) 返回字符B首次在A中出现的位置,不存在返回0 lcase() 转换成小写 left(string2 ,length ) 从string2中的左边起取length个字符 lower() 将字串转化为小写 upper() 将字符转化为大写 replace() 替换字符 substr() 返回字符串A从start位置开始，长度为len的字符串 substring() 截取字符串 substring_index() 通过截取获取不同索引位的字符 LTRIM (string2 ) 去除前端空格 RTRIM (string2 ) 去除后端空格 时间函数 函数名 定义 NOW ( ) 当前时间 extract() 抽取具体的年、月、日 date() 返回时间的日期部分 year() 返回时间的年份 month() 返回时间的月份 day() 返回日期的天 hour() 返回时间的小时 minute() 返回时间的分钟 second() 返回时间的秒 week () 第几周 dayofweek() 返回星期几，1为星期天 dayofyear() 一年中的第几天 sec_to_time ( ) 秒数转成时间 dateadd() 时间相加 date_sub() 时间相减 datediff() 时间的差值 date_format() 输出指定时间格式 datename() 返回日期部分的参数 datepart() 返回日期、时间的单独部分 窗口函数等 函数名 定义 rank() 排名相等的会留下空位 dense_rank() 排名相等的不会留下空位 row_number() 排名不管数据是否相等 lag() 访问相同结果集的先前行中的数据 lead() 访问相同结果集的后续行中的数据 first_value() 返回组中数据窗口的第一个值 last_value() 返回组中数据窗口的最后一个值 if() 条件判断函数 case…when…else…end 判断各个元素是否满足了某种条件的集合 over() 与聚合函数sum(), count(), avg()等结合使用， 实现分组聚合的功能 split() hive字符串分割函数 intersect 交集 except 差集 union all 并集 round 把数值字段舍入为指定的小数位数 difference 衡量两个值之间的差异 coalesce 1、将控制替换成其他值；2、返回第一个非空值 pivot 行转换列 以上就是我总结的常用的 SQL 函数， 你还有哪些好用的 SQL 函数， 欢迎留言补充。]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>数据分析技能</tag>
        <tag>SQL 函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何用数据说话]]></title>
    <url>%2F2019%2F07%2F29%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A-%E5%A6%82%E4%BD%95%E7%94%A8%E6%95%B0%E6%8D%AE%E8%AF%B4%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[如何用数据说话背景-冲突-疑问-回答 作为一名数据分析师， 经常要写很多的运营分析报告， 但我发现自己写完的分析报告交给领导看， 总是被领导指正说报告的说服力不够。经过这一段时间的磨练， 我也思考了如何才能增加报告的说服力。 一份运营分析报告， 看似简单，描述自己通过数据观察到的现象， 暴露公司运营中存在的问题， 但你揭露公司的问题， 同时也对相应的运营人员的结果的拷问， 人家肯定会质疑你报告的准确性， 如何才能让别人心服口服呢， 在最近的工作中，我总结出以下三点： 要用数据说话。 能用数据说明的，绝对不要用莫能两可的语言。 比如：本周活跃用户数比上周好。 这样的语言让人感觉很空洞， 就不如写成本周活跃用户较上周增长了20万用户， 增长表现良好。 要给出一个结论， 一定要有数据的支撑才行。 对复杂的数据口径进行说明。 不要以为运营人员能够能够很容易理解你的统计指标与口径， 要把他们当小白一样去对待才行。比如留存率是如何计算的， 有时你不必特意的去强调， 但是必要的标注还是得有。免得运营人员多次询问。 对数据进行多维比较，佐证结论。 有时你通过一个维度的数据比较很难将问题说明清楚，需要多维比较。 比如， 本周用户环比上周下降了20%， 那么这能说明本周比上周运营的差吗， 会不会存在月初月末周期的影响。如果要排除这些因素的话， 其实还需要求上月同时间段的环比数据。 如果上月同时间段用户比上周只下降了5%， 那证明可能不是时间的原因。 对于别人给出的原因你也需要数据验证。 有时我们发现某个数据下降，然后去问运营的负责人情况， 在他说完情况之后， 我们应该再根据他的情况进行数据验证， 而不是轻信别人，直接将这个原因写到报告中去。 报告要有结论和建议。 一份分析报告中， 最难的部分就是分析的结论和建议， 很多时候，我们只是简单的描述统计，而要做到逻辑和建议， 其实是一件很难的事情。 报告的内容和布局要有逻辑性。 首先，对于分析的内容， 要保证逻辑正确，避免给出引导运营错误的结论。 比如：一个用户的行为路径分析， 必须保证一个路径下转化率必须是同一个口径。 而不能与第二个目的进行对比。避免引导运营错误。 其次，报告的整体排版必须遵循一定的逻辑， 不能说用户行为，突然就跳到用户充值了。 最后， 把自己写好的分析报告给领导看下， 有时他们的建议能够弥补我们在思维视角上的缺陷， 更快的提高我们的分析撰写能力。 当然， 以上步骤只是我工作中的一点总结，仅供参考。每个公司，每个团队不一样， 要求的分析报告的侧重点不一样，但我们撰写分析报告的目的都是一样的：希望能够指出部门运营中的不足，说服运营人员进行迭代改进。 你还有哪些能够增加分析报告说服力的技巧， 欢迎一起分享交流。]]></content>
      <categories>
        <category>数据分析报告</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>报告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[沟通系统]]></title>
    <url>%2F2019%2F07%2F01%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E6%B2%9F%E9%80%9A%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[背景知识 中西方文化差异 椰子文化。 擅长熟人社会的社交规则和技巧，不擅长与陌生人打交道。 桃子文化。 人情关系中很多都是和你相似的人，而信息关系能让你认识大量不同质的人。 真正的社交不是为了利用别人，而是帮助别人成功，是合作与互助。你和他人共享信息，蛋糕就会越做越大。 如何闲谈心态建立 主人心态 假设自己是活动组织者。 我们是还没有认识的朋友。 最糟的情况就是他不理你，这又有什么关系。 闲谈的方法 问一个让对方自如的问题。 不要问那种一个词就可以回答的问题。 你喜欢恐怖电影吗？你喜欢哪种类型的电影？ 不要问太泛或者太深的问题 封闭式和开放式问题经常穿插使用。 你对一带一路怎么看？一带一路对你们那个行业有什么影响？电信类算不算最大的？ 养成一问二答的习惯。 你们家乡也会那么冷吗？没那么冷。 今年冬天咱们这真是少有的冷。不过我今天穿了发热衣，真的好像我身上在发热。 仔细聆听对方的话，从中找到信息点，然后不断扩展。 扩展在于真正的倾听。 你要把对方的话放在你的话里面， 让对方感觉被关注了。 有些人倾听， 仅仅是在等待自己发言的机会。 停留在很初级的“一边听一边点头，或者重复最后几个词，或者看对方眼睛等。 当一个人真正在听的时候， 不需要有意展示这些聆听技巧。 用自己发散的、跳跃的思维， 抓住原信息中的关键词，扩展出一堆新信息。 如何开场，构建话题 冷读者 + 热捧者 不要有压力，傻白甜的问题都可以，明知故问也行。 冷读者： 展现你的观察力， 让第一句话显得不唐突。 热捧者： 展现你的善意，谈话以给对方造成愉悦为己任。 你是做什么的?你说话很有条理，你是从事培训行业的吗？ 如何找话题 从周围的道具找话题 你的装备挺齐全的，能借支笔吗？ 从对方身体、个性、气质风度、服饰上找话题 你这肌肉练得挺好，经常健身吧？ 从那时那刻的状态上找话题 看你今天兴致很高，有啥开心事吗？ 猜谜游戏 你是从哪来的？你是从哪来的，等等，让我猜猜，给我两个提示吧。 放低身段，诚心请教 虽然我还没找到女朋友，但想取取经，让一段感情持久的秘诀是什么？ 注意事项 要“冷读+热捧”，而不要去做一个挑战者。 对讨论本人的话题，做积极正面的评论，用“是的，…而且…”的模式。 把握交谈的节奏 说、问、说 三部曲 先做一个自我陈述， 然后问一个开放式问题， 之后再自我陈述。 你问了问题之后， 有两种可能， 第一种是对方滔滔不绝，那你就做个可爱的聆听者。 第二种，他回应不多，那你就要准备好退路， 做自我陈述。 A：北京的夏天好热啊，热的我眼睛都冒汗了。 你是北京人吗？B： 不是A: 哦哦， 我在西安住过三年，那儿的天气更热， 那儿只有两个季节：室内、室外。 冷场急救术 另起炉灶 正反回应正面回应，我和你很有共鸣；反面回应，我和你没有共鸣，但我很有兴趣探究你的世界。 A:我刚从罗马回来正面回应： 我刚重温完《罗马假日》， 真正的罗马和电影的罗马有什么区别？反面回应： 我从来没去过罗马，罗马哪些地方值得一游？ 扮演苏格拉底 为什么？….的原因是？ 我不大懂你的意思，能再解释一下吗？ 注意事项 聊天是平衡的艺术，就像打网球。 球不能永远在某一方手里。 一方接到球后，将生活中的细节娓娓道来，你对他的话稍加评论，然后再加上新的观点，问个新问题，他又接球。 不要把球拽在自己的手里超过20s,禁止把球拽在自己的手里超过40s。 社交最基本的底线是当你主动加他人得说明自己是谁，做什么，加好友的用意是什么三句话的敲门砖都不会如何与他人交流和沟通呢]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>沟通</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[培养数据敏感度]]></title>
    <url>%2F2019%2F07%2F01%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E5%9F%B9%E5%85%BB%E6%95%B0%E6%8D%AE%E6%95%8F%E6%84%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[对于数据分析师来说，培养数据敏感度是需要长期经验积累的，更需要通过刻意练习来提高，那么有哪些好的方法呢，今天我们就来谈一谈。 熟记业务关键指标 一些日常运营的关键数据：日活、月活、消息推送每天的量、常用的口径，能够做到随问随答。这有利于自己迅速判断及反应，也能够让同事认为你对数据非常敏感，懂得用数据说话。 多去记录一些行业当中比较重要的指标，比如游戏行业，你能通过次日留存、7日留存等数据，迅速判断这个游戏属于哪一个评级。 多做报表，多画思维导图 通过日报、周报、月报的制作来加深自己对业务的理解，有时根据自己的业务需求有目的的创造一些报表。 多进行一些项目类型的业务分析，做报表之前将自己的思路利用思维导图整理下，做到逻辑清楚，结构紧凑。 强迫自己用数据说话 在平时的沟通中， 多引用相关数据去表达，能够非常有力的辅助你要表达的观点， 也会让人觉得你说话比较靠谱，增强说服力。 在日常的数据报告中， 多用数据说话，能才让别人信服。 多玩一些数据游戏 24点，根据一闪而过的汽车牌照玩24点 数独类APP游戏 学会质疑， 善于找茬 对于身边的新闻数据， 报道数据，学会质疑，养成独立思维的习惯。 看到一个业绩报告后，不断去问自己背后的更多的数字，考验自己或别人数据的广度。 多看财经类的新闻报道，当看到数据的时候可以通过搜索、查证、思考，逻辑判断等来证明这个数据是正确还是错误。 多做案例分析题 判断是否正确：iDATA公司业务员大数有24个客户，7月不重复客户购买率为78%。（注：不重复客户购买比例=有订单的客户总数/总客户数，重复购买的客户只算一次） 判断是否正确：我国城镇住房建设较快发展，人均住宅建筑面积升至26.11平方米，（北京市为32.68平方米）户均住宅建筑面积为82.2平方米。同时城镇住宅建筑面积达到历史最高的300.16亿平方米 判断是否正确：某学校200名学生全部参加了优秀学生干部的选举活动，最后大数同学以88.8%的投票支持率当选（注：共5名候选者，每位同学只能选择支持一位，候选者也可以参加投票） 填空：3 4 6 10 (?) 解答：要求将3，5，7，8 这4位数字组合，计算结果=24，并要求使用2种方法。 以上就是自己总结的培养数据敏感度的方法，你还有哪些好的建议，欢迎留言交流。]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据敏感度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[金字塔原理]]></title>
    <url>%2F2019%2F06%2F22%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86%E3%80%8B%2F</url>
    <content type="text"><![CDATA[表达的逻辑 对受众来说，最容易理解的顺序是：先了解主要的、抽象的思想，然后了解次要的、为主要思想提供支持的思想。 首先表达的主要思想， 使受众对表达者的观点产生疑问，而主要思想下一层次上的思想将回答这些疑问。通过不断进行疑问/回答式的对话，受众就可以了解文章中的全部思想。 只有通过说出来或者写出来，我们才能准确地把握自己的思想。 人大脑的两个需求： 一次记忆不超过7个思想、概念或项目 找出逻辑关系 先提出总结性的思想，然后提出被总结的具体思想。 写文章时需要注意的逻辑规则： 文章中任一层次上的思想必须是下一层思想的总结概括。 每组中的思想必须属于同一逻辑范畴 苹果和西瓜都是水果。 桌子和椅子都是家居。 苹果和桌子都是物体 每组中的思想必须按照逻辑顺序组织。 演绎顺序： 大前提、小前提、结论时间顺序：第一、第二、第三结构顺序： 北京、西安程度顺序： 最重要、次重要。。。 金字塔内部结构： 纵向关系 横向结构 序言结构 背景、冲突、疑问、回答 自上而下构建金字塔 你准备讨论的话题是什么 你希望回答读者头脑中关于该主题的哪些疑问？ 写出对该疑问的答案 前3步是你需要在大脑中思考的 背景： 做出第一个不会引起争议的表述。（客户建议改变记账方式） 背景中发生了哪些冲突，对冲突进行介绍 （我知道， 有什么问题吗？ 冲突：建议是否可行） 金字塔结构，进行论证。对读者的疑问，进行疑问/回答式对话。（为什么这么说？——用金字塔结构分点描述） 后三步是你需要要写的文章。 自下而上法 列出你想要表达的所有思想要点。 找出各要点之间的逻辑关系。 得出结论。 如何写序言 背景-冲突-疑问-回答 序言必须先介绍读者熟悉的某些“背景”， 说明发生的“冲突”，并由此引发读者的“疑问”，然后针对该“疑问”给出“答案”。 序言采用讲故事的形式，让读者抛开复杂的思想，专注于你的话题。（背景） 冲突类似于讲故事时推动情节发展的因素，促使读者提出“疑问”。 * 序言的长度：2-3段]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>思维方法</tag>
        <tag>写作方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化]]></title>
    <url>%2F2019%2F06%2F08%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[注意事项： 数据可视化的目的是让数据更高效的理解 突出数据背后的规律 突出重要的因素 最后才是美观 两个概念 维度 描述分析的角度和属性，分类数据产品类型，性别，城市 度量 具体的参考数值，数值数据销量，销售金额等 图表美观color.adobe.com 初级图表数据透视 excel -数据透视表 sql - group by python - pivot_table 散点图与气泡图折线图与面积图柱形图、直方图、堆积柱形图，瀑布图饼图漏斗图雷达图 高级图表树形图桑基图热力图关系图箱线图标靶图词云图地理图信息图seabornhttps://blog.mazhangjing.com/2018/03/29/learn_seaborn/ bokeh https://towardsdatascience.com/data-visualization-with-bokeh-in-python-part-one-getting-started-a11655a467d4 https://juejin.im/post/5c34a9dee51d4551d044efce 统计学知识点在python中各种图形的绘制 条形图 1234567891011121314from matplotlib import pyplot as pltplt.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;] #解决中文乱码# 语法：plt.bar(left, height, width=0.8, bottom=None, hold=None, data=None, **kwargs)num_list = [1, 2, 3, 4]name_list = [&apos;Monday&apos;,&apos;Tuesday&apos;,&apos;Friday&apos;,&apos;Sunday&apos;]# 如何想让条形图横放， 将 plt.bar 改为 plt.barhplt.bar(range(len(num_list)), num_list, color = &apos;rgb&apos;, tick_label = name_list) plt.show() 折线图 123plt.plot([1, 2, 3, 4], [1, 4, 9, 16], &apos;g&apos;)plt.ylabel(&apos;some numbers&apos;)plt.show() 折线图要注意起始位置， 避免被图形误导。 饼图 1234567891011121314151617plt.figure(figsize=(6,9)) #调节图形大小labels = [u&apos;大型&apos;,u&apos;中型&apos;,u&apos;小型&apos;,u&apos;微型&apos;] #定义标签sizes = [46,253,321,66] #每块值colors = [&apos;red&apos;,&apos;yellowgreen&apos;,&apos;lightskyblue&apos;,&apos;yellow&apos;] #每块颜色定义explode = (0,0,0,0) #将某一块分割出来，值越大分割出的间隙越大patches,text1,text2 = plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct = &apos;%3.2f%%&apos;, #数值保留固定小数位 shadow = False, #无阴影设置 startangle =90, #逆时针起始角度设置 pctdistance = 0.6) #数值距圆心半径倍数距离#patches饼图的返回值，texts1饼图外label的文本，texts2饼图内部的文本# x，y轴刻度设置一致，保证饼图为圆形plt.axis(&apos;equal&apos;)plt.show() 箱型图 12345678910111213141516171819import matplotlib.pyplot as plt def draw_plot(data, edge_color, fill_color): bp = ax.boxplot(data, patch_artist=True) for element in [&apos;boxes&apos;, &apos;whiskers&apos;, &apos;fliers&apos;, &apos;means&apos;, &apos;medians&apos;, &apos;caps&apos;]: plt.setp(bp[element], color=edge_color) for patch in bp[&apos;boxes&apos;]: patch.set(facecolor=fill_color) example_data1 = [[1,2,0.8], [0.5,2,2], [3,2,1]] example_data2 = [[5,3, 4], [6,4,3,8], [6,4,9]] fig, ax = plt.subplots() draw_plot(example_data1, &apos;red&apos;, &apos;tan&apos;) draw_plot(example_data2, &apos;blue&apos;, &apos;cyan&apos;) ax.set_ylim(0, 10) plt.show()]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析师的通关升级]]></title>
    <url>%2F2019%2F05%2F18%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E9%80%9A%E5%85%B3%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[数据分析师的级别 业务分析能力 问题界定 助理分析师: 他人的指导下进行分析分析师： 独立进行分析高级分析师： 在分析的技术上推动解决问题 分析思路 助理分析师: 在他人的指导下才能够有思路分析师： 独立进行思考高级分析师： 思路更开阔，更清晰，并且能够有效指导他人进行思考。 分析方法 助理分析师: 进行一些简单的描述统计分析师： 可以做推断，多元的统计分析高级分析师： 在多元分析的基础上，可以做探索性，验证性的分析 价值应用 助理分析师: 编制常规报表，帮助运营人员进行常规的业务查询。只能帮企业界定难题是什么的初步的判断。分析师： 开展多维分析，警报，统计等工作，对企业的决策力度更大，在判断企业难题是什么的基础上，能够分析这个难题为什么会产生，以及未来将会如何发展变化。高级分析师： 在此基础上，通过预测模型等一些优化方法，帮助企业去寻找解决难题的各种方法，找出最优的解决方法，回答怎么办的问题。 报告撰写 助理分析师: 基本能够说清楚自己的观点分析师： 在基础上，条理更加清晰高级分析师： 结构清晰，有理有据，生动展现 执行管理能力 助理分析师: 不需要管理，按照别人的要求，完成自己分内的分析任务。分析师：担任项目经理， 需要具有一定的管理能力， 通过自己和团队的合作，合理的分工，有效的指导，带领团队完成多项分析工作，并且能够控制分析的进度和质量。高级分析师：部门经理，能够在带团队的基础上，实现跨部门的合作，协调企业内外的资源。 业内的影响力 助理分析师: 不具备影响力分析师： 建议容易被领导或者客户采纳，在团队中具有一定的影响力高级分析师： 在会议或媒体上发表观点，业内有知名度和影响力。 数据分析的多元思维模型 中观能力 专业度： 长期总结和思考，能够很好的发现其他分析师分析中的问题。 技术理解 数据标准化： max-min方法、 z-score 方法、指数对数法 逻辑性 价值点 微观能力 有效沟通+快速发散收敛能力， 能够从业务的交流中发现问题， 找到方向。 想象力 解决问题能力 敏感度 快速发现提问 高维视角 快速捕捉、提炼、找到问题、解决问题 黄金思维圈法则 了解业务运营情况， 反问业务方为何要做这件事，找到切入点。 做一些准备工作再沟通 沟通前做好一定的准备， 说出自己的独特视角。 对于某一个新业务问题， 跟业务沟通之后，分析师有很多的想法。快速给出一个有根据的解法。 宏观能力 洞见性的全局观，能够从社会事件、整个行业发展中找到业务的决策方向。 困扰 需求模糊 需求不准确 职责不清晰 通关的要求 界定问题 开启分析思路 提升分析价值 掌握分析方法 撰写分析报告 界定分析问题 需求模糊 独立思考 + 刨根问底 需求不准确 收集资粮 + 假设验证 职责不明细 特点发散，概念拆分等方法进行业务分解]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Excel模板]]></title>
    <url>%2F2019%2F05%2F18%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-Excel%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[必会的54个函数日期函数： day month year date today weekday weeknum 一年中的第几周 数学函数 product rand randbetween round sum sumif sumifs sumproduct累加相乘 统计函数 large small max min median rank 排名 count countif countifs average averageif averageifs 查找和引用函数 choose match index indirect column row vlookup hlookup lookup offset getpivotdata 文本函数 find left right concatenate replace search text trim 函数—— 删除字符串中多余的空格 len mid value 逻辑函数 and or false true if iferror 指定Excel模板 自定义区域 数据源区域 分析辅助区域 业务预警区域 业务分析区域 报告展示区域 数据可视化常见图表 散点图 气泡图 单轴散点图 折线图 面积图 柱形图 瀑布图 漏斗图 雷达图 高级图表 树形图 桑基图 热力图 关系图 箱线图 标靶图 词云图 地理图 股价图 数据形式： 日期， 开盘价，最高价， 最低价， 收盘价 图表配色网址： color.adobe.com 图标矢量图csv文件有20位的数字怎么办新建excel,选择数据， 选择来自文本， 导入csv 文件， 选择逗号进行分列， 并同时对数字选择文本格式， 点击确定， 导成 xlsx格式。]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>EXCEL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析——数据分析的常用指标]]></title>
    <url>%2F2019%2F05%2F12%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E5%B8%B8%E7%94%A8%E6%8C%87%E6%A0%87%2F</url>
    <content type="text"><![CDATA[数据分析师如何搭建业务运营指标作为一名数据分析师，在工作中通常需要一些指标来衡量数据发展的好坏，毕竟，如果你不能衡量它，那么你就不能增长它。 那么数据分析中常见的指标都有哪些，如何在工作中制定业务指标呢，今天的文章来详细探讨一下。 首先， 好的指标都应该符合哪些要求呢？ 必须有一个核心指标， 符合目前公司业务发展的阶段。 比如， 公司初创早期更关注新增用户数，中期更关注用户活跃与留存， 后期更关注付费转化率。 好的指标应该多维度去衡量数据， 指标需要给公司业务增长带来显著效果。 比如，投放一个广告，曝光量是 1000， 但点击量只有 10， 点击转化率只有1%，单纯的曝光量高并不能解决问题。 其次，互联网运营通常都有哪些指标，我们用AARRR模型来说明。 获取用户：通过砸钱让产品在某渠道进行曝光，并将用户转化成产品用户核心： 找到获客成本较低且用户质量较高的渠道。 常见的指标： 安装用户数 激活用户数 一次会话用户数 新用户下载完APP， 仅打开过产品一次，且该次使用时长在2分钟以内。（避免机器刷单） CPM - 每千人成本 广告展示时就向广告主收费，以曝光为目的，不强调实际获客效果。 倾向于保护流量主利益。 CAC - 每点击成本 用户发生点击行为时向广告主收费。 CAC = 新增用户总投入 / 新增用户总数 CPA - 每行动成本 以后端收费为主，也就是用户看到广告并点击后，有进一步了解的欲望，完成某些特定行为， 如下载APP、预约报名或购买了产品。 倾向于保护广告主利益。 CPPC - 每付费用户的获取成本 CPS - 以实际销售额换算广告金额 类似销售提成 CPD - 每下载成本 CPT - 每时间段成本 例如： 这个位置一个星期多少钱 ROI - 投资回报率 ROI = 销售所得利润 / 广告成本 * 100% 提高用户活跃度：提高产品使用粘性，提升用户使用深度。 DNU - 日新增用户数 DAU - 日活跃用户数 WAU - 周活跃用户数量 MAU - 月活跃用户数 ACU - 平均同时在线用户数 PCU - 最高同时在线用户数 UV - 访问用户数 PV - 访问量/ 点击量 CTR - 点击率 点击量 / 曝光量 人均点击次数 TS - 用户平均在线时长 人均启动次数 N次操作占比 用户行为路径 用户访问频次 跳出率 用户打开网站的某个网页， 然后直接退出网站。跳出率是直接衡量网页（网站）对“新用户”吸引力的重要指标例如： 100个人进入该页面，5个人直接从该页面离开该网站，则跳出率为5%。 退出率 从该页面离开网站的次数占该网页总浏览次数的比例。退出率则是综合衡量用户离开网站行为的重要指标（也可能满足需求了就离开了）例如： 20个人从该页面离开网站，该页面的总浏览量为200次，则退出率为10%。 用户会话次数 用户在时间窗口的所有行为集合。 例如：用户打开APP， 搜索商品，浏览商品，下单并支付，最后退出，整个算一次会话。会话时间，网页端用户超过30分钟再次操作，算第二次会话。 移动端的时间窗口为5分钟。 功能渗透率 功能使用用户数 占 总活跃用户数 新老访客占比：衡量网站的生命力 访客时间： 衡量内容质量 访客平均访问页数：衡量网站对访客的吸引力，访问深度 访客来源： 访客从哪里来 用户行为转化率 首页访客占比：衡量网页结构，对新用户导航是否友好 TGI ： [目标群体中具有某一特征的群体所占比例 / 总体中具有相同特征的群体所占比例] * 100 例如，在15-24岁的人群中，有8.9%的人过去一年内服用过斯达舒，而在总体人群中，服用过斯达舒的人数比例为6.6%，则斯达舒在15-24岁人群中的TGI指数是134.9，这说明，斯达舒主要定位在15-24岁的人群中。TGI指数表征不同特征用户关注问题的差异情况，其中TGI指数等于100表示平均水平，高于100，代表该类用户对某类问题的关注程度高于整体水平 提高留存率（retention) : 如何让用户不断的使用我们的产品， 减少用户的流失，提升用户的粘性。 次日留存率 次3日留存率 次7日留存率 30日留存率 回流率 用户在使用该App离开的N天/周/月之后，再次使用该App的比例 用户流失率 用户生命周期（周期/(1-周期内新增留存率)) 功能使用率 衡量产品功能是否受用户欢迎 用户忠诚指数 忠诚指数是对活跃留存的再量化。活跃仅是产品的使用与否，A用户和B用户都是天天打开App，但是B产生了消费，那么B比A更忠诚。 提高收入（revenue) : 从用户中获取收益 pu 付费用户 CR 付费转化率 注册用户到付费用户的转化率 ARPU 平均每用户收入 ARPPU 平均每付费用户收入 APA 活跃付费用户 PUR 用户付费率 APA / AU LTV 生命周期价值 如果我们获取到1万个用户需要花10万元，那么，如果这1万个用户从安装到卸载能够给公司带来大于10万元的收益，则这个产品就是可盈利的。 PBP 回收期 当我们预测到产品是可盈利的之后，所付出的成本需要多久才能收回，产品才能开始真正地盈利，这个时间就是回收期PBP，为了保证公司资金链不出问题，一般认为PBP能够在一年以内是最好的。 GMV 网站成交金额 拍下订单的总金额，包含付款和未付款两部分 支付uv 支付pv 访购率 人均订单数 客单价 总收入/订单数 复购率 单位时间内，消费两次以上的用户数占购买总用户数 退货率 消费次数 消费频率 订单量 购买间隔 APPU 每个用户的平均利润 用户推荐（refer): 通过提升产品的竞争力， 使用户给其他人推荐此产品。 分享率 分享次数 K因子 即每一个用户能够带来几个新用户 病毒传播周期 假设1000位种子用户在10天邀请了1500位用户，那么传播周期为10天，K因子为1.5。 NPS净推荐值 计量某个客户将会向其他人推荐某个企业或服务可能性的指数净推荐值(NPS)=(推荐者数/总样本数)×100%-(贬损者数/总样本数)×100% 其他缩写 PP —— 英文percent point的简称，意思为百分比 UGC —— 用户原创内容 SEO —— 搜索引擎优化 CR —— 转化率 ： 衡量转化环节的好坏 visit —— 用户访问次数 ： 用户来到网站-关闭网站页面 Landing Page —— 着陆页 ： 用户从外部链接直接跳转到的第一个页面 Bounce Rate —— 跳出率 ： 用户来到网站，没有做任何行为就指标离开网站。 Referrer —— 引荐流量 PR —— 公众关系， 组织机构与公众环境之间的沟通与传播关系。 在真实的工作中，我们需要研究公司目前都有哪些业务，盯紧整个部门的核心的指标， 再根据具体的业务将核心指标拆解到有逻辑关联的二级指标。 如大目标是营收， 那么更多的付费用户能带来营收，更长的生命周期能带来营收，更高的客单价能带来营收，将二级指标分配个多个团队或多个时间段来执行。 其次， 在指标的考核落实上， 一定要细化到某个部门、某个人，这样我们就可以追踪当指标不能完成时能找谁背锅。然后，通过日报、周报、月报的总结汇报，来说明业务运营的问题，促进公司业务更好的发展。 参考资料： 学习数据分析，从了解方法论开始万字干货总结：最全的运营数据指标解读 如何建立业务数据指标 数据君 指标体系不重要，重要的是指标之间的关系 假设进入一个企业， 要从0-1去搭建指标体系。 调研 一方面是业务的调研，比如我们现在有哪些业务？这些业务在行业有没有一些标准的指标？ 另一方面使需求调研，比如哪个部门处于我们业务流程的哪个阶段，他们关注什么指标？ 这两点很重要，因为我们后面做的分析都是要通过指标去看业务的发展，而每个业务发展的阶段都是某个或者某些部门一起来完成，这就会埋下一个很深的伏笔，问题出现了，谁来背锅。 找到适合自己企业的方法论比如互联网企业都在用AARRR，整体的拆分逻辑是【获取-活跃-留存-营收-传播】， 这个模型在各个公司都会被改良，因为太笼统不够细化，但它给了我们一种关键行为的思路。 比如有的分为好几个阶段： 认知、注册、行为、互动、交易、售后、客服等等，你需要对每一个类型进行进一步的拆分。 比如： 认知阶段，也就是你和用户第一次见面在哪里？可以分为线上广告，品牌类推广、SEM\SEO、CPS、CPC等等， 线下的灯箱广告、楼宇、公交广告、地铁等，这样去制定每个渠道的关键性考核指标，比如线下可能多是曝光，不懂可以去进行搜索，这种方法可以依次拆分注册、行为、互动等等。 技巧自己要画几个方框，在方法论走通的前提下，每一个业务动作都话一个方框，注明什么动作，再补充这个动作需要哪些指标，到最后一目了然，领导看后肯定喜悦，这就是指标体系与业务之间的商业画布。 落实在方法论和商业画布的基础上，要对应到部门，比如认知阶段，很多都是市场部、品牌部、渠道从部负责，那么这样指标有问题，你就知道找谁背锅了。 这里面需要注意的一点，现在很多部门的指标比较单一，比如渠道部只负责拉点击，不负责注册，那么你就要通过指标的表现和系统性，考虑跨部门背指标，这一点比较难，但还是要提出来，或者用权重的方式去解决，让领导去拍板，一般指标体系老板都要产于，因为他们想要找个方式来量化一切。 最后以上的部分只是让你从业务和企业的角度梳理出来适合自己的衣服，但是指标既然存在就要有量化之后的数据，最难的是数据之间的关系，所以这里面也要指出每个阶段，每个部门更关注的一些指标，也被称为第一关键指标或者北极星指标，这样会让自己更清晰，而不是简单的对指标进行归类，一个是自上而下，一个是自下而上，思路是不一样的。 核心最核心的一点， 指标体系的搭建其实很简单，主要是如何从你的报告体系中反应出来，比如日报应该反应什么，周报应该反应什么，月报应该反应什么？这就很烧脑了。]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>常用指标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[心理系统]]></title>
    <url>%2F2019%2F05%2F12%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E5%BF%83%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[《自我发展心理学》如何改变改变很难，因为自己的理智很难左右头脑中的大象，大象一般都在是活在经验中， 被过往的经验所支配。 如何改变， 你需要创造出新的经验， 如果你只是想象中的期待，而不去行动，那么你是不可能改变的。 改变的方法： 奇迹提问法 如果你的愿望最终实现了， 你觉得你现在应该做什么事情 环境场方法让自己待在一个合适的环境中， 或者自己创造一个合适的环境 不要只是自责， 自责会产生焦虑，让自己失去控制感， 而要掌握控制感，人就会拖延。 思维进化认知模型 什么是心智模式 当你遇到一件事情，习惯性的想法，就是心智模式。 心智模式的作用 塑造我们的经验，影响我们的情绪。 对同样的事情有不同的解读，并产生不同的情绪。 引发行动 如果你觉得一件事你能应付，那你就会想各种方法，全力以赴，最后这件事果然做成了。 然后加深了你“我能应付”的信念。 成长与防御型思维如何建立起来的 安全感是否被满足，特别是我们与父母的依恋关系 足够的安全感——自主性——解决问题——能力成长——胜任感——充满自信——自主性安全感缺失——回避伤害——在意头脑的规则——在意别人的评价——失去行为自主性——防御性思维 防御性思维的三种类型 僵固思维 防御内心完整自我的形象 应该思维 防御内心已有的规则 绝对化思维 防御可能的伤害 什么是僵固型思维]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>心理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive 进阶查询]]></title>
    <url>%2F2019%2F05%2F07%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-Hive%E8%BF%9B%E9%98%B6%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[CASE 表达式case when 的简单用法1. 语句123case when sex = &apos;1&apos; then &apos;男&apos; when sex = &apos;2&apos; then &apos;女&apos;else &apos;其他&apos; end 注意： 必须写 end, else 部分默认为 null 2. 等值转换 有这么一张表 pop ： area(地区) population(万) 渭南市 538 延安市 226 商洛市 238 昆明市 673 曲靖市 650 青岛市 769 需要得出如下表的结果： 省 人口（万） 陕西 1002 云南 1326 其他 769 sql如下：12345678910111213141516171819-- 将地名转换成省select case area when "渭南市" then "陕西" when "延安市" then "陕西" when "商洛市" then "陕西" when "昆明市" then "云南" when "曲靖市" then "云南" else "其他" end as district, sum(population)from pop-- group by -- case area-- when "渭南市" then "陕西"-- when "延安市" then "陕西"-- when "商洛市" then "陕西"-- when "昆明市" then "云南"-- when "曲靖市" then "云南"-- else "其他" end]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《你凭什么做好互联网：从技术思维到商业逻辑》 读书笔记]]></title>
    <url>%2F2019%2F05%2F02%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E4%BB%8E%E6%8A%80%E6%9C%AF%E6%80%9D%E7%BB%B4%E5%88%B0%E5%95%86%E4%B8%9A%E6%80%9D%E7%BB%B4%E3%80%8B%2F</url>
    <content type="text"><![CDATA[前言优秀的人，将理想建立在自己的奋斗上，比如说，我要做一个什么事业，我要完成一个什么目标；而平庸的人，将理想建立在其他人身上，比如，我要中个大奖，我要换份好工作，遇到好老板。 初学者的建议几点建议： 平时学到的东西，多思考一下，应用场景在哪里。 平时上网站下APP的时候，多思考，人家用了什么技术，怎么实现的，自己学到的东西在里面能做什么。 如果学了算法或其他知识，想想能否用在这些工具上，能否提出优化和改进的方案。 如果是对产品和运营感兴趣，多想想人家成功产品是怎么运营，怎么推广，怎么发展用户的。 这里最为重要的一点是，多学人家做得好的地方，特别是细节，比如文案、标题抓的用户心理诉求是什么。 如果从事互联网技术，试着做一个APP或网站。 多学习人家的开发思路和设计理念，有机会把自己的一些代码发布到GitHub,并在一些技术社区多解答问题，多分享自己的东西，可能对未来工作帮助很大。 如果你想从事互联网运营和产品， 试着运营一个微博或者微信公众号，或者你能在知乎上成为一个有表现力的活跃账户。这些对求职都会有帮助。 关于考证，要清楚什么证有用，什么证没用。技术达人应该多做一些竞赛挑战。 简历，你做过什么，你有什么能力，你以前表现出怎样的水平。 年轻人不要怕表现，要敢于出来表现，但要有正确的度，你的表现是分析问题和解决问题的能力， 而不是表现自己读过什么数，懂什么算法。一个有正常价值观的公司，最终还是会用你的实际效果说话。 尽信书不如无书，我支持各位多看书，多读书，有些技术原理、基本理论确实没有过时，但是，关于商业、关于市场、关于行业的发展方向，我们必须更努力地往前看，而不能迷信与书本，至于媒体报道，你可以作为参考，但是你要知道 ，这些还多东西都是包装出来、拼凑出来的，真相需要你认真挖掘。最后，切记玻璃心，特别能抗骂抗造的，一般发展都不错。 走出心理舒适区心理舒适区 往往来自一种习惯，来自你所熟悉的场景。 很多打工的人觉得自己很辛苦，很努力，但是其实很多时候他们的辛苦，努力也是在掩盖自己拒绝改变的一种懦弱。 辛辛苦苦去很早上班，做很多事情，但是拒绝去学一种新技能，拒绝尝试一种新的领域和机会，这都是躲在心理舒适区的表现。 为什么学霸们的心理舒适区有问题呢？因为他们习惯的场景太窄了，把自己未来的路设计的太窄了。 你一定要想办法拓展和扩大自己的心理舒适区，不要让自己总是躲在一个很小的舒适区里出不来，要敢做一些改变的常识，挑战一下自己之前胆怯的领域，这样对职场，对工作才能更好的适应。 如何扩大自己的舒适区？ 多参与分享，多上台演讲，能够克服演讲恐惧，对未来的工作和个人发展绝对大有帮助。 多接触不同的人群，多了解不同领域的信息，尝试和各种人沟通。视图理解更多以前无法理解的东西 力所能及地尝试做一些不同的事情，并尽量做好。比如，组着一个主题社团，接一些有挑战性的工作。 适当学一点无聊没意义的东西，扩大接触面和知识面，很多看上去没用的东西，很有可能潜移默化地帮到你。比如绘画，书法等 进入和浏览不同类型的社区，观察和参与一些职场人士的讨论，不要盲目用想象来猜测职场。 在职场，我们要不断摸索，寻找新的心理舒适区，心理舒适区不代表你不累，不辛苦，当你觉得工作很有趣很开心，说明你找到了自己的心理舒适区。这个过程需要你正确的认识自己。 关于职业选择哪些茫然无知冲进新行业的年轻人，他们的平均回报率远远超过那些在自己擅长领域因循守旧的家伙。 如何评判自己适合什么工作？适合的工作，就是工作虽然累，但是很开心，很有成就感。 遇到合适的时机，勇敢地清空自己，从零开始，任何时候都可能有巨大的机会在等着你。 建议： 不断反思自己，适合什么，不适合什么，喜欢什么，不喜欢什么，要认清自己的内心。 看未来，看方向，要知道未来在哪里，而不是只看现在是什么。 你看未来市场增量是多少，而当前市场盘子是多大，如果有十倍、百倍空间，你进入这个领域，机遇就比去饱和行业要大。 很多时候，我们基于已有问题和困境，而不敢相信未来，这是发展的一大障碍。 选择offer时，不要被描述所迷惑。去巨头公司，接触核心部门，接触核心数据，可能对自己的行业认识帮助更大。 很多时候，你认为自己想做的，不过是因为很多人都觉得好。 所有已有经验都是有价值的，但不代表你不可以换别的试试，在一些新兴或跨界的领域，往往学习能力和适应能力比经验更重要。 任何时候，都必须保持学习、保持饥渴，保持对新领域的好奇和敏感。 信用问题 牺牲信用和节操就是牺牲未来不可多得的机遇。 守时是一个人基本的信用体现。 首先，对约定的目的地、路程时间又预判，做出一定的提前量，而不是一切按照最佳的可能去思考。 其次，当我们比约定时间早很多到达目标地点，不要急于联系对方，先找个地方休息一下，等差不多还有10分钟的时候，发个消息告诉对方已经到了。如果没有反馈，在基本接近约定的时间再打电话联系。 再者，当我们遇到一些交通状况或意外导致我们无法准时，提前一点时间给对方法消息，告诉对方可能延误多久。有一个提前的提示与不做提示，给对方的印象是相差极大的。信用的本质就是别人对你的印象。 不要轻易承诺无法兑现的事情，有担当不等于不负责任的揽事。做不到的事情直接回绝。没有把握的事情，要明确可能性。 要有担当，敢揽事，但是你担当之后要拼尽全力去兑现的。如果无把握，你可以去拼，但是请记住，你可以承诺的只有你的努力和付出，而不是结果。 错了要敢认，不推诿。 替人或产品背书要先做好背景调查，就是是朋友，也要把握原则。 学习一项技能的方法理脉络，认场景，扣细节。 理脉络 首先，你要有一个对自己未来的目标，你希望十年之后成为怎样的一个职业人才。 有了目标之后，你要搜索或咨询专家，了解针对这个目标，你需要储备怎样的知识体系，你需要点亮的技能树有哪些。 给自己一个学习计划，然后去学习课程。 认场景 学一门技术、一门课程，要结合应用场景，工作场景。一门课程，一项技术是在哪些工作场景中需要用到的，是如何体现其价值的。 多了解工作场景，了解知识在职场中的具体表现。 抠细节 这个知识在真实的产品中是不是可以完美实现这个功能逻辑。在实际中，如果要做到更好，在这个算法之外，还应考虑什么？ 除了这个基本策略之外，你还需要从哪些角度入手，对系统做优化，你需要羊场这样的思考习惯。 抠细节，需要对场景中每个环节的认知和敏感性，以及对自我知识体系不断评估不断优化的一种习惯。 能认真分析市场领先产品好在哪里，体验顺畅在哪里也是一种抠细节的表现。 商业分析思维建立 看数据 将商业逻辑拆解，分解出先行指标，逐一优化，仍需关注与业务可持续相关的隐性指标。 拆解商业逻辑，是一种思考习惯，先训练这样的思考习惯，再训练用这样的思考习惯看产品的视角，对商业分析的能力提升就会很大。 搜索引擎收入 搜索收入 = 用户搜索量 广告展现率 广告点击率 * 平均广告点击价格隐形指标： 客户续费率 电子商务 销售收入 = 产品曝光度 用户点击率 用户下单率 付费成功率 （平均客单价 - 平均客成本） 平均客成本: 基本采购成本, 仓储成本，退货率和退货成本，以及市场营销和运营成本 曝光度：采购流量， 自然搜索流量，用户分享的流量。 隐形指标：客户重复购买率 琢磨人性 竞价排名。跳动入局者的竞争，从中获得最大利润。 个别的]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>互联网思维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音乐]]></title>
    <url>%2F2019%2F04%2F23%2F%E7%94%9F%E6%B4%BB%E8%B5%84%E6%96%99-%E9%9F%B3%E4%B9%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[李志-回答 卑鄙是卑鄙者的通行证，高尚是高尚者的墓志铭。看吧，在那镀金的天空中，飘满了死者弯曲的倒影。冰川季过去了，为什么到处都是冰棱？好望角发现了，为什么死海里千帆向竞？ 我来到这个世界上，只带着纸、绳索和背影，为了在审判之前，宣读那些被判决了的声音：告诉你吧，世界，我不相信！纵使你脚下有一千名挑战者，那就把我算作那第一千零一名。 我不相信天是蓝的，我不相信雷的回声；我不相信梦是假的，我不相信死无报应。如果海洋注定要决堤，就让所有的苦水都注入我心中；如果陆地注定要上升，就让人类重新选择生存的峰顶。新的转机和闪闪的星斗，正在缀满没有遮拦的天空，那是五千年的象形文字，那是未来人们凝视的眼睛。 李志-忽然 李志-这个世界会好吗？ 李志-热河 李志-黑色信封 李志-梵高先生 李志-关于郑州的回忆 李志-人民不需要自由 李志-墙上的向日葵 李志-光阴路的夏天 李志-动静 李志-14跨年演唱会 左小祖咒/陈升-爱情的枪 Pink Floyd - Wish You Were Here Queen - Love Of My Life 轻音乐-Cello Collection with Calcifer]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[改版分析]]></title>
    <url>%2F2019%2F04%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E6%94%B9%E7%89%88%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[改版分析 新改版页面的效果怎么样？ 产品迭代的需求来源： 市场调研、竞品分析、用户反馈、数据分析、团队头脑风暴。 分析方向： 改版后， 新功能是否受欢迎 改版后， 对产品的流程转化率是否有提升 改版后， 对产品的整体留存的影响 改版后， 用户究竟如何使用新功 功能活跃比新功能的用户数 / 同期客户端活跃用户数 漏斗转化提升 次日留存、周留存、月留存等指标是否朝着更好的方向发展。 用户使用新功能， 是否符合你的预设， 还是说用户创造出了新的玩法。]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>改版分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试系统]]></title>
    <url>%2F2019%2F04%2F22%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E9%9D%A2%E8%AF%95%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[目标岗位美团-数据分析师（业务支持） 面试问题对行业的认识 你觉得一个数据分析师应该具有哪些能力？你更侧重什么能力？ 你为什么会来美团，你为什么对数据分析感兴趣？ 你的职业规划是什么？ 数据分析能力考查 假如有一天我们的复购率下降了， 你如何分析和假设，并制定策略？ https://mp.weixin.qq.com/s/_WhFj4u9ptZa22jk2WLxDQ?utm_source=wechat_session 你做过的项目中， 在宏观、中观、微观层面实用的方法有哪些？他们之间的逻辑关系和分析的层级是什么样子的？ 你在工作中具体做了哪些事， 给公司和客户带来了什么样的提升 产品数据发生变化，如何分析，原因分析。 对产品数据有一个直觉。 A/B test 问题 用户流失的分析， 新用户流失和老用户流失有什么不同？ 在一个国家中某些机型留存率下降， 如何分析并定位原因？ 元旦过后整体DAU连续多天下跌，如何分析？ 是否参与过仪表盘的设计及指标选择？ 如果有请描述 输入法用户画像如何设计？可以有哪些指标以及如何可视化呈现？ 如何快速了解一个业务， 并建立监控体系？ 预测未来10年北京人口变化趋势 要求： 请用思维导图呈现具体分析思路， 请给出你认为研究所需要的所有数据/变量/指标， 并给出分析实施步骤 SQL 能力考查sql面试题 工作中， 提数数据时，有没有遇到过数据倾斜问题， 什么是数据倾斜， 如何避免数据倾斜问题? 如何理解过度拟合 解释 left join 与 right join 的区别并举例说明 按天统计各国新增uvtop5 版本及对应新增 uv 数。 新增用户表名为 table_a; 分区为d_s; 其中国家为 ip_code、版本为 ver、 用户ID 为 userid 解释 lateral view 函数用法并描述一种使用场景http://www.voidcn.com/article/p-tyndabwi-bmt.html 统计学能力考查 某城市有两种颜色的出租车，蓝车和绿车的比率是15:85. 一辆出租车夜间肇事逃逸，但有一位目击证人，这位目击证人认定肇事的出租车是蓝色的。 但是，他的目击未必可信，公安人员经过在相同环境下对该目击者进行“蓝绿”测试得到：80%的情况下识别正确，20%的情况下不正确。那么， 实际为蓝车的可能性为多少。 什么是归因分析？ 如何识别归因于相关系数？举例说明 为什么说均方误差不是一个衡量模型的好指标？你建议用哪个指标替代？ 交流能力 描述一下，之前如何和别人去合作的 你能不能谈一个让你觉得非常有挑战的个案，你是如何理解和应对的？ 请你谈谈你的缺点，并详细讲一下具体的细节 你觉得这个方案有什么地方可以改进 这项新技术你是怎么精通的 你对加班怎么看 曾经被老板指出过什么问题吗 你近期的困惑是什么 商业能力考查python 能力考查 用 python 实现 1+2+3+……+100 excel，sql,可视化，python 现场操作 算法能力考查 为什们说朴素贝叶斯是“朴素”的 K-means 算法 和 knn 算法的区别是什么 答案对行业的认识 你觉得一个数据分析师应该具有哪些能力？你更侧重什么能力？ 要分开说：业务、思维、工具、算法、用户体验、宏观层面。回答的时候不要扯数据、分析。 你为什么会来美团，你为什么对数据分析感兴趣？ 不要说 google 非常好，非常有趣， 数据非常多之类的话要讲你个人的感受，小细节。让别人能够感受到你对这个工作非常的有兴趣。 数据分析能力考查 假如有一天我们的复购率下降了， 你如何分析和假设，并制定策略？ 复购率，从商业角度来讲，就是竞争能力下降，无非价格、质量、口碑等因素。复购率 = 重复购买率。 也就是复购次数 &gt;=2 的用户占所有购买总用户的占比，影响复购率的直接因素是两个， 一个是总用户群体中， 一个是购买次数&gt;=2的用户数，复购率第要么是购买总用户数增大，要么是购买次数&gt;=2的用户减少，然后再分别去找这两个对应的因素，并进行细分，最后给出结论是正向影响还是负向影响，采取什么措施去解决这样的问题。 你做过的项目中， 在宏观、中观、微观层面实用的方法有哪些？他们之间的逻辑关系和分析的层级是什么样子的？ 1.宏观层面一般影响的是一个业务，甚至是企业的发展方向。会向外看竞品分析，行业分析、包括潜在竞品分析，甚至是对于整个大环境的预判。比如人工智能，5G等。向内看经营分析，对业务完整的经营闭环的健康分析。2.中观层面，分析方法论。 如AAARR分析模型。 漏斗分析模型，路径分析模型等。3.微观层面， 数据分析的软实力。如数据敏感度，逻辑思维能力。4.逻辑关系： 中观能力是硬核能力，微观能力是转实力，两者具备才能上升为宏观能力。 你在工作中具体做了哪些事， 给公司和客户带来了什么样的提升 把实际问题分层定位问题，从数据的角度发现了管理的误区和营销的浪费发现了好机会，对目前的业务发展和增长空间进行了诊断分析, 让业务又了新的方向优化了商业模式，借助上下游产业分析，找出了利于公司在**方面迅速提升……回答问题要有原则，务实，通俗易懂，直击企业场景 产品数据发生变化，如何分析，原因分析。 对产品数据有一个直觉。 对产品需要特别熟悉， 对每个按钮都点击，思考产品经理在做这个按钮时，用户是什么群体，实现什么功能，我作为用户会如何去用，这个产品好不好，你会不会去用，原因是什么，不会去用的原因是什么？ A/B test 问题 统计学能力考查 某城市有两种颜色的出租车，蓝车和绿车的比率是15:85. 一辆出租车夜间肇事逃逸，但有一位目击证人，这位目击证人认定肇事的出租车是蓝色的。 但是，他的目击未必可信，公安人员经过在相同环境下对该目击者进行“蓝绿”测试得到：80%的情况下识别正确，20%的情况下不正确。那么， 实际为蓝车的可能性为多少。 蓝车： 150 80% 蓝车 120 量 20%绿车 30量绿车： 850 80% 绿车 680 蓝车 170120/ (120+170) = 41.37% 最基本的统计概率知识 sql 查询能力考查 工作中， 提数数据时，有没有遇到过数据倾斜问题， 什么是数据倾斜， 如何避免数据倾斜问题? 如何理解过度拟合 商业能力考查 商业，产品如何去赚钱， 商业的流量， 如何变现，如何转化 交流能力 交流能力，为什么这么做， 我是怎么想的， 为什么要这么做， 概率问题要讲清楚。 讲故事的能力。 面试官问我这个问题， 是想考察我什么， 保证在回答过程中， 将能力与经验体现出来。 是否聪明， 你解决问题的能力。 你一上来并不知道答案是什么，但你能够依照步骤，有条理，有逻辑的提供解决问题的方案。 需要注意： 先证明自己是否真正的听懂了， 是否真正理解问题 想把自己的思路想清楚， 然后把自己的思路给别人讲清楚。 你这么想的目的是什么，能解决什么样的问题 能够将你的整体思路进行概括 你不提供原因， 没法在工作中说服别人， 让别人去信服你说的是否靠谱。 给一个困难的场景， 问你如何去做。 描述一下，之前如何和别人去合作的如果你去旅游，但突然有工作安排，你会如何去做….. 你能不能谈一个让你觉得非常有挑战的个案，你是如何理解和应对的？ 请你谈谈你的缺点，并详细讲一下具体的细节 面试亮点 能够感觉到你对公司非常的感兴趣， 你对现在的工作非常的感兴趣。 对商业问题非常的有兴趣，解决了什么问题。 你对你做的事情，你非常的感兴趣。 希望能够跟积极的人去工作。 你怎么能让我喜欢你，觉得你非常的有趣， 非常有亲和力。小细节。 工作经历必须有有价值的东西。 你这个产品，你这个经历，学到了什么东西 把每个问题都回答的好一点。 分析问题的思路是最重要的。 面试时要积极，价值观等 否决原因一票否决： 撒谎： 懂一点，但是夸大了很多。表达的方式， 让别人不信任你说的。 错误的答案。 sql 错误。 面试中代码重要吗？ 不重要 把时间花费在 sql 上， 要写sql 你的sql 要非常非常好 你写sql, 是如何解决问题， 确定要做的事情， 数据是什么样子， 你先做哪一步， 你的思路是什么，在写的时候要一直去说 你要去敲出正确的sql 代码 注意事项简历要有关键词： 学校，公司， 技能关键词， 面试现场面试官的角度 面试者的两种心态 蛰伏者：我老实干活，不要裁我，等熬过寒冬，就不怕了。 一旦被裁，满心惊恐，被迫匆忙面试。 躁动者：公司万一朝我动刀，我就麻烦了，不如赶紧找出路。随未雨绸缪，但急于找到下家。 面临准备不足，急于求成，不能把能力清晰明确的表达出来。 公司到底想要什么样的人？ 怎样才算对公司对团队有价值的员工？ 个人工作结果质量高， 价值高。 工作结果在性能、易用性、维护性方面符合要求，对客户有用， 能够客户带来价值，解决产品的真正问题。 赋能别人做出成果 分享精力去帮助同事工作 分享技能帮助同事提升技能 分享自己的视野和观念，领导他人更快更好的工作。 考查应聘者的哪些内容？ 经验公司目标： 和职位需求匹配。 工作经历的对象和产出， 体现为专业相关的知识和思维结构， 用来指导思考和行为。普通人， 在技术拓展速度适中的工作中， 3年可以达到独立、熟练工作的程度。 5年能够带领别人完成工作。 技能公司目标： 和职位需求匹配。 做事的能力， 体现一个人的专业性。 技能可以让你基础已有的经验，运用新的工作、技术达成产出，形成新的经验。 产生 Idea 的能力： 针对问题， 基于经验，收集、理解、分析和指定新的方案，涉及理解、思考、沟通等过程。 执行的技能： 运用工具， 把方案应用到时间，从而解决问出。 团队协作、管理资源，甚至领导和影响他人。 潜力公司目标： 学习、创新和精益能力好的候选人。 增长经验和技能的能力。有成长性思维： 技能可以通过努力获得，关键是要保持好奇心，平时爱思考、总结、尝试，愿意接受挑战，不怕错误和失败。 动机公司目标：人品好，职业价值观和团队文化一致，职业性格和职位匹配。 做事情的内心目标、意愿和态度。很多事情不是没有能力做， 而是被不想做、觉得困难等心理因素困扰，这就是动机不足。想要做成事， 动机非常重要。 动机决定着应聘者的潜能发挥、技能习得和经验形成。动机决定前面三项。 信任感应聘者的行为是否可以被预测。 假如将来发生某种状况，你能否预测出他的决定和行动？ 即使某种技能暂时不够， 但你能预测他有潜力快速提高。即使一件事情很麻烦， 但你预测他会不辞辛苦， 认真对待。 什么决定动机？ 人格品质 诚实守信、认真负责、坚毅勇敢等。 职业价值观 在工作中能区分是非、明确轻重的观念。 职业性格 长久的思维和行动习惯，受环境影响固话成的心态定势。面试管希望性格多样，但要与职位性质相契合。 技能形成经验，潜力决定技能增长速度，动机决定潜力、技能和经验的发挥。 如何准备 用真诚的态度， 有效地表达自己的能力和价值，建立相互的信任和认可。 了解考查的各项内容和期待， 做到“知彼”，做好充足准备。 从个人精力中挖掘素材，突出契合职位需要的内容，满足面试官的预期。 经验、技能、潜能要在工作中的每一天积累、总结、提高。 要有发掘和表达自己能力的能力。 面试流程 招人的三种情况 填补空缺 工作细节清楚、职责明确，确定性高。招聘职位期待明确，应聘者可轻松上手，但要超越前任才能获得好评。 新增职位 工作难度和职责不清晰，职位期待不清，工作需要很多探索和磨合，较难上手，但很容易获得好评。 岗位申请需求 出现招聘需求 —— 部门经理明确岗位职责和要求 —— 提交招聘申请 —— 审批确定——发布职位说明——面试 收集简历的渠道 内推： 通过率最高 公司网站：需注意职位发布时间。 社交平台： 官方微博、微信公众号。 招聘网站 线下招聘会 猎头公司 投递简历注意事项 简历邮件标题 写清应聘职位、姓名 简历用PDF格式 用正式的个人邮箱投递 面试流程 电话预约面试 做好心理准备，不要紧张，尽最大可能展现自己的能力，给对方留下好印象。 笔试 摸清应聘者的基本功和技能点，有利于验证能力水品。 HR 考查基本面： 动机（价值观、职业性格）和潜力。 部门大牛 关注应聘者在工作细节上的经验和技能，解决问题的能力。 部门经理 验证技能要求，同时验证动机和潜力，确保能认可公司文化，融入团队。 高级经理 确定符合团队需要。 你能得到更多公司与团队信息，判断是否满足你的预期，符合职业发展规划。 面试通过，HR 谈薪资福利。 提出符合自己预期的薪水期望。部门经理决定给你薪水多少。 试用期 承担工作责任，用能力说话，持续建立和加强团队信任，推动个人和团队发展。 谈薪每个岗位都有自己的薪资浮动范围，即是2个人面试同一个岗位，薪资也是有很大的差异，也许你1w,他1.5w.要靠就职后去加薪，还是挺难的。 1难的是考核，多数领导是感官，其他数据基本围绕感官。2难的是加薪机制，一般都是阶梯制度，你要保证你在top20%塔顶。三是职场欲的感知，你付出的别人未必回报你。要是自身硬，那么开始就要很硬，面试谈的那份薪水很重要，也许以后的你只能依靠跳槽来加薪。 自我介绍面试官好，我叫张宇，个人的成长经历主要分为两个阶段，]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>面试问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[流量分析]]></title>
    <url>%2F2019%2F04%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[背景-冲突-问题-答案 在互联网公司运营中，其中有很重要的一项是渠道推广，特别是在产品前期阶段，要进行拉新活动。那么如何鉴别渠道用户质量的好坏，控制并提高渠道推广效果，今天我们就来谈一谈。 首先，常见的推广渠道都有哪些呢？ 内部渠道（不花钱） 公司内部各产品之间推广 比如： 腾讯视频给微信读书带量，今日头条给抖音带量 公司之间进行资源互换 比如：A公司在产品上投放B公司广告，B公司在其产品上投放A公司广告。 外部渠道 搜索引擎 比如：百度搜索广告 APP内部广告 比如： 电信欢 go APP 上展现京东广告。 社交媒体广告 比如：抖音、朋友圈广告 软件市场广告 比如：豌豆荚、应用宝等下载市场 其他线下广告（暂且不谈） 比如： 电梯广告。 其次， 我们如何对渠道鉴别渠道质量的好坏？ 对于渠道质量的好坏，我们可以从两个维度进行评判： 数量 质量（留存/收入) 对于数量少，质量高的渠道， 要进行扩量 对于数量多，质量高的渠道，要加强这部分用户的变现能力 对于数量高，质量低的渠道， 要进行精细化运营 对于数量低，质量低的渠道，要对这部分渠道放弃 最后，渠道分析的关键指标与方法都有哪些？ 渠道分析的关键指标 留存率 ROI 投资回报率: 销售所得利润 / 广告成本 * 100% 产品前期看有效用户数（避免渠道刷量）和次留， 产品中期看次留、7日留存、30日留存， 产品后期看ROI 常见的分析方法 渠道细分 对渠道进行细分， 先按照一级渠道拆解， 然后再按照二级渠道拆解，找出不同渠道之间渠道的优化点。 趋势分析 查看每个渠道的变化趋势， 主要是查看各渠道的用户数量和留存率。 对比分析 对不同渠道进行趋势对比 寻找渠道路径之间转换的优化空间通过数据分析，来寻找是否能从产品投放到用户使用路径进行优化， 可能会经历以下步骤 外部渠道投放 文案展示 产品落地页 下载APP 打开APP 注册APP 浏览APP 退出 那么渠道是如何推广的？ 外部渠道投放 文案展示 产品落地页 下载APP 打开APP 注册APP 浏览APP 退出 渠道流量分析 用户从哪里来，在产品经过什么，产生了什么价值，如果波动了，为何波动。 渠道分析从哪里来， 各渠道流量质量的好坏 常见渠道与渠道分类：内部渠道：内部产品矩阵 外部渠道： 转化分析在客户端行为漏斗， 各功能模块点击 价值分析带来多少收入，是否是产品忠实用户 波动分析流量跌涨原因， 日常监控分析 http://www.woshipm.com/pmd/152265.htmlhttps://zhuanlan.zhihu.com/p/27181920]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>流量分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[竞品分析]]></title>
    <url>%2F2019%2F04%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E7%AB%9E%E5%93%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>竞品分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive 基础查询]]></title>
    <url>%2F2019%2F04%2F18%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-Hive%E5%9F%BA%E7%A1%80%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[什么是 HiveHive 是一种建立在Hadoop文件系统上的数据仓库架构, 并对存储的数据进行分析和管理，可以将 SQL 语句转换为 MapReduce 任务进行运行，这样就使得数据开发和分析人员很方便的使用 SQL 来完成海量数据的统计和分析。 Hive 擅长的是非实时的、离线的、对响应及时性要求不高的海量数据批量计算，统计分析。 Hive 不适用于在线交易处理 Hive 的常见查询语句 Hive 中的 SELECT 基础语法和标准 SQL 语法基本一致，支持 WHERE、DISTINCT、GROUP BY、ORDER BY、HAVING、LIMIT、子查询等 1. Hive 脚本如何注释可以用 - - 开头的字符串来表示注释， 也可以将需要注释的 sql 选中， 然后用 ctrl + ? 快捷键来进行注释。 2. 切换数据库1use android; 123# 查看当前数据库select current_database() 12# 重置默认数据库use default; 3. 查看表 查看当前使用的数据库中有哪些表 1show tables; 查看非当前使用的数据库中有哪些表 1show tables in myhive; 查看数据库中以 android 开头的表 12use android;show tables like 'android*' 查看表的详细信息 1desc formatted android 4. select…from 语句 基本查询 12# 查询 employee 表中的 name 和 salary。select name, salary from employee; 加入表中一列含有多个元素， 我们可以只查找此列的第一个元素 1select name, subord[0] from employees; 使用键值进行索引 1234567select name, deductions["state taxes"] from employees;# 可以使用 "点" 符号， 类似：表的别名 . 列名 这样的用法select name, address.city from employees; 使用列值进行计算 1234567select upper(name), salary, deductions["Federal Taxes"], rount(salary * (1 - salary, deductions["Federal Taxes"]))from employees;# ZHANGYU 100000.0 0.2 80000 使用正则表达式 12345# 选出所有列名以 price 作为前缀的列select 'price.*' from stocks; 常用的关系运算 12345678910111213 等值比较: = 等值比较:&lt;=&gt; 不等值比较: &lt;&gt;和!= 小于比较: &lt;小于等于比较: &lt;= 大于比较: &gt; 大于等于比较: &gt;= 区间比较 空值判断: IS NULL 非空判断: IS NOT NULL LIKE比较: LIKE JAVA的LIKE操作: RLIKE REGEXP操作: REGEXP 数学运算 123456789加法操作: +减法操作: –乘法操作: *除法操作: /取余操作: %与操作: &amp;或操作: |异或操作: ^取反操作: ~ 常用的聚合函数 1234567891011121314151617count(*) # 个数统计函数count(distinct col) # 统计去重之后的个数sum(col) # 求和sum(distinct col) #去重之后的和avg(col) # 平均值avg(distinct col) # 去重之后的平均值min(col) # 最小值max(col) # 最大值corr(col1, col2) # 相关系数var_pop(clo) # 方差var_samp(col) # 样本方差stddev_pop(col) # 标准偏差stddev_samp(col) # 标准样本偏差covar_pop(col1, col2) # 协方差covar_samp(col1, col2) # 样本协方差select count(distinct account), avg(salary) form employees; 使用别名 1234select count(distinct acount) as uv from employees; 使用limit语句限制返回的行数 123456# 只显示 10 行select count(distinct account) as uvform employees limit 10; 嵌套 select 语句 12345678910select e.name, e.salaryfrom( select upper(name) from employees) as ewhere e.salary &gt; 500; case…when..then句式 123456select name , salary, case when salary &lt; 5000 then 'low' when salary &gt; = 5000 and salary &lt; 70000 then 'middle' else 'high' end as bracket from employees; 5. where 语句, 添加条件 常见用法 1select * from employees where country = 'us' and state = 'ca'; 可以在where条件下计算 12345678select name , salary, deductions['first taxes'], salary * (1-deductions['first taxes'])from employeeswhere round(salary * (1-deductions['first taxes']) ) &gt; 70000;# zhangyu 100000.0 0.2 80000 对上式进行优化 1234567891011select e.* from ( select name , salary, deductions['first taxes'], salary * (1-deductions['first taxes']) from employees ) ewhere round(salary * (1-deductions['first taxes']) ) &gt; 70000; 条件中有浮点数 1234567# 对浮点数进行比较select name, salary, duductions['first taxes']from employees where duductions['first taxes'] &gt; 0.2; 出现的结果中会有 0.2， 因为 DOUBL 和 FLOAT 类型不同 123456select name, salary, duductions['first taxes']from employees where duductions['first taxes'] &gt; cast (0.2 as float); 出现的结果中不会有0.2 like 和 rlike rlike 子句是Hive功能的一个扩展， 可以通过Java的正则表达式来指定匹配条件 12345678select name, address.streetfrom employees where address.street rlikt '.*(beijing|shanghai).*';# 用likeselect name, address from employeeswhere address.street like '%beijing%' or address.street like '%shanghai%'; 6. group by 语句, order by, 与 having 分类并排序 12345678910select year(ymd), avg(price_close) from stockswhere exchange = 'nasdaq' and symbol = 'aapl'group by year(ymd)order by year(ymd) desc; having 子句来限制输出结果 123456789# 例子1select year(ymd), avg(price_close) from stockswhere exchange = 'nasdaq' and symbol = 'aapl'group by year(ymd)having avg(price_close) &gt; 50.0 ; 123456789# 例子2select col1from t1group by col1having sum(col2) &gt; 10 123456789101112131415# 如果没有having， 将要使用嵌套select子查询# 例子1select s2.year, s2.avg from( select year(ymd) as year, avg(price_close) as avg from stocks where exchange = 'nasdaq' and symbol = 'aapl' group by year(ymd)) s2where s2.avg &gt; 50.0 12345678910111213# 例子2select col1 from (select col1, sum(col2) as col2sum from t1 group by col1 ) as t2where t2.col2sum &gt; 10 having 与 where 的区别 Where 是一个约束声明，使用Where约束来自数据库的数据，Where是在结果返回之前起作用的，Where中不能使用聚合函数。 Having是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。 123456789# 查找平均工资大于3000的部门select deparment, avg(salary) as average from salary_info group by deparment having average &gt; 3000 123456789#查询每个部门工资大于3000的员工个数select deparment, count(*) as c from salary_info where salary &gt; 3000 group by deparment 7. join 语句 Hive中Join的关联键必须在ON ()中指定，不能在Where中指定 内连接 只有进行连接的两个表中都存在与连接标准相匹配的数据才会被保留下来。 123456SELECT a.ymd, a.price_close, b.price_closeFROM a JOIN b ON a.ymd = b.ymdWHERE a.symbol = 'Apple' and b.symbol = 'Ibm' ON 子句指定了两个表间数据进行连接的条件。 对于多张表进行连接查询 1234567SELECT a.ymd, a.price_close, b.price_close, c.price_closeFROM a JOIN b ON a.ymd = b.ymd JOIN c ON a.ymd = c.ymdWHERE a. symbol = 'Apple' AND b.symbol = 'Ibm' AND c.symbol = 'Google' 为什么条件内不加表 b 和表 c 进行连接操作， 因为 Hive总是按照从左到右的顺序来执行 Join 优化 Hive 会假定查询中最后一个表是最大的表， 在对每行记录进行连续操作时， 它会尝试将其他表缓存起来，然后扫描最后那个表进行计算。 因此， 我们在查询时， 要保证连续查询中的表的大小从左到右依次是增加的。 假如，在 a, b 两个表中，b表最小， 则 sql 需要修改为： 123456SELECT a.price_close, b.price_closeFROM b JOIN a ON b.ymd = a.ymd AND b.symbol = a.symbolWHERE a.symbol = 'APPLE' 使用 “标记” 来指定哪张表是大表， 不需要排序 123456SELECT /*+Streamtable(a)*/ a.price_close, b.price_closeFROM a JOIN B on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 左外连接 123456SELECT a.price_close, b.price_closeFROM a LEFT OUTER JOIN b on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 左边表符合 WHERE 条件的全部返回，右表不符合 ON 条件的返回 NULL 完全外链接 123456SELECT a.price_close, b.price_closeFROM a FULL OUTER JOIN b on a.ymd = b.ymd AND a.symbol = b.symbolWHERE a.symbol = 'Apple' 返回所有表中符合 WHERE 语句条件的所有记录 Hive 不支持右半开连接 8. 排序 ORDER BY Order by 对查询的所有结果进行排序 可在字段加 DESC 关键字， 进行降序排序。 （默认 ASC， 升序） 1234567891011SELECT a.price_close,FROM a WHERE a.symbol = 'Apple'GROUP BY a.price_closeORDER BY A.PRICE_close DESCLIMIT 10; 9. 子查询 Hive中如果是从一个子查询进行SELECT查询，那么子查询必须设置一个别名 From 子句进行子查询 1234567891011121314151617181920212223242526select dt, count(distinct account) as uv, count(1) as pvfrom (select dt, count(distinct account) as uv, count(1) as pv from client.android_log_viewUNION ALL select dt, count(distinct account) as uv, count(1) as pv from client.ios_log_view ) group by dtorder by dt Hive 0.13 开始， Where 子句也支持子查询 1234567SELECT *FROM AWHERE A.a IN (SELECT foo FROM B); SELECT AFROM T1WHERE EXISTS (SELECT B FROM T2 WHERE T1.X = T2.Y) 将子查询作为一个表的语法，叫做Common Table Expression（CTE） 如果用 distinct, select 后面必须直接跟 distinct 1234567891011121314151617181920212223242526272829with a1 as (select distinct user_account, provincefrom computer_viedatawhere hit_date between '2018-09-01' and '2018-09-30'union allselect distinct user_account, provincefrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-30')select province, count(distinct user_account) as uvfrom a1group by provinceorder by uv DESC Hive查询性能优化1. 什么是数据倾斜当我们在Hive上进行查询时，因为数据的分散度不够， 导致大量数据集中在一台或者几台服务器上， 导致数据的计算速度远远低于平均计算速度， 计算过程特别耗时。 2. 数据倾斜的表现任务进度长时间维持在99%，查看任务监控页面，发现只有少量子任务未完成。 3. 如何避免数据倾斜 sql优化 业务逻辑优化 方法1： 在查询中， 避免使用 select *, 使用条件限制取需要的列 方法2： 当数据量特别大时，用 group by 代替 count(distinct) count(distinct ),在数据量特别大的情况下，效率较低, 可以用先 group by 再 count 的方式进行代替。因为count(distinct)是按group by 字段分组，按distinct字段排序 12345678910use computer_view;select hit_date, count(distinct user_account) as uvfrom datawhere hit_date between '2018-10-01' and '2018-10-02'group by hit_date 可以转换成： 1234567891011121314151617use computer_view;select hit_date, count(user_account) as uvfrom(select hit_date, user_accountfrom datawhere hit_date between '2018-10-01' and '2018-10-02'group by hit_date, user_account) agroup by hit_date 方法3： join 优化 在使用 Join 进行外关联时， 将副表的过滤条件写在 where 后面，会先全表关联， 再进行过滤， 这样会耗费资源。 123456SELECT a.price_close, b.price_closeFROM b JOIN a ON b.ymd = a.ymd AND b.symbol = a.symbolWHERE s.symbol = 'APPLE' 正确的写法是将 where 条件卸载 on 后面 1234SELECT a.price_close, b.price_closeFROM b JOIN a ON ( b.ymd = a.ymd AND b.symbol = a.symbol and s.symbol = 'APPLE') 方法4： 避免 union all 子查询中使用 group by 【替换 count(distinct) 除外】、count(distinct)、max、min等。 12345678910111213141516171819202122232425262728use computer_view;with a1 as ( select user_account, hit_date from data where hit_date between &apos;2018-12-01&apos; and &apos;2018-12-13&apos; and nbtn_name like &quot;%支付宝%&quot; union all select user_account, hit_date from data where hit_date between &apos;2018-12-01&apos; and &apos;2018-12-13&apos; and nbtn_name like &quot;%支付宝%&quot;)select hit_date, count(user_account) as pvfrom a1group by hit_date 方法5： 避免不同数据类型进行关联 使用CAST函数对数据类型进行转换，语法为cast(value AS TYPE)123456789select a.price_close, b.price_closefrom a join b on a.user_id = cast(b.user_id as string)where hit_date between &apos;2018-11-01&apos; and &apos;2018-11-02&apos; and a.symbol = &apos;apple&apos; 方法6： 无效ID在关联时的数据倾斜问题 把空值的 key 变成一个字符串加上随机数，就能把倾斜的数据分到不同的 reduce 上 ,解决数据倾斜问题。需要用到Case When … Else…End语法 写法1：123456789101112131415Select *From a Join bOn a.user_id is not nullAnd a.user_id = b.user_idUnion allSelect * from awhere a.user_id is null 写法2：1234567891011Select *From a left out Join bOn Case when a.user_id is null then concat(‘dp_hive’,rand() ) else a.user_id = b.user_id end; 求两组数据的交集， 并集， 差集并集union 与 union all union, 结果包含所有行， 并删除重复行unoin all, 结果包含所有行， 但不删除重复行 写法1：1234567891011121314151617181920212223use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" union select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 点击支付宝或者手淘活动的人数总共有 435499 人 写法2：1234567891011121314151617181920212223use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" union all select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 点击支付宝或者手淘活动的次数为 665935 交集-intersect函数写法1：1234567891011121314151617181920212223use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%支付宝%" intersect select user_account from data where hit_date between '2018-12-01' and '2018-12-02' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 点击支付宝又点击手淘活动的人数为 66174 差集-(except 函数 与 join写法)写法1：1234567891011121314151617181920212223use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%支付宝%" except select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%手淘%")select count(user_account) as pvfrom a1 写法2：12345678910111213141516171819202122232425use computer_view;with a1 as ( select user_account from data where hit_date between '2018-12-01' and '2018-12-25' and nbtn_name like "%支付宝%"),a2 as ( select user_account from data where hit_date between '2018-12-20' and '2018-12-25' and nbtn_name like "%支付宝%")select count(distinct a1.user_account) as pvfrom a1 left outer join a2 on a1.user_account = a2.user_account and a2.user_account is null 只参加支付宝活动， 没有参加手淘活动的人数为 369325在求差集时， 需要注意前后顺序， 否则会出现逻辑错误可以发现， 差集 + 交集 =并集， 369325 + 66174 = 435499 写法3： 1234567891011121314151617181920212223242526272829303132333435--详细列出差集的版本号with a1 as(select distinct two as user_accountfrom test.data_csvexcept (select distinct user_accountfrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-03' union all select distinct user_accountfrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-03'))select a2.six , COUNT(a2.two) as uv, count(a1.user_account) as uv_1froma1, test.data_csv as a2WHERE a1.user_account = a2.twogroup by a2.sixlimit 100 常用函数字符串截取函数：substr,substring, substring_index语法: substr(string A, int start, int len),substring(string A, int start, int len) 返回值: string 说明：返回字符串A从start位置开始，长度为len的字符串 举例1： 12345678910use computer_view;select substring(charge_products,2,30)from datawhere hit_date between '2018-10-01' and '2018-10-05'group by charge_productslimit 15 举例2：1234567891011121314select substring(a2.charge_products,2,80), a1.namefrom lookup.products_lookup as a1 join computer_view.data as a2 on a1.product = substring(a2.charge_products,2,80)where hit_date between '2018-10-07' and '2018-10-13' and mall_events is not nullgroup by substring(a2.charge_products,2,80), a1.name 举例3： 123456789101112131415--打断selectsubstring_index(page_url, '?', 1),count(distinct user_tracking_id) as uv,count(page_url) as pv from computer_view.jt_wap_log_viewwherehit_date between '2019-04-09' and '2019-04-09' and campaign like "%scjh-scep-tcnr-9yuanka%"group by substring_index(page_url, '?', 1)order by uv DESC 刷新数据表1refresh table computer_log.client_ios_log 留存率不同写法 求11月10-15号每天的1、3、7日留存率 方法： 统计每天的uv 使用date_add 函数， 一次性求出10-15号每一天的次1、3、7日留存 算出留存率 步骤1： 123456789101112-- 统计10-15号每天uvSELECT hit_date, count(distinct user_account) as uvFROM computer_view.dataWHERE hit_date between '2018-11-10' and '2018-11-15'group BY hit_dateorder BY hit_date 步骤2：123456789101112131415161718192021222324252627282930-- 统计10-15号每天的次日留存数， 统计次3、7日留存只需将1换为3、7with a1 as ( select user_account, hit_date from computer_view.data where hit_date between '2018-11-10' and '2018-11-15'),a2 as ( select user_account, hit_date from computer_view.data where hit_date between '2018-11-10' and '2018-11-25')select a1.hit_date, count(distinct a1.user_account) as uvfrom a1 join a2 on a1.user_account = a2.user_accountWHERE a2.hit_date = date_add(a1.hit_date, 1) group by a1.hit_dateorder BY a1.hit_date 拓展方法：(迷神) 123456789101112131415161718192021-- 留存sql优化select count(1)from( select userid, count(1) from( select t1.userid, t1.statdate from table1 t1 where t1.statdate &gt;= $&#123;上30天日期&#125; and t1.statdate &lt;= $&#123;上一天日期&#125; group by t1.userid, t1.statdate ) s1 group by userid having count(1) &gt; 2 ) R1 此sql为一个样例，计算连续跟任意都适用，至于计算第N天，只需要更改下日期过滤条件，变成=$[上N天日期]，=${上一天日期}。另外，这种方式适合跑当前周期数据，如果跑历史数据，可以写个循环。当然，最暴力还是直接用userid 关联。 这种写法，更多是针对现在大部分分布式处理平台的特性，尽可能将数据合理均匀分片，每台服务器各自运算自己的，最后汇总。 尽可能少用 count distinct 这种写法，因为无法利用分片的特性。 HIVE中的窗口函数over 函数 语法： over(partition by ….)作用： 与聚合函数sum(), count(), avg()等结合使用， 实现分组聚合的功能 123456789# 根据日期 和 mac_id 进行分组求每组的数量和， 并按日期排序select hit_date, mac_id, mac_color, day_num, sum(day_num) over(partition by hit_date, mac_id order by hit_date) as sum_numfrom test.datas hit_date mac_id mac_color day_num sum_num 20171011 1292 金色 11 89 20171011 1292 黑色 19 89 20171011 1292 粉金 58 89 20171011 1292 金色 1 89 20171011 2013 金色 9 22 20171011 2013 金色 3 22 20171012 1292 金色 5 18 20171012 1292 粉金 1 18 20171012 2013 粉金 1 7 20171012 2013 金色 6 7 20171013 1292 黑色 1 1 20171013 2013 粉金 2 2 123456789101112# group by 语句select hit_date, mac_id, sum(day_num) from test.datagroup by hit_date, mac_idorder by hit_date day_id mac_id sum_num 20171011 124609 1 20171011 20130 22 20171011 12922 89 20171012 12922 18 20171012 20130 7 20171013 12922 1 20171013 20130 2 over(partition by) 与 group by 的区别grou by 字段只能显示与分组聚合相关的字段， 而 over(partition by)可以显示所有字段 LAG 和 LEAD 函数 语法： LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值;LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值 123456789101112131415161718192021# 计算11月1-10号， 不同日期同一用户登陆客户端 pv 量对比with a1 as (select user_account, count(user_account) as pv, hit_datefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-10'group by user_account, hit_date)select user_account, a1.hit_date, a1.pv, lag(a1.pv, 1) over (partition by user_account order by user_account, a1.hit_date) as pv1, lead(a1.pv, 1) over(partition by user_account order by user_account, a1.hit_date) as pv2from a1limit 100 first_value() 和 last_value() 函数 语法:first_value() ：比较每个用户浏览次数与第一天浏览次数进行比较，查询返回当前浏览次数以及第一天浏览次数last_value() ： 比较每个用户浏览次数与最新一天浏览次数进行比较，查询返回当前浏览次数以及最新一天浏览次数 12345678910111213141516171819with a1 as (select distinct user_account, count(user_account) as pv, hit_datefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-10'group by user_account, hit_date)select distinct user_account, a1.hit_date, a1.pv, first_value(a1.pv) over (partition by user_account order by user_account, a1.hit_date) as pv1, last_value(a1.pv) over(partition by user_account order by user_account, a1.hit_date) as pv2from a1limit 100 rank、dense_rank、 row_number 排序函数row_number函数说明 12ROW_NUMBER ( ) OVER ( [ PARTITION BY value_expression , ... [ n ] ] order_by_clause ) 说明： rank函数， 返回数据项在分组中的排名， 排名相等的会留下空位， 如1、2、2、4dense_rank函数， 返回数据项在分组中的排名， 排名相等的不会留下空位， 如1、2、2、3row_number函数， 返回数据项在分组中的排名， 排名不管数据是否相等， 如1、2、3、4 1234567select a, row_number() over(order by b) row_number, rank() over(order by b) rank, dense_rank() over(order by b) dense_rank from lijie.test_rank a row_number rank dense_rank A 1 1 1 C 2 2 2 D 3 3 3 B 4 3 3 E 5 5 4 F 6 6 5 G 7 7 6 业务问题 求点击【确认充值】按钮的上一步点击的名称 1234567891011121314151617181920212223242526use default;with a as (select user_account, btn_name, lag(btn_name, 1) over (partition by user_account order by create_timestamp) as previous_btn_namefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-01' and btn_name is not nullhaving btn_name like '确认支付')select previous_btn_name, count(distinct user_account) as cfrom agroup by previous_btn_nameorder by c desclimit 1000 上一步点击的名称我已经知道了， 现在要想 之前通过上一步点击这些条件之后， 再点击【确认支付】按钮的 去重uv 1234567891011121314151617181920212223242526272829use default;with a as (select user_account, btn_name, lag(btn_name, 1) over (partition by user_account order by create_timestamp) as previous_btn_namefrom computer_view.datawhere hit_date between '2018-11-01' and'2018-11-01' and btn_name is not nullhaving btn_name like '确认支付')select count(distinct user_account) as cfrom awhere (previous_btn_name like "%10元%" or previous_btn_name like "%30元%" or previous_btn_name like "%50元%" or previous_btn_name like "%10元%" or previous_btn_name like "%30元%" or previous_btn_name like "%50元%" or previous_btn_name like "%100元%" or previous_btn_name like "%200元%" or previous_btn_name like "%300元%" ) 125752 临时需求创建临时表12345678910111213141516use default;create table test.nine_android_user_version_10select user_account, app_versionfrom computer_view.datawhere hit_date between '2018-09-01' and '2018-09-30' and user_account is not null and app_version is not nullgroup by user_account, app_version 原始日志中取数12345678910111213141516use default;create table test.nine_user_version_10select url_par(url_query,'account') as user_account, split(url_par(url_query,'AppID'),' ')[1] as app_versionfrom apache_log.client_ios_sensorwhere dt between '2018-10-01' and '2018-10-20' and url_par(url_query,'account') is not null and url_par(url_query,'AppID') is not nullgroup by url_par(url_query,'account'), split(url_par(url_query,'AppID'),' ')[1] 取 pv &gt;1 的用户有多少？12345678910111213141516171819202122232425262728293031with a1 as (SELECTuser_accountFROMcomputer_view.dataWHEREnbtn_name is not null andhit_date between &apos;&#123;&#125;&apos; and &apos;&#123;&#125;&apos;union all SELECTuser_accountFROMcomputer_view.dataWHEREnbtn_name is not null andhit_date between &apos;&#123;&#125;&apos; and &apos;&#123;&#125;&apos;),a2 as (SELECT user_account,count(user_account) as pvfrom a1group by user_accounthavingcount(user_account) &gt; 3)SELECT count(distinct user_account) as uvfrom a2 sql 中的时间处理函数date()date_add() 对时间相加date_add(dt,interval 1 day ) 在dt的基础上加上一天 date_format() 对时间的格式进行改变date_format(dt, “%Y-%m-%d”)date_sub()对时间相减datediff()日期之间相差多少天 在 spark 中写 hive 循环, 工具 zeppelim12345678910111213141516171819202122232425262728%sparkfor( a &lt;- 0 until 30)&#123; // val sql= s&quot;&quot;&quot;use default&quot;&quot;&quot; // spark.sql(sql) val sql = s&quot;&quot;&quot; with a1 as ( select user_account from computer_view.data where hit_date between &quot;2018-11-01&quot; and date_add(&quot;2018-11-01&quot;,$&#123;a&#125;) union all select user_account from computer_view.data where hit_date between &quot;2018-11-01&quot; and date_add(&quot;2018-11-01&quot;,$&#123;a&#125;)) select count(distinct user_account) as uv from a1 &quot;&quot;&quot; val data = spark.sql(sql) println(&quot;day:&quot;, a, &quot;uv:&quot;, data.show())&#125; 用python脚本连接数据库作为一名数据分析师，日报、周报、月报数据一个也不能少。 相应的， 就要在数据库中提取大量的数据， 并处理大量的Excel表格。 在提取和处理数据的过程中， 对于一些重复性的劳动， 写个Python脚本来实现半自动化， 能够大幅提高自己的工作效率。 以下是自己工作中的一点总结经验。 首先， 用Python连接数据库 对于数据库的ip地址，用户名，密码等， 如果不清楚，或数据库连接不上， 需要和开发人员对接 12345678from pyhive import hive import timeconn = hive.Connection(host='ip地址', port=10000, username='用户名', database = 'default', auth='NOSASL')cursor = conn.cursor()# 获得连接的游标 设置开始和结束时间 可以用python中的time函数设置时间 12startdate = '2018-09-01'enddate = '2018-09-19' 用Python中的format函数将日期传入{}中 python中写sql脚本时， 需要用\来进行换行符的转换, \后面不能有空格。 日期用两个{}来代替， 用format函数将开始日期与结束日期传入 123456789101112131415161718192021222324# 提取积分类uv,pv数据sql_jifenxinxi_an = &quot;&quot;&quot;select count(distinct user_account) as uv, count(1) as pv from computer_view.data where hit_date between &quot;&#123;&#125;&quot; and &quot;&#123;&#125;&quot; and (btn_position like &quot;服务-查询-积分信息%&quot; or btn_home = &quot;积分-扇形左&quot; ) limit 1000&quot;&quot;&quot;.format(startdate,enddate)# format 插入时间cursor.execute(sql_jifenxinxi_an)# 运行此语句cursor.fetchall()#fetchall():接收全部的返回结果行. 我们可以按照这个格式写工作中需要运行的多个SQL语句。 这样， 当脚本运行的时候， 我们可以腾出时间来去干其他工作， 等过一段时间，所有的SQL语句都跑完了， 我们再进行统一的整理。 参考资料：Hive 编程指南Hive的那些事Hive 官网一起学HiveHive性能优化上的一些总结过往记忆——hive]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类比汇总]]></title>
    <url>%2F2019%2F03%2F30%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E7%B1%BB%E6%AF%94%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[学习一门技能，你需要知道最少必要知识。 这就好像你拿着一张地图，不可能一下子掌握其中所有的细节，但花几分钟搞清楚 “图例”（Legend）部分总是可以的，知道什么样的线标示的是公交车，什么样的线标示的是地铁，什么样的线标示的是桥梁，然后知道上北下南左西右东 —— 这之后，就可以开始慢慢研究地图了…… 在我们使用函数的过程中，我们常常有意忽略它的内部如何完成从输入到输出之间的处理过程 —— 这就好像我们平日里用灯泡一样，大多数情况下，我们只要知道开关的使用方法就够了 —— 至于为什么按到这个方向上灯会亮，为什么按到另外一个方向上灯会灭，并不是我们作为用户必须关心的事情…… 当然，如果你是设计开关的人就不一样了，你必须知道其中的运作原理；但是，最终，你还是希望你的用户用最简单方便的操作界面，而不是必须搞懂所有原理才能够使用你所设计的产品…… 在任何一本编程书籍之中，关于字符串的内容总是很长 —— 就好像每本英语语法书中，关于动词的内容总是占全部内容的至少三分之二。 教育就像一副眼镜。戴上眼镜之前和之后，我们看到的其实是同样的世界；但是戴上眼镜之后，我们就看得更清楚。 我们是这样一台计算机，厂商（我们的父母）并没有为我们提供详尽的说明书，也不负责定期升级我们的操作系统——即使他们并非故意。 人与人之间很不一样，就好像计算机和计算机之间也很不一样，有些中央处理器（头脑）更强大一些，有些人的内存容量（记忆力）更大一些，有些人的硬盘空间（笔记与藏书）更大一些，有些人显示器（外表）更漂亮一些。 很多人的处理器是落伍的，输入和输出设备常常残缺不全，内存小到没法用的底部，硬盘甚至根本就没有……至于连网设备么，真的很差，甚至真的还不如没有，因为即使连着网也因为缺乏通讯协议而完全无法使用… 科学是由信息构成的，正如房子是用砖头盖的一样，可问题在于，正如仅仅一堆砖头放在那里的时候，我们不能称其为房子一样，一堆信息放在一块就叫科学，有点不像话…… 学习电脑编程的函数时，我把函数想象成铅笔刀，钝铅笔进去，锐利的铅笔出来，这个模型不依赖于图像，但是过程类似。 两个自我： 大象和骑象人 人的感性面就是一头大象，而理智面就是一个骑象人。骑象人骑在大象背上，手里握着缰绳，好像是他在指挥大象，但实际上，他的力量微不足道。一旦和大象发生冲突，他想往左，而大象想往右。那他通常是拗不过大象的。 就像人有一套生理免疫系统来排斥不属于身体的微生物一样，人的心理也有一套免疫系统，它会排斥我们采取新的行为方式，以此来维持心理结构的平衡和稳定。 我们要验证这些假设对不对，什么时候成立，什么时候不成立。 这就像学习游泳，我们既不能只在岸上熟读《怎么学游泳》的书，也不能一下子要求自己跳到深水区，这样就被淹死了。 同一辆车， 在公路上开， 和在泥地上开， 要达到相同的速度， 付出的努力是不同的。 同理， 不同的工作环境和内容， 带来不同的难度， 对采用的技术和努力程度也有不同的要求。 所以只衡量结果却不考虑过程， 有失公平。 考虑过程， 就包括了对工作暖色、环境因素带来的工作复杂度的度量， 也体现了对个人技能、态度的衡量。 中国人是椰子文化，擅长熟人社会的交往规则，不擅长与陌生人打交道。西方人是桃子文化， 擅长与陌生人打交道。 闭环原则是工作中最常用也是最有效的原则，但很少有人能够一直做到。这就像“运动和良好的饮食可以帮助我们保持健康和身材”一样，几乎所有人都知道， 但很少有人能够做到。 “回音壁”效应： 基于数据算法的产品就像是一个回音壁，你发出声音后，应用反馈给你的是与你自己声音相似的回音。你认为自己的“声音”得到了印证，所以你会对自己“声音”的正确性更加坚定不移。由此，你的信息、知识圈层只会更加固话，视野越发狭窄。 爱因斯坦：事情不会在出现问题的那个层面得到解决，只有上升到更高的层面才会得到解决。这就像你家的羊被狼叼走了一只，你往里面补了一只羊，表面上看这个问题解决了。过些天，又有羊被叼走了，你又得不断的补羊。可是有一天你登高望远，发现原来是羊圈出现了破损，那么你只要把破损的地方补好就可以了。用大海捞针的方式穷举各种可能进行试验，这其实是一种受限于无法利用更高潜能的“笨方法”。如果人自己可以提升视野和维度，去“补羊圈”，问题往往迎刃而解，并不需要无穷次的实验。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>类比</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-决策树]]></title>
    <url>%2F2019%2F03%2F24%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E7%AE%97%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[什么是决策树想像一下，一个女孩的妈妈给女孩介绍相亲对象的场景，当女孩在询问男孩的基本情况时， 她就已经在生成一个决策树了。 在日常的生活当中，我们经常会基于以往的经验来做判断。 当我们把判断背后的思考逻辑整理起来，你会发现，它其实是一个树状结构，也就是决策树 决策树本质上就是一系列 if-then 语句， 但关键是如何确定哪个属性先判断，哪个属性后判断。 我们在做决策树的时候，会经历两个阶段：构造和剪枝。 构造构造就是选择什么属性来作为判断节点的过程。 通过构造，从而生成一棵完整的决策树 在了解决策树是如何构造之前， 我们先来了解三个概念： 根节点：树最开始的那个节点， 也就是上图中的身高超过170？ 子节点： 树中间的那些节点， 上图中的月收入过万 是否有房 长得帅不帅 叶节点： 树最底层的那些节点， 上图中的 见 不见 在构造决策树时， 哪个属性做根节点， 哪些属性做叶节点？如何选择判断是决策树中机器学习算法的关键， 就引出算法： ID3， C4.5 和 CDAR。 ID3算法ID3 算法原理我们常说一篇文章信息很多， 或者信息很少， 但却很难说清楚信息到底有多少。 比如，《习惯的力量》这本书到底有多少信息量。 直到 1948 年，信息论之父-香农提出了“信息熵”理论， 才解决了对信息的度量问题，让我们能够通过数学计算来确定信息的不确定程度。当事物越不确定时， 信息熵越大，H(X)度量了X的不确定性。 随机变量 X 的熵的表达式为：$$H(X) = -\sum_{i=1}^{n} p_{i} log p_{i}$$其中 n 代表了 X 有 n 种不同的离散取值。 $p_{i}$ 代表了X 取值为 i 的概率，log为以2为底的对数。 例如：A：在 6 次相亲中， 女生有 3 次选择见面， 3 次选择不见。 则这则消息的信息熵为 $$H(X) = -(\frac{3}{6}log\frac{3}{6} + \frac{3}{6}log\frac{3}{6}) = 1$$ B：在 6 次相亲中， 女生有 5 次选择见面， 1 次选择不见。则这则消息的信息熵为$$H(X) = -(\frac{5}{6}log\frac{5}{6} + \frac{1}{6}log\frac{1}{6}) = 0.65$$ 我们可以看到， 消息A的不确定性大于消息B， 所以信息熵也比较大。 条件熵 上面我们讨论了在一个变量下，消息的信息熵大小的计算。现在有两个变量，X 与Y,在已知随机变量Y 的条件下，随便变量X的不确定性还剩多少呢？ 已知Y的前提下，随机变量X的熵为$$H(X|Y) = -\sum_{i=1}^{n}p(x_{i}, y_{i})logp(x_{i}| y_{i}) = \sum_{j=1}^{n}p( y_{j})H(X|y_{j})$$ 我们刚才提到了H(x)度量了 X 的不确定性， 条件熵H(X|Y) 度量了在知道 Y 以后 X 的不确定性， 那么 H(x)-H(X|Y)呢？ H(x)-H(X|Y)度量了 X 在知道Y以后不确定性减少的程度， 记为I(X,Y). 在决策树 ID3 算法中叫做信息增益。通过信息增益，来衡量通过哪个属性之后，信息不确定减小的程度最多。 ID3算法就是用信息增益大小来判断，当前节点应该用什么特征来构建决策树。 通过计算，信息增益最大的属性，最适合来建立决策树的当前节点。 以上就是ID3 算法的原理 ID3算法的计算过程在决策树（一）中，我们讨论了ID3算法的原理， 在这篇文章中，我们来一步步展现ID3算法的计算过程。 我们用 ID3 算法来决定天气是否适合我们打篮球。 过去两周中，收集了14天的天气数据， 如下图所示： 编号 天气 户外 温度 风速 活动 1 晴天 炎热 高 弱 取消 2 晴天 炎热 高 强 取消 3 阴天 炎热 高 弱 进行 4 雨天 温柔 高 弱 进行 5 雨天 凉爽 正常 弱 进行 6 雨天 凉爽 正常 强 取消 7 阴天 凉爽 正常 强 进行 8 晴天 温柔 高 弱 取消 9 晴天 凉爽 正常 弱 进行 10 雨天 温柔 正常 弱 进行 11 晴天 温柔 正常 强 进行 12 阴天 温柔 高 强 进行 13 阴天 炎热 正常 弱 进行 14 雨天 温柔 高 强 取消 天气用四个属性来进行描述， 户外， 天气，温度和湿度。 它们的属性分别为： 天气 = {晴天， 阴天， 雨天} 户外 = {炎热，温柔， 凉爽} 温度 = {高，正常} 风速 = {弱， 强} 选择根节点： 步骤1：计算决策属性的熵决策属性活动有14个记录， 其中9个活动可以进行，5个活动取消，则 计算熵为： $H(决策) = -(\frac{9}{14}log\frac{5}{14} + \frac{5}{14}log\frac{5}{14}) = 0.940$ 步骤2：计算条件属性的熵样本共有四个条件属性， 户外， 温度，湿度和风速 风速的熵 计算分为2个过程，先计算属性值的熵， 再计算属性的熵 风速分为风速强和风速弱， 我们分别计算这两个属性值的熵： $H(弱) = -(\frac{6}{8}log\frac{6}{8} + \frac{2}{8}log\frac{2}{8}) = 0.811$ $H(强) = -(\frac{3}{6}log\frac{3}{6} + \frac{3}{6}log\frac{3}{6}) = 1$ 属性的熵（在风速分别为强和弱的前提下，决策的熵） $H(决策，风速) = \frac{8}{14}H(弱) + \frac{6}{14}H(强) = 0.892$ 户外的熵 户外分为凉爽、温柔和炎热， 我们分别计算这三个属性值的熵： $H(凉爽) = -(\frac{3}{4}log\frac{3}{4} + \frac{1}{4}log\frac{1}{4}) = 0.811$ $H(温柔) = -(\frac{4}{6}log\frac{4}{6} + \frac{2}{6}log\frac{2}{6}) = 0.918$ $H(炎热) = -(\frac{2}{4}log\frac{2}{4} + \frac{2}{4}log\frac{2}{4}) = 1 $ 属性的熵 $H(决策，户外) = \frac{4}{14}H(凉爽) + \frac{6}{14}H(温柔)+ \frac{4}{14}H(炎热) = 0.911 $ 天气的熵 天气分为晴天、阴天和雨天， 我们分别计算这三个属性值的熵： $H(晴天) = -(\frac{2}{5}log\frac{2}{5} + \frac{3}{5}log\frac{3}{5}) = 0.971$ $H(阴天) = -(\frac{4}{4}log\frac{4}{4} )= 0$ 熵为0表示信息完全确定，没必要再分 $H(雨天) = -(\frac{2}{5}log\frac{2}{5} + \frac{3}{5}log\frac{3}{5}) = 0.971$ 属性的熵$H(决策，天气) = \frac{5}{14}H(晴天) + \frac{5}{14}H(雨天) + \frac{4}{14}H(阴天) = 0.693 $ 温度的熵 温度分为高、低， 我们分别计算这两个属性值的熵： $H(高) = -(\frac{4}{7}log\frac{4}{7} + \frac{3}{7}log\frac{3}{7}) = 0.985$ $H(正常) = -(\frac{1}{7}log\frac{1}{7} + \frac{6}{7}log\frac{6}{7}) =0.591 $ 属性的熵 $H(决策，温度) = \frac{7}{14}H(高) + \frac{7}{14}H(正常) = 0.789 $ 步骤3： 计算各属性的信息增益 风速的信息增益 = H(决策) - H(决策，风速) = 0.940 - 0.892 = 0.048 户外的信息增益 = H(决策) - H(户外，风速) = 0.940 - 0.911 = 0.029 天气的信息增益 = H(决策) - H(天气，风速) = 0.940 - 0.693 = 0.246 温度的信息增益 = H(决策) - H(温度，风速) = 0.940 - 0.789 = 0.151 条件属性天气有最大的信息增益， 所以天气作为根节点。 选择子节点晴天节点下， 检验哪个属性？因为已经使用了天气作为根节点，所以只剩三个变量： 户外、温度和风速 第一步：计算天气为晴天的熵 从前面可知， H（晴天） = 0.970 第二步：计算天气为晴天下，各属性的熵 户外的熵 户外各属性值的熵： H（凉爽） = 0 （信息确定）H（温柔） = 1H（炎热） = 0 （信息确定） 户外的熵$$H（晴天|户外） = \frac{1}{5}H（凉爽）+ \frac{2}{5}H（温柔）+ \frac{2}{5}H（炎热） = 0.4$$ 温度的熵 温度各属性值的熵 H(高) = 0H(正常) = 0 温度的熵H（晴天|温度） = 0 风速的熵 风速各属性值的熵$H（强） = -(\frac{1}{2}log\frac{1}{2} + \frac{1}{2}log\frac{1}{2}) = 1$$H（弱） = -(\frac{1}{3}log\frac{1}{3} + \frac{2}{3}log\frac{2}{3}) =0.918$ 风速的熵$H（晴天|风速） = \frac{2}{5}H（强） + \frac{3}{5}H（弱） = 0.9508$ 第三步：计算在晴天下，各属性的信息增益 温度的信息增益 = H（晴天） - H（晴天|温度） = 0.970 户外的信息增益 = H（晴天） - H（晴天|户外） = 0.570 风速的信息增益 = H（晴天） - H（晴天|风速） = 0.019 条件属性温度有最大的信息增益， 所以温度作为根节点。 雨天节点下，检验哪个属性雨天与晴天计算同理， 故不再计算。 决策树计算结果 最后根据计算，得出的决策树分类如图所示： 1以上就是ID3分类算法计算原理的全过程 用 python3 实现 ID3算法1. 导入数据库、常用模块、函数1234567import pandas as pdimport sklearn as treefrom sklearn.tree import DecisionTreeClassifierfrom sklearn.feature_extraction import DictVectorizerfrom sklearn.tree import export_graphvizimport graphvizimport pydotplus 2. 读取原始数据 我们用决策树（二）中的打篮球数据来进行决策树的建立 1data = pd.read_excel(r'C:\Users\Administrator\Desktop\tree\打篮球数据.xlsx') 12# 查看数据前5行data.head() 天气 户外 温度 风速 活动 0 晴天 炎热 高 弱 取消 1 晴天 炎热 高 强 取消 2 阴天 炎热 高 弱 进行 3 雨天 温柔 高 弱 进行 4 雨天 凉爽 正常 弱 进行 3. 对数据进行预处理 scikit_learn默认不支持文本标签，使用 pandas库将文本标签转化成数字 12345datas['活动'] = datas['活动'].map(&#123;'取消':0, '进行':1&#125;)datas['风速'] = datas['风速'].map(&#123;'弱':0, '强':1&#125;)datas['温度'] = datas['温度'].map(&#123;'正常':0, '高':1&#125;)datas['户外'] = datas['户外'].map(&#123;'凉爽':0, '温柔':1, '炎热':2&#125;)datas['天气'] = datas['天气'].map(&#123;'雨天':0, '阴天':1, '晴天':2&#125;) 1data.head() 天气 户外 温度 风速 活动 0 2 2 1 0 0 1 2 2 1 1 0 2 1 2 1 0 1 3 0 1 1 0 1 4 0 0 0 0 1 4. 给定节点与结果123data = ['天气','户外','温度','风速']train_data = datas[data]train_labels = datas['活动'] 将数据转化成机器学习中可用的数值型特征 123from sklearn.feature_extraction import DictVectorizerdvec = DictVectorizer(sparse = False)train_data = dvec.fit_transform(train_data.to_dict(orient='record')) 查看转换后的数据 1print(train_data) [&apos;天气&apos;, &apos;户外&apos;, &apos;温度&apos;, &apos;风速&apos;] 5. 进行决策树123from sklearn.tree import DecisionTreeClassifierdecision_tree = DecisionTreeClassifier(criterion ='entropy')decision_tree.fit(train_data, train_labels) DecisionTreeClassifier(class_weight=None, criterion=&apos;entropy&apos;, max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&apos;best&apos;) 6. 查看决策1234567891011# 生成pdf文件from sklearn.tree import export_graphvizimport graphvizimport pydotplusfrom sklearn import treedot_data = tree.export_graphviz(decision_tree, out_file=None,feature_names=decision_tree.feature_importances_, filled=True, rounded=True, special_characters=True)graph = pydotplus.graph_from_dot_data(dot_data)# 保存pdf文件graph.write_pdf("treetwo.pdf") 打开pdf文件，可以看到生成的决策树 查看决策树-方法2 12dotData = tree.export_graphviz(decision_tree, out_file=None)print(dotData) digraph Tree { node [shape=box] ; 0 [label=&quot;X[2] &lt;= 0.5\nentropy = 0.94\nsamples = 14\nvalue = [5, 9]&quot;] ; 1 [label=&quot;X[0] &lt;= 0.5\nentropy = 0.592\nsamples = 7\nvalue = [1, 6]&quot;] ; 0 -&gt; 1 [labeldistance=2.5, labelangle=45, headlabel=&quot;True&quot;] ; 2 [label=&quot;X[3] &lt;= 0.5\nentropy = 0.918\nsamples = 3\nvalue = [1, 2]&quot;] ; 1 -&gt; 2 ; 3 [label=&quot;entropy = 0.0\nsamples = 2\nvalue = [0, 2]&quot;] ; 2 -&gt; 3 ; 4 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [1, 0]&quot;] ; 2 -&gt; 4 ; 5 [label=&quot;entropy = 0.0\nsamples = 4\nvalue = [0, 4]&quot;] ; 1 -&gt; 5 ; 6 [label=&quot;X[0] &lt;= 1.5\nentropy = 0.985\nsamples = 7\nvalue = [4, 3]&quot;] ; 0 -&gt; 6 [labeldistance=2.5, labelangle=-45, headlabel=&quot;False&quot;] ; 7 [label=&quot;X[0] &lt;= 0.5\nentropy = 0.811\nsamples = 4\nvalue = [1, 3]&quot;] ; 6 -&gt; 7 ; 8 [label=&quot;X[3] &lt;= 0.5\nentropy = 1.0\nsamples = 2\nvalue = [1, 1]&quot;] ; 7 -&gt; 8 ; 9 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [0, 1]&quot;] ; 8 -&gt; 9 ; 10 [label=&quot;entropy = 0.0\nsamples = 1\nvalue = [1, 0]&quot;] ; 8 -&gt; 10 ; 11 [label=&quot;entropy = 0.0\nsamples = 2\nvalue = [0, 2]&quot;] ; 7 -&gt; 11 ; 12 [label=&quot;entropy = 0.0\nsamples = 3\nvalue = [3, 0]&quot;] ; 6 -&gt; 12 ; } 访问 WebGraphviz 并粘贴输出，点击 Generate Graph 可以看到它先基于温度进行分割，再基于风速进行分割。 7. 测试决策树​12345print(decision_tree.predict([[2,0,0,0]]))print(decision_tree.predict([[1,2,0,0]]))print(decision_tree.predict([[2,2,1,1]])) [1] [1] [0] 输出1， 证明活动可以进行；输出0，证明活动取消。 ID3 的缺陷ID3算法相对简单，并且可解释性强。但同样也存在缺陷。在上面的计算中，我们有意忽略了编号这一列。 如果把编号也作为一个候选划分属性，则它的信息增益远大于其他候选划分属性。因为编号将产生14个分支，每个分支只包含一个样本，这些分支节点的纯度已经达到最大。然而，这样的决策数不会有泛化能力，无法对新样本进行有效预测。 C4.5算法ID3算法利用的信息增益，对取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响， C4.5算法在其基础上进行升级，利用信息增益率来选择划分最优属性。 信息增益率 = 信息增益 / 属性熵 = I（x，y） / H(x) C4.5是ID3算法的改进版本，针对四个主要的不足进行改进： 不能处理连续特征 用信息增益作为标准容易偏向于取值较多的特征 不能处理缺失值 容易发生过拟合问题 C4.5 算法的缺点： 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。 另外，C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。 对决策树进行剪枝ID3 算法对数据递归的产生决策树，直到不能继续进行下去，这样产生的决策树往往对训练数据的分类很准确，但对未知的测试数据的分类却并没有那么准确，即会出现过拟合现象。 过拟合现象的原因是在生成决策树时，过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。解决办法是对已生成的决策树进行剪枝。 CART算法 - 分类回归树ID3 和 C4.5 算法可以生成二叉树或多叉树，而CART 算法只支持二叉树。 同时CART算法既可以作为分类树， 也可以作为回归数。 分类和回归的区别在于输出变量的类型。 定量输出称为回归，或者说是连续变量预测； 定性输出称为分类，或者说是离散变量预测。 举个例子： 预测明天的气温是多少度，这是一个回归任务； 预测明天是阴、晴还是雨，就是一个分类任务。 CART算法介绍CART算法生成的决策树是结构简洁的二叉树,它在每一步决策时只能是是或者否。 CART算法在构建决策树时，主要分为两步： 生成决策树 对决策树进行剪枝 CART算法与ID3、C4.5 相比，主要有两处不同： 在分类时， CART不再采用信息增益或信息增益率， 而是采用基尼指数来选择最好的特征并进行数据的划分。 在ID3 和 C4.5决策树中， 算法根据特征的属性值划分数据， 可能会划分出多个组。而CART算法采用了二叉树，每次把数据切成两份，分别进行左子树、右子树。 我们知道， 决策树分类的过程本身是一个不确定性降低的过程。ID3 选择节点属性是基于信息增益来做判断， 而 CART和ID3类似，只不过选择时是使用 基尼系数来做判断。 基尼系数本身反应了样本的不确定度。 当基尼系数越小时，说明样本之间的差异性小，不确定程度低。 所以CART 算法在构建分类树是，会选择基尼系数较小的属性作为节点的划分。 CART 算法计算原理t为节点， 则该节点的基尼系数计算公式： $GINI（t） = 1 - \sum_{k}^{}[ p(C_{k}|t )]^{2}$ $ p(C_{k}|t )$ 表示 t节点属于类别$C_{k}$的概率 节点t的基尼系数等于 1减去各类别 $C_{k}$概率平方和 例如： 6个人都去打篮球 3个人打篮球，3个人不打篮球 条件1中， 所有人都去打篮球， 所以 $C_{k}|t = 1$ , $[ p(C_{k}|t )]^{2} = 1$, 因此$GINI（t）= 1-1=0$ 条件2中，一半人打篮球，一半人不打篮球。所以：$ p(C_{1}|t ) = 0.5$， $ p(C_{2}|t ) = 0.5$。 因此$GINI（t）= 1-（0.5^{2}+0.5^{2}）=0.5$ 通过2个基尼系数，可以看到， 条件1的基尼系数最小，样本最稳定。而条件2的样本不稳定行更大。 同理，延伸我们可以计算节点D的基尼系数： 节点D的基尼系数等于节点D1和D2的归一化基尼系数之和， 用公式表示为： $$GINI（D,A） = \frac{D_{1}}{D}GINI（D_{1}）+\frac{D_{2}}{D}GINI（D_{2}）$$ 所以 节点D 的基尼系数为：$GINI（D,A） = \frac{6}{12}GINI（D_{1}）+\frac{6}{12}GINI（D_{2}）$ = 0.25 CART算法计算过程打篮球数据： 编号 天气 户外 温度 风速 活动 1 晴天 炎热 高 弱 取消 2 晴天 炎热 高 强 取消 3 阴天 炎热 高 弱 进行 4 雨天 温柔 高 弱 进行 5 雨天 凉爽 正常 弱 进行 6 雨天 凉爽 正常 强 取消 7 阴天 凉爽 正常 强 进行 8 晴天 温柔 高 弱 取消 9 晴天 凉爽 正常 弱 进行 10 雨天 温柔 正常 弱 进行 11 晴天 温柔 正常 强 进行 12 阴天 温柔 高 强 进行 13 阴天 炎热 正常 弱 进行 14 雨天 温柔 高 强 取消 设定晴天为 t1, 阴天为t2， 雨天为t3 1234gini(晴天) = 1 -(3/5)2-(2/5)2 = 0.48gini(阴天) = 1 -(0/4)2-(4/4)2 = 0gini(雨天) = 1 -(3/5)2-(2/5)2 = 0.48gini(天气) = 5/14 * 0.48 + 4/14*0 + 5/14*0.48 = 0.343 设定温度 高为 t1, 温度正常为 t2123gini(高) = 1 -(4/7)2-(3/7)2 = 0.49gini(正常) = 1 -(1/7)2-(6/7)2 = 0.245gini(温度) = 7/14 * 0.49 + 7/14 * 0.245 = 0.365 设定风速强为 t1 风速弱为 t2123gini(强) = 1 -(3/6)2-(3/6)2 = 0.5gini(弱) = 1 -(2/8)2-(6/8)2 = 0.375gini(风速) = 6/14 * 0.5 + 8/14* 0.375 = 0.43 设定凉爽为t1, 温柔为t2, 炎热为 t31234gini(凉爽) = 1 -(1/4)2-(3/4)2 = 0.375gini(温柔) = 1 -(2/6)2-(4/6)2 = 0.444gini(炎热) = 1 -(2/4)2-(2/4)2 = 0.5gini(户外) = 4/14*0.375 + 6/14*0.444 + 4/14*0.5 = 0.4402 以上我们完成了基尼系数的计算。 我们将各个属性下的基尼系数进行对比， 来决定决策树的层次结构。 gini(天气) = 0.343gini(温度) = 0.365gini(风速) = 0.43gini(户外) = 0.4402 所以我们将天气作为根节点， 然后将温度作为第二子节点, 风速作为第三子节点， 户外作为第四子节点。 然后我们将每个属性下，条件基尼系数最小的作为二叉树分叉的节点， 得到的决策树如下图： 大家常听到的数据挖掘，机器学习，深度分析就是来回答这个问题，由于有大量的现有客户的特征及其态度偏好和行为上的特点，就可以归纳出这些现有用户的特征和行为的关联性，比如你是汽车企业的，你通过分析发现30-35岁的人比其他年龄段的更倾向于买车，那么就可以根据这种特征反推对新用户的策略，你会更关注30-35-岁的人群。4机器学习的方法类似于我们人脑学习，比如有一天小孩看到一只小动物，妈妈说这是猫，小孩观察了一下，发现它有毛，而且体格小。又有一天小孩看到一只小型带毛动物，她高兴说这是小猫，然后妈妈说，这是小萨摩，因为虽然它小型带毛，但它没有胡子，叫声是汪汪汪，而小猫有胡子，叫声是喵喵喵，于是这个小孩就知道判断小猫，除了要看毛发，体型，还要看叫声和胡子。而机器学习的一些方法，比如神经网络，决策树，关联分析等数据挖掘方法就是这种通过归纳，试错的方法找到现有用户的特点。为了验证归纳的可靠性，将现有数据分成训练集和测试集，用训练集产生模型，用测试集检验效果。4但大家常说神经网络是个黑匣子，你只能得出用它得到的模型进行新用户判断可靠的程度，却拿不到相应的模型，而logistic回归模型则既可以得到量化模型，又能生成相应的概率，比如30-35-岁的用户有多大的可能性买车，而其他年龄段的有多大可能性买车，从而可以为我们的用户进行画像。]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL面试题]]></title>
    <url>%2F2019%2F03%2F24%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-SQL%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[结合两个表 问题描述： 表1：Preson Column Name Type PersonId int FirstName varchar LastName varchar 表2： Address Column Name Type AddressId int PersonId int City varchar State varchar 要求： 为Person表中的每个人提供以下信息，无论每个人都有一个地址：1FirstName, LastName, City, State 答案： 12345678SELECT Person.FirstName, Person.LastName, Address.City, Address.StateFROM Person LEFT join Address on Person.PersonId = Address.PersonId; 考查点： 使用 join 对两表进行连接查询。 取出排名第 2 高的数据 问题描述 表： Employee Id Salary 1 100 2 200 3 300 要求： 根据上面的 Employee 表，查询返回 薪水工资第二高的数据：200, 如果没有第二高的薪水， 返回Null。 SecondHighestSalary 200 答案 答案1 解法： 在除过第一名薪水中，找出最高的薪水，也就是第二名。 123456SELECT MAX(Salary) as SecondHighestSalaryFROM EmployeeWHERE Salary &lt; (SELECT MAX(Salary) FROM Employee); 答案2 解法： 跳过排名第一的数据， 并取出1条数据，即读取第2条数据。 123456789SELECT DISTINCT Salary as SecondHighestSalaryFROM Employeeorder by Salary DESC limit 1 offset 1-- 可缩写为limit 1,1 但上式写法错误， 因为如果表中没有第二薪水的话，那sql运行报错，而不是返回Null。 我们将其作为临时表可解决此问题： 12345678SELECT (SELECT DISTINCT Salary FROM Employeeorder by Salary DESClimit 1 offset 1) AS SecondHighestSalary 或者使用 IFNULL 1234567891011SELECT IFNULL( (SELECT DISTINCT Salary FROM Employeeorder by Salary DESClimit 1,1), NULL ) AS SecondHighestSalary 延伸 找出排名第三的薪水 1234567891011SELECT IFNULL( (SELECT DISTINCT Salary FROM Employeeorder by Salary DESClimit 2 offset 1), NULL ) AS SecondHighestSalary 对数据进行排序 问题： 表： Scores Id Score 1 3.50 2 3.65 3 4.00 4 3.85 5 4.00 6 3.65 要求： 对以下 Scores 表中的分数进行排名，如果两数相同，则有相同的排名， 排名相等的不会留下空位。 输出结果为： Score Rank 4.00 1 4.00 1 3.85 2 3.65 3 3.65 3 3.50 4 答案 答案1： 步骤1： 返回不同的成绩 1Select Distinct Score from Scores 步骤2： 统计并计算排名 1Select Count(1) + 1 From (Select Distinct Score from Scores) as uniqeScores where Score &gt; sc.Score 步骤3： 汇总 12345678910Select sc.Score, (Select Count(1) + 1 From ( Select Distinct Score from Scores) as uniqeScores where Score &gt; sc.Score) as rank From Scores sc Order by sc.Score Desc; 答案2： 123456select s1.Score, COUNT(DISTINCT s2.Score) Rankfrom Scores s1 inner join Scores s2 on s1.Score &lt;= s2.Scoregroup by s1.Idorder by s1.Score desc 答案3： 12345select Score, dense_rank() over(order by Score) as Rankfrom Scores 延伸 rank、dense_rank、 row_number 的区别 rank函数， 返回数据项在分组中的排名， 排名相等的会留下空位。 如1、2、2、4 dense_rank函数， 返回数据项在分组中的排名， 排名相等的不会留下空位。 如1、2、2、3 row_number函数， 返回数据项在分组中的排名， 排名不管数据是否相等。 如1、2、3、4 留存率 问题： 写出6月5-10号每日客户端活跃用户的次1日、次3日、次7日留存 答案 答案1：123456789101112131415161718192021222324with a1 as (select dt, user_accountfrom computerwhere dt between '2019-06-01' and '2019-06-17'),a2 as (select dt, user_accountfrom computerwhere dt between '2019-06-01' and '2019-06-17')select a1.dt,count(distinct a1.user_account) uv,count(distinct case when datediff(a2.dt, a1.dt) = 1 then a1.user_account else null end ) next_day,count(distinct case when datediff(a2.dt, a1.dt) = 3 then a1.user_account else null end ) three_day,count(distinct case when datediff(a2.dt, a1.dt) = 7 then a1.user_account else null end ) seven_dayfrom a1 join a2 on a1.user_account = a2.user_accountgroup by a1.dtorder by a1.dtlimit 100 输出结果为： 日期 uv 次1日 次3日 次7日 2019/6/1 50231 6578 6642 5154 2019/6/2 42000 6293 5027 4304 2019/6/3 44312 6760 8331 5042 2019/6/4 37852 5298 7133 0 2019/6/5 30678 6082 4648 0 2019/6/6 39405 8173 4972 0 2019/6/7 31267 5352 4920 0 2019/6/8 25614 4451 0 0 2019/6/9 24113 4568 0 0 2019/6/10 26242 0 0 0 答案2：步骤1：1234567891011SELECT dt, count(distinct user_account) as uvFROM computerWHERE dt between '2019-06-01' and '2019-06-17'group BY dtorder BY dt 步骤2：123456789101112131415161718192021222324252627282930-- 统计10-15号每天的次日留存数， 统计次3、7日留存只需将1换为3、7with a1 as ( select user_account, dt from computer where dt between '2019-06-01' and '2019-06-17'),a2 as ( select user_account, dt from computer_view.client_android_log_view where dt between '2019-06-01' and '2019-06-17')select a1.dt, count(distinct a1.user_account) as uvfrom a1 join a2 on a1.user_account = a2.user_accountWHERE a2.dt = date_add(a1.dt, 1) group by a1.dtorder BY a1.dt 步骤3：1留存率 = 用步骤2结果/ 步骤1 结果 连续出现三次的数字 问题： 查找出连续出现至少三次的所有数字 表 Logs 如下： Id Num 1 1 2 1 3 1 4 2 5 1 6 2 7 2 得到如下结果： ConsecutiveNums 1 答案 答案1： 12345678910select distinct a1.Num as ConsecutiveNumsfrom Logs as a1left join Logs as a2 on a1.Id = a2.Id-1left join Logs as a3 on a1.Id = a3.Id -2where a1.Num = a2.Num and a2.Num = a3.Num 答案2： 1234567891011121314select distinct a1.Num as ConsecutiveNumsfrom Logs a1, Logs a2, Logs a3where a1.Id = a2.Id -1 and a2.Id = a3.Id -1 and a1.Num = a2.Num and a2.Num = a3.Num 答案3：1234567891011121314---连续 N 次出现， 则将 3 改为 N 即可。SELECT distinct num as ConsecutiveNumsFROM(SELECT id, num, @pre := @cur, @cur := num, @rep_ct := IF(@pre = @cur, @rep_ct + 1, 1) as rep_ctFROM `Logs` l, (SELECT @pre := null, @cur := 0, @rep_ct := 1) init) temp WHERE rep_ct &gt;= 3 连续 4 个月活跃的用户明细 问题：求出 1-4 月每月连续登陆客户端的用户数 思路 将用户登录的月份按从小到大排序， 找出排序等于 4 的用户 答案 1234567891011121314151617181920212223242526with a1 as(select id, month(dt) as monthfrom datawhere dt between '2019-01-01' and '2019-04-30'group by id, month(dt) ),a2 as ( select id, a1.month, row_number() over(partition by id order by a1.month) as numfrom a1) select count(distinct id) as uvfrom a2where a2.num= 4 查询比经理薪资高的员工姓名 问题 表：Employee 包含员工和经理的Id 与薪水 Id Name Salary ManagerId 1 Joe 70000 3 2 Henry 80000 4 3 Sam 60000 NULL 4 Max 90000 NULL 要求： 查找收入高于经理的员工，得到如下结果： Employee Joe 前3列 来自a1, 后两列来自a2 答案 答案1： 利用 join 对表进行合并前3列 来自a1, 后两列来自a2 Name Salary ManagerId Id Salary Joe 70000 3 3 60000 Henry 80000 4 4 90000 1234567select a1.name as Employeefrom Employee as a1 join employee as a2 on a1.ManagerId = a2.Idwhere a1.Salary &gt; a2.Salary 答案2： 123456789101112131415161718with a1 as ( select name,salary, ManagerId from Employee),a2 as ( select managerid, Id from Employee)select a1.namefrom a1 join a2 on a1.ManagerId = a2.Idwhere a1.Salary &gt; a2.Salary 答案3： 步骤1： 12SELECT *FROM Employee AS a1, Employee AS a2 此步骤输出结果为： 结果将获得这两个标的笛卡尔积，输出结果将使 4*4 = 16条记录， 我们对输出结果进行过滤。 12345678SELECT a.Name AS 'Employee'FROM Employee AS a, Employee AS bWHERE a.ManagerId = b.Id AND a.Salary &gt; b.Salary 找出重复邮件 问题 表： Person Id Email 1 a@b.com 2 c@d.com 3 a@b.com 要求： 找出Person 表中所有重复电子邮件，得到如下结果： Email a@b.com 答案 答案1： 123456789101112select a1.Emailfrom(select Email, count(Email) as numfrom Persongroup by Email) as a1where a1.num !=1 答案2： 12345678select Emailfrom Persongroup by Emailhaving count(Email) !=1 5月中连续7天登陆的用户数 问题:根据用户登录表 data，取出连续登录了K天的用户uid id dt A 2019-06-01 B 2019-06-03 B 2019-06-04 B 2019-06-05 B 2019-06-06 C 2019-06-05 C 2019-06-06 C 2019-06-07 答案： 将用户按照电话号进行排序 id dt num A 2019-05-01 1 B 2019-05-03 1 B 2019-05-04 2 B 2019-05-05 3 B 2019-05-06 4 C 2019-05-05 1 C 2019-05-06 2 C 2019-05-07 3 1234567891011select id, dt, row_number() over(partition by id order by dt) as numfrom Datawhere dt between '2019-05-01' and '2019-05-07'group by id, dt 将日期与排序进行相减 id dt num diff A 2019-05-01 1 2019-04-30 B 2019-05-03 1 2019-05-02 B 2019-05-04 2 2019-05-02 B 2019-05-05 3 2019-05-02 B 2019-05-06 4 2019-05-02 C 2019-05-05 1 2019-05-04 C 2019-05-06 2 2019-05-04 C 2019-05-07 3 2019-05-04 12345678910111213141516171819202122232425with a1 as ( select id, dt, row_number() over(partition by id order by dt) as num from computer_view.client_android_log_view where dt between '2019-06-01' and '2019-06-03' group by id, dt)select id, dt, num, (DATE_SUB(dt, num )) as diff from a1group by id, dt, numlimit 100 统计差值相同的数字个数，并大于等于3 1234567891011121314151617181920212223242526272829303132333435with a1 as ( select user_account, hit_date, row_number() over(partition by user_account order by hit_date) as num from computer_view.client_android_log_view where hit_date between '2019-06-01' and '2019-06-05' group by user_account, hit_date),a2 as (select user_account, hit_date, num, (DATE_SUB(hit_date, num )) as diff from a1group by user_account, hit_date, num)select diff, max(num), count(distinct user_account)from a2group by diffhaving max(num) &gt;= 1limit 100 找出连续登录4天以上的用户数 123456789101112131415161718192021222324252627282930313233343536with a1 as ( select id, dt, row_number() over(partition by id order by dt) as num from computer_view.client_android_log_view where dt between '2019-06-01' and '2019-06-05' group by id, dt),a2 as (select id, dt, num, (DATE_SUB(dt, num )) as diff from a1group by id, dt, num)select id, diff, count(diff) from a2group by id, diff having count(diff) &gt;= 4limit 100 id diff count(diff) B 2019-05-02 4 C 2019-05-04 3 找出未订购任何内容的用户 问题： 表： Customers Id Name 1 Joe 2 Henry 3 Sam 4 Max 表： Orders Id CustomerId 1 3 2 1 要求： 根据上面两个表，找出从未订购任何内容的所有客户。输出结果如下： Customers Henry Max 答案 答案1： 123456SELECT Name as CustomersFROM Customers left JOIN Orders on Customers.Id = Orders.CustomerIdwhere Orders.CustomerId is NULL 答案2： 12345678910select customers.name as Customersfrom customerswhere customers.Id not in (select CustomerId from Orders) 找出各部门薪水最高的员工 问题： 表： Employee Id Name Salary DepartmentId 1 Joe 70000 1 2 Jim 90000 1 3 Henry 80000 2 4 Sam 60000 2 5 Max 90000 1 表： Department Id Name 1 IT 2 Sales 要求：找出各部门薪水最高的员工 Department Employee Salary IT Max 90000 IT Jim 90000 Sales Henry 80000 答案 步骤1： 查出各部门最高薪水 1234567SELECT DepartmentId, MAX(Salary)from Employeegroup by DepartmentId 步骤2： 12345678910111213141516171819selectEmployee.Name as Department,Department.Name as Employee,Salary from Employee join Department on Employee.DepartmentId= Department.Idwhere ((Employee.DepartmentId, Salary) in (SELECT DepartmentId, MAX(Salary)from Employeegroup by DepartmentId))group by Department,Employee,Salary 获取每个部门中薪水前三名的员工 问题： 表：Employee Id Name Salary DepartmentId 1 Joe 85000 1 2 Henry 80000 2 3 Sam 60000 2 4 Max 90000 1 5 Janet 69000 1 6 Randy 85000 1 7 Will 70000 1 表： Department Id Name 1 IT 2 Sales 要求： 找出各部门薪水前三的员工， 输出结果如下： Department Employee Salary IT Max 90000 IT Randy 85000 IT Joe 85000 IT Will 70000 Sales Henry 80000 Sales Sam 60000 答案 步骤1：对各部门薪水进行排序 合并12345678910select Employee.Name AS Employee, Employee.Salary AS Salary, Department.Name AS Department from Employee join Department on Employee.DepartmentId = Department.Id group by Employee, Salary, Department Employee Salary Department Joe 85000 IT Henry 80000 Sales Sam 60000 Sales Max 90000 IT Janet 69000 IT Randy 85000 IT Will 70000 IT 步骤2 ： 找出排名前三的 思路： 再添加一张Employee 表，与步骤1中的 A 表进行对比， 令 B 表中的 salary 大于 A 表中的 salary 条件限制：B表中 salary 大于 A 表中salary 的个数小于3 123456789101112131415select A.Name AS Employee, A.Salary AS Salary, Department.Name AS Department from Employee as A join Department on A.DepartmentId = Department.Id WHERE (select count(distinct B.Salary) from Employee as B WHERE B.Salary &gt; A.Salary and B.DepartmentId = A.DepartmentId) &lt;3 sql题 学生-课程-成绩案例 内容：表： student id name 1 zy 2 hz 3 zy 4 lx 5 lx 表： course id name 1 match 2 python 3 java 表: student_course sid cid score 1 1 60 1 2 50 2 2 80 4 3 90 2 2 80 3 3 50 问题 问题1： 查询 student表中重名的学生， 结果包含id 和name, 按 name 升序 12345678910select name, idfrom studentwhere name in (select name from student group by name having count(name) &gt; 1)order by name 问题2： 查询 student_course 表中的平均份不及格的学生， 列出学生的 id 和平均分 123456789select sid, avg(score) as avg_scorefrom student_coursegroup by sidhaving avg_score &lt; 60 问题3： 查询每门课成绩都不低于80的学生id 123456789101112select distinct sidfrom student_coursewhere sid not in (select score from student_course where score &lt;80) 问题4： 查询每个学生的总成绩，列出学生名称和总成绩 12345select student.name, sum(student_course.score)from student left join student_course on student.id = student_course.sid 问题5：查出总成绩最高的学生 123456789select sid, sum(score)from student_coursegroup by sidorder by sum(score) desclimit 1; 问题6： 查询课程1,成绩第二高的学生 方法1：123456789101112---在除过第一高的成绩中，找出最高的成绩select cid, max(score)from stuent_scorewhere cid =1 and score &lt; (select max(score) from student_score) 方法2： 12345678910111213---跳过排名第一的数据， 取1条数据select max(score)from stuent_scorewhere cid = 1 group by score order by score desc limit 1 offset 1 --limit 1,1 问题7： 查看各科成绩最高的学生id与课程id 1234567891011121314select cid, sid, scorefrom student_course as a1where score &gt;= (select max(score) from stuent_score as a2 where a1.id = ax.id) 错误写法： 12345678select sid, cid, max(score)from student_scoregroup by cid 问题8： 在student_course 表中查询每门课的前2名，结果按照课程id 升序， 同一课程按照成绩降序。 123456789101112131415select *from student_course xwhere 2 &gt;( select count(*) from student_course y where y.cid = x.cid and y.score &gt; x.score)order by cid, score DESC 对每季度数据进行汇总 问题： 表： sales 年 季度 销售 1991 1 11 1991 2 12 1991 3 13 1991 4 14 1992 1 21 1992 2 22 1992 3 23 1992 4 24 要求： 通过 SQL 语句显示以下结果： 年 一季度 二季度 三季度 四季度 1991 11 12 13 14 1992 21 22 23 24 答案： 123456select 年, sum(case when 季度=1 then 销售量 else 0 end) as 一季度, sum(case when 季度=2 then 销售量 else 0 end) as 二季度, sum(case when 季度=3 then 销售量 else 0 end) as 三季度, sum(case when 季度=4 then 销售量 else 0 end) as 四季度 from sales group by 年 解释 lateral view 函数描述 描述： lateral view 用于和 split、explode、collect_set 函数 等一起使用， 能够将一行数据拆成多行数据，在此基础上对拆分后的数据进行聚合。 问题1： 问题 将 表 table 中的 adid_list 转换为单独的行。 表： table pageid adid_list front_page [1,2,3] contact_page [3,4] 答案： 12345SELECT pageid, adidFROM tablelateral view explode(adid_list) adTable as adid 输出结果为：|pageid |adid_list||—|—||front_page|1||front_page|2||front_page|3||contact_page|3||contact_page|4| 问题2： 问题：要求： 计算特定广告的展现次数 答案： 1234567SELECT adid, count(1)FROM tablelateral view explode(adid_list) adTable as adidGROUP BY adid 输出结果为： adid count(1) 1 1 2 1 3 2 4 1 问题3： 问题： 多个 lateral view 查询 表： table2 array col2 [1,2] [“a”，”b”] [3,4] [“c”, “d”] 答案： 123456SELECT myCol1, myCol2FROM baseTableLATERAL VIEW explode(col1) myTable1 AS myCol1LATERAL VIEW explode(col2) myTable2 AS myCol2 输出结果为： myCol1 myCol2 1 “a” 1 “b” 2 “a” 2 “b” 3 “c” 3 “d” 4 “c” 4 “d” 删除重复的电子邮箱 问题 表：Person Id Email 1 zhang@qq.com 2 yu@gmailc.om 3 zhang@qq.com 要求: 删除 Person 表中所有重复的电子邮箱，只保留 Id 最小的那个。 Id Email 1 zhang@qq.com 2 yu@gmailc.om 答案： 答案1： 步骤1：找出 Id 大的重复邮箱 1234567select a1.*from Person a1 join Person a2 on a1.Email = a2. Emailwhere a1. Id &gt; a2.Id 步骤2： 删除 Id 较大的重复邮箱。 123456DELETE a1FROM Person a1 join Person a2 on a1.Email = a2. Emailwhere a1. Id &gt; a2.Id 答案2： 123456DELETE a1FROM Person a1, Person a2 where a1.Email = a2. Email and a1. Id &gt; a2.Id 上升的温度 问题 表： Weather Id(INT) RecordDate(DATE) Temperature(INT) 1 2015-01-01 10 2 2015-01-02 25 3 2015-01-03 20 4 2015-01-04 30 要求：查找与昨天日期相比温度更高的所有日期的 Id, 返回结果如下： Id 2 4 答案： 答案1： datediff 函数 123456SELECT a1.Idfrom Weather a1 join Weather a2 on datediff(a1.RecordDate, a2.RecordDate) = 1 and a1.Temperature &gt; a2.Temperature 答案2： ADDDATE 函数 123456SELECT a1.Idfrom Weather a1 join Weather a2 on a1.RecordDate= date_add(a2.RecordDate,1) and a1.Temperature &gt; a2.Temperature 游戏玩家分析1此表显示某些游戏玩家的活动。每一行都是某天用某些设备登陆并玩多个游戏的玩家记录。 表： Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-05-02 6 2 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 显示每个玩家的第一次登陆日期， 输出如下结果 player_id first_login 1 2016-03-01 2 2017-06-25 3 2016-03-02 答案： 123SELECT a1.player_id, a1.event_date as first_loginFROM activity a1 left join activity a2 on a1.player_id=a2.player_id and a1.event_date&gt;a2.event_dateWHERE a2.event_date is NULL 12345678910select player_id, to_char(event_date, 'yyyy-mm-dd') as first_loginfrom (select player_id, event_date, row_number() over (partition by player_id order by event_date asc) rn from Activity)where rn = 1 https://codeday.me/bug/20190309/737795.html 游戏玩家分析2表： Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-05-02 6 2 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 写取出每个玩家第一次玩游戏的设备号 输出结果如下： player_id device_id 1 2 2 3 3 1 答案： 123456789SELECT a1.player_id, a1.device_idFROM activity a1 left join activity a2 on a1.player_id=a2.player_id and a1.event_date&gt;a2.event_dateWHERE a2.event_date is NULL 12345678select player_id, device_id from ( select * from Activity where (player_id,event_date) in (select player_id, min(event_date) from Activity group by player_id) ) as t 123456789select player_id, device_idfrom (select player_id, device_id, row_number() over(partition by player_id order by event_date asc) rn from Activity)where rn = 1 游戏分析3表：Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-05-02 6 1 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 取出每个玩家在不同日期下的累积玩游戏次数。 例如： 玩家 id 为 1 的玩家， 在 2016-05-02 时，玩游戏的总次数为 5+6=11， 在2017-06-25 时，玩游戏的总次数为 5+6+1=12。 输出结果如下： player_id event_date games_played_so_far 1 2016-03-01 5 1 2016-05-02 11 1 2017-06-25 12 3 2016-03-02 0 3 2018-07-03 5 答案： 12345select player_id, to_char(event_date, 'yyyy-mm-dd') as event_date, sum(games_played) over(partition by player_id order by event_date) games_played_so_farfrom activity 1select a.player_id ,a.event_date,(case when @player_id=a.player_id then @value:=@value+a.games_played when @player_id:=a.player_id then @value:=a.games_played end ) as games_played_so_far from (select * from Activity order by player_id,event_date) a, (select @player_id:=Null,@value:=0)s 游戏分析4表： Activity player_id device_id event_date games_played 1 2 2016-03-01 5 1 2 2016-03-02 6 2 3 2017-06-25 1 3 1 2016-03-02 0 3 4 2018-07-03 5 要求： 查询在首次登陆后第二天再次登陆的玩家比例， 四舍五入到小数点后两位。 换句话说： 你需要计算从首次登陆日期开始至少连续两天登陆的玩家数量， 然后将该数量除以玩家总数。 输出结果如下：| fraction ||———–|| 0.33 | 12345678--- 错误select CAST( count(b.player_id) / count(distinct a.player_id) as decimal(38, 2)) as fractionfrom Activity as aleft join Activity as b on a.player_id = b.player_id and a.event_date = b.event_date+1 123456789101112131415select round(count(if(datediff(a2.event_date ,a1.event_date )=1,1,null))/count(distinct a1.player_id ),2) as fractionfrom Activity a1, Activity a2where a1.player_id =a2.player_id and (a1.player_id,a1.event_date) in ( select player_id , min(event_date) event_date from Activity a3 group by player_id ) 求中位数表： Employee Id Company Salary 1 A 2341 2 A 341 3 A 15 4 A 15314 5 A 451 6 A 513 7 B 15 8 B 13 9 B 1154 10 B 1345 11 B 1221 12 B 234 13 C 2345 14 C 2645 15 C 2645 16 C 2652 17 C 65 要求：查找每个公司的薪水中位数 Id Company Salary 5 A 451 6 A 513 12 B 234 9 B 1154 14 C 2645 答案：https://www.cnblogs.com/jxlwqq/p/5868206.htmlhttps://www.oschina.net/translate/how-to-calculate-median-value-in-mysql-using-a-simple-sql-query 进行排序123456789select Id, Company, Salary, ROW_NUMBER ( ) OVER (PARTITION BY Company order by Salary) as rank_name, count(1) over (partition by company) as numfrom Employee Id Company Salary rank_name num 3 A 15 1 6 2 A 341 2 6 5 A 451 3 6 6 A 513 4 6 1 A 2341 5 6 4 A 15314 6 6 8 B 13 1 6 7 B 15 2 6 12 B 234 3 6 9 B 1154 4 6 11 B 1221 5 6 10 B 1345 6 6 17 C 65 1 6 13 C 2345 2 6 14 C 2645 3 6 15 C 2645 4 6 16 C 2652 5 6 找到中位数 12345678910select id, company, salaryfrom (select id, company, salary, row_number() over (partition by company order by salary) as rank_name, count(1) over (partition by company) as num from employee )where abs(rank_name - (num+1)/2) &lt; 1 -- 顺序编号在公司薪水记录数中间的，即为中位数 查找至少有5名直接下属的经理表：Employee Id Name Department ManagerId 101 John A null 102 Dan A 101 103 James A 101 104 Amy A 101 105 Anne A 101 106 Ron B 101 要求： 查询来查找至少有5名直接下属的经理 输出结果为： Name John 答案： 123456789select a2.Namefrom Employee a1 join Employee a2on a1.ManagerId = a2.Idgroup by a1.ManagerIdhaving count(*) &gt;=5 给定数字的频率查中位数表： Numbers Number Frequency 0 7 1 1 2 3 3 1 要求： 数字为 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3，所以中位数是 (0 + 0) / 2 = 0，输出结果如下 median 0.0000 答案： 1234567891011121314151617181920select avg(n2.number) medianfrom (select min(n.number) numberfrom (select number, frequency, (@cumsum:=@cumsum+frequency) 'cumsum'from numbers ,(select @cumsum:=0) temp order by number) nwhere n.cumsum &gt;= (floor(((SELECT SUM(frequency) FROM numbers) +1 ) / 2))union select min(n1.number) numberfrom (select number, frequency, (@cumsum1:=@cumsum1+frequency) 'cumsum'from numbers ,(select @cumsum1:=0) temp order by number) n1where n1.cumsum &gt;= (ceil(((SELECT SUM(frequency) FROM numbers) +1 ) / 2))) n2; 找出当选最多的人名称表： Candidate id Name 1 A 2 B 3 C 4 D 5 E 表： Vote id CandidateId 1 2 2 4 3 3 4 2 5 5 表 Candidate 为候选人名称表， 表 Vote 中CandidateId 是 Candidate表中的 id。 要求： 找出当选者的名称，返回结果为当选者B。输出结果如下：| Name ||——|| B | 答案：12345678910111213141516select Namefrom Candidatewhere id = ( select CandidateId from Vote group by CandidateId order by count(*) DESC LIMIT 1 ) 选出所有 bonus &lt; 1000的员工的 name 以及 bonus表：Employee empId name supervisor salary 1 John 3 1000 2 Dan 3 2000 3 Brad null 4000 4 Thomas 3 4000 表：Bonus empId bonus 2 500 4 2000 要求： 选出所有 bonus &lt; 1000的员工的 name 以及 bonus。输出结果如下 name bonus John null Dan 500 Brad null 答案： 123456789select a1.name, a2.bonusfrom Employee as a1 left join Bonus as a2 on a1.empid = a2.empid where ifnull (bonus, 0) &lt; 1000 12345678910select a1.name, a2.bonusfrom Employee as a1 left join Bonus as a2 on a1.empid = a2.empid where nvl (bonus, 0) &lt; 1000 谁有最多的好友表： request_accepted 表中存储了所有好友申请通过的数据记录，其中，requester_id 和 accepter_id 都是用户的编号。 requester_id accepter_id accept_date 1 2 2016_06-03 1 3 2016-06-08 2 3 2016-06-08 3 4 2016-06-09 要求： 求出谁拥有最多的好友和他拥有的好友数目。输出结果如下 id num 3 3 答案： 1234567891011121314select id as id, ucnt as numfrom( select id, count(1) as ucnt from ( select requester_id as id from request_accepted union all select accepter_id as id from request_accepted ) group by id order by ucnt desc)where rownum = 1 找出人流量的高峰期表：stadium id visit_date people 1 2017-01-01 10 2 2017-01-02 109 3 2017-01-03 150 4 2017-01-04 99 5 2017-01-05 145 6 2017-01-06 1455 7 2017-01-07 199 8 2017-01-08 188 要求： 找出人流量的高峰期。高峰期时， 至少连续三行记录中的人流量不少于100。得出结果如下 id visit_date people 5 2017-01-05 145 6 2017-01-06 1455 7 2017-01-07 199 8 2017-01-08 188 答案： 1234567SELECT distinct a.*FROM stadium as a,stadium as b,stadium as cwhere ((a.id = b.id-1 and b.id+1 = c.id) or (a.id-1 = b.id and a.id+1 = c.id) or (a.id-1 = c.id and c.id-1 = b.id)) and (a.people&gt;=100 and b.people&gt;=100 and c.people&gt;=100)order by a.id; 12345678910111213141516select id, to_char(visit_date, 'yyyy-mm-dd') as visit_date, peoplefrom (select id, visit_date, people, count(1) over (partition by offset) cnt from (select id, visit_date, people, (row_number() over (order by id) - id) offset from stadium where people &gt;= 100 ) )where cnt &gt;= 3 -- 连续 3 天（及以上）order by id 预约连续空余座位表：cinema seat_id free 1 1 2 0 3 1 4 1 5 1 要求：获取所有空余座位，并将它们按照 seat_id 排序。输出结果如下 连续空余座位的定义是大于等于 2 个连续空余的座位。1 表示空余，0 表示已被占据。 seat_id 3 4 5 答案： 1234567891011121314151617181920select seat_idfrom(select seat_id, count(1) over (partition by num) as cumfrom( select seat_id, (row_number() over (order by seat_id) - seat_id) as numfrom cinemawhere free = 1))where cum &gt;= 2order by seat_id 找出符合条件的电影表：cinema id movie description rating 1 War great 3D 8.9 2 Science fiction 8.5 3 irish boring 6.2 4 Ice song Fantacy 8.6 5 House card Interesting 9.1 要求： 找出所有影片描述为非 boring (不无聊) 的并且 id 为奇数 的影片，结果请按等级 rating 排列。输出结果如下 id movie description rating 5 House card Interesting 9.1 1 War great 3D 8.9 答案1：12345678910select *from cinemawhere mod(id, 2) = 1 and description != 'boring'order by rating DESC 答案2：12345678910select *from cinemawhere description != 'boring' and id % 2 !=0order by rating DESC 表：Sales sale_id product_id year quantity price 1 100 2008 10 5000 2 100 2009 12 5000 7 200 2011 15 9000 表：Product product_id product_name 100 Nokia 200 Apple 300 Samsung 要求： 编写sql查询， 选择每个销售产品的第一年的数据， 输出结果如下 product_id first_year quantity price 100 2008 10 5000 200 2011 15 9000 答案：123456789101112131415select product_id, year as first_year, quantity, pricefrom ( select product_id, year, quantity,price, rank() over(partition by product_id order by year) rn from sales)where rn=1 找到购买所有产品的顾客表1： customer customer_id product_key 1 5 2 6 3 5 3 6 1 6 表2： product | product_key |+————-+| 5 || 6 | 要求： 找出从 customer 表中购买了 product 表所有产品的客户id。 输出结果如下 customer_id 1 3 答案：123456789101112select customer_idfrom customergroup by customer_idhaving count(distinct product_key) = (select count(distinct product_key) from product ) 12345678910111213141516select customer_idfrom (select customer_id, count(distinct product_key) as num from customer group by customer_id) as a1join ( select count(product_key) as num from product) as a2on a1.num = a2.num 查询关注者的关注数据表：follow | followee (博主) | follower(关注者) ||————-+————|| A | B || B | C || B | D || D | E | 要求： 查询每个关注者， 被多少人关注。 输出结果如下： | follower | num ||————-+————|| B | 2 || D | 1 | B 和 D 都在在 follower 字段中出现，作为博主，B 被 C 和 D 关注，D 被 E 关注。A 不在 follower 字段内，所以A不在输出列表中。 答案： 123456789101112select f1.follower, count(distinct f2.follower) as numfrom follow f1inner join follow f2 on f1.follower = f2.followeegroup by f1.followerorder by f1.follower 如何用python操作mysql步骤 安装 mysql-connector 1pip install mysql-connector 连接数据库 通过 connection 对数据库的连接进行管理， 通过 cursor 创建游标对数据库中的数据进行操作。 12345678910111213import mysql.connector# 创建数据库连接db = mysql.connector.connect( host='ip地址', user = "root", passwd = "1234", # 数据库密码 database = 'default', # 连接的数据库 auth_plugin = 'mysql_native_password" )# 获取操作游标cursor = db.cursor() 编写sql语句 123456789# 输出sql 语句sql = """select btn_namefrom cinemawhere hit_date = "2019-07-26" """ 执行sql语句并返回结果 1234567891011121314# 执行sql语句cursor.execute(sql)# 获取数据集中的所有行cursor.fetchall()# 获取数据中的第一行# cursor.fetchone()# 获取数据集中的n条数据# cursor.fetchmany(n)# 返回数据集中中的行数# cursor.rowcount 关闭游标和数据库连接 12345# 关闭游标cursor.close()# 关闭数据连接db.close() 延伸： 捕获异常信息。 在对数据进行增加、删除和修改时， 可能会出现异常，需要对异常数据进行捕获。 123456789101112131415161718import tracebacktry: sql = """INSER INTO player (team_id, player_name, height) VALUES (%s, %s, %s)""" val = (1000, "zhangyu", 1.95) # 执行sql语句 cursor.execute(sql, val) # 进行提交 db.commit() print(cursor.rowcount, "记录插入成功。")except Exception as e: # 打印异常信息 traceback.print_exc() # 回滚 db.rollback()finally: # 关闭数据库连接 db.close() 参考资料： 极客时间-sql必知必会 求出每个项目中经验最丰富的员工表：Project table project_id employee_id 1 1 1 2 1 3 2 1 2 4 表：Employee table employee_id name experience_years 1 Khaled 3 2 Ali 2 3 John 3 4 Doe 2 要求： 求出每个项目中经验最丰富的员工， 输出结果如下 ID为1和3的员工，在第一个项目中拥有最丰富的经验， 对于第二个项目， ID为1的员工拥有最丰富的经验 project_id employee_id 1 1 1 3 2 1 答案： 1234567891011select project_id, employee_idfrom (select p.project_id, e.employee_id, rank() over(partition by p.project_id order by e.experience_years desc) rn from project p, employee e where p.employee_id = e.employee_id)where rn = 1 求所有员工的平均工作经验，保留2位小数。表： Project project_id employee_id 1 1 1 2 1 3 2 1 2 4 +————-+————-+ 表：Employee employee_id name experience_years 1 Khaled 3 2 Ali 2 3 John 1 4 Doe 2 要求： 求每个部门所有员工的平均工作年限， 保留两位小数。输出结果如下 第一个项目的平均工作年限为（3+2+1）/ 3 = 2.00第二个项目的平均工作年限为（3+2）/ 2 = 2.50 project_id average_years 1 2.00 2 2.50 答案1：123456789select project_id, round(avg(experience_years),2) as average_yearsfrom Project, Employeewhere Project.employee_id = Employee.employee_idgroup by project_id 查询每个专业的学生人数 一所大学有 2 个数据表，分别是 student 和 department ，这两个表保存着每个专业的学生数据和院系数据。 表：student student_id student_name gender dept_id 1 Jack M 1 2 Jane F 1 3 Mark M 2 表：department dept_id dept_name 1 Engineering 2 Science 3 Law 要求： 查询 department 表中每个专业的学生人数 （即使没有学生的专业也需列出）。将你的查询结果按照学生人数降序排列。 如果有两个或两个以上专业有相同的学生数目，将这些部门按照部门名字的字典序从小到大排列。输出结果如下 dept_name student_number Engineering 2 Science 1 Law 0 答案1： 1234567891011SELECT a1.dept_name, COUNT(student_id) AS student_number FROM department a1 LEFT JOIN student a2 ON a1.dept_id = a2.dept_id GROUP BY a1.dept_nameORDER BY student_number DESC, a1.dept_name 答案2：12345678910111213141516select dept_name, (case when student_num is null then 0 else student_num end) student_numberfrom(select dept_id, count(*) student_numfrom studentgroup by dept_id) t1right join department t2 on t1.dept_id=t2.dept_idorder by student_number desc, dept_name asc 表：salesperson 表 salesperson 存储了所有销售员的信息。每个销售员都有一个销售员编号 sales_id 和他的名字 name 。 sales_id name salary commission_rate hire_date 1 John 100000 6 4/1/2006 2 Amy 120000 5 5/1/2010 3 Mark 65000 12 12/25/2008 4 Pam 25000 25 1/1/2005 5 Alex 50000 10 2/3/2007 表：company 表 company 存储了所有公司的信息。每个公司都有一个公司编号 com_id 和它的名字 name 。 com_id name city 1 RED Boston 2 ORANGE New York 3 YELLOW Boston 4 GREEN Austin 表： orders 表 orders 存储了所有的销售数据，包括销售员编号 sales_id 和公司编号 com_id 。| order_id | order_date | com_id | sales_id | amount ||———-|————|———|———-|——–|| 1 | 1/1/2014 | 3 | 4 | 100000 || 2 | 2/1/2014 | 4 | 5 | 5000 || 3 | 3/1/2014 | 1 | 1 | 50000 || 4 | 4/1/2014 | 1 | 4 | 25000 | 要求： 根据给定的三个表，salesperson， company， orders。输出所有表 salesperson 中，没有向公司 ‘RED’ 销售任何东西的销售员。 根据表 orders 中的订单 ‘3’ 和 ‘4’ ，容易看出只有 ‘John’ 和 ‘Pam’ 两个销售员曾经向公司 ‘RED’ 销售过。所以我们需要输出表 salesperson 中所有其他人的名字。 输出： name Amy Mark Alex 答案1： 1234567891011121314SELECT a1.nameFROM salesperson a1 LEFT JOIN orders a2 ON a1.sales_id = a2.sales_id LEFT JOIN company a3 ON a2.com_id = a3.com_idGROUP BY a1.nameHAVING SUM(IF(a3.name = 'RED', 1, 0)) = 0ORDER BY a1.sales_id 答案2： 12345678910111213select a1.namefrom salesperson a1where not exists (select * from orders a2 join company a3 on a2.com_id=a3.com_id where a3.name='RED' and a1.sales_id=a2.sales_id) 答案3：123456789101112SELECT name FROM salesperson WHERE sales_id not in (SELECT DISTINCT a1.sales_id FROM orders a1 LEFT JOIN company a2 ON a1.com_id = a2.com_id WHERE a2.name = 'RED') https://github.com/MisterBooo/LeetCodeAnimation https://github.com/azl397985856/leetcode http://leetcode.liangjiateng.cn/leetcode/game-play-analysis-ii/description题源 力扣-leetcode 175176177178180181182183184185196197511512]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析——常见的数据分析方法与方法论]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[https://mp.weixin.qq.com/s/IGsE86BT6CY7hT2uVHmN-g 数据分析的常见方法论方法论： 从宏观角度出发， 提出分析框架，指导具体分析方向。 象限法通过象限法， 找到问题的共同原因， 从而建立分组优化策略。 内外因素分解法 用户分群 RFM 用户分群 5W2H 分析法在知乎上看到一个很好的回答： 什么原因 (why) 导致 什么事情 (what), 需要哪些人 (who) 在什么时间完成 (when),在什么地点 (where) 用什么方法 (how)完成, 预算是多少 (how much)? 二八法则 / 帕累托法则 将对象分为重要和不重要两类， 20%的用户贡献了80%的销售额。 数据中， 20% 的变量将直接产生 80% 的效果，数据分析应该围绕这20%的变量来进行。 和业务和KPI紧密相关，花费很少的精力就能达到不错的效果。 在条件允许的状况下， 依旧不能放弃全局，否则会让思维变得狭隘。 升级版本： ABC 分析法与之对应： 长尾理论 AARRR 模型移动应用的生命周期 基于用户生命周期的数据分析体系 对应的关键指标 SWOT方法指定发展战略前，对自身进行全面的分析及竞争优势定位。 对自己进行解析 指定相应的对策 USED方法针对SWOT分析后的结果，使用USED方法产出解决方案 如何善用每个优势？ How can we Use each Strength? 如何停止每个劣势？ How can we Stop each Weakness? 如何成就每个机会？ How can we Exploit each Opportunity? 如何抵御每个威胁？ How can we Defend against each Threat? 4P 与 STP 理论市场营销与市场定位 4P 理论 STP 理论 SLEPT分析法 社会和文化环境-social 法律环境-legal 经济环境-economic 政治环境-political 技术环境-technology PEST分析方法企业的战略外部环境分析。PEST、SWOT 与 SLEPT 可以作为企业与环境分析的基础工具。 延伸： 个人IPO模型 波特五种竞争力分析模型 SPACE-战略地位与行动评价矩阵 企业的内部因素与外部因素 SCP模型 分析在行业或者企业收到表面冲击时，可能的战略调整及行为变化。 AISAS-用户行为决策分析模型 注意- 兴趣-搜索-行动-分享 KANO模型 对用户需求分类和优先排序 将影响用户满意度的因素划分为五个类型，包括： 魅力因素：用户意想不到的，如果不提供此需求，用户满意度不会降低，但当提供此需求，用户满意度会有很大提升; 期望因素(一维因素)：当提供此需求，用户满意度会提升，当不提供此需求，用户满意度会降低; 必备因素：当优化此需求，用户满意度不会提升，当不提供此需求，用户满意度会大幅降低; 无差异因素：无论提供或不提供此需求，用户满意度都不会有改变，用户根本不在意; 反向因素：用户根本都没有此需求，提供后用户满意度反而会下降; PDCA模型 麦肯锡七步分析法 界定问题 将问题分解成议题 去除不重要的议题（优先排序） 制定详细工作计划 分析重要议题 汇总研究成果 准备你的故事 SMART原则 意义：人们在制定工作目标或者任务目标时，考虑一下目标与计划是不是SMART化的。只有具备SMART化的计划才是具有良好可实施性的，也才能指导保证计划得以实现。有的又如此解释此原则：S代表具体(Specific)，指绩效考核要切中特定的工作指标，不能笼统；M代表可度量(Measurable)，指绩效指标是数量化或者行为化的，验证这些绩效指标的数据或者信息是可以获得的；A代表可实现(Attainable)，指绩效指标在付出努力的情况下可以实现，避免设立过高或过低的目标；R代表现实性(realistic)，指绩效指标是实实在在的，可以证明和观察；T代表有时限(time bound)，注重完成绩效指标的特定期限。 时间管理 A、重要且紧急紧急状况迫切的问题限期完成的工作你不做其他人也不能做B、重要不紧急准备工作预防措施价值观的澄清计划人际关系的建立真正的再创造增进自己的能力C、紧急不重要造成干扰的事、电话、信件、报告会议许多迫在眉捷的急事符合别人期望的事D、不重要不紧急忙碌琐碎的事广告函件电话逃避性活动等待时间 任务分解法 即Work Breakdown Structure，如何进行WBS分解：目标→任务→工作→活动。WBS分解的原则：将主体目标逐步细化分解，最底层的任务活动可直接分派到个人去完成；每个任务原则上要求分解到不能再细分为止。WBS分解的方法：至上而下与至下而上的充分沟通；一对一个别交流；小组讨论。WBS分解的标准：分解后的活动结构清晰；逻辑上形成一个大的活动；集成了所有的关键因素包含临时的里程碑和监控点；所有活动全部定义清楚 二八原则 巴列特定律：“总结果的80%是由总消耗时间中的20%所形成的。” 按事情的“重要程度”编排事务优先次序的准则是建立在“重要的少数与琐碎的多数”的原理的基础上。 数据分析的常见方法在分析过程中使用的方法 对比分析法对比分析， 给单独的数据一个参考系， 否则孤立的数据毫无意义。 问题： 超市 A 今天的营业额是 2000 块。 我们该如何评判这个超市的运营状况是好是坏呢？ 时间上的同比环比 环比本次统计时间段 与 相连的上次时间段 之间的比较。 比如：本周和上周的对比。 环比增长率（本期数 - 上期数） / 上期数 100% 或 （本期数 / 上期数 -1） 100% 同比：某个统计时间段，今年和去年 之间的比较。 比如： 19年2月营销额和18年2月营销额之间的对比。 同比增长率（本期数 - 去年同期数） / 去年同期数 100% 或 （本期数 / 去年同期数 -1 ） 100% 竞争对手对比 与其他维度结合，进行对比 活动促销前后的对比 细拆维度之间的对比 各渠道之间的对比等 漏斗分析法漏斗分析法， 还原用户转化的路径， 分析每一步的转化率， 针对性的优化和改善 多维度拆解法 维度划分 注意事项维度拆解不够， 容易导致辛普森悖论 公式法将一切问题皆可量化，拆解成最小的维度，通过 +、-、*、/ 进行计算 假设法假设-验证-判断。 当没有直观数据时， 以假设先行的方式进行推断。 例如： 如果商品提价后， 公司收益会不会变化？ 假设流量不会发生变化， 那么商品价格会影响转化率，确定转化率的下降。 计算日常的转化率， 针对不同的用户，如：忠诚用户、普通用户、羊毛用户， 预估各类别用户提价后的转化率变化。 指数法指定一个标准， 解决衡量的问题 线性加权： 反比例： 1-1/n， 范围为0-1 log指数法 热度公式： log(uv+ 5*评论,2) +(time -初始时间) / 10 结构分析对比分析时间序列分析相关性分析机器学习]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>思维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人成长书单]]></title>
    <url>%2F2019%2F02%2F20%2F%E7%94%9F%E6%B4%BB%E8%B5%84%E6%96%99-%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[数据分析： 《网站分析实战》 《精益数据分析》 《运营之光》 《计算广告》 《新零售：低价高效的数据赋能之路》 《增长黑客》 《女士品茶》 《数据化管理》 《流量池》 麦肯锡： 《麦肯锡教我的思考武器》 《麦肯锡教我的写作武器》 《麦肯锡意识》 《麦肯锡方法》 《麦肯锡图表工作法》 《麦肯锡教我的谈判武器》 《麦肯锡笔记思考法》 批判思维与逻辑思维： 《批判性思维工具》 《学会提问》 《金字塔原理》 《零秒思考》； 已写文章 行动： 每天问自己的10个问题 如何学习： 《学习之道》 《如何学习》 《刻意练习》；已写文章 《刻意学习》；读书笔记 《好好学习-个人成长指南》 ；已写文章 ； 读书笔记 行动： 反思日记 如何生活： 《基本穿搭-适用一生的穿衣法则》 《奇特的一生》 《我是个怪圈》 《习惯的力量-原版》 《医治受伤的自信》 《智能时代》 职场技能： 《精准表达：让你的方案在最短的时间内打动人心》 《小强升职记》 《像外行一样思考，像专家一样实践》 你凭什么做好互联网 如何思考： 《系统之美》 《思考-快与慢》 《原则》 《怎样解题》 《第五项修炼》 《穷查理宝典》 《改变》 《万万没想到-用理工科思维理解世界》； 已写文章 商业数据分析学习思路 七周成为数据分析师 数据分析思维案例课程 统计学、excel、sql、ppt 《活用数据》 行业报告，多问自己，如果是你来做报告出发点是什么？为什么这样做？ 《网站分析实战》 《运营之光》， 《计算广告》， 《黑客增长》， 做一个自己满意的框架体系报告 适合产品经理的十本书 俞军 入门三本书： 社会心理学 阿伦森 插图第七版：特别好，适合成为“产品经理的第一本书” 第一本经济学：经济学帮助人们洞察世事 学会提问：学习辨别信息和言论的真假对错 以上三本都是既可以当做产品经理的入门书读，又可以在职业生涯反复读的书。 思维： 认知心理学及其启示：人类认知和思维的基本机制 思考快与慢：人如何有缺陷地思考 超越智商：如何克服缺陷做理性决策 思维与决策 第四版：系统介绍思维与决策领域的研究 学习深度思考和决策需要的书籍，以上四本够用很久了，因为仅仅阅读多是没用的，最终还是阅读、思考、实践的最短板决定决策水平。 经济学： 经济学原理 曼昆版 微观分册：最通用的经济学教材 错误的行为：行为经济学离PM最近，但尚无好教材，先用这一本占坑 新制度经济学 一个交易费用分析范式：学习交易费用思考商业模式 魔鬼经济学： 史蒂芬.列维特 统计数据会撒谎 / 统计陷阱 超级数字天才 女士品茶]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>阅读</tag>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AB测试]]></title>
    <url>%2F2019%2F02%2F17%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-AB%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[https://mp.weixin.qq.com/s/WhTjW1cCzFehDU0AZ2_DiA https://www.optimizely.com/optimization-glossary/ab-testing/ 什么是A/B测试 A/B测试是一种将网页]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析方法</tag>
        <tag>日常工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[业务分析——工作报表、临时需求、异常数据排查]]></title>
    <url>%2F2019%2F02%2F17%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E6%97%A5%E5%B8%B8%E5%B7%A5%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[一、 日报、周报、月报日报 日报每天都要看。编写数据脚本，实现日报半自动化。 为什么每天要看日报： 了解公司业务现状 当公司同事询问数据时，能够做到对基础的业务数据脱口而出,一定要对公司的核心指标数据熟记于心 培养个人数据敏感性 当每天看数据时，都能够看到数据的波动变化。比如每日客户端活跃用户数都是在550-600万用户之间，突然一天增长到605万，能够做到有所怀疑，并进一步寻找原因。这就是数据敏感性。 提供业务发展建议 通过日报的数据观察，能够知道当产品运营做出哪些优化时， 数据会出现涨跌情况，给业务运营提供发展建议。 周报 看短期趋势。 周报作用： 新版本发布往往一到两周，通过一周的时间长短， 可以分析APP新版本的改版效果。 一周的数据更加稳定， 有说服力。 月报 给出建议。 月报内容： 通过月报对公司业务进行梳理，月报一定要有给业务运营的建议，不能只是罗列数据。 当通过数据变化发现某些活动效果好时， 一定要把分析原因放到月报里去展现，让所有管理层知道，从而推送业务的发展。 二、临时数据需求 管理层需求： 优先级最高 了解需求背景，思考为何要这个数据， 通过这个数据可以进行哪些决策 一定要进行核对，不能出错，只能给一遍。 必须时候找上级进行询问 业务需求： 询问为何要这个数据 建立该业务类的分析框架 只给业务方最核心的需求，其他延伸需求让自己去取数 坚决不做提数机 例如： 优惠券的使用情况如何，如何优化？建立分析框架： 优惠券的下发人数 优惠券的点击人数 优惠券的使用人数 优惠券的使用金额 用户消费优惠券的频次 优惠券的消费时段]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>日常工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[路径分析]]></title>
    <url>%2F2019%2F01%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[玩转用户行为路径分析，3种方法就够了 http://www.sylan215.com/upload-to-qiniu.html]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>路径分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何整理大脑思绪]]></title>
    <url>%2F2019%2F01%2F20%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E9%9B%B6%E7%A7%92%E6%80%9D%E8%80%83%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[自己时常有这种感觉，总觉得自己的大脑反应很迟钝，思绪比较混乱，看一个问题想法很模糊，有时心情急躁却找不到问题的解决方法。工作中和别人沟通时，有时词不达意，表达不够清晰，导致工作中出现很多问题。自己也明白自己需要更加深入的思考，但总是没有找到好的办法。 最近在看《零秒思考》这本书，书中作者提供了一个解决此类问题的方法：时刻写下自己的想法。 我们每天会接受不同的信息，在脑海中会产生大量的想法与感觉。很多时候，这些想法还没有转换成语言之前，便在含混朦胧、内心纠结的状态下消失了。虽然想法会暂时忘记，但是那种纠结的感觉并没有消解，会导致自己的心情消极的，产生精神上的压力，进而让大脑变得迟钝。 时刻记录自己想法的好处是，写下来能够将纠结于心的情绪发泄出来，在写的过程中对大脑的思绪进行整理，也能更准确的表达自己的想法。这个方法的关键是：在1分钟的时间限制内，迅速写出大量自己的原始感受。 具体的做法是这样： 写标题： 写出有关大脑中思绪的一个疑问句。 写内容：写4-6行文字来写下自己的原始想法。 字数限制：每行文字字数在10-15字之间。 时间限制：在2分钟之内完成。 数量限制：每天写10条。 每个做法对应的原理是这样： 标题，用疑问句可以让自己更有写下去的冲动。 内容，写4-6行文字，能够将自己大脑中浮现的想法基本都写下来，而不至于重复。 字数，10-15字，让自己不至于写的太短而不能充分表达想法，也不会字数太长在规定时间内写不完。 时间，限制时间，避免大脑受环境和周围状况的影响。 数量，每天写10条，不会过多占用时间，更容易坚持。 书中作者要求在A4纸上写，个人感觉不是很方便，自己目前习惯于通过手机自带的【闪念胶囊】软件来进行记录。记录想法的方法与写反思日记有些相似，两者都要求把自己的想法写下来，不同之处在于，反思日记是对自己这一天做的事情进行反思记录，而记笔记是对你时刻产生的想法进行记录。 目前自己按照这个方法写了10天左右，感觉自己一个很大的变化就是下班回家走在路上，可以通过自问自答的方式来对一个问题进行深入的思考。虽然有时也想着想着就跑偏了，但是自己对于思考这件事情，不再有抵触的情绪。 书中作者还提供了通过回顾记录来挖掘价值的方法： 回顾自己的笔记， 然后再把笔记的内容当做标题， 每个标题再写4-6行。 这样自己对这类问题的思考会更加的深入。 多角度的写一个标题。 让自己对带有个人情感的内容作出更冷静的判断， 能够站在别人的角度去看问题。 将笔记按照不同领域来进行分类整理。 每三个月回顾一次笔记，了解自己面临的问题，探寻自己的成长轨迹。 最后，想说的是，看到一个方法论，我们常常会怀疑这样的方法真的有用吗，但问题本质是看你选择先相信再看见，还是先看见再相信。 我相信时刻记录想法是一个看似简单却对个人成长大有裨益的方法，所以准备践行100天再看看效果。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>思维方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反思日记]]></title>
    <url>%2F2019%2F01%2F13%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E5%8F%8D%E6%80%9D%E6%97%A5%E8%AE%B0%E3%80%8B%2F</url>
    <content type="text"><![CDATA[“我应该不会拒绝从头到尾把生活再过一遍，只是希望能够获得唯有作家才有的特权——在‘再版’的生活中修正‘初版’的错误，生活的悲哀之处在于我们总是老得太快而又聪明得太晚，等你不再修正的时候，你也就不再了” ——西塞罗《论老年》 在18年下半年，自己有一种感觉特别的强烈，就是总感觉时间过得飞快，而自己还什么都没有做，一周就完了，甚至自己想不到自己上周主要做了哪些事情。于是，自己想了一个办法，来抵抗这种感觉，就是每天写日记。 开始的时候，自己主要是记录自己这一天都干了什么，写了一个月之后，自己总感觉自己是在记流水账，刚好那时候，在看一本书《好好学习：个人知识精力管理指南》，里面提到了通过写反思日记的方法来掌握知识，自己按照里面的方法写了 100 多天，感觉还是非常有用的。 反思日记主要分为两个部分，反思与日记。反思就是对自己做的事进行思考，对产生结果的原因进行分析。日记则是要每天都要去写，每天都要对自己的生活进行记录。自己现在更加深刻的认识到， 一个人的变化不是突然发生的， 而是发生在每一天做的事情中的。 根据自己的实际情况，我给自己制定了反思模板，每天日记的任务主要是回答自己这7个问题。 今天自己做的不好的事情是什么？ 自己当时是怎么想的， 身体是如何反应的 如果自己再重新来一次， 自己会如何做 自己今天做的很好的事情是什么 自己目前最主要的目标是什么 自己今天任务的完成情况。 自己明天的计划是什么 这7个问题背后的原理是这样的： 问题1-3，是对自己思考方式的反思。我们平时做一件事情，是基于 假设-行动-结果 这样的过程。 而反思，就是通过 观察结果-研究原来假设-反思校正假设 这样的顺序对自己思考的再思考。 问题4， 是为了提高自己的自信心。个人认为自己在生活中不够自信，通过每天记录自己做的事情，来让自己增加自信心。 问题5，提醒自己时刻盯住自己的目标，为了自己的目标而努力。 问题6，对比昨天的计划，监督自己今天任务的完成情况。 问题7，是为明天的事情，做出一个良好的计划。 有时候，翻看自己之前的记录，会发现自己当时会面临这样的问题，回过头来再看也是比较有意思的事情，比如, 翻看自己18年10月22号的日记，发现自己是这样想的： 通过写反思日记，自己发现了一些自己反复会犯的问题。比如： 自己下班一回到房子就什么也不想干，总是在刷微博、看美剧，但是自己在看完之后，自己并没有产生放松的愉悦感，在写反思日记的时候，自己总是懊恼自己为什么这样浪费时间，这实际上是自己的精力管理方面出了问题，认识到这个问题之后，现在自己也在尝试各种方式来恢复自己的精力。 个人认为培养出记反思日记的习惯还是很有必要的，通过记录自己的生活并不断反思， 能够让我更清醒的认识到自己的不足，从而尝试做出改变。 作者在《好好学习-个人知识精力管理指南》这本书中还提到了通过写反思日记来进行对标管理，把一本书中的知识进行每日的反思等方法。大家可以根据书中的内容，指定自己的个人反思模板。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>思考方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人三观]]></title>
    <url>%2F2019%2F01%2F06%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E4%B8%AA%E4%BA%BA%E4%B8%89%E8%A7%82%2F</url>
    <content type="text"><![CDATA[我的价值观 勤奋 诚实 认真 问题我自身是不是一个有价值、值得被爱的人。能没有能给别人幸福和安全感的强大内心，有没有给予女孩一个理想的、美好的未来的能力。 价值观 挣钱你得解决一个核心问题， 那就是为什么别人愿意给你钱。 你要提高自己的能力，让自己值那个价钱，让别人愿意付钱。越有能力的人，越不计较一些短期得失。关心长期利益的人一定不是投机者，而是投资者，投资者会把时间、精力、金钱投资在能让自己成长和提升的地方，能让自己施展本领与抱负的地方，他们培养自己的领导力和影响力。 技术学习能力是一个好的工程师必须具备的能力。 花时间再技术的原理和技术的本质上，需要了解各种各样的技术的设计方法以及能在原理。 并不存在没有时间，关键在于你对学习有多少渴望程度，对要学的东西有多大的热情。 这点是非常重要的，因为学习者件事其实是听反人性的。反人性的事基本上都是要付出很多，而且还要坚持很久。所以， 如果对学习没有渴望的话，或者不从学习中找到快乐的话，那么其实就很难坚持，无论你有没有时间。 职业首先，我必须完成公司交给我的任务， 然后，我会尽我所能的找到工作中可以提升效率的地方，并改善它。某件事的进步一定会和现状有一些摩擦。有的人害怕摩擦而选择忍耐，我觉得和别人的摩擦并不可怕，因为大家的目标都是基本一致的，只是做事的标准和方法不一样，这是可以沟通和相互理解的。 相反，如果没有去推动这件事，我觉得对于公司和个人来说，都是一种人生的浪费。 客户我更愿意鲜明的表达我的观点，并拉着用户和我一起成长，因为我并不觉得完成客户的项目有成就感，我的成就感来自客户的成长。 面对客户做的不对的地方，我基本都是直言不讳的说出来。 因为我觉得把真实的想法说出来是对客户、对自己的基本尊重，不管客户最终选择什么，我都要把利弊跟客户讲清楚。 写作 第一阶段，写文档阶段。 把学习到的都系都以笔记的方式记录下来，方便我以后可以翻出来看看。 第二阶段，有利益驱动的阶段。 因为我的一篇技术文章，让我接到了一个培训的私活。 第三个阶段， 记录自己观点打自己脸的阶段。 写博客记录自己的一些想法和观点， 然后过一段时间，打自己脸。 能够看到自己成长的过程，并且可以及时修正。 第四个阶段，与他人交互的阶段。 写一些观点鲜明的文章。学会从不同的观点，以及别人的批评中，让自己变得更加完善和成熟。 从写作中锻炼了自己的表达能力，能够更好的与别人交流和沟通。 人生 第一阶段： 20-30岁， 打基础阶段。在这个阶段，我们要开阔眼界，把基础打扎实，努力学习和成长。 第二阶段：30-40岁，人生发张阶段。因为整个社会一定会把社会的重担交给这群人，30-40岁的人年富力强，既有经验又有精力，还敢想敢做，所以这群人是整个社会的中流砥柱。在这个阶段，你要明确自己奋斗的方向，需要做有挑战的事，需要提升自己的技术领导力。 建议 客观的审视自己找到自己的长处，不断在自己的长处上发展自我。知道自己几斤几两才能清楚自己适合干什么。不然，目标设置过高自己达不到，反而让自己难受。在职场上，审视自己的最佳方式，就是隔三差五的出去面试一把，看看自己在市场上能够到什么样的级别。 确定自己想要什么如果不确定这个是，你就会纠结，不知道自己要什么，也就不知道自己要去哪里。注意，你不可能什么都要，你需要极端地知道自己要什么。所谓“极端”，就是自己不会受其他东西或其他人的影响，不会因为这条路上有人退出你就开始迷茫或疑惑，而不会因为别的路上有人成功了，你就羡慕。 注重长期的可能性，而不是短期的功利。20-30岁，因为多经历一些有挑战的事，多去选择能给自己带来更多可能的事。多去选择能让自己成长的事，尤其是能够让自己开阔眼界的事情。 尽量关注自己会得到的东西，而不是自己会失去的东西。因为无论你怎么选，你都会有得有失。 不要喝大众的思维方式一样。因为绝大多数人都是平庸的，所以，如果你和大众的思维方式一样，你做出来的选择也会和大众的一样平庸。 很多事情能更早做的什么程度，其实在思想的源头就被决定了，因为它会绝大程度地收到思考问题的出发点、思维方式、格局观、价值观等因素的影响。而这些才是最本源的东西，甚至可以定义为思维的“基因” 我的三观 人生观-你想成为什么样的人 价值观-你觉得什么对你来说更重要 世界观-你是怎么来看这个世界的 世界观 要有一个好的世界观，你需要亲身去经历和体会这个世界，而不是光听别人怎么说 你的影响力体现在有多少人信赖你并希望得到你的帮助。 因此，多交一些朋友，多吧自己的想法付诸实践，哪怕没有成功，你的人生也会比别人过得有意义。 多通过一件事来引发你的思考，想一想有什么可以改善的地方，有什么方法可以做的更好，有哪些是自己可以添砖加瓦的？你会发现，只要你坚持这么做，你个人的提升以及对社会的价值会越来越大，你的影响力也会越来越大。 人生观什么样的人干什么样的事，什么样的阶段做什么样的选择。 有人说，选择比努力更重要，我觉得，选择和决定，比努力更难。 努力是认准了一件事之后不停的发力， 而决定要认准哪件事作为为自己坚持和努力的方向，则是令人彷徨和焦虑的。面对人生，你每一天都在做一个又一个的决定，在做一个又一个的选择，有的决定打大，有的决定小，你的人生轨迹就是沿着这一个一个的决定和选择走出来的。 选择是有代价的，而不选择的代价更大。 选择时要冒险的，你不敢冒险时风险可能更大‘选择时需要放弃的，鱼和熊掌不可兼得。想想等你老了回头看时，好多事情再年轻的时候不敢做，可你再没有机会了，你就知道不敢选择、不敢冒险的代价有多大了。 选择时一种权衡，这世上根本不会有什么完美，只要你想做事，有雄心壮志，你的人生就是一个坑接着一个坑，你所能做的就是找到你喜欢的方向跳坑。 因此你要想清楚你自己想要什么，不要什么，而且还不能要得太多，这样你才好做选择。否则，影响决定的因子太多，决定就不好做，也做不好。 你对你选择结果的坚持和守护，成为了你的三观，而你的三观影响着你的选择，你的选择影响着你的人生。 必须做的5件事 想尽办法，跟牛人在一起 在跟牛人的交流中， 能迅速打开视野，增长见识， 还能交到朋友。经常交流的人， 对你有很大的反向塑造里，想成为牛人，就一定要常见牛人，付费约见是一种很好的方式。 读以致用， 好书至少读十篇 一定要每天坚持读书， 哪怕每天只读5页 输出， 读完之后， 需要总结，写出文章来，没有输出的输入，质量是不行的。 好书读十遍，遇到好书， 一定要反复读 读以致用， 成长的关键在于干事情，并且做出成绩来，读完就要用 做人大方，持续真诚地利他如果你是个持续大方的人，别人就会知道，跟你合作、和你交往，不会吃亏，朋友、机会才会越来越多 视时如命，有极强的抗扰力主动见想见的人，去做该做的事情，但不要被别人打乱你的节奏。 持续分享，传播有用的内容想要打造个人品牌，持续对外输出有用的内容，是至关重要的事情。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>认知</tag>
        <tag>三观</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人原则]]></title>
    <url>%2F2019%2F01%2F06%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E4%B8%AA%E4%BA%BA%E5%8E%9F%E5%89%87%2F</url>
    <content type="text"><![CDATA[闭环原则 谁难受谁推动 凡事往大的范围想 永远不要等着准备好了再去做，机会是不等人的，边学边做才是最快的成长方法。 你的问题就在于读书太少而想的太多，永远不要在无意义的思考上耗费太多时间，多读书，多行动，只有在知识和阅历增长之后，你的思考才会更有价值。 你赚钱的多少，与你的劳动强度，技能水平，有关系，但都不大。关键在于你的不可替代性，以及你所在的平台，你的行业。 不可替代性其实包括很多，一种是你业务水平的提升，一种是你是复合型人才，另外一种是积累人脉。 提高业务水平很容易理解，就是不断提升你的专业水准。而复合型，则指的是，能够将两种或多种不同的技能进行融合，从而产生新的技能。 当你在一个行业足够久了，你的行业人脉将变得不可替代。尤其是一些管理岗位，大部分的工作都需要协作，需要你去调动资源，而只有掌握了人脉的人，才能做成这种事，这不是一个实习生可以替代的了的。 通过观察对方的沟通、演讲、写作方式，从而学习他们的思维方式、学习他们身上最优秀的思维习惯 睡眠其实真正决定了生命的效率。因为睡眠决定着第二天的心情、状态、专注度等，而心情、状态、专注度直接影响结果，我们的现在就是由大大小小的这些结果构成的。所以睡个好觉可能是让生活变得更好的最大的捷径。 保持自我，并不断变得更好，其实在一段感情里，远比委曲求全，一味地宠溺对方，更重要。保持自我可以测试出和对方是否合拍，不断变得更好，可以让感情更深刻而持久。千万不要因为孤独、无助、父母逼迫、个人面子、焦虑等原因仓促地选择一个人。这个人是自己生命的一部分，对自己施加着无以复加地影响，所以谨慎点，即便单身都比错误好很多。 习惯很重要，但没人跟我说重要到深度影响自己生活、人生选择和生命质量的程度。因为几乎大多数人，每时每刻都生活在形形色色的思维习惯、生活习惯中，比如健身、跑步、阅读、表达、写作、沟通、学习等等，所有影响我们生活工作结果的全是这些习惯。我们养成习惯，然后习惯养成我们。 因为只有身体得到良好的休息，才有足够的精力去处理工作。这里的休息，包括很多方面：1，早睡早起2，中午小憩，但不会超过30分钟3，体育锻炼4，周末彻底放下工作，去做一些不消耗太多精力的事情5，听音乐这一切都以恢复精力为目的，只有精力充沛，你才能做好事情，才能做到自律。 无聊坚持下去却很有意义的事情 写日记 正念 阅读 你在孤悬绝壁上攀登跳跃，在一望无际的大洋中孤帆远航，看不到峰顶，也看不到重见陆地的希望。你顶着压力，踩着动力，孤单，但心怀梦想，一路前行。终于有一天，你登临绝顶，一览众山小，在群峰之上享受阳光洒满脸庞的温暖；终于有一天，你乘风破浪，凝视大洋最深处的奥妙。又或许，你并没有抵达梦想的彼岸，你在山腰依山而居，成了一个看林人；你在海边结网而渔，成了一个打鱼人。但无论如何，奋斗的过程已经为你的生命打上了深深的烙印，你看过阿尔卑斯山上融化的积雪，看过蓝色的湖泊里飘荡的雾气，看过高山上怒放的花朵和迎风站立领口张开的姑娘……]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>认知</tag>
        <tag>原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[职场学习]]></title>
    <url>%2F2019%2F01%2F06%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E8%81%8C%E5%9C%BA%2F</url>
    <content type="text"><![CDATA[工作中明白的几点道理： 工作中要做到不用别人盯着，会驱动自己完成更高的目标。 工作不是别人给你什么需求你都要做， 你要思考哪些需求需要做， 哪些需求不需要做， 要学会有技巧的拒绝。 对于比较重要的数据， 你不能单方面给业务人员， 需要做到让领导知会。 你做没做工作， 是否真的在做工作，大家是能够看到的，能够感觉到的， 但是大家平时不说出来， 关键时候自有评判。 不要总是为了逃避思考，而去做那些枯燥无意义的事情，学会知道什么最重要。 自己的成长最重要， 不要总是认为现在工作做好就行了， 你永远不知道你什么时候会被公司裁掉， 保持自己的高竞争力才是王道。 当一个任务来临的时候， 不要总想着逃避，很多时候，你心理的不舒服， 只是你在这项技能上的短板。 男人要自律 工作中如果别人向你提一个需求， 你们商定好了完成的时间后， 你一定要按时去完成，如遇到特殊情况一定要提前解释好。每一次交互都是你名片的传递，注意细节。 数据分析工作好坏的四个层次 有没有找到真正的问题， 人都是有逃避心理的。 想到了问题的第几层 想到了最后一层， 并且去执行解决问题 做到了，并且分享帮助别人 文字摘录 冯大 加班严重，没有自己的时间，看不到自己的未来 大部分对自己工作不满意的人，又没有能力去找到更好的工作。那就应该警醒一点，这就是你能找到的最好的工作，你该有个好心态对待这份工作。认真一点，敬业一点。别整天抱怨，那些都解决不了问题。 人抱怨都是因为自己的无能，要能力号就可以有选择，就不会有那么多抱怨。 你的选择，应该是选择一个好的形态，把当下这份工作认真做好。 曹大 超过35如果头衔和行业地位没有达到一定高度，职场竞争力直线下降。简单说就是，跳槽机会直线下降 影响力的价值，怎么强调都不过分，不需要说写个公众号天天拉粉丝那种，在你业内的很多同行和竞争对手中高层都知道你，都知道你的水平，这很重要。抛头露面分享宣讲的机会要重视。 锻炼表达沟通能力，对所有职位通用 学会情绪控制 多结善缘，简单说就是帮助那些值得帮助的人，有的人给你的回报可能超出想象，但可能也需要很久，比如十年，或更久。你不知道哪个看上去不起眼的年轻人未来会是你的福星或金主 读这种文章，先把里面数据撸出来，多少用户，多少账户，收入多少，估值多少，然后自己算算，对行业认知就会多一点，不要看个八卦，发几句牢骚，觉得知道这个事了。数据控就是对里面每个数字都敏感，然后再去admin5对比一下，算算单用户价值差多少，想想差在哪里。 一个人有能力赚到钱，有能力让别人知道他，有影响力，只要是合理合法的，那这个人就是有本事的人 一个创业者，如果连竞争对手厉害在哪里都不知道，而只是看人家哪里不好，就自以为找到了突破点，通常都是一厢情愿。 一个管理者，如果不能发现自己员工的价值点和才能，而只是觉得自己的人这个不好，那个不好，觉得所有问题都是员工能力不足，那么就算是千里马，也没办法在他手底下跑起来。 一个职场员工，看不出自己企业的竞争力和管理者的决策权衡判断依据，只是一昧的埋怨，挑问题，在职场上的前景也相当堪忧。一个技术人员，在接手，调整和优化别人代码和系统的时候，如果不能体会人家设计的初衷和面对场景诉求的思考方式，而一昧的从一些细节去挑错，也很难成长成为独当一面的技术顶梁柱。 一个商务合作和市场合作经理，如果不能在合作中分析和挖掘合作伙伴的价值点和优势所在，而只是一昧的埋怨对方的配合度和问题，也很难促成持续有价值的合作。 我跟很多初入职场的年轻人提个醒，不管外面多光鲜的企业，你深入去看，里面一定有无数问题，有很多让你觉得不爽的地方和你所认为低级的问题，但这其实并不重要，重要的是你要发现和理解人家强在哪里，为什么会成功，然后在这个基础上，你再去理解和分析那些问题，可能就会有不同的认识，而在能够理解其竞争力和目标的基础上，再去对你所发现的问题做价值排序，并试图去解决，可能你考虑的方案才会更全面，你的价值才会更容易体现。 此外，正确的结论，正确的判断，往往并不是大多数。曲高和寡这句话，希望从业人员能真的明白，我还是那句话，如果你跟绝大部分人的判断和分析一致，请问你的价值在哪里？ 离那些批评家远一点，除非你真的具有全局判断力。 工作方法 在工作上发生失误，要用于承担错误，并且第一时间先找到解决方案，把失误造成的影响挽回。（最好是认错和解决同时进行。不要跟领导说下次再也不会犯错了，那是不可能的，说这种没有意义的承诺，等到你下次真的又错了（哪怕不是同一件事情），领导会觉得你的承诺不可信。 在会议上要踊跃发言，哪怕你觉得自己的建议跟S..t一样，至少要让领导知道你有认真在思考方案，总有一天领导会觉得你的某个观点是值得采纳的。 工作及时反馈，领导某天突然临时给了你一项任务，你很好的执行了，但转眼几天后领导忘记了，也没来催你。等到他又突然想起来，问你这项工作进行的怎么样的时候，你再去跟他说已经完成了（哪怕超出预期的完成），事实上领导感官上已经大打折扣了。当你主动汇报甚至是提醒领导的时候，他表面不露声色，但是在内心肯定给你加分了，觉得你很可靠，以后有什么项目都会优先想到你。所以要学会主动汇报工作进度或结果。 想要推进一个需要跨部门配合的项目，一定要主动跟项目相关的人沟通联系，甚至是催他们给反馈结果，大家都很忙，有时候你的任务不是他的主任务，如果你不催而是等待别人来主动给你反馈，先不说概率问题，至少项目推进很慢，效率很低。所以推动项目前进最好的方式是，主动出击，不断在他们耳根前重复重复，让他们都不好意思再推迟下去了。emmmm,一句话，脸皮要厚。哈哈哈 如何看待频繁跳槽的行为（caoz的小密圈-贝勒爷） 成本 短期来看，通过各种方式优化建立，确实可以让你拿到更高的工资， 但这点钱对你整个人生来说，根本不值一提。 因为频繁跳槽换来的看似是涨了一些工资，但是你很难在一家公司获得长久的知识积累，要知道知识和各方面的积累（老板对你的信任，业务知识的深度学习，人际口碑的建立等）是有复利效应的，是你一辈子的财富。 而金钱，永远是一种可再生资源。 另外每一家公司都是有不同的业务，不同的架构，不同的切市场蛋糕的方向。频繁跳槽只会让你永远在学习新的东西，但永远学的都是皮毛，每去一家公司都是浅尝而至。 而真正能在一家公司成长起来的人，哪一个没有被老板反复考验才赢得信任？哪一个没被下属骂傻逼收了很多夹在中间的委屈才赢得同事的尊重？哪个没被业务上的困难折腾到不干翻这些困难就觉得在浪费人生？ 反复跳槽带给你的是需要在新公司熟悉新的业务，新的人际关系，新的知识，建立口碑。这些都是需要时间耐心经营的，需要你时间成本和获得这些财富的机会成本。 价值 工资的本质是老板花钱买你的时间，买你的价值，当你在求职市场挂牌交易的时候，工资实质上只是老板对你的估值。估值不等于实际的价值。 虽然有时市场的估值会高于或低于你的真实价值，但长久来看，你的估值（工资）始终会在你的价值线上下波动。 每一个老板都是精明的商人，都懂得低位买入，买未来可能会持续增值的资源。所以公司更欣赏学习能力强、吃苦耐劳的人， 因为这种人未来增值的可能性是巨大的。 所以我们不要太刻意在意估值， 应该真正关注自己的真实价值，让自己获得长久的积累并反复刻意练习持续让自己成为潜力股。 诚信 在一家公司， 最难的不是你能获得多少工资， 多高的职位，难得是领导和老板对你的新人。 没有信任你永远都挤不进核心的圈层。 在如今，很容易得到一个人的历史与大家对你的评价。一条不诚信的消息，足以让你得不到信任和重用。 我们要考虑如何建立别人对你的信任， 如何经营别人对你的尊重。 如何赢得这些财富， 需要你一次又一次做到了超越别人预期。 用心经营自己， 别总想着快速走捷径，坦诚做人。 不要想着糊弄，不要喊高估值， 不要在乎给多少钱做多少事，把自己当做老板，给自己打工，把老板当你的投资人，一次一次做好每一件事，挑战自己能做到更好，追求极致，耐心一点，用心辅佐你的老板和领导，用心带领团队伙伴，和大家一起战斗，别老想着驾驭。 最后你用心做了这一切，直到自己看到了自己的价值积累，那就笃信自己一定会更好吧，耐心一点。 产品经理产品经理应该思考需求，定优先级，而不是画交互稿 产品是以创造用户价值为工具，打破旧的利益平衡，建立对己方有利的新利益链，建立新平衡的过程。 用户价值 = （新体验-旧体验）-换取成本 创造用户价值是满足用户未被满足的需求，解决用户的痛点问题 一个产品能否建立在足够大，足够强的问题上，决定了这个产品能做多大，走多远 建立对己方有利的新利益链你的护城河是什么 微信读书建立的新利益链是： 低价吸引到用户- 平台-出版社-网文变现。 这个新模式下，的护城河之一是你前期敢投入更多的钱，让用户可以以更低的价格看到更多的书籍。 所以微信有无限阅读卡模式。 然后通过产品体验、裂变玩法，吸引更多的人加入。 建立新的平衡 新的平衡由你的产品设计到的所有的对象构成，你的用户、你的合作方、你的团队，每一个参与对象都获得了更高的回报，而你作为新平衡的建立者，获得了商业回报。 逻辑上的成立，跟能够做成这件事情，相差甚远。 逻辑推理都是建立在一个个假设上，而你构建的链条变量越多，成功概率越低。 创业 最大的感受是一定要站在巨头上，不管国内巨头还是国外，不管是中间页还是小程序，抖音号，一切商业模式无非站在巨头肩膀上做中间页或符合巨头战略战术诉求的。对巨头的研究很重要，这是大局。不管是淘宝，微信，亚马逊，各种平台趋势诉求还是规则深度理解 还是要专业细分，钻下去研究。 新一代创业思维，要甘愿做生态系统中一个点，不要妄想自己建立平台 ，同时产品和服务 要做简单 小的 不要太复杂 但能解决问题的。 永远有机会，没机会可能是你姿势不对，粥左罗2018年3月才开始做号，到现在成为新一代网红，说明机会其实一直在 只是姿势变了，正确的方法+正确的坚持，公众号领域和以前站长领域一样 也是互帮互助的，形成细分领域集团军 。 人性是最好的赚钱工具 利用焦虑赚钱很正常 焦虑也是一种需求。如英语社群打卡，每天学习一句英语口语，能缓解焦虑就是满足人的需求，这和道德无关。 跨境电商打的是文化不同和习惯不同 国内其实互联网生态已经高度发达，反过来国外还没渗透 时间机器理论用到这里，现在从中国包抄世界，反过来也行。 少即是多，大部分年入千万以上的同学都是在自己领域深钻，不要看着别人好，别人在自己的领域付出的努力你没有看到。 成功创业者，大部分base一线大城市，信息密度高，确实大城市和大厂近，厉害的人自然多，信息高地+交流广自然方向选的准，业内还是要有好朋友 人的眼光的敏锐度，思考的角度非常重要，要去敏锐的思考事物之间的联系，这个过程中，人的执行力也很重要 看准一个东西，能赚钱的，不要守着一棵树，该批量的批量，该扩大规模的一定要扩大规模。 一定要利用红利期来赚钱，红利期的策略执行是真的非常非常重要，赚钱速度会非常快 不要老是盯着一个渠道赚钱。实际上我们团队非常有危机感，比如我们觉得facebook赚钱，但是我们一定不会满足facebook这个渠道，我们会时刻观察新的渠道，比如instaram，比如pinterest 别人付费提供的产品（服务），你免费提供，而且质量比别人付费的还要好。这样的话，你的产品就成为全市场最优竞争力的产品。它虽然没法直接给你带来收入，却可以给你带来大量精准的流量和潜在客户。后面，你再用自己付费的产品去转化这些客户，就实现了商业模式的启动。 技能技术人创业至少需要以下这些突破： 1）产品思维 程序员大多是直男，这方面普遍欠缺。咱们自己做的东西，往往体验和文案都不忍直视。 代码写得再漂亮，可能用户看了半天都不知道是干啥的，也搞不明白怎么用。2）运营思维 获客成本是很容易被人忽略的东西，包括怎么做留存 ，这些方面做不好的话，上线第一天就是焦虑的开始。3）商业化 技术出身的人往往有些书生气，不愿意深入思考怎么赚钱，经常做一些离钱太远的事情。特别是现在融资越来越难的情况下，项目的商业化能力就更重要了。4）领导力 创业不再是单打独斗，怎么样让小伙伴们信任你，你带着他们全心投入，不断打硬仗、打胜仗。这一点也是习惯了跟机器打交道的人面临的巨大挑战。 你们的产品到底是哪些人在用？他们的使用场景是什么？ 用户的增长模型是什么？获客成本怎么样？公司的收入结构又是怎么样？这些环节有哪些问题，你又能在哪些方面帮他们解决问题？ 多思考上面这些问题，这样才能创造更大的价值。 如何寻找实习如何评价应届生在面试中说的「虽然我没有经验，但是我非常愿意学习」这句话？ 1、说自己热爱学习是废话，和说自己是个好人没任何区别。 2、求职是零和博弈，你三本毕业说出花来，面试官十分感动，然后要了那个北大的。 3、普通应届生水平就是差，在企业里根本就干不了什么活，很多工作换谁来干都一样，还不如找个漂亮/听话/老乡/校友等等。（当然这不怪学生，国内就没有职前教育这个概念。在这点上，山东蓝翔吊打国内90%的大学） 别太相信什么面试技巧能帮你找到好工作。 面试技巧是锦上添花。 面试让你过了又咋样，你啥样自己心里没点数么？试用期啥概念知道不？不好用分分钟让你走人。 成功案例要么是应聘者自身并没有很差，要么是好工作其实没那么好，还有一小部分就是运气好。 这些没啥统计学意义，你就当鸡汤喝了完事，真以为自己也可以这样，会饿死人的。应届生面试最重要的是啥？ 实习经历！ 没有实习经历，最重要的就是看学历。其他什么奖项、校园活动、学生会经历都是扯淡。名校的学生们都会尽早的找大机构去实习，刷简历，简历不到位很多大机构的门都进不去。 奈何普通大学很多人都没这个意识，大多数都是在其他人开始实习之后，才会意识到自己要走出校园走向社会了，才开始手忙脚乱的各种临时抱佛脚。 在这种情况下，当其他的应届生还是个无忧无虑、天真可爱、喜欢问十万个为什么的宝宝，而你已经是个皮实耐操、精通各种体位、老板一声令下你立刻就能上岗干活的打工仔了！ 那么问题来了，怎么找实习呢，这不成了一个先有鸡还是先有蛋的哲学问题么？ 莫慌。 如果你还是大二、大三的水灵灵小学弟and小学妹，请开启舔狗模式，尽可能多的认识师兄老大爷and师姐老阿姨，多了解他们的实习动向，很多企业对实习类岗位的要求并不是很严苛，只要你能保证时间，他们也不在乎多一个少一个。 这有助于你早早的认识社会，对工作、企业以及自己以后感兴趣的方向能有真实、具体的概念。光靠看A片你是成不了老司机的，自己在象牙塔里脑补臆想都没用，真刀真枪的干才是成长的硬道理。 如果你当了三年的废柴，已经没有笨鸟先飞的机会，也别担心。 人贱还有老天收呢，废柴也会有人要的，不怕不怕。 你要记住，求职招聘是双向选择，NB的公司要NB的人，那么不NB的公司呢？ 这类公司就是你的目标。 1、问师兄师姐，你想去的行业内有没有什么二线公司，规模不大，但还算靠谱的。 2、自己网上找，相对小众的公司，没什么名气，但产品靠谱的。 3、关注下风投领域的新闻，看最近有什么企业拿到了天使轮/ABC轮的融资。 4、在网上找相关行业的员工，给人家发个红包，问下行业里面有没有什么二、三线或者大厂员工出去创业的。 此类创业期、规模较小的公司，普遍很缺人手，但他们又不能随便招人，找一个正式员工的成本很高。 做一个勤奋的廉价劳动力，这就是你最大的价值。 准备工作： 1、提前收集好公司信息 发展状况 人员规模 主营产品（自己可以购买/下载试用） 你可以在企业的官网、微信公众号、微博找到相关信息 2、站在用户角度写一篇自己对产品的理解分析 不怕你写的垃圾，用心就是加分项 注意逻辑清晰，尽量别有前后驴唇不对马嘴、读起来狗屁不通的低级错误。 写完找同行给你改，不认识人就花钱找 尽量多写，反复推敲，反复检查，拿出当年打LOL上分的劲头来认真写 如果是面向大众类产品，记得看用户评论，是个很好的理解产品的方法 如果你excel、powerpoint之类用的不是很好，尽量趁着写这份东西的同时去学习，带着问题边实践边学习效果是最好的，比单纯为了买个课程死记硬背要好的多。 3、投递简历 认识人的让内部员工帮你投递，不出意外获得面试的概率是70% 不认识人想办法去认识，关系一般拿钱砸，你态度诚恳多数情况下还是会有人愿意帮你一把 尽量别在招聘网站上投，容易石沉大海 公司官网上留的联系方式，也可以投简历，被看到的几率会更大 实在不行找到公司地址去蹲点，直接到前台说要面试，只要你礼貌些，别有啥过分举动，不像精神有问题，前台一般会帮你转达，如果面试官不在或者他们不接受这样的面试，你就往门口一戳（别看着给讨债似的），尽可能找机会认识内部员工（人家总要恰饭的嘛），坚持下来总会有结果。 进公司后： 1、比公司要求时间，早到半个小时、晚走一个小时，最好不要迟到。迟到是个态度问题，没有能力再没态度，那谁也救不了你。 2、通常实习生到岗，除了HR与直属上司的例行流程外，一定会有人带你去吃饭，告诉你各种新人需要知道的各种信息。你一定要和这个人打好关系，在未来实习过程中，他是你为数不多的可以请教各种问题的人。（尽量不要麻烦上级领导，人家通常没那么多时间教你） 3、别以为有实习机会就万事大吉了，实习不一定能转正，而且最重要的是，你要实习出成绩来，之后才好找工作（或转正留下）。 4、别怕苦，多干活，活干完了，找领导要。这世界上领导千千万，好坏强弱啥样都有，但没有领导会讨厌主动干活的人。 5、在办公室里多帮其他员工的忙，端茶倒水拿外卖什么的，自己主动点，别觉得没尊严，这都9102年了，但凡有一定规模的正规公司，不太会出现欺凌新人的情况，无非就是让你多干活、跑个腿。而且你平时多跪舔自己的上司，别人打狗也得看主人，不会对你太过分。 6、每天做完事之后，一定要总结，今天学到了什么；工作中遇到问题，整理起来，有合适的机会就请教其他人，好好记认真听，别老问重复的问题，别人也烦。 7、工作量必须和正式员工一样，只能多不能少，时间上尽量满足八小时全天在岗，人家正式员工怎么干你就怎么干。 检验你是否成功的标准很简单——时间长了大家是否还把你当实习生看，还是已经按照正式员工的标准来要求你了。 在这样的状态下，工作一年。 这一年的时间意味着什么？ 意味着： 当别人还是应届生，简历上一片空白，只能写什么学习能力强、热爱工作、参加校园活动取得圆满成功的时候，你的简历已经可以和有一年工作经验的正式员工媲美了。 别人：「虽然我没有经验，但是我非常愿意学习。」 你：「我做过。」 面试官会怎么看？ 事实胜于雄辩 傻逼定律，很多年前微博发过，开始增补。第一定律，从来没觉得自己傻逼过的，往往是不可救药的大傻逼。第二定律，觉得别人都是傻逼的，往往自己才是最傻逼的一个。第三定律，收割傻逼的会被傻逼们封神，试图唤醒傻逼的是傻逼眼中的傻逼 学历只有在前一两份工作的时候有意义 认真，光认真你就赢过80%以上的人 重视你的承诺，说到要做到 认真建立同辈人脉 搞定老板是绝对要学会的一门功课 要不就三个月内跑路，要不就待满两到三年 跳槽是个好选项，但不要只考虑薪资差别 拥抱失败，但别把失败当成理所当然 不要停止学习，但也不要被流行词迷惑 对自己要有自信，但不要小看其他人，包括你的老板、主管与客户 要对赚钱，对流量进行关注， 需要培养自己的赚钱思维 要有创业的心态去打工， 在职场进行工作时， 同时需要有自己的副业。 要不断尝试自己的副业。 要不断的去积累。当到一定的阶段， 才会爆发。 牛人的自控能力一定是非常强的。 自控能力是衡量一个人能否爆发的关键。 是否真的每一天都在进步。 努力能够让你的职业保持线性增长， 而要达到指数型增长， 需要时机， 需要别人帮助。 社交也是一个技能。 多看别人身上的优点。 那些比你级别更高的人， 一定是有值得你学习的地方。 让他知道你有能力， 可以值得别人帮你。 前提是别人知道你有能力， 然后能够报大佬的大腿。 你有能力， 一定要让别人知道。 然后大佬们才能够帮助你， 前提是你必须要有能力才行。 如果社交群能够比你高那么一点， 才有用。 年轻， 一定要多加杠杆。 (不是搞股票) 年轻， 一定要敢于冒险， 敢于尝试。 要多折腾， 要有冒险精神。 对于一些投资自己的东西， 有损失是正常的。 对于买股票， 买基金， 如果钱全部亏完了， 你能否接受？ 一定要多尝试。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>认知</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[专题分析]]></title>
    <url>%2F2018%2F12%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E4%B8%93%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[专题分析数据分析师的一个重要考核， 就是专题分析的效果 需求沟通 一定要将20%以上的时间分配在沟通需求上，一定要当面沟通。 原始需求——了解需求—— 本质需求——逻辑树——sql提数——分析方法——写分析报告 例如上线活动效果的专题分析流程： 业务需求解读————需要与业务方当面沟通， 业务沟通贯穿整个分析流程。 活动效果的数据情况 目前活动对整个APP活跃用户，或者留存率的影响，以及活动的问题有哪些 活动的拉新、促活，用户粘性情况， 活动效果的优劣 通过逻辑树进行整理 建立分析AP， 分析师与业务方之间完成分析数据对焦，形成最终报告框架和结构。 通过SQL进行取数验证 分析： 组成部分、数量比较、维度变化、各项变化、各项相关性、其他数据挖掘 撰写报告： 90%的图+10的文，标题就是结论。 结论前置。 讲故事，报告的逻辑性一定要强。 项目专题分析的特征 有目标——围绕项目KPI来进行。 有节奏——2-3周输出一份完整的报告。 有闭环——报告不能太技术性， 要写成大白话最好， 说人话。 要明确给业务方提供建议改进方向， 而不是自己技术展现。 3.专题分析实战 项目背景：电信app要在数据分析的基础上， 对产品运营进行优化，提升用户留存5%的绝对值。 第1阶段：新用户留存整体分析目的： 摸清数据现状， 同时找到若干个切入点。关键点： 不要太注重细节， 该过程讲究报告产出的时效性，指明数据分析的方向， 让其他人员感受到数据分析师的存在。过程：渠道方面， 各渠道的uv, 一、二级渠道的次留、7留。 产品方面, 主要功能的渗透率，功能是否出问题， 关键漏斗数据如何， 漏斗数据上有无发现。 用户方面， 产品用户的画像是什么， 用户的行为分布如何。 使用产品用户的分布。 第2阶段： 寻找优化切入点， 一般是1-2个。比如： 1. 关键立即数据发现曝光pv到点击pv的ctr很低， 我们可以围绕这个点细致分析： 对于新用户， 应该曝光什么，在什么时候， 什么位置曝光。 2. 某个量大的二级渠道的次留明显低于其他渠道， 围绕这个点，来进一步分析原因： 渠道本身质量存在问题？用户安装了竞品？当前产品设计与渠道用户不太匹配？高留存的渠道本身特征是什么？通过这两点， 给渠道和运营的同事提供建议， 结合A/B测试， 就能看到数据分析的效果。 第3阶段： 不断重复前两个阶段， 继续寻找其他切入点。 同时进行竞品分析， 营销活动分析，用户流失分析等等 每一次分析报告都要有能落地的点， 并且真正的落地了。 形成闭环， 评判数据分析师的标准： 产出专题分析的质量和数量。 质量就是数据分析落地的点和提神的kpi。 改版分析 新改版页面的效果怎么样？ 产品迭代的需求来源： 市场调研、竞品分析、用户反馈、数据分析、团队头脑风暴。 分析方向： 改版后， 新功能是否受欢迎 改版后， 对产品的流程转化率是否有提升 改版后， 对产品的整体留存的影响 改版后， 用户究竟如何使用新功 功能活跃比新功能的用户数 / 同期客户端活跃用户数 漏斗转化提升 次日留存、周留存、月留存等指标是否朝着更好的方向发展。 用户使用新功能， 是否符合你的预设， 还是说用户创造出了新的玩法。]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>专题分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[业务分析——埋点方案]]></title>
    <url>%2F2018%2F12%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E5%9F%8B%E7%82%B9%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[数据埋点方案https://www.sensorsdata.cn/blog/20181114-2/ 问题： 需求整理不完善， 没有整体考虑， 版本更替原有埋点不可用 数据统计口径不清楚，没有将埋点的具体采集时机郑群传达，埋点不是自己想要定义的指标 数据采集方案没有想清楚， 哪些应该在前端埋点，哪些应该在后端埋点，埋点采集sdk如何正确使用没有了解清楚]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>埋点方案</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[业务分析-数据分析师岗位介绍]]></title>
    <url>%2F2018%2F12%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E5%B2%97%E4%BD%8D%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[1. 数据分析师岗位介绍 什么是数据分析师？ 数据分析师， 就是专门从事数据收集、研究分析，并依据数据来指导业务决策的人员。 岗位分类 其中的数据收集、研究分析、业务指导刚好可以将数据分析的岗位分为三个大的部分： 数据收集——数据研发工程师 主要职能是搭建数据处理的基础设置，让大数据的存储、处理、计算能按要求完成，包括数据仓库搭建、数据存储、计算处理、报表开发等。 数据挖掘、算法工程师 主要是应用机器学习和数据挖掘算法，进行用户行为分析和用户属性挖掘，建立模型，预测、用户画像等为业务场景提供支持。 业务数据分析师 分析业务数据， 发现问题，分析问题，得出分析结论，为决策提供支持，主要支持市场运营部门。 如需详细了解数据分析师的岗位划分，可以参考秦路老师的文章：数据分析的职业规划 业务数据分析师的日常工作有哪些? 业务前期： 建立业务数据指标， 梳理业务数据口径， 确定数据埋点方案， 进行埋点测试，确保数据采集的准确性。 日常工作： 公司的日报、周报、月报数据支持，业务方临时性数据支持， 数据异常原因分析， 业务专题分析。 业务数据分析师的技能要求 数据分析思维和对公司业务的理解程度， 是业务数据分析的主要核心技能。 必备技能有： Excel, Hive/Sql, 统计学，PPT 软技能有： 逻辑思维能力，分析方法论， 数据敏感度， 沟通协调能力 加分技能： Python, R, 机器学习算法 业务数据分析的发展方向 业务数据分析是入门相对容易， 但要精通比较困难， 在公司属于比较基础的岗位。如果专精于业务方向， 可以往管理方面发展， 如数据运营经理/总监。也可往数据挖掘工程师方面发展， 需要进一步掌握Python和机器学习算法等知识，后面也可以往数据产品经理的方向发展。 对于我自己来说，目前的职业发展方向是业务数据分析师， 主要任务是不断学习和完善业务数据分析的所有技能， 加强互联网运营的业务理解能力，打好职业发展的基础，未来的期望是往数据挖掘方面发展。 业务数据分析师的考量标准 业务数据分析师的考核标准产品理解能力： 熟悉业务的各种核心数据，明白用户从哪里来，进来之后做了什么，了解用户反馈最多的问题是什么。 了解产品功能渗透率和关键路径，再以这些数据为切入点，思考当前产品有哪些问题，并与产品经理沟通如何优化，同时看竞品数据和行业数据，深入了解业务数据。 深入了解： 要有自己的洞见，对于整个行业，各个不同阶段的领头羊是谁，他们靠什么成为领头羊，又因为什么出现增长瓶颈，当前各自的大法测试什么，对我们自身的app有什么借鉴，后续我们要监控哪些数据。 分析方法论： 能够快速从一个较全面、逻辑性、价值性的角度去分析，而不是单点无架构分析。所有方法论都是通过不断提炼、总结、实践得出来的。 指标体系方法论 流量分析方法论 路径分析方法论 产品分析方法论 营销活动分析方法论 用户流失分析方法论 A/B 测试 最大概率法则、二八定律、幸存者偏差等 可视化能力： PPT 制作能力 PPT专题报告之间的逻辑性 内容是否符合金字塔原理 数据可视化内容美观性 演讲能力： 表达能力 讲故事能力 形象化能力 大心脏能力如何 协作沟通能力： 跟产品、业务、研发沟通时的软技能 如何在团队中定义好自己的位置并让其他人感到舒服 逻辑思维能力： 分析推导过程的全面性、合理性、价值型 技术能力： excel的常规操作 统计知识是否能够熟练应用 hive、sql的熟练程度 python 中常用的数据分析库能否熟练应用 算法模型是否熟练搭建并知道有哪些坑。 —如何规划数据职业生涯 数据产品经理-产品架构师 掌握基础技能和思想技能：excel, sql, hive, python, 统计学、 基础机器算法策略产品： 机制设计、冷启动、用户画像标签体系思维模式： 依赖数据做决策，建立产品闭环——从数据产生、收集、统计、分析、反馈。职能分工： 功能产品，策略产品 参与完整的业务闭环-open建立明确的优化目标(objective)打通数据记录和分析流程(process)建立A/B测试优化的框架(Experiment)将目标按转化网络分解(Net) 通过闭环的优化过程， 感知数据。 独立负责项目或产品 机器学习定理 没有免费午餐定理，NFL定理没有任何算法在所有数据情形下有天然优势， 在没有实际背景下，没有一种算法比随机胡猜的效果好。 所有模型是没有好坏之分的， 当数据有线性分布时， 模型就会有效。 先掌握领域前言知识， 用它来指导业务， 而不是把每一个模型都跑一遍。 丑小鸭定理两只白天鹅的区别与丑小鸭与白天鹅的区别一样远。 https://blog.csdn.net/mnshenyanping/article/details/51280731 不要追求成为全栈工程师。 产品的逻辑一定要懂。什么是产品？-定义问题， 解决问题的逻辑。 比如： 用户标签体系、冷启动策略等。 不要频繁切换从事的业务领域 业务领域先验知识的积累， 是成功进行数据建模的关键。 业务领域的商业逻辑需要花时间搞清楚， 这对产品的决策至关重要。 同一个领域的不断努力可以形成个人口碑。 数据分析应该具备的能力不同企业不同职位去判断一个数据分析专家的标准和侧重点肯定不同，但所谓牛人的特性，庖丁解牛。 就是不管多复杂多麻烦的一个事，一个分析工作，到他手里，能很快的清晰的给出脉络，给出解构，给出路线图。这就是牛人的共性，不仅是数据分析。 那么我觉得针对数据专才，很重要一点就是，对于所属行业，所从事领域的一些数据现象，数据特征，数据逻辑，随时问他，清晰了然。 为什么机会来的时候老板会想到他，因为你很难找到一个人能对各个核心部门的业务了如指掌。能快速厘清部门的业务脉络并有效接手，他最后一个接手的部门是百度联盟事业部，担任事业部总经理，马国林出事后他去救火。 现在已经离开百度做投资基金， 为什么做投资，因为对流量变现的思路和认知太了解了。回到我最初的那句话，数据是公司的，贩卖数据肯定是违法的，但见识和视野是自己的，是可以随时带走的。 我也知道有在百度做数据的老同事 ，坦白说，对数据毫无感觉，完全是为了领导的工作而完成数据，那，就没啥可说的了。旧文有个坐守金山不自知，说的就是那种。 对场景的理解，认知。 书本，教育，在线讨论，都是基于明确的场景提出问题，寻找解决方案。 但现实工作中，对一个职场新人，或技术人员，理解业务场景并寻找和发现问题 是非常需要经验的。我以前说过，acm的算法大牛，我可以给他们讲搜索算法优化，不是因为他们算法能力不如我，而是应用场景理解上我秒杀他们。 数据分析的基本方法论 工作内容周末报表： 整体业务报表：核心指标和产品核心业务与功能变化 新用户报表：用户获取与渠道质量、新用户行为分析、新用户相关运营活动分析 分析师分析报表：分析师结合核心指标与产品内部的活跃现象，自行去分析用户行为数据，挖掘有效增长点，并讨论后产出有价值的分析报告 异常分析报表： 日活、留存、新增等数据发生异常时，通过细分探寻原因，定位问题。 如果日活正常偏高，可提醒业务同事选择进行一些活动。 根据报表数据与其他部门进行沟通，推动业务产品的迭代和发展。 每次产品改进时，和产品经理沟通本次改版的方向和目的 在新版本或功能上线后， 在第一时间（1-2天内）给产品经理搭建新版本报表，反馈改进结果。（新版本覆盖情况，新功能使用情况，新优化的数据表现；整体表现数据：留存，转化。具体功能的使用人数、使用率、使用留存等） 在1-2周内，给出3-4份详细的分析报告，进一步分析用户对新功能或新版本的反馈，挖掘信息，证明有效性，分享给产品经理，推动他们解决问题 3. 数据分析师能力如何展现 如何提高自己的数据分析能力 行业认知， 多看一些咨询公司的报告，了解分析的角度和行业趋势及现状。 数据认识， 对数据的敏感度不能局限在统计意义， 而是要掌握数据来源的方式，业务之间的埋点如何， 采集方式是什么样 分析的目的是什么，能否还原用户或产品行为 注重数据的探索， 多角度去思考， 输出与目的相关的发现，由点到面，还原到用户行为或营销策略的制定，比如， 用户使用的一款app, 什么时间发的信息能够让DAU迅速提升。 掌握统计学， 统计学是对各种假设检验的还原，要深入理解每个算法的场景和弊端 要尝试总结归纳，输出自己对行业的看法，动手+动脑思维。 假设你是领导，你如何看数据而不是玩数据；假设你是运营人员， 你如何建立分析体系， 指标设定如何让目标更有效 写文章，能够提高自己的故事构思和思维能力， 更有效的是能够积累文笔、表达、沟通深度等。想的越多， 说的才能越有深度。 如何算是懂业务、有思路的数据分析师 数据君 硬实力 工具的掌握 算法的掌握 有自己的技术博客 工具的操作和应用上有自己的输出和展示 软实力 要有好的思路 说话表达有套路，比如 总分总 等逻辑 要对方法路有深入的思考。 比如：swot,pest,5w2h,生命周期，aaarrr,4p， 金字塔原理等 训练方式： 脑图，逻辑树 案例 例如： 为什么最近GMV的增速放缓了？ 大局观，用pest,swot等方法先看看大环境的状态是什么？竞争对手如何 GMV计算的切入点，比如，人、货、物等（思维框架） 用5w2h、aaarrr、生命周期等方法去定位和排查问题出现的可能性。（不同方向有不同的方法论） 数据罗列和验证过程， 从数据分析的本身流程去全面核实，数据来源追溯、口径核实、对比历史等，找到产品用户放缓的原因到底是什么，假设验证的过程 问题和策略落实到人或者部门，要不然你的建议就是咨询，无法很好的落地，假设几个角色，要不面试官会觉得你只停留在学术层面 面试官要的不是答案，而是你思考的过程。 战斗力 你学了什么课程， 有没有输出自己的作品。把自己所学的做成一份从0-1的报告呈现给面试官，你的印象分会很高，他们会觉得你的心智更成熟，很有想法，每个团队其实都缺少一定的活力， 这才是年轻人应该有的担当。 当你把自己的作品展现出来， 总会有一些人和你产生共鸣，而你在共鸣中不断的迭代自己， 这才是一个良性的循环，你才有可能有不平庸的资本。 其实数据分析师一个入门简单， 深入难的学习， 他不是依靠参加各类培训和课程积累，而是依靠你的经验和思维系统。 4. 数据分析方法论数据分析的主要方法 趋势分析 通常我们在数据分析产品中建立一张数据指标的线图或者柱状图，然后持续观察，重点关注异常值。在这个过程中，我们要选定第一关键指标(OMTM，One Metric That Metter)，而不要被虚荣指标(Vanity Metrics )所迷惑。以社交类APP为例，如果我们将下载量作为第一关键指标，可能就会走偏;因为用户下载APP并不代表他使用了你的产品。在这种情况下，建议将DAU(Daily Active Users，日活跃用户)作为第一关键指标，而且是启动并且执行了某个操作的用户才能算上去;这样的指标才有实际意义，运营人员要核心关注这类指标。 多维分解 多维分解是指从业务需求出发，将指标从多个维度进行拆分;这里的维度包括但不限于浏览器、访问来源、操作系统、广告内容等等。 为什么需要进行多维拆解?有时候一个非常笼统或者最终的指标你是看不出什么问题来的，但是进行拆分之后，很多细节问题就会浮现出来。 举个例子，某网站的跳出率是0.47、平均访问深度是4.39、平均访问时长是0.55分钟。如果你要提升用户的参与度，显然这样的数据会让你无从下手;但是你对这些指标进行拆解之后就会发现很多思路。 用户分群 用户分群主要有两种分法：维度和行为组合。第一种根据用户的维度进行分群，比如从地区维度分，有北京、上海、广州、杭州等地的用户;从用户登录平台进行分群，有PC端、平板端和手机移动端用户。第二种根据用户行为组合进行分群，比如说每周在社区签到3次的用户与每周在社区签到少于3次的用户的区别，这个具体的我会在后面的留存分析中介绍。 用户细查 用户行为数据也是数据的一种，观察用户在你产品内的行为路径是一种非常直观的分析方法。在用户分群的基础上，一般抽取3-5个用户进行细查，即可覆盖分群用户大部分行为规律。绝大多数产品都或多或少存在一些反人类的设计或者BUG，通过用户细查可以很好地发现产品中存在的问题并且及时解决。 漏斗分析 漏斗分析是一套流程式数据分析，它能够科学反映用户行为状态以及从起点到终点各阶段用户转化率情况的重要分析模型。漏斗分析模型已经广泛应用于网站用户行为分析和APP用户行为分析的流量监控、产品目标转化等日常数据运营与数据分析的工作中 漏斗分析要注意的两个要点：第一：不但要看总体的转化率，还要关注转化过程每一步的转化率;第二：漏斗分析也需要进行多维度拆解，拆解之后可能会发现不同维度下的转化率也有很大差异。 留存分析 留存分析是一种用来分析用户参与情况/活跃程度的分析模型，考察进行初始行为的用户中，有多少人会进行后续行为。这是用来衡量产品对用户价值高低的重要方法 衡量留存的常见指标有：次日留存率、7日留存率、30日留存率等等 留存分析可以帮助回答以下问题：一个新客户在未来的一段时间内是否完成了您期许用户完成的行为？如支付订单等；某个社交产品改进了新注册用户的引导流程，期待改善用户注册后的参与程度，如何验证？想判断某项产品改动是否奏效，如新增了一个邀请好友的功能，观察是否有人因新增功能而多使用产品几个月？ A/B测试与A/A测试 A/B测试是为了达到一个目标，采取了两套方案，一组用户采用A方案，一组用户采用B方案。通过实验观察两组方案的数据效果，判断两组方案的好坏。在A/B测试方面，谷歌是不遗余力地尝试;对于搜索结果的显示，谷歌会制定多种不同的方案(包括文案标题，字体大小，颜色等等)，不断来优化搜索结果中广告的点击率。 这里需要注意的一点，A/B测试之前最好有A/A测试或者类似准备。什么是A/A测试?A/A测试是评估两个实验组是否是处于相同的水平，这样A/B测试才有意义。其实这和学校里面的控制变量法、实验组与对照组、双盲试验本质一样的。 5. 如何分析业务数据问题陈述、产生假设、收集数据、分析数据、获取结论、采取行动 评估和定位问题 在深入研究任何类型的数据之前，应该快速找到你需要解决的真正问题，并用最简单的话定义它 如果无法用简单的语言解释你要解决的业务问题，那么任何数据分析都无法解决问题。 快速评估和定位问题的三问： 这是否是系统异常导致的问题？ 下载量下跌，但激活量没有，也许是下载数据没有埋点或埋点错误？ 这是更大问题的预兆吗？ 注册号码的下降是网站故障的指示吗？ 你在看一个重要的度量指标吗？ 如果网站的转化率下降，但原始注册量没有下降， 那么就从一个紧急事件变成了一个谜团待揭开 确定潜在原因 经验检索，快速寻找原因根据经验，寻找任何明显的可能原因或问题的答案, 当你检查显示问题的来源或报告后，是否有任何异常原因立即浮现在脑海中？ 例如，你的电子商务网站的ssl认证可能过期，导致浏览器弹窗窗口警告数据不安全，从而显著降低购物车转化率 询问相关人员原因这个问题会影响和涉及其他团队吗？如果是这样，他们是否对可能的原因有任何了解？即使问题与其他团队之间没有明显的联系，也有必要咨询一下。 营销经理可能会问客户支持： 我注意到注册数据下降了，你能否想一想过去几周你发现过什么相关的变化吗？ 创建假设一个假设知识一个尚未得到证实的有根据的猜测。 在分析数据之前，清楚地说明问题的几个可能原因非常重要，这有助于防止常见的数据分析误区。 导致注册量突然下降的假设： 某些地区的公众假期 最近对营销网站的更改 星期一网站中断导致注册过程中出现错误 转换率下降减少了注册量 产品页面在某搜索排名下降到搜索结果的第二页 技术思维的方法——科学假设需具备的条件： 涉及一个自变量和一个因变量 它是可测试的 它是可证伪的 有时查看数据可能会产生一个新的假设，需要再次测试。最终，我们的假设会在下一步通过数据分析得到证实或反驳。 分析数据 分割并确定相关数据指标根据你的假设，你需要查看哪些数据？哪些指标可以帮助你证明或者反驳假设？ 你可以按国家/地区， 渠道和网络会话持续时间细分注册次数，以测试你的假设 注意你的数据基于你已知的业务指标，你可以判断数据是否出现异常？如果无基准线，请用历史数据作为起点。 app注册量同比下降20% 评估异常或趋势的影响经过前两个步骤，你要查看发现的趋势/异常是否足以解释问题 在寻找数据中的异常或趋势时，要注意这些异常或趋势不仅要具有统计意义，也要具有实际意义。我们需要弄清楚是什么会对我们发现的问题产生实际影响。 统计显著性检验用于确定你注意到的异常是由于抽样误差还是适用于所有对象。 6. 数据分析面试问题 假设你的产品新功能上线，那么哪些数据指标可以量化这些功能？这些变化产生的影响，你准备如何入手？ 提示：从数据角度讲，可能从页面的热力图选取热区，或根据 A/B test 实验来选择方案可能会更加理想。 如果抖音一个视频的页面变宽， 那么它的点击数，曝光数，和点击率如何变化 面试技巧：理论基础要非常好，面试环节和谈薪资环节，一定要非常淡定，有一颗大心脏，不到最后签合同，绝不松懈。 活动的拉新效果怎么评估 国企面试技巧 软技能——与人相处能力、展示能力、时间管理能力、预判力 面试技巧——积极主动、沟通能力、逻辑框架性、表现自信、淡定。 BAT面试 1面-电话面说话要有逻辑性，简历中项目的数据要非常清晰， 目前公司app的日活、月活、渠道留存。 2面-现场面多使用应聘岗位公司的app, 带一份自己写的优秀的分析报告，当面试官问你有什么想问的，结合公司app内容， 提前想好一些问题， 问面试官， 并给出自己的见解。 3面-总监面要有亮点， 有自己代表性的项目， 了解产品的宏观知识，行业趋势， 了解产品竞品， 行业痛点， 产品改进， 之前项目的上下游关系， 要多有想法。 4.必问的三个问题 流量波动 常用的三个app 之前产品的商业模式，如cpc, cpm 7. 专题分析流量分析 从哪里来 经过什么 产生什么价值 波动分析 渠道分析——常见渠道内部渠道外部渠道作用： 拉新用户前期靠渠道推广， 中后期靠自传播，或用户的免费推广 软技能+面试技巧进入一家公司靠能力， 在一家公司的发展空间靠能力+软技能。同样一个问题，如何快速领会出领导的意图，并且能够有效的表达和展现，往往决定后面的发展高度。 开会提前准备会议内容，并且随时准备表达自己的数据分析能力。把会议当做展示自我的一个机会。 比如ceo开员工大会，对业务提出一些问题，或数据不太清楚，业务该怎么走。如果你能够对公司的业务数据了然于胸，并对该类问题有过见解，必然会脱颖而出。 BAT工作阿里：对寻找方向，重点解决，方法论研究。腾讯： 埋点，指标体系，检测，异常，A/B测试。 增长黑客。百度： 用户运营，体系 用户增长 日常主要工作：数据异常排查专项分析KPI埋点 数据异常排查：解释数据波动，排查原因。 数据较大波动说明两个问题：1. 数据本身有问题。 2. 业务本身有问题 数据异常排查的前期准备： 业务理解 指标口径 当前数据的产出过程 异常排查的方法论：判断是否异常 亲自看数据的准确性 时间轴拉长，看是近期异常，还是周期异常把近三个月的数据拉出来 看和该指标关联的其他指标或其他核心指标是否异常 找到一个关键人物，提前沟通一下。 最大概率法则闭合 8. 数据分析方法案例如何提高全站留存率？ 选择高留存的行为，并选择其中比较容易扩大使用者面积的几个，在产品功能层面放大，让更多的人看到并发生转化，从而提升留存。 评估最终效果时，首先评估该功能的使用人群和占比是否有效提升，有则认为改进有效 以上主要因为产品在改进期间会同时发生很多其他改进，也会有各种不同的市场，运营活动，单纯用留存来评估，无法有效验证。 例如：即刻产品的核心功能之一就是内容的分发，用户绝大多数的时间都在浏览关注、推荐和动态页的内容与评论。按照用户使用这些内容模块的行为，可以按其门槛和深浅分为路人行为（如浏览帖子）、围观行为（点击并查看评论）、普通参与行为（点赞、转发）、深度参与行为（发布评论）等。通过留存分析功能，发现行为深度越深，用户的留存就越高。但由于扩大发生参与行为的门槛过高，落地性也就较差。因此，选择围观行为，通过放大其面积来提升用户全站留存，所以，就在产品信息流列表页露出一条热评，一方面让更多的用户看到最精彩评论，另一方面更有力的引导用户点击查看更多内容。 新增热评功能后，成功将阅读评论的用户比例提升，并且成功提高了全站留存 具的操作只是帮你快速业务流程梳理出关键性的分析和指标体系，那么这些体系和指标的度量和之间的关系就要依靠统计学去界定和规范 一个网站改版了，新版的页面没有改变原来的交互操作，只是改变了视觉样式，用户访问量和点击量变化了，这些变化是好是坏? 1、我们已知的是改版前后点击量的数据和用户访问量的数据2 、我们想知道这个变化是好是坏 要怎么做?算一下改版前后用户的百分比和点击量的百分，如果改版后用户量下降了，点击量下降了是不是改版就不成功?显然我们不能如此简单的看问题。要比较这两个样本，我们可以使用T检验。 T检验(Student’s t test)是用于小样本(样本容量小于30，总体标准差σ未知的正态分布)的两个平均值差异程度的检验方法。 我的置信区间是95%，所以如果sig&lt;.05就代表差异显著。 从表上看，改版前后点击量和用户数两项上差异并不显著，所以我们可以认为这次改版至少没引起什么不良的影响。 当然现实问题往往更复杂，仅就改版为例，我们需要考虑很多问题，例如： 1、改变了哪些内容? 外观还是交互方式?或者外观+交互方式?布局有什么变化?交互方式的变化对用户完成一个任务所需的步骤或点击次数是否有改变?2、改版前的数据采集了多少天?改版后的数据采集了多少天?3、改版前后的时期在每一年的相应劫夺，用户的访问量是否有显著变化?趋势是怎样的? tabula工具， 将PDF表格提取到Excel 对新版本的分析 改版后，新功能是否受欢迎 要衡量一个新功能是否受欢迎，基本就看这个功能上线之后，用的人数多不多，用的人越多，表示这个新功能还是挺受欢迎的（当然，这里还有一些运营推广的因素）。 一个比较好的衡量指标是功能活跃比，什么叫功能活跃比，也就是使用了新功能的用户数/同期活跃用户数，比如说新功能的用户数是1000人，而同时期产品的整体活跃用户数是10000人，那么这个功能的活跃比就是10%。 对产品流程转化率是否有提升 我们就需要通过去观察整个产品的流程转化率是否因为产品迭代改版而有所提升。最基本的方法，就是通过创建流程漏斗来进行数据观察们就可以将上述事件组装成一个转化漏斗，如果你优化了商品详情页或者是搜索页面，那么就可以很好地通过漏斗来看出，改版之前和改版之后，这个流程的转化数据发生了什么变化，每个小环节的漏斗转化率又发生了什么变化，这样就能比较准确地评估出产品迭代对流程转化率是否具备提升作用 对产品整体留存的影响 在迭代之后，也可以好好观察一下产品的整体留存是否产生了变化，比如次日留存、周留存、月留存等等指标，是否朝着更好的方向发展 用户究竟如何使用新功能 用户究竟是如何使用产品新功能的，是否符合你预期设想的那样，还是说用户自己创造出了新的玩法 向老板汇报注册量下降的原因 核心问题： 我们的注册量下降， 是什么原因导致的？ 假设： 由于….导致了注册量的下降 某些地区的公众假期 最近对营销网站的更改 星期一网站中断导致注册过程中出现错误 转换率下降减少了注册量 产品页面在某搜索排名下降到搜索结果的第二页 数据分析：思考数据有多少变化?是否真的异常分别按照天和小时查看数据的变化，发现更改网站（网站注册会出现中断）时注册量确实有下降，但网站更改完成后注册量仍然在下跌，且进一步分析发现对注册表单样式的更改，使转化率略有上升，因此不是对营销网站的更改导致。通过进一步查看数据，发现在总体注册量下降期间，到达注册页面的人数减少了大约 10％，因此，可能是上游问题导致的。接下来，考虑假期假设（下跌开始时间是某些地区的公众假期）。但随着时间的推移，各国的注册量都有所下跌，所以该假设排除此时，她整理了一下思绪，决定分析点击付费广告投放更改后的数据。发现其中一个广告系列转化率下降了 50％，但这个只占注册量的 1％，所以不是主要原因。Jody 又通过渠道查看注册率，发现有机搜索（占注册量的 70％）下降了 20％，推测是几周前页面更改引起的页面排名的变化。于是，她开始检查 SEO 数据，发现主要关键字已降低排名，现在位于第二页，这样一来，除了注册量其他方面也会受影响。最终，Jody 除了解释注册量下降之外，还创建了一个策略来恢复注册，并将分析报告呈现给了产品副总裁和首席执行官。 为什么购物车到下单的转化率在降低？ 核心问题：许多潜在客户在购物车结算这一步流失，我们该如何降低流失率？ 假设： 由于…转化率下降 放入购物车的人绝对数量增加 最近对付费流程的更改 季节性（即假期，学校休息等） 促销结束导致更多人放弃下单 某些商品出现问题，影响下单 Tyler 第一步思考加入购物车的人绝对数量是否增加？如果有大量人开始向购物车添加商品但完成购买的人数保持不变，那么可以判断有一批购物者的转化率降低，他注意到加入购物车的人数略有增加。 然后他开始询问相关团队的人，如有没有促销活动？有没有推出新产品？会不会有季节性影响？付费过程有什么变化吗？价格是否经过调整？（注意：根据业务和产品范围的不同，这可能会有很大差异。） Tyler 最终得知付费流程发生了一些小变化。现在，他们不仅仅列出购物车中的商品，而是展示每件商品的图片。 为了进一步分析这种变化的影响，他将付费流程分成了不同的步骤，发现用户的浏览数据正常，事实上，更多的人正在进行下一步，所以这似乎不太可能是罪魁祸首。 接下来，Tyler 通过将本周的购物车转化率与前几年的同一周进行比较来寻找任何季节性影响，他还通过快速浏览日历，了解任何可能的线索，但由于会话和电子邮件开放率等相关指标未受影响，季节性因素假设也排除。 Tyler 之前咨询到最近的促销结束了，按照常识，当人们意识到促销已经结束时，他们更有可能放弃下单。Tyler 在购物车转化率下降之前使用促销代码查看付费比例，发现只占 5％，但放弃率的变化是三倍，所以这只能算一个促成因素。 Tyler 又开始思考这是商品库存的原因吗？但所有商品的性能相当一致，这个假设也不成立。 在考虑其他可能的原因时，Tyler 再次审查付费流程。发现商品价格页面中对运费的描述部分大大减少，他回忆起之前对产品页面进行一些外观修改的时间与流失率增加时间完美吻合。 回顾这些变化后，他的新假设是潜在客户放弃下单，是因为他们期望下单时购买的价格是产品页面设定的较低价格，一旦他们看到全价（包括运费），就会放弃下单。 发现这一点后，Tyler 非常有自信的准备使用 A / B 测试来检验假设，如将产品更改恢复到以前的设计，或者尝试使用包含运费的版本。最终，他验证了假设，并调整了页面。 想找出所负责的 App 激活率降低的原因 核心问题： 初始下载后，打开和使用 App 的人数减少了，怎样才能提高激活率？ 假设：由于……激活率下降 App 的更改使人们不太愿意激活 一群新的（或不同的）人开始尝试这种产品 她注意到在过去 3 个月中激活（打开并开始使用 App）的比例一直在稳步下降（与下载总数相比） Sofia 先查看一些数据来获得更多背景资料。最终她发现下载的绝对数量明显增加，而激活人数仅略有增加。不过两个指标的绝对数字都在增加，让她松了一口气。（注意：根据不同的企业，这可能是也可能不是问题。最终，这取决于是否浪费了额外的注册资金。） Sofia 后续很快确定应用程序中与激活下降相关的初始体验没有任何变化。 现在，她更密切地关注哪些人正在下载应用程序以及人口统计数据是否发生了变化。因此，她按地区对下载人群进行了分层，发现来自较低激活区域的下载量略有增加，但这远远不足以解释激活率的下降。 接下来，Sofia 分析不同渠道（例如，应用商店搜索，社交广告，推荐等）的下载情况，发现推荐下载渠道的下载量大幅增加，且似乎与她之前提到的增加的下载次数大致相同。深入分析后，她发现通过推荐下载的激活率明显低于其他渠道。 Sofia 通过咨询营销团队，了解到基本是一个高流量文章引起的推荐渠道的下载量增加，而且它没有任何成本，具有很大的潜力待开发。Sofia 和营销经理下一步准备采取行动增加该渠道的激活量。 Sofia 最终通过一些快速的数据分析，使最初的问题变成了一个机会 9. 如何避免数据分析中的坑要避开哪些坑？ 不要重复无意义的工作。许多刚入行的小伙伴喜欢把清理数据作为主要工作，纪敏认为这只是让你接触数据的一种方法，每天重复地提出需求、整理表格，会磨灭掉许多对于分析师岗位的热情。 不要“全手动”，要寻找代替的工具。既然不能重复地做无意义的工作，那么就要学会用工具去代替人工，选择合适的用户行为模型和工具，能把分析师的主要精力放在规律和策略的探索上，才能充分发挥一名数据分析师应有的价值。 数据分析只是一种辅佐手段，它无法从根本上改变产品方向、功能价值，主要辅佐和支持的产品，探索更有价值的数据意义。 https://www.sensorsdata.cn/blog/20181107/ 避免数据偏见在分析数据时受个人偏见和动机的影响，即仅选择支持你声明的数据，同时丢弃不支持声明的部分。“数据偏见”将让数据的客观性荡然无存。 避免这种谬误的方法是在分析数据时，尽可能收集相关数据，并询问他人意见 避免数据疏浚数据疏浚（Data Dredging）是指未能确认相关性，实际上是偶然的结果。 在寻找问题的原因时，很容易被数据蒙蔽。乍一看，这些数据可能具有统计学意义，但进一步测试（例如，检查趋势是否持续，查看相关指标等）可能会发现只是偶然结果。 避免这种谬误的方法是在分析数据时，从假设开始检查相关指标和观察数据变化趋势。 区分因果关系和相关性 在数据分析时很容易将两个事件同时发生（相关），判断为因果关系。 避免这种谬误的方法是，收集更多数据并查看可能的第三方原因，有时会发现他们的相关关系可能与第三个独立因子相关，而不是彼此相关。 例如，我们发现放弃其在线购物车的潜在客户往往具有较低的总购物车价值（放弃时购物车中物品的总成本）。此时，我们没有足够的数据来确定这是一致的相关性，是偶然结果，还是由其他因素引起的。深入挖掘我们可能会发现运输成本导致购物车到下单的流失率上升，因为免费送货仅适用于超过特定最低购物车价值的订单。 解决问题，做出明智的决定在找到数据支持的结论后，你需要记下一个简短的摘要（包括问题，数据显示的内容以及由此产生的决策 / 行动），这样做有两个目的： 1.将你所分析的数据和结论告知可能涉及或受影响的任何其他团队，为其他人提供有价值的背景信息。 2.这个记录也将使你在将来出现类似情况时更容易参考和以防其他人想要查看数据本身。 最终，问题解决了，也总结了有价值的经验。 对数据进行分析的最佳途径： 业务梳理——了解业务需求 确定业务目标——弄清产品目标以及当下的首要问题 事件设计——记录和目标相关的用户行为，并定义为相应事件 数据采集——保证采集质量，确定好事件采集时机，和开发进行沟通 构建指标体系——确定想要看的指标，想要达到的分析粒度，建立产品的第一关键指标 数据分析——业务人员根据自己的经验，进行数据分析，迭代优化 以子弹短信app来进行举例 产品信息结构图了解产品承载了哪些信息和功能，这些信息的目的是什么， 想要用户干什么 产品功能结构图将产品的功能模块梳理出来， 功能之间怎样跳转，功能的上游入口和下游入口是什么，都要想清楚，并标记出来 核心业务梳理流程图弄清梳理出产品的核心业务流程，密切观察用户在核心业务流程运转的整个过程，比如：注册流程，新手完成任务流程等 梳理产品需求首先明确我们要分析什么样的场景，解决什么样的业务问题，要解决这个业务问题，要看什么数据，要衡量什么指标。 定义指标明确产品的目标和目前产品阶段来说最重要的问题。比如，要增加销售额，销售额等于活动流量乘以付费转化率乘以客单价，我们就需要把这个指标需求进一步细化，分给不同的角色各有侧重点的去执行。 要梳理这个指标需求和产品逻辑有什么关系？比如，活跃用户指标，一般是启动app的用户来定义活跃，实际上，每一款产品的核心功能不同，只有完成核心功能的用户才能算活跃 事件设计和数据采集埋点设计根据用户在使用产品功能时产生的行为数据，从用户使用行为分析的角度去分析需要的埋点 用户行为：发布话题——上传图片、视频——进入本地视频列表——选择视频——输入话题——发布话题 操作系统，应用版本，话题分类 操作系统，应用版本 操作系统，应用版本，是否取消 操作系统，应用版本，操作类型，是否取消 操作系统，应用版本，输入话题名称方式，话题名称 操作系统，应用版本，话题分类，话题名称，是否成功 https://www.sensorsdata.cn/blog/20180929/ https://www.geckoboard.com/learn/data-literacy/basic-data-analysis-guide/ 一个提升用户体验的绝好方法：触点管理]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>岗位介绍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[营销活动分析]]></title>
    <url>%2F2018%2F12%2F22%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95-%E8%90%A5%E9%94%80%E6%B4%BB%E5%8A%A8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[营销活动分析营销活动分析介绍互联网公司经常会做一些运营活动，比如比如当当网的限时优惠活动，春节期间支付宝的集五福活动等。这些活动花费了公司大量的人力与财力， 那么活动的效果该如何评估呢？这就需要用数据来说话。 数据分析在营销活动中的任务，不仅是在活动后对数据进行分析， 更要在活动前、活动中、活动后三个方面来都进行跟踪。 活动前期： 目的 和运营人员商定好本次活动的目标，这次活动主要是为了：拉新、促活还是品牌推广，没有目标的活动不是好的运营活动。 埋点 和运营人员商定好这次活动都需要了解哪些数据，针对需要采集的页面位置，写好埋点方案：字段名、埋点位置、上报方式 和研发人员沟通埋点方案，数据埋点完成后，测试采集数据是否准确， 避免采集数据有误。 搭建指标体系 写出这次活动自己都需要哪些指标，如何计算， 提前搭建好指标体系 提前订好这次活动自己需要输出哪些数据，用什么形式来进行展现， 定好数据的输出格式。 活动中期 观察活动前3天的数据 观察活动第1天的数据， 详细查看各指标体系的报表数据是否有异常，对于发现的问题做到及时修改。 观察1-3天的数据趋势， 预估活动目标的完成度， 考虑活动目标是否需要调整。 活动数据及时数据 定时输出活动战报，及时发现数据异常波动， 让运营人员和项目领导知道数据的实时动态。 对于长期活动，第一周后需要进行一次复盘，将结论同步给管理层， 让更高视野的人给建议。 活动后期 活动的效果 短期效果 活动对大盘的影响 参与活动uv 打开APP， 首次进入活动uv 大盘的日环比、周同比 新增用户拉动低活跃用户重新活跃数目标完成度品牌传播指数 长期效果 新增用户留存率低活用户留存率 活动优化 活动主漏斗数据转化率 活动功能模块渗透率 用户反馈 活动报告 在活动结束1-2周内输出，要有时效性。 活动与活动之前的数据对比更能说明问题 思考每次活动的本质和意义。 敢于暴露问题， 把已知的事实告诉上级，邮件同步给运营负责人 涉及到钱的问题， 需要让业务方给， 邮件说明情况，钱问题比较敏感。 案例分析支付宝集五福活动 带来新增用户，提升用户的活跃度，品牌传播量 在活动开始之前应该确定一个重点提升的核心数据。 这样的数据包括新用户注册、用户活跃度、用户付费转化、产品交易额、品牌知名度（百度指数、新浪指数等）等等。 非商品交易类的互动性活动，需要关注： 产品核心数据（日活、新用户) 的提升效果。 专题页面的uv、pv, 活动产生的用户互动量和人均互动次数、分享次数 老用户和新用户的互动比例 交易类产品的促销活动： 互动为平台带来的总交易额、购买人数、人均客单价（关键指标） 活动页面商品的 uv、pv、进入活动页面的人数占比（活动吸引力） 浏览-加入购物车-下单的转化率，分析潜在用户流失原因。 优惠券核销量/ 优惠券发放量 不同渠道用户的付费比例，单价，留存]]></content>
      <categories>
        <category>数据分析方法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>活动分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[投资系统]]></title>
    <url>%2F2018%2F10%2F27%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E6%8A%95%E8%B5%84%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[理想的收入来源 工资收入 出卖时间 成为某个领域的行家，做出成绩，争取超出领导的期待，然后升职加薪。 兴趣收入 个人品牌变现 持续给大家提供价值，帮助大家解决问题，满足大家的需求提升自己的写作能力 投资收益 资本生息 李想买股票的心得： 我自己必须是这个公司忠实用户，我几乎每天都在用它，非常了解它 这个公司的价值观不能扭曲，价值观要积极正面，虽然不是非要什么认同 用户量和业务又比较好的支撑，用户增长率、收入增长率、利润增长率，现金流效率，这四个里面只要有两个表现优秀即可。 在你的钱还没有多到可以通过交易直接大规模影响股价的层面，不要分散投资，越集中越好，不要超过三只股票 不要在意短期的涨跌，拿得住才是利润，两三年以上交易一次都是翻好多倍的。 连续下跌一段时间是买入的好时机，买了以后跌也别纠结。 买股票，就是买公司。]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学]]></title>
    <url>%2F2018%2F10%2F20%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-%E7%BB%9F%E8%AE%A1%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[前言：为什么应该学点统计学统计学是人类发明用来研究我们自身的科学，它与我们的生活息息相关。 小到支付宝根据用户个人消费数据判断其消费水平，从而有针对性进行限额借贷。大到国家通过国民生产总值这样的统计数据分析，来研究国家经济发展趋势等， 都需要用到统计学知识。 我们可以从统计大师 Hans Rolling 的演讲中， 来看下 1960 年到 2003 年的世界各国出生率与经济发展是如何变化的。 Hans Rolling —— 统计的魅力 有人会问，统计学那么多高深的概念和复杂的算术， 在平时的生活中自己也应用不到。 这种想法其实是错误的。我们学习统计学， 不光是学习怎么对数据进行统计计算，更重要的是学会运用统计思维去更理性地看待周围的事物。 比如， 最近报道的一名美国公民在 10 月 23 号中了 16 亿美元的彩票， 看到这则消息，你会不会也有点心动， 也想去买个彩票。其实， 关于是否要买彩票，统计学有一个重要的概念来衡量：期望值 即同一种行为多次重复之后，所能得到的平均收益 举例来说， 假如某彩票规则为：每次买张彩票需要 2 元，假设 200 次抽奖可以中奖一次，奖金为 300 元。 期望值 = 300 (1/200) + 0 (199/200) = 1.5。 期望值是 1.5 元， 但是每次抽奖成本为 2 元， 于是每次净亏损 0.5 元。如果你偶尔买一次就算了， 但如果你长期买彩票，就肯定会亏很多钱。 况且现实生活中，中奖的概率远远低于 1/200 你可能会觉得，概率那么低， 那我怎么感觉天天有人中奖呢， 这背后其实是媒体的选择性报道， 也就是统计学中的选择性偏差问题 例如：二战期间，盟军为减少飞机在敌人防空炮火中的损失，军方决定为飞机加装防护，多数人认为，应该在机身中弹多的地方加强防护。但统计学家沃德认为，应该给那些没有中弹的油箱和驾驶部位进行防护，因为这些部位中弹的飞机根本没有机会飞回来。 现实生活中，也往往会存在一些选择性偏差的数据，我们生活中接触的数据越来越多， 解读数据背后的信息， 辨析数据真伪就显得非常的重要，这则 TED 视频对此有更深入的讲解。 为什么应该学点统计学 那么统计学到底要学什么呢？统计学主要学习两个方面 描述统计， 描述数据的基本情况 通过研究数据的平均值，中位数，标准差等指标， 来了解数据的整体分布状况，从杂乱的数据中得出有用的信息 推理统计，根据样本数据来对总体进行估计 通过对样本数据的研究， 来对总体数据进行估计，评估推理数据的准确度，统计学中就会通过置信度， 卡方分布等来对总体进行估计。 统计学是我们将客观数据转化成有用信息的一把钥匙， 运用统计概念对一些更为广泛而大致的信息及规律进行思考， 可以改善我们做出的判断和决定。我们当然不能指望这些判断不出错误， 但每一个好的决策都会帮助你更有效的利用这些信息，积少成多，把事情做成的概率会大很多 。 Hans Rolling —— 东方崛起 对数据位置和变异程度的度量 均值 12import numpy as npa = [1, 3, 3, 4, 5, 7, 7, 15, 15, 15] 12# 均值np.mean(a) 中位数 1np.median(a) 众数 12345678#方法1# np.bincount, 计算非负的int数组中，每个值出现的次数counts = np.bincount(a)#[0 1 0 2 1 1 0 2 0 0 0 0 0 0 0 3]#返回沿轴最大值的索引np.argmax(counts) 123# 方法2from scipy import statsstats.mode(a)[0][0] 极差 1b = max(a) - min(a) 均值 总体均值： $\mu = \frac{\sum_{i=1}^{N}{x_{i}}}{N}$ 样本均值：$\frac{}{x} = \frac{ \sum_{i=1}^{n}{x_{i}}}{n}$ 方差 总体方差： $\sigma ^{2} = \frac{ \sum_{i=1}^{N}(x_{i}-\mu)^{2}}{N}$ 样本方差 总体方差一般很难求出， 因为你没有办法获得总体数据。 但样本方差是可以求出的。对样本来进行分析， 从而估计出总体参数 $s^{2} = \frac{ \sum_{i=1}^{n}(x_{i}-\frac{}{x})^{2}}{n}$ 用样本方差来估计总体方差， 通常会低估总体方差的,所以我们要用这样的公式： $s_{n-1}^{2} = \frac{ \sum_{i=1}^{n}(x_{i}-\frac{}{x})^{2}}{n-1}$ 标准差 总体标准差 $\sigma = \sqrt{\sigma ^{2}} =\sqrt{\frac{ \sum_{i=1}^{N}(x_{i}-\mu)^{2}}{N}} $ 样本标准差$ s = \sqrt{s_{n-1}^{2}} = \sqrt{\frac{ \sum_{i=1}^{n}(x_{i}-\frac{}{x})^{2}}{n-1}}$ 标准差 比 方差 更容易解释， 因为标准差与数据的单位相同 对分布形态， 相对位置的度量 偏度 偏度 ：$\frac{n}{(n-1)(n-2)} * \sum (\frac{x_{i}-\frac{ }{x}}{s})^{3}$ 左偏， 偏度为负数， 右偏，偏度为正数，数据对称，偏度为0 当数据严重偏离时， 中位数是位置的首选度量。 z-分数 z-分数：$\frac{x_{i}-\frac{ }{x}}{s}$ 衡量数据对于平均值的相对位置， 比如z-分数为-1.5， 则表示此数据比平均值小1.5个标准差 切比雪夫定理 定理： 与平均值的距离在z个标准差之类的数据项所占比例至少为$(1-1/z^{2})$， z大于1。 当z为2,3和4个标准差时： 至少75%的数值与平均数的距离在z=2 个标准差之内 至少89%的数与平均数的距离在z=3个标准差之内 至少94%的数与平均数的距离在z=4个标准差之内 检验异常值 异常值： 当z-分数小于-3或着大于+3的数值视为异常值。 对两变量之间关系的度量 样本相关系数 相关系数的范围是-1~+1， 当数为0时， 线性不相关 $r _{xy} = \frac{ s _{xy}}{s _{x}s _{y}}$ 样本协方差：$s_{xy} = \frac{\sum (x_{i} - \frac{ }{x})(y_{i} - \frac{ }{y})}{n-1}$ x的标准差：$s _{x}$ 用python进行计算 12345a = [1,2,3,4]b = [2,4, 6,9]import numpy as npnp.corrcoef([a,b]) 1234import scipy.stats as statsstats.pearsonr(a,b)# 结果的第一个数为相关系数 123456import pandas as pddf= pd.DataFrame()df[&apos;a&apos;] = [1,2,3,4]df[&apos;b&apos;] = [2,4, 6,9]df.corr() 概率 组合 从N项中任取n项的组合 $c_{n}^{N} = \frac{N!}{n!(N-n)!}$ 用python来进行计算 123from scipy.special import comb, permcomb(5,2) 排列 从N项中任取n项的排列数 $P_{n}^{N} = \frac{N!}{(N-n)!}$ 用python来进行计算 123from scipy.special import comb, permperm(5,2) 概率的基本性质 事件的补$P(A) = 1 - P (A^{c})$ 事件的并 $P(A\bigcup B ) = P(A) + P(A) - P(A\bigcap B )$ 互斥事件 $P(A\bigcup B ) = P(A) + P(A)$ 条件概率 在事件B发生的条件下， A条件发生的概率 $P(A|B ) = \frac{P(A\bigcap B)}{P(B)}$ $P(A\bigcap B) = P(B)P(A|B) = P(A)P(B|A)$ 独立事件 两个事件A和B是相互独立的 $P(A|B) = P(A) $ $P(A\bigcap B) = P(A) P(B)$ 贝叶斯定理 计算方法： 先假定一个概率， 然后根据样本获得新的信息， 根据这些信息对 原先假设的概率进行修正， 得到准确的概率。 $P(A|B) = \frac{P(A) * P(B|A)}{P(B)}$ 数学之美番外篇：平凡而又神奇的贝叶斯方法 贝叶斯奥卡姆剃刀《数学之美》第24章《决策与判断》Machine Learning, a Probabilistic Perspective 贝叶斯推断及其互联网应用（一）：定理简介 贝叶斯学习与未来人工智能 《统计学关我什么事》 快速理解贝叶斯定理假设一家商城， 顾客分为： 想买商品的顾客，和随便逛逛的顾客。 假设， 随机走进来一个顾客，他为有意愿度的顾客占20%， 为随便逛逛的顾客占80%。 现在增加了一个主动询问店员的动作。 假设有意愿度购买的顾客， 向店员询问的概率为70%， 不询问的概率为30%。随便逛逛的客户， 主动询问店员的购买概率为 10%， 不询问的概率为 90%。 现在问 如果一顾客主动向店员询问， 那么他是有意愿购买的顾客的概率是多少。 有意向且询问的概率为 14%。 有意向不询问的概率为 6% 无意向且询问的概率为 8%， 无意向且不询问的概率为 72% 现在 主动询问这个动作已经做出了， 所以总体为两部分： 有意向且询问， 和无意向且询问 14:8 = 7:4。 所以她有意向且愿意购买的概率为 7/11 63.6% 如何判断她喜欢你的概率 贝叶斯定理 假设 你是一名女生， 在情人节这天， 一名男生送给你一盒巧克力， 你可能会有疑问，他是不是喜欢你， 他喜欢你的概率是多大？ 因为你没有证据来说明你就是他喜欢的类型， 所以， 我们假设 你或者是他喜欢的类型， 或者是一名路人。 假设各有50%的概率。 通过调查， 我们发现 一个男生对心意女生送出巧克力的概率为 45% 对路人送出巧克力的概率 为 20%， 那他现在送给你一盒巧克力， 在他已经送你巧克力的这件事情已经确定了， 所以他们现在是一个整体他喜欢你的概率是多少呢。 0.5 0.45 0.5 0.2 0.225 0.1 225 ： 100 225 / 325 = 69.2% 的概率会喜欢你 当然， 贝叶斯概率 能够计算出这个概率， 但是否要继续， 取决与你。 贝叶斯概率在我们生活中的应用是非常广泛的， 常见的， 比如 在邮件中的反垃圾邮件。 这是一种贝叶斯概率非常好的使用案例。 在上面的推理中， 我们总会觉得贝叶斯定理有些“牵强”牵强的原因主要是因为先验概率。 这种主观上假定或者大概的概率， 会让人感觉牵强。 但也正是由于设定了先验概率， 贝叶斯定理才会有即是只有少量信息， 也能够进行推理。 当然， 贝叶斯定理有另一学习功能， 就是信息越多， 推理结果就越精确。 离散型概率分布 离散型概率函数的基本条件： $f(x) \geqslant 0$ $\sum f(x) = 1$ 离散型随机变量的数学期望：$E(x) = \mu \approx \sum xf(x)$ 比如：掷一枚公平的六面骰子，其每次“点数”的期望值是3.5 方差$Var(x) = \delta ^{2} = \sum (x-\mu )^{2} f(x)$ 连续性概率分布 离散型概率分布和连续性概率分布的区别离散型： 概率函数给出了随机变量x取某个特定值的概率 连续性： 概率密度函数， 通过面积给出该区间取值的概率。 正态概率分布 正态分布的最高点在均值处， 标准差决定了曲线的宽度和平坦度。 正态分布曲线的总面积为1 标准正态分布 均值为0，且标准差为1 七周数据分析-统计学描述统计学1.数值数据 与 分类数据 分类数据描述统计频数统计频数百分比 平均数，中位数，众数、 分位数、方差、标准差： 描述数据的离散程度 数据标准化： Z-Score 公式： z = (x - u) / 方差 。 可以用数据标准化进行预估计算 切比雪夫定理-异常值检测 至少有75%的数据在两个标准差之内 至少有89%的数据在三个标准差之内 至少有95%的数据在5个标准差之内 概率 贝叶斯： 通过结果来反推原因 参加活动的人群中，女性只占30%， 是否说明女性不喜欢参加此类活动？ 某种疾病的发病率为千分之一。现在有一种试纸，它在患者得病的情况下，有99%的准确率判断患者得病，在患者没有得病的情况下，有5%的可能误判患者得病。现在试纸说一个患者得了病，那么患者真的患病的概率是多少？ 某城市有两种颜色的出租车，蓝车和绿车市场比率为15:85。 一辆出租车肇事逃逸，当时有一位目击者证人，这位证人认定肇事的出租车是蓝色的。但是他的目击未必可信，公安人员经过在相同环境下对该目击者进行“蓝绿”测试得到：80%的情况下识别正确，20%的情况下不正确。那么实际为蓝车的可能性是多少？ 我们经常会受到垃圾短信，假设1000条正常短信中，包含【澳门赌场】的短信有2条，而在垃圾短信中，包含澳门短信的短信有400条。现在我们接受到了一条新短信，在不浏览内容的情况下，假定它的正常几率是50%。现在对短信内容进行解析，发现澳门赌场这个词，那么它是垃圾短信的概率有多高。 二项分布 在各类促销活动中， 抽奖是一种常见的促销方式。现在希望运营方设计一个抽奖模式。用户能够抽10次，中奖概率是10%。如果用户抽中了3次及以上， 则公司会亏本。那么公司亏本的概率是多少？ excel 函数： BINOM.DIST 泊松分布 某医院急救中心一天收到呼叫次数服从泊松分布，平均数为20， 那么该急救中心一天收到15次呼叫的概率是多少？ 收到小于15次呼叫的概率是多少？ excel 函数： POISSON.DIST 正态分布 现在有一个 u = 10 和方差=2的正态随机变量，求x介于10到14之间的概率excel 函数： norm.DIST 假设检验 某个APP， 用户购买的平均转化率出25%， 在进行全新的产品设计之后，转化率变成了30%， 这个转化是波动？还是产品改进有效？ A/B 测试： Z检验]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑系统]]></title>
    <url>%2F2018%2F10%2F14%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E9%80%BB%E8%BE%91%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[结构化思维 什么是结构化思维 面对问题，能够通过某种结构， 把它拆解成一个个你能解决的部分。 怎么识别筛选信息 识别信息中的 结论、理由、事实 识别结论 找对方语句里表示结论的提示词 关注信息中的几个重要位置：开头、结尾 面对面交谈，问对方：所以呢。 看文章问自己：这篇文章想要表达的结论是什么？ 识别 支持结论的理由 关注话语里的一些提示词: 原因是、因为这个事实、有下列原因、鉴于、证据是、第一、第二、第三 识别事实 数据和不带感情色彩的事例 如何判断消息的真实性和可靠性 找到信息的结论， 画在金字塔塔尖 下一层，根据提示词的线索来找到支撑结论的理由。 从理由再往下，找有没有支撑理由的事实。 证明事实和理由， 理由与结论之间存在着强逻辑关系。 如何对信息进行分类 MECE 分类法： 不重不漏 二分法： 将信息分成A和非A两个部分。 过程法： 按照事情发展的时间、流程、程序、对信息进行逐一分类。 要素法： 从上到下、从外到内、从整体到局部。说明事物的各个方面特征。 公式法： 按照公式设计的要素去分类。 销售额 = 单价 × 数量。 矩阵法： 4象限 特定场景下的分类模型： 3c、 4p 如何提炼信息结论 结论是有中心思想的主题句 前： 上一年培训工作总结后： 去年打造有生命力的营销培训项目 提炼方法1： 归纳法 找出各个信息要素之间的共性。 描述性概括 找出事物属性上的共同点。 行动行概括 找出事件结果的共性。 先找到事物本身的共性，再通过总结事物发展的结论，给出一个完整有意义的结论信息。 概括需要彻底， 多问自己：所以呢？ 提炼方法2： 演绎法 大前提、小前提、结论 大前提 引用普适的真理或者客观事实，罗列不要超过三项。 避免主观判断。 小前提 最好是一个已经发生的事实。 如何清晰表达信息 四个原则： 论、证、类、比 论： 结论先行一次表达只支持一个思想， 最好能够出现在开头。 证： 以上统下任何一个层次的要点都必须是它下一个层次要点的总结概括， 指导最后一个层级的内容是客观事实或数据为止。 类：归类分组每一组要点必须要属于同一范畴。 比： 逻辑递进每个要点都需要按照一定的逻辑顺序进行排列。 顶层是总结论，然后支撑结论的要点要层层下分， 直到客观事实跟数据； 横向上，每一组要点都有一定的规律和分类， 彼此也是有逻辑关系的。 重要的事情说三点 首先， 给出结论 然后，给出支撑这个结论的三个理解。 它们之间符合“论证类比”的原则。 如何解决问题问题解决的4个层次 有没有找到真正的问题， 人都是有逃避心理的。 想到了问题的第几层 想到了最后一层， 并且去执行解决问题 做到了，并且分享帮助别人 工作中解决问题的方法 快速按照理解去做拆解，去做思维导图， 能想到多少是多少 拿着拆解思维导图去跟业务方的人去请教，一定要找到业务方真正关心的点 结合业务方给出的具体建议， 修改第一步的思维框架， 做完后，请教你的领导 再改一次， 回报给业务方领导 遇到坑之后， 一定要文档详细记录下来。 让团队中其他人知道， 节省团队时间。 知道自己在哪块花了大量时间，为后续分析节省时间。 解决问题的四个步骤 用80%的精力去拆解和定位问题， 剩下20%的精力去寻找解决方案。 明确和理解问题 一定要问自己： 我遇到的问题本质到底是什么 很多时候，领导在派任务的时候，可能并不足够清晰。 但这个问题到底是什么问题， 你可能不敢问，只能自己揣测。 请务必自己明确一下问题， 然后去跟托你解决问题的人确认一遍。 找出对方关心的问题点， 找对方确认。 人员流失超过50%， 您要解决的是不是这个？ 明确解决的目标 是将目标降低到30%， 还是10%? 明确用来解决这个问题的资源 需要人力部门提供离职数据等 拆分和定位问题 定位到“元问题” 元问题： 最本质、最细小的待解决的问题。复杂问题： 掺杂了多维度和变量的问题。 用公式思维拆解问题 广告收入 = 展现量 x 点击率 x 每个点击的价格 尽可能去寻找公式化方式。 假设驱动先做一个合理的假设，假设问题出在某个细分的问题点上。 节省时间，通过不断修改假设，然后根据新的假设去收集信息，验证信息，最终得到最接近真实的结果。 搭建逻辑树 找出核心问题和起始问题。 明确导致核心问题和起始问题的主要原因。 确定问题导致的主要后果 根据因果关系画出逻辑树 反复修改和审查逻辑树 MECE 法则 熟悉你所在领域的业务和常识 经常提问和学习，获得更多的信息，对熟悉领域有自己的一套理解，能够更好的拆解问题。 各种维度对比 提出解决方案 在实际生活当中，别人是否觉得是对的，要比你自己是否觉得是对的更重要一点？？？ 事实 —— 理由 —— 结论 总结问题 人生的 IPO 模型 输入 —— 处理 —— 输出 四个典型人生解决方案 不断问自己为什么 列一个清单，然后排序做选择 假设一种无条件获得的极端情况 不断了解你的选择，不断的去试错]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>逻辑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习系统]]></title>
    <url>%2F2018%2F10%2F12%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[如何高效学习合适的学习方法 学习方法一： 模仿 英语、书法、乐器等 学习可以碎片化，积少成多，以量取胜，平时注意量的积累。 学习方法二： 创造 注重结构，体系化的学习，学完之后，目的是为了创造，需要产生质变。 注意点 把你的目标要拆碎，针对那些细节进行反复的练习，不要一开始就顾全大局。 带着困惑和问题进行学习，多使用搜索功能。最终要将这些碎片链接起来。 用任务驱动学习 做事的驱动力 内部： 个人兴趣爱好 外部：做完任务之后带来的奖励 任务的三个方面 生活中的任务驱动 生活的更好 工作中的职业强迫 挣钱 以教为学 自己对自己设置的一个任务，设定的一个目标，任务驱动 以教为学，能够让你学的更好。 心态调整 在心态上要有一种自觉，自己来聘请自己，做任何事情都要这样做。 你要有一个非常清晰，并且实际的目标。 成年人要放弃一种需求，就是学什么东西都要有个兴趣，我们要放弃这样的想法。 我们要带着任务来驱动学习，没有任务自己创造任务，带着教别人的心态参加学习，效果是最好的。 –&gt;]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅读系统]]></title>
    <url>%2F2018%2F10%2F10%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E9%98%85%E8%AF%BB%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[困惑在日常的读书学习中，自己总是会出现这样的困惑， 就是发现自己看了很多书， 但是看完就忘。看完一本书也很难用其中的论点指导自己的生活，难道自己陷入看了那么多书，却依然过不好这一生的困境中吗？ 借鉴在最近翻阅的一本书《万万没想到-用理工科思维理解世界》中， 万维钢老师写的一篇【用强力研读书】中提出的读书观点，自己很受启发。在这篇文章中， 作者主要强调了读书要做到两点： 1. 一本好的书籍最少要读两遍2. 第二遍读书的时候一定要做笔记 反思自己的读书方法，就能够看到自己过去读书的很多问题: 自己看书为了追求看完， 总是囫囵吞枣的看， 看完一遍就将书扔到一边。 在看书过程中即使自己会有一些思考， 自己也不会马上记笔记将自己的思考写下来， 没有将书中的观点和知识内化到自己的系统中， 在以后遇到类似的知识也不会进行升级， 因为自己已经将这个知识忘光了。 方法当然，记笔记并不是将书中的总结性内容抄到笔记本上就完事了，在这篇文章中， 万维钢老师还详细的介绍了如何做才能让自己的读书效率最大化: 读好书一定要读两遍。第一遍是陷进去，按作者的思路去读。 第二遍跳出来， 抓住文章的精髓仔细读， 做笔记。 在读第二遍的时候要找出文章的思想脉络。很多时候你没有真正理解书中的内容， 就是因为看不到书中的脉络。因为你作为读者，看书是将用线性的视角来一行一行看的，而作者写一篇文章是将网状的思考， 把树状的结构， 用线性的语言表达出来。 书中每一个小章节的逻辑结构可能就只有几句话。 在你读书过程中要做的就是找出这样的逻辑结构。 当我们看到文章好的亮点时， 我们要把它记下来据为己有，也许是一句话， 也许是一个故事。记笔记， 是当你看到了一个想法之后很激动，必须把这个想法记下来据为己有的行为。 读书，在某种程度上就是寻找能够刺激自己思维的那些亮点， 我们在分析书本脉络的时候要忽略故事，分析完脉络再好的把故事带走。 当我们看书的时候，我们要写下自己对书中内容的评论， 就好像和作者对话一样。你可以对书中的观点表达支持， 质疑， 或者写下这个观点给了你启发— 让你想到了自己最近发生的一件事， 听过的一个故事， 你都可以写下来。 当你看完一本书的时候， 你也许会发现自己在另一本书上又发现相似的论点， 或者你在网上看到了另一个人对这个观点的表达， 这个时候， 你就要将不同地方看到的蕾西知识整理到自己的笔记上， 不断的完善它， 形成自己的观点， 并写文章发表出来。 再引述一下作者的话： 好书之所以要读两遍， 最重要的目的就是为了读书后的心得、灵感和联系。记笔记是对一本书最大的敬意，记笔记是个人知识的延伸。 总结总结文章的观点， 就是读两遍，理脉络，记笔记，写心得，融体系。能够做上述几点，相信你的读书效率一定会大大改善的。 最后，结合自己的经验，我认为如果为了提高自己的认知能力而读书， 就一定要记读书笔记， 要不读书的效率会差很多。要想改变读了那么多书却依然过不好这一生的困境，我觉得可以用自己很喜欢的一句话来进行回答： 知识不会改变命运，除非它带来行动；行动也不会改变命运，除非它带来结果；是一个一个的结果，在改变你的命运； 参考资料：1.《万万没想到-用理工思维看世界》2.《超级个体》 读书三问： 为什么我坚持读书写作很久了，却没有进步 有认真消化吗，自己读了以后，能教别人吗 你所写的内容， 是简单的搬运，还是行动之后的反思总结 不要只是读读写写，你得去做事，事上磨练，才是最好的学习方式 一年要读多少数 你更应该关心的是， 你能践行多少内容]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写作系统]]></title>
    <url>%2F2018%2F10%2F10%2F%E4%B8%AA%E4%BA%BA%E7%B3%BB%E7%BB%9F-%E5%86%99%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[写作准备： 从生活中想到一个你想要写的主题。 在日常中思考素材， 注意素材的积累。 想清楚你想表达的思想是什么， 用一句话表达清楚 写作， 是自我对话， 认识自己的一种方式。 写作的本质， 情绪 与 传递 文章风格： 逻辑 + 生活 + 有趣 写： 生活 —— 素材库 —— 观点库（逻辑，情绪） —— 结构库 —— 草稿库 检查： 逻辑是否清晰， 是否有自己的观点， 是否有趣 排版， 标题， 错别字 写作模板： 这篇文章主要表达什么思想， 用两句话来说清楚。 自己准备的素材都有哪些 自己选择什么布局？ 从证据到结论 从结论到证据 将第二重要的内容放首位， 最重要的内容放最后 写文章引言 提出一个现象， 或者一个有争议的观点， 由此导出你的观点。 讲一则简洁的故事， 这个故事能够很好地阐述你将要表达的观点 撰写文章的结论 简明进行综合， 告诉读者为什么应该赞同你的观点 对引言的故事加以评论 记住哪些观点需要论证， 以及你将如何论证 提供高质量的伦军来支撑自己的观点， 检查每一个观点和证据， 用以下各类方式呈现出来 提供事实性的细节， 比如数据 描述人或事 提供一篇文章或一本书的总结 引用或转述某个学者的观点 对真实或假设性事件简明或扩展地叙述 追溯历史发展 呈现字面上或者深层次的含义 细化某一过程或程序 解释相似性和差异性的联系与区别 分析原因或产生的影响 评价某人的观点 阐述其优点和不足 根据以上步骤写出你的草稿 修改用批判的眼光阅读初稿， 大声朗读出来。问自己以下问题： 我可以做什么上中心思想表达更清楚 哪个段落需要做进一步全面解释，以便上读者了解深意 怎样增强文章连贯性 用哪种形式编排句子和段落， 让文中思想更容易理解 我需要在哪加上过度聚， 用来标志转入下一个观点 哪些想法需要重点强调， 哪些可以一笔带过 怎样更好地强调重点， 我是否没有找到更充足的证据来支持观点 编辑找出表改正那些在语法、错字， 标点、加粗等问题 努力达到的标准 让文字看起来很自然 力求简洁 用简单的语言来表达你的观点 让你的句子富于变化 尝试不同的句子， 试着变化结构， 学习长短句交叉使用 让文字生动起来 尽量把你的想法用有想象力和有个人色彩的语言表现出来 好的写作能力， 对个人发展的赋能实在太大了，写作这件事，你需要突破 下笔困难，写不出什么好东西来，最大的问题在于输入的质和量跟不上 练习很重要，你可以每天写几十个字，每隔一段时间写一篇长点的 起步阶段，把某个你特别喜欢的作者的书籍，都找过来，逐字读5遍，你会发现，自己的表达风格，会有他的烙印。 追求简洁流畅、表达精准、有说服力 参考书籍：《思考的艺术》《金字塔原理》 有效写作的四个特点： 统一协调 用一两句话来清晰地表达你的想法，这篇文章的中心思想，指导你后面的写作。 连贯一致 明白观点的先后顺序， 当你转入另一观点时， 一定要将前一观点表述清楚。同时用一些连接词进行连贯的过渡。 重点突出 对重要观点进行详细阐述 将观点按重要程度进行排序，最重要的观点放在最后，次重要的论点放在开头，另外两个论点放中间。 拓展升华 详细阐述重要的观点，强调的点要能够引发读者的共鸣，可以使用例证、描述、定义、释义等方法 写作的阶段渐进法计划 整合观点在产生和评价了自己的想法之后，你就需要整理下自己要用到的材料。想法、笔记、他人观点等 选择布局 从结论到证据 先呈现结论，再通过例证来支持结论。 从证据到结论 让读者逐步接受你的结论。适用于辩驳那种广为人知或根深蒂固的观点。 从原因到结果 先讨论产生某一现象的原因，然后说明这一现象的影响。从结论到原因 重要性顺序 将第二重要的内容放在首位，最重要的内容放在最后 撰写文章引言的方法 提出一些突出的问题，并讨论可能的答案 讲一则简洁的故事，这则故事能够很好地阐述你将要表达的观点 引用名人名言，从而导入你的中心思想 提出一个你不同意的观点，由此导入你的观点 撰写文章结论的方法 根据内容中提到的争议提出一个可行方案 回答引言提出的问题，或对引言和故事加以评论 利用新的引言来深化中心思想 描述一则新故事，确保这则故事能够强化你的中心思想，并且不会带入新的问题 阐述采纳你观点的益处和不采纳你观点的害处 简明扼要地进行统合， 告诉读者为什么应该赞同你的观点。 哪些观点需要进行论证以及你将如何进行论证 写作系统-辉哥 2015年之前，随便写写2015-2018年， 为终身事业而写18年——至今， 日更 什么是写作系统 为什么要建立写作系统 怎么建立写作系统 写作技能： 要专注哪个领域个人成长 为什么要选择这个领域我擅长， 大家需要 写作技能要怎样才能持续提升大量的阅读相关的书籍， 大量的实践， 通过阅读和实践， 总结出自己的个人成长系统，并通过足够多的案例， 让自己的成长系统本身去迭代。 读者社群： 选择哪类读者对未来抱有希望，但是在现实中遭遇困惑的人。 为什么要选择这类读者从他们看到身上看到自己的影子 怎样获得更多匹配的读者持续就这个领域写出更好的作品， 出版书籍， 获取更大的认可。 怎样才能更好的满足读者在这个领域更好的需求自己更好的成长，并对成长系统梳理的更加清晰。 商业： 如何从写作中获益让读者获益， 并让读者支付会员费。 怎样获得持续稳定的收益在会员体系中提供稳定的， 并持续增加的正向收益，并获得很好的口碑， 鼓励会员进行链接。 怎样不断提升收益更好的作品，更多的读者，更好的引导转化 梳理自己的写作系统 驱动写作的一页纸：使命：愿景：价值观： 写作系统的目标：关键结果： 与写作相关的微习惯：每日阅读：每日写作： 如何判断自己的文章好坏-建议： 多写 这篇文章对读者是否真的有用 写作是双向沟通而不是单向表达 你能理解多少人，就能拥有多少读者。 内容质量判断： 逻辑严谨 论证精彩 逻辑推理的三个层面： 形式逻辑-formal logic 非形式逻辑-informatl logic 认知偏差纠正-coginitive bias correction 《thinking fase and slow》 cognitive bias list of cognitive bias 精彩的例子是攒出来的，不是找出来的。 《successe quation》 文采的判断： 修辞——类比 韵律—— 格式化写作： 提出一个观点 说明这个观点的意义究竟有多大 证明这个观点 驳斥对这个观点的质疑 说清楚这个观点的超级意义 我要说的是什么概念 这个概念为什么重要 这个概念普遍被如何误解 这个概念实际有什么意义 正确理解这个概念有什么意义 如何正确理解这个概念 错误使用这个概念有什么可怕之处 这个概念与什么其他重要的概念有重要的联系 《the walking dead》 写作的本质， 为了产生影响。我的读者读过之后有什么样的变化？ 《ask right questions》 关于自媒体：通过公众号，其实建立的影响力更重要，在这个过程你可以获取更多的资讯，更多的人脉，更好的产品信息和资讯，好的产品，人脉，这些价值是无价的，这些东西不是虚无缥缈的东西，而是实实在在在我们身上起到非常大的效果。 坚持写作（找到方向很重要），那么你其实可以收获巨大的价值和流量 你所写的文章，一定要从用户的角度去出发，模拟用户看了你的文章，是一个什么样的感受。不要着急，你去看现在的很多人，其实都意识到媒体的重要性，但是根本等不及，很多人动不动，才写两篇文章都想变现，我觉得这是太急功近利了，我自己写文章都写了6年了，跑步都跑了10年了，所以我非常能沉得住气，如果一件事可行，可以花时间去慢慢沉淀。 鼓励分享，鼓励写作，是你自己能更好的提升表达能力，沟通能力，建立影响力的方式，其价值是长远的。 写爆款赚钱快的年轻人不是没有，我最近撩了好几个，但不要说百里挑一，千里挑一都没有。我是个筛子，我看见的，去撩的，都是已经冒出来的，比如粥左罗这样的。那些冒不出来的，不好意思，我真看不到。几千个几万个年轻人里，我看到那么几个冒出来优秀的，我把他们介绍给大家，然后你们一看，好像很容易么，你们没看到分母啊。 分享一定是对的，分享即学习，有点耐心，坚持进步，慢慢的，你会受益，长远看，一定是对的]]></content>
      <categories>
        <category>个人系统</category>
      </categories>
      <tags>
        <tag>写作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas 库学习总结]]></title>
    <url>%2F2018%2F09%2F28%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-Pandas%E5%BA%93%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[python中的单引号，双引号，三引号的不同作用 Pandas简介Pandas是python数据分析中一个非常核心的数据库， 在日常的工作中经常需要使用Pandas库来对数据进行处理分析。Pandas的核心为两大数据结构， Series和DataFrame，Series用于存储一维数据， 而DataFrame存储多维数据。 常用的软件Anaconda是数据分析中运行python的一款利器， 安装教程可参考Anaconda入门使用指南 Series对象Series用于存储一维数据，由两个相互关联的数组组成， 主数组用来存放数据。 创建Series对象 1zy = pd.Series([2, 3, 4, 6, 7, 4], index = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;]) 查看Series对象的两个数组 12345# 查看元素zy.values# 查看索引zy.index 查看元素 1234567# 将zy看做Numpy数组，指定键zy[2]zy[0:2]# 指定标签zy[&apos;c&apos;]zy[[&apos;b&apos;, &apos;c&apos;]] 筛选元素 1zy[zy &gt;3] 查看组成元素 123# 查看包含的不同元素zy.unique()zy.value_counts() 通过字典来创建 1zy=Series(&#123;&apos;a&apos;:1,&apos;b&apos;:2,&apos;c&apos;:3&#125;) 时间函数12import timefrom datetime import datetime, time, timedelta 现在时间 1now = datetime.now() 昨天 12ysd = now - timedelta(days = 1)ysd = now.replace(day = now.day-1) 本月第一天 1month_first = now.replace(day = 1) 上月最后一天 1lastmonth_end = month_first - timedelta(days=1) 上月第一天 123lastmonth_first = now.replace(month = now.month-1, day =1)lastmonth_first = lastmonth_end.replace(day=1) 转化为日期形式 1this_firsts = lastmonth_first.__format__(&quot;%Y-%m-%d&quot;) 读取与写入Excel数据 读取文件夹的内容 1234567891011import pandas as pdimport numpy as npfrom pandas import Series, DataFrameimport osfile_list = os.listdir(r&apos;E:\工作文件\周报\周数据\测试\0902-0908&apos;)print(file_list, &apos;\t&apos;)# 读取当前文件夹地址os.getwd() 相对路径与绝对路径 https://blog.csdn.net/m0_37693335/article/details/81474995 读取xls格式Excel表 1234df = pd.read_excel(&apos;E:/工作文件/周报/周数据/测试/0902-0908/an-商品汇总-uv.xls&apos;)df = pd.read_excel(r&apos;E:\工作文件\周报\周数据\测试\0902-0908\an-商品汇总-uv.xls&apos;)df = pd.read_excel(r&apos;E:\工作文件\周报\周数据\测试\0902-0908\an-商品汇总-uv.xlsx&apos;) 读取csv格式Excel表 1df = pd.read_csv(&apos;E:/工作文件/周报/周数据/测试/0902-0908/商品汇总.csv&apos;) 读取txt格式数据 123456df = pd.read_table(r&apos;C:\Users\Administrator\Desktop\haha.txt&apos;)with open(r&apos;C:\Users\Administrator\Desktop\haha.txt&apos;, &apos;r&apos;) as f: df = f.readlines() df = np.loadtxt(r&apos;C:\Users\Administrator\Desktop\haha.txt&apos;) # 将txt文件存为numpy数组 将数据写入Excel表， 并输出 123data.to_excel(&apos;C:/Users/Administrator/Desktop/&apos;+&apos;商品分类.xlsx&apos;)data.to_excel(r&apos;C:\Users\Administrator\Desktop\\&apos;+&apos;商品分类.xlsx&apos;)data.to_excel(r&apos;C:\Users\Administrator\Desktop/&apos;+&apos;商品分类.xlsx&apos;) 其他数据格式 1234567891011121314151617181920# 从SQL表/库导入数据 pd.read_sql(query, connection_object)# 从JSON格式的字符串导入数据 pd.read_json(json_string)# 解析URL、字符串或者HTML文件，抽取其中的tables表格 pd.read_html(url)# 从你的粘贴板获取内容，并传给read_table() pd.read_clipboard()# 从字典对象导入数据，Key是列名，Value是数据pd.DataFrame(dict)# 导出数据到SQL表 df.to_sql(table_name, connection_object)# 以Json格式导出数据到文本文件df.to_json(filename) 常见问题： 当文件有中文时， 可能会出现错误：Initializing from file failed 有中文， 可以用此方法解决 12f = open(&apos;我的文件.csv&apos;)res = pd.read_csv(f) 修改数据格式，并存储 1234567891011121314151617181920212223import pandas as pdimport numpy as npimport os#切换工作目录os.chdir(r&apos;E:\detil_data&apos;)# 显示当前目录# os.getcwd()# 将目录变成列表data = os.listdir()# for 循环此目录for i in data: a = open(i) datas = pd.read_csv(a) datas.to_csv(&apos;F:\\zy_data\\文件\\&apos;+ i +&apos;222.csv&apos;, index=False,encoding=&apos;utf_8_sig&apos; )#datas = pd.read_csv(&apos;a.csv&apos;,encoding=&apos;gbk&apos;)# datas.to_csv(&apos;test12.csv&apos;, index=False,encoding=&apos;utf_8_sig&apos; ) 将求出的数据存储在excel中的多个sheet中 12345678910import pandas as pdfrom openpyxl import load_workbook writer = pd.ExcelWriter(&apos;F:/notebooks/zy_zhoushuju/zhoushuju.xlsx&apos;)btn_navigation.to_excel(writer, sheet_name = &apos;底部导航&apos;)shouye_top20.to_excel(writer, sheet_name = &apos;首页top20&apos;)shouyedier_top2.to_excel(writer, sheet_name = &apos;首页第二屏top20&apos;)writer.save()writer.close() 当文件特别大， 1个多G时， 可以用for循环查看数据 12for i in data: print(i) 查看大文件有多少列 1234data = open(&apos;E:/电信活跃用户数/2018-09-01至2018-09-11全国活跃用户明细.csv&apos;)data1 = pd.read_csv(data, iterator=True)data2 = data1.get_chunk(5)print(data2) 迭代器 对输出数据进行处理https://www.jianshu.com/p/5c0aa1fa19af 123456789101112131415import numpy as npimport pandas as pddf = pd.DataFrame(np.random.randn(150, 150))# pd.set_option('expand_frame_repr', False) #数据超过总宽度后，是否折叠显示pd.set_option('display.width', 100) #数据显示总宽度pd.set_option('max_rows', 100) #显示最多行数，超出该数以省略号表示pd.set_option('max_columns', 100) #显示最多列数，超出该数以省略号表示pd.set_option('max_colwidth', 16) #设置单列的宽度，用字符个数表示，单个数据长度超出该数时以省略号表示pd.set_option('large_repr', 'truncate') #数据超过设置显示最大行列数时，带省略号显示/若是info则是统计信息显示pd.set_option('show_dimensions', True) #当数据带省略号显示时，是否在最后显示数据的维度print(df)pd.set_option('max_info_columns', 100) #当列数超过这个值时，调用df.info()函数时不会统计每列的非空值。print(df.info()) 将数据变成小数形式12345678910import pandas as pd inputfile = '../data/electricity_data.xls'outputfile = './electricity_data_analyze1.xls' data = pd.read_excel(inputfile)data[u'线损率'] = (data[u'供入电量']-data[u'供出电量'])/data[u'供入电量'] #data[u'线损率']的类型为series； data[u'线损率']为小数data[u'线损率'] = data[u'线损率'].apply(lambda x: format(x, '.2%')) #Series.apply()让序列的值依次在lambda函数中执行； data['线损率']由小数转化为百分数 data.to_excel(outputfile, index=False) 描述数据 表信息 1df.info() 显示数据的行列数 1df.shape 查看数据格式dtpyes 1df.dtypes 显示列名、元素 12df.columnsdf.values 添加默认列名 12# 如果数据没有标题行，可用pandas添加默认的列名df = pd.read_excel(&apos;x.xlsx&apos;, header = None) 显示前数据前5行 12df.head(5)df[[&apos;标题&apos;, &apos;客户端uv&apos;]].head() 显示数据后5行 1df.tail(5) 值 1df.values 读取a列 1df[&apos;a&apos;] 修改索引 1df = df.set_index[&apos;标题&apos;] 显示数据唯一值（unique函数） 12# 数据有0， 是因对缺失值进行了填充df[&apos;经纪人级别&apos;].unique() 对第几行数据不读取 12#不读取哪里数据，可用skiprows=[i]，跳过文件的第i行不读取df = pd.read_excel(&apos;x.xlsx&apos;,skiprows=[2] ) 对缺失值进行识别 12# 所有缺失值显示为Truepd.insull(df) # df.isnull() 计算 1234567891011#计算此data的数量df[&apos;data&apos;].value_counts()# 升序计数df[&apos;data&apos;].value_counts(ascending = True)# 升序计数并分组df[&apos;data&apos;].value_counts(ascending = True, bins = 2)# 计数df[&apos;data&apos;].count() 数据清洗 删除空值 （dropna函数） https://blog.csdn.net/yuanxiang01/article/details/787388121df.dropna(how=&apos;any&apos;) 123456789用法：DataFrame.drop(labels=None,axis=0, index=None, columns=None, inplace=False)参数说明：labels 就是要删除的行列的名字，用列表给定axis 默认为0，指删除行，因此删除columns时要指定axis=1；index 直接指定要删除的行columns 直接指定要删除的列inplace=False，默认该删除操作不改变原数据，而是返回一个执行删除操作后的新dataframe；inplace=True，则会直接在原数据上进行删除操作，删除后无法返回。 123# 删除包含 集团 二字 的行read_data = data_excel_2[- data_excel_2[&apos;所属省份名称&apos;].isin([&apos;集团&apos;])] 填充空值（fillna函数） 12345# 空值用0填充df.fillna(value=0)# 用均值对空值进行填充df[&apos;经纪人响应时长&apos;].fillna(df[&apos;经纪人响应时长&apos;].mean()) 更改数据格式 12# 将数据格式int64,改为float格式df[&apos;大区&apos;].astype(&apos;float64&apos;) 更改列名称, 修改列名。 123data2.columns = [[&apos;导航&apos;,&apos;uv&apos;, &apos;pv&apos;,&apos;户均点击&apos;]]df.rename(columns=&#123;&apos;IM渠道&apos;: &apos;渠道&apos;&#125;) 找到重复值 1df.duplicated() 删除重复值 https://www.cnblogs.com/cocowool/p/8421997.html 12345# 默认第一次出现的保留，其余删除df[&apos;门店&apos;].drop_duplicates()最后一次出现的保留，其余删除df[&apos;门店&apos;].drop_duplicates(keep = &apos;last&apos;) 对列表内的值进行替换 1df[&apos;客户UCID&apos;].replace(&apos;10531975&apos;, &apos;110&apos;) 找出异常值 12print(data.describe())# 对异常值进行删除 修改数据 1234567891011121314# 修改结果df.replace(参数)# 修改索引df.rename(参数)# 增加, 将一列数据添加到另一列数据后。 df.append(参数)# 删除def df[&apos;a&apos;]df.drop([&apos;a&apos;, &apos;b&apos;], inplace = True) 对数据进行处理 对两个数据进行合并- mearge, join, concat函数 1234567891011121314151617181920212223242526272829303132# 按照轴把多个对象拼接起来pd.concat(df1, df2)# join函数适合根据索引进行合并，合并索引相同但列不同的对象# merge函数，根据一个或多个键连接多行, 相当于excel中的vlookupleft = pd.DataFrame(&#123;&apos;key&apos;:[&apos;ko&apos;,&apos;k1&apos;,&apos;k2&apos;,&apos;k3&apos;], &apos;key2&apos; : [&apos;ko&apos;,&apos;k1&apos;,&apos;k2&apos;,&apos;k3&apos;], &apos;A&apos; :[&apos;ao&apos;,&apos;a1&apos;,&apos;a2&apos;,&apos;a3&apos; ], &apos;B&apos; : [&apos;bo&apos;,&apos;b1&apos;,&apos;b2&apos;,&apos;b3&apos; ]&#125;)right =pd.DataFrame(&#123;&apos;key&apos;:[&apos;ko&apos;,&apos;k1&apos;,&apos;k2&apos;,&apos;k3&apos;], &apos;key2&apos; : [&apos;ko&apos;,&apos;k1&apos;,&apos;k2&apos;,&apos;k4&apos;], &apos;c&apos; :[&apos;co&apos;,&apos;c1&apos;,&apos;c2&apos;,&apos;c3&apos; ], &apos;d&apos; : [&apos;do&apos;,&apos;d1&apos;,&apos;d2&apos;,&apos;d3&apos; ]&#125;)# 将left和right进行合并pd.merge(left, right)# 指定以key为键进行合并pd.merge(left, right, on = &apos;key&apos;) pd.merge(name_3, name_1, left_on = [&apos;ming&apos;], right_on = [&apos;标记&apos;])# key2列不相同的部分会直接舍弃掉pd.merge(left, right, on = [&apos;key&apos;, &apos;key2&apos;])# 保留key2列不相同的部分pd.merge(left, right, on = [&apos;key&apos;, &apos;key2&apos;], how = &apos;outer&apos;)# 不相同的部分指定以左表为基准pd.merge(left, right, on = [&apos;key&apos;, &apos;key2&apos;], how = &apos;left&apos;) 将 list 格式转化成 DataFrame 格式 1df = pd.DataFrame(data, columns = [&apos;省份&apos;, &apos;按钮名称&apos;, &apos;uv&apos;, &apos;pv&apos;] ) 对数据进行排序 12345data =pd.DataFrame(&#123; &apos;group&apos;:[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;a&apos;], &apos;data&apos; : [4, 2, 5, 6, 7, 8, 2, 9, 4]&#125;)# 在保证group列降序的情况下，对data列进行升序处理data.sort_values(by = [&apos;group&apos;, &apos;data&apos;],ascending = [False, True], inplace = True) 对数据进行分组——excel中的数据透视表 123456789# 如果price列的值&gt;3000，group列显示high，否则显示lowdf[&apos;group&apos;] = np.where(df[&apos;客户当天发送消息数&apos;] &gt; 5,&apos;high&apos;,&apos;low&apos;)# 对符合多个条件进行分组# 符合经纪人级别为A1且经纪人响应时长&gt;24的在sign列显示为1df.loc[(df[&apos;经纪人级别&apos;] == &apos;A1&apos;) &amp; (df[&apos;经纪人响应时长&apos;]&gt;= 24.0), &apos;sign&apos;]=1 对数据进行分列 12pd.DataFrame((x.split(&apos;网&apos;) for x in df[&apos;客户注册渠道&apos;]), index=df.index,columns=[&apos;客户注册渠道&apos;,&apos;size&apos;]) 新增一列 123data = data.assign(ration = [4, 2, 5, 6, 7, 8, 2, 9, 4])data[&apos;rations&apos;] = [5, 2, 5, 6, 7, 8, 2, 9, 4] 对数据进行切分 12bins = [1,3,6,9]data_cut = pd.cut(data[&apos;data&apos;], bins) 取出的数据， 指定取到小数点几位数？ 123# 取到小数点后3位for i in a : print(&quot;) 对数据进行提取,筛选12df = pd.DataFrame(&#123;&apos;A&apos;:[7,8,9,20, 10, 11, 14, 13, 14], &apos;B&apos; : [1,2,3,4,5, 6, 7, 7, 8]&#125;) 按条件进行提取 1234567891011121314151617181920212223242526272829# 选出B列的值大于3的数df[df[&apos;B&apos;]&gt;3]# 当 A列的值大于13时， 显示B，c列的值df[[&apos;B&apos;,&apos;C&apos;]][df[&apos;A&apos;]&gt;13]# 用isin函数进行判断# 使用isin函数根据特定值筛选记录。筛选A值等于10或者13的记录df[df.A.isin((10, 13))]# 判断经纪人级别是否为A3df[&apos;经纪人级别&apos;].isin([&apos;A3&apos;]) # 先判断结果，将结果为True的提取#先判断经纪人级别列里是否包含A3和M4，然后将复合条件的数据提取出来。df.loc[df[&apos;经纪人级别&apos;].isin([&apos;A3&apos;,&apos;M4&apos;])]# 使用&amp;（并）与| （或）操作符或者特定的函数实现多条件筛选 # A列值大于10， 并且B列值大于5df[(df[&apos;A&apos;] &gt; 10) &amp; (df[&apos;B&apos;] &gt;5)]df[np.logical_and(df[&apos;A&apos;] &gt; 10, df[&apos;B&apos;] &gt; 5)]# A列值大于10，或 B列值大于5df[(df[&apos;A&apos;] &gt; 10) | (df[&apos;C&apos;] &gt;20)]df[np.logical_or(df[&apos;A&apos;] &gt; 10, df[&apos;C&apos;] &gt; 20)] 按索引进行提取 12345678910111213141516171819202122232425262728293031323334353637383940414243# 按标签索引df[1:4]# 传入列名df[[&apos;A&apos;, &apos;B&apos;]]# loc函数# 知道column names 和index(这里df的index没有指定，是默认生成的下标)，且两者都很好输入，可以选择 .loc同时进行行列选择# 根据标签取第一行， 显示为DataFrame格式df.loc[:0]# 取标签为2,3,4， A列的数据， 显示为Series格式df.loc[2:4, &apos;A&apos;]# iloc函数# 行和列都用index来进行提取df.iloc[0:5, 1:3] # 返回第一行 df.iloc[0,:]# 返回第一列的第一个元素df.iloc[0,0]#[0, 2, 5] 代表指定的行，[ 4, 5 ] 代表指定的列df.iloc[[0,2,5],[4,5]]# ix#ix的功能更加强大，参数既可以是索引，也可以是名称，相当于，loc和iloc的合体df.ix[1:3, [&apos;A&apos;, &apos;B&apos;]]# at函数根据指定行index及列label，快速定位DataFrame的元素，选择列时仅支持列名df.at[3, &apos;A&apos;]# iat函数选择时只使用索引参数df.iat[3, 2] 按日期进行提取 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import pandasimport datetime as dt# 重新设置索引df.reset_index()#设置日期为索引df=df.set_index(&apos;日期&apos;)#提取2016年11月2号的数据df[&apos;2016-11-02&apos; : &apos;2016-11-02&apos;]dt_time = dt.datetime(year = 2018, month=9, day = 17, hour = 22, minute = 43)print(dt_time)#构造时间ts = pd.Timestamp(&apos;2018-09-17 22:43:00&apos;)ts = pd.to_datetime(&apos;2018-09-17 22:43:00&apos;)ts = pd.to_datetime(&apos;17/09/2018 22:43:00&apos;)# 月份ts.month#日期ts.day# 加日期ts + pd.Timedelta(&apos; 10 days&apos;)ts.hour# 构造时间序列， 构造十个日期， 每12分钟一次pd.Series(pd.date_range(start = &apos;2018-09-17 22:43:00&apos;, periods = 10, freq = &apos;12min&apos;))读取文件， 有时间列， 先将时间字符串转换成时间格式， 再进行处理或当读取数据时， 就对数据格式进行修改data = pd.read_csv(&apos;.../db.csv&apos;, index_col = 0, parse_dates = True)# 读取时间为2013年的所有数据data[&apos;2013&apos;]# 取所有8点到12点之间的数据, 不包含8点和12点data[(data.index.hour &gt; 8) &amp; (data.index.hour &lt; 12)]# 包含8点到12点data.between_time(&apos;08:00&apos;, &apos;12:00&apos;)# 时间序列的重采样-看每月的平均值data.resample(&apos;M&apos;).mean() 数据汇总 对数据进行分类 - group by函数 123456789101112131415161718192021222324# 创建数组df = pd.DataFrame(&#123;&apos;key&apos; : [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;,&apos;a&apos;, &apos;b&apos;, &apos;c&apos;,&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], &apos;data&apos; : [0, 2, 4, 5, 6, 7, 8, 9, 4]&#125;)# 分别计算a, b, c 的和df.groupby(&apos;key&apos;)[&apos;data&apos;].sum()df.groupby(&apos;key&apos;)[&apos;data&apos;].mean()s = pd.Series([1, 2, 3,1, 2, 3],[8,7,6,8,7,6])# 对索引进行排序grouped = s.groupby(level = 0， sort =False)grouped.first()df2 = pd.DataFrame(&#123;&apos;x&apos;:[&apos;a&apos;, &apos;b&apos;, &apos;a&apos;, &apos;b&apos;], &apos;y&apos; : [1, 2, 3, 4]&#125;)# 只关注x中的bdf3 = df2.groupby([&apos;x&apos;]).get_group(&apos;b&apos;)# 查看个数df2.size() 对数据进行透视, 相当于Excel中的数据透视表功能。 将行变为列 12345678910111213pd.pivot_table(data, values=None, index=None, columns=None, aggfunc=&apos;mean&apos;)df = pd.DataFrame(&#123;&quot;A&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;], &quot;B&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;, &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;], &quot;C&quot;: [&quot;small&quot;, &quot;large&quot;, &quot;large&quot;, &quot;small&quot;, &quot;small&quot;, &quot;large&quot;, &quot;small&quot;, &quot;small&quot;, &quot;large&quot;], &quot;D&quot;: [1, 2, 2, 3, 3, 4, 5, 6, 7]&#125;)table = pd.pivot_table(df, values=&apos;D&apos;, index=[&apos;A&apos;, &apos;B&apos;], columns=[&apos;C&apos;], aggfunc=np.sum) 将列变为行 1pd.melt(df2, id_vars=[&apos;date&apos;], value_vars = [&apos;&apos;,&apos;&apos;]) 对数据进行映射 12# 用map函数对字典进行映射， 新加一列data[&apos;upper&apos;] = data[&apos;group&apos;].map(dataUpper) 数据统计 数据采样 12345678910111213# 简单随机抽取sampledf.sample(n=3)# 设置采样权重# 需要对每一行进行权重设置，列表行数少可行，过多不可行# 假设有4行数据，设置采样权重weights = [0, 0, 0.5, 0.5]df.sample(n=4, weights=weights)## 确定采样后是否放回# 采样后放回，Truedf.sample(n=6, replace=True) 统计计算 1234567891011121314151617181920# 描述统计 describe函数#自动生成数据的数量，均值，标准差等数据#round（2）,显示小数点后面2位数，T转置df.describe().round(2).T# 标准差std()df[&apos;经纪人响应时长&apos;].std()# 协方差covdf[&apos;经纪人当天发送消息数&apos;].cov(df[&apos;客户当天发送消息数&apos;]# 相关性分析corrdf[&apos;客户当天发送消息数&apos;].corr(df[&apos;经纪人当天发送消息数&apos;])# 中位数df.median() 对字符串进行操作 大小写 12a.lower()a.upper() 长度 12# 长度a.len() 去除空格 123a.strip()a.lstrip()alrstrip() 替换 1df.columns.str.replace(&apos; &apos;, &apos;_&apos;) 切分与分列、 合并 1234567891011121314151617181920212223242526272829#切分a.split(&apos;_&apos;)# 切分， 且成为新列a.split(&apos;_&apos;, expand = True)# 对切分进行限制, 只切1次a.split(&apos;_&apos;, expand = True, n=1)# 查看是否包含a.str.contains(&apos;A&apos;)# 分列s.str.get_dummies(sep= &apos;|&apos;)# pandas对dataframe中的某一列使用split做字符串切割：# words = df[&apos;col&apos;].split()# 报错：# AttributeError: &apos;Series&apos; object has no attribute &apos;split&apos;# 原因是df[&apos;col&apos;]返回的是一个Series对象，需要先把Series对象转换为字符串：pandas.Series.str.split# words = df[&apos;col&apos;].str.split()对两列数据进行合并df[&apos;省份_名称&apos;] = df[&apos;省份&apos;].str.cat(df[&apos;名称&apos;],sep = &apos;_&apos;) 读取excel 中的各个sheeht名称，并且进行合并12345678910rbook = []kong_data = os.listdir(r&apos;F:\zy_data\省资源位数据\3月省资源位数据\省资源位&apos;)for file_name in kong_data: data_excel = pd.ExcelFile(r&apos;F:\zy_data\省资源位数据\3月省资源位数据\省资源位\\&apos;+file_name) sheet = data_excel.sheet_names for i in sheet: data_button_rest = pd.read_excel(r&apos;F:\zy_data\省资源位数据\3月省资源位数据\省资源位\\&apos;+file_name, sheet_name= i ) rbook.append(data_button_rest) result_df =pd.concat(rbook)datas_excel = pd.DataFrame(result_df) 将运行的所有数据都展现出来， 而不是只展现最后一条12from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = &quot;all&quot; 字符和数值之间的转化int() # 转化成整数float() # 转化成浮点数str() # 转化成字符type() # 查看格式 `]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个好用的插件]]></title>
    <url>%2F2018%2F09%2F25%2F%E7%94%9F%E6%B4%BB%E8%B5%84%E6%96%99-%E5%A5%BD%E7%94%A8%E7%9A%84%E6%8F%92%E4%BB%B6%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[一个好用的插件神器最近发现了一个特别能够提高生活幸福感的插件：Tampermonkey, 中文翻译过来叫做油猴。 安装好这个插件最大的作用， 就是我们可以从Greasy Fork这个网站来安装我们需要的脚本， 从而极大的提高浏览器的使用效率。 比如：我们在Greasy Fork网站找到智能划词翻译这个脚本， 然后点击安装脚本即可。安装完成脚本之后， 我们打开一个英文网页，对需要翻译的段落进行框选，点击翻译按钮，就可实现在原网页查看中文翻译， 对于我这种英语不好的人来说， 有很大的帮助。 我们还可以安装微博过滤设置脚本，来对微博页面进行个性化设置， 自己设置完成后的微博页面是这个样，相对于原版网页来说简洁了不少。 也可安装微博浮图脚本， 查看微博图片也比较方便， 只需把鼠标光标放在图片上即可 如果想找资料或电影资源的话， 也可以下载豆瓣资源下载大师, 或百度网盘直接下载助手等脚本， 当然，有能力还是要支持正版。 例如：安装豆瓣资源下载大师脚本后， 打开豆瓣电影网页， 页面是这个样子。 在Greasy Fork这个网站还有很多别人写好的脚本， 比如百度文库文字复制、购物党自动比价工具、 Download Youtube videos and subtitles等好用的脚本， 可以根据自己的需要进行安装。]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于工作和成长的建议（脱不花）]]></title>
    <url>%2F2018%2F09%2F02%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%85%B3%E4%BA%8E%E4%BA%BA%E7%94%9F%E5%92%8C%E5%B7%A5%E4%BD%9C%E7%9A%84%E5%BB%BA%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[面对批评 面对批评，得体的第一反应是“不急于解释， 不反唇相讥”。 很多批评的发生时是因为误会。所以，首先建立情感层面的信任，其次澄清事实，然后才是消除误会。这三步能解决大部分因批评带来的关系问题。 被批评时，思考的重点应该是“我应该从哪里入手解决问题”，而不是“对不对”。 对“评论”不理不睬，对“批评”高度重视。 如果对批评有不同意见或者不明之处，直接问当事人的完整意见。别回避。 关于单身生活 单身过得不愉快，有伴侣之后也不会愉快。 单身且愉快，一个重要前提是有较高收入且未来可期。 单身时最值得花时间去做的是投资一切长本事长能耐的事儿：学习、进修、放纵好奇心。因为有伴侣以后很难再有大块时间可以自由支配。 拥有联系非常紧密的至交好友，且能够共同成长，两个条件缺一不可。 不够紧密则对彼此生活缺少实际支持，不能同步成长则无法长期维持关系。 建立自己的生活秩序， 但要有弹性。 弹性是指随时可以接纳一个因伴侣而带来的新秩序。很多人被动长期单身的原因是因为沉浸在自己的世界里、过度缺乏弹性以至于无法接纳别人。 积极参加有意思的社交活动，认识陌生人，多交朋友。 选择偏保守的理财方式，给自己买足额的大病保险，小心对待自己的钱。 和婚姻生活质量较高的人交朋友，人在面临重大选择时需要榜样和示范。 不要上来就用长期关系的标准要求对方，关系是递进的：可见、可约、可睡、可长期交往，然后才是可固定长期关系。在不同阶段，标准不一样。 主动点。对一切事。 关于个人形象管理 对普通人来说，“好看”的意思其实等同于“体面”。做到体面，完全是任何人能力范围内的事情。并非苛求。 清洁是最低标准。对于现代化城市工作生活的职场人来说，清洁的定义就是每天洗澡每天换衣服搽皮鞋。 你看起来像什么地位，你就是什么地位。 把衣服的数量最小化，然后把单价提高到力所能及范围内的最高。 尽快找出自己的“基本形象”：任何人都会有一个最佳穿衣模式，固定下来。 健身可以帮助你更好的认知自己的身体，再贵的衣服也纠正不了驼背弯腰的仪态。 一个人从里到外让人有“看起来好干净”的感觉，是一种极高的形象水平。 那些质疑个人形象管理重要性的人，从来都不会知道因为糟糕的形象而损失了什么。 关于重大选择 尽自己最大努力做到有钱、好看、有本事、受欢迎。手里的牌多一些，做选择的主动性就高一些。 选择大于能力。有人管这个叫“命运”。其实是一种长期被忽略的能力：关键时刻快速做出最优选择的能力。 最优选择就是对个人远期价值最大化的选择。过于关注当下利益往往是人生的大坑。那些抱着要给未来的孩子找个好爸爸的女生，在婚姻生活中往往过得比寻找最佳男朋友的女生要好，就是这个原理。 成大事者不纠结。一旦决定，全力以赴。 掌握“概率权”。 两张牌，一张掀起来保证给你一百万美金，另一张有百分之五十的概率有1个亿美金，或者为零。想清楚，选哪张？怎么选？ 可以征求别人的意见。但是这个“别人”是特指那些你由衷佩服和学习的对象。 无论别人给你什么意见，都要记住决定是你自己的。不要依赖别人，更不要把后果归罪于外。 远离安全的舒适区。 远离颠倒梦想，乐于动手做具体事，少想，多干。 做选择时不要只看自己，要看如果做了一个决定之后，你会跟什么样的人混在一起。事业选择这一点尤为重要。 关于人际关系 良性的人际关系只有一种， 叫做独立自主、强强联合。从来就没有抱团取暖这回事。 做到对别人有价值， 是建立良性人际关系的前提。 哪怕是暂时只创造了微小的价值，也是价值。 所有关系中最多正向循环最少事后负担的， 是交易关系。市场最残酷但也最善意。 所有关系中最危险最有破坏力的， 是纯感情关系。 所以， 一段关系想要良性发展，要有能力从纯感情喂养，发展成“复合材料”： 比如就婚姻而言，激情不长久，但是双方可以成为共同成长的伙伴，或者某个具体目标的合作者。甚至就亲子关系而言，也可以发展出协同学习的伙伴关系。 不成为别人的负担。 这包活了不成为别人的心理和时间负担，接受别人对自己的不接受。 对自己负责。这包括了对自己的选择和决定负责，承受由之而来的任何后果。 定期梳理和剖析自己的原生家庭和亲密关系。 适度学习一点帮助自我认知的方法，清楚认识并且正面接受自己在人际关系中的短板和问题。大量的人际关系能力缺陷是在原生家庭中已经形成，无需自卑或者自责，因为正面接受自己是战胜这一问题的开始。而且大部分人的大部分心理障碍是可以被消除的。 第一反应是选择信任别人， 但是同时保持独立思考的能力。 人际关系不仅有交互频率这一个维度，还有交互深度。 熟人未必是知己。 远离巨婴、远离不具有建设性能力的人。 人际关系是一个人真实自我的外在镜像。 关于命中贵人 贵人是那些在关键时刻给出关键点拨的人。 他们有能力呈现世界的本来面目。路原来就在那里，但是没有他们的指路你就看不见。 他们之所有原因帮你是因为他们的修行，而不是因为我的能耐和好处。 对他们最好的回报是努力成为和他们一样的人。 贵人不是等到的，是寻到的和求到的。前提是对他们而言至少你不是减分项。 以求道之心与人交往。 举手之劳、锦上添花，才是良性关系。不要求人雪中送炭。跟世态炎凉没关系，有则感谢珍惜，无则检讨自己。 务必定期让人看到帮助你的结果，分享喜悦和成果。 逢年过节快递两盒点心，送一辈子，也不算有礼。若想要感谢对方，花心思观察，送出终身难忘的礼物。 不要黏着对方，不要成为别人的负担。要让对方感觉掌握关系的主动权。人家帮过你，但最怕被要求帮你一辈子。 有机会帮别人的时候，姿态放低再放低，尽量不让对方有心理压力。帮完之后，对方不提，自己不提。 也许终有一天你会超过那些你生命中曾经那么重要的人，往前看，别害怕。 既往不恋。 关于压力管理 压力是公平的。 真正在入世过活的人，没有人能够置身事外。坚信这一点，不易起怨懑(men)之心。 职场压力和生活压力无法互相消解。因此不要把压力释放错了地方。 做一个乐观的悲观主义者。因上努力，果上随缘。 充分想象最坏的结果，如果认为是无法承受的后果，一定源自自身的贪婪，果断踩刹车。君子不立危墙之下。 压力无法被替代，注意力可以被转移。到难以承受之际，刷一小时消消乐，剧烈运动两小时，都可以回血。问题依然还在，但不妨缓口气再来。 有无话不说且旗鼓相当的朋友。说出来可能是最有效的减压之道，并非有人可以安慰你，而是因为站在别人的视角重新看一遍问题会简单很多。 做不到上一条，就试着把压力和问题写下来，只给自己看。然后会发现其实没有那么复杂。 永远用最直接的方式面对压力源。拖延和迂回只会让压力变大。 永远不做任何不能让别人知道的决定和交易， 无论好处有多大。 把压力想象成一个具体的形象，比如一只怪兽，每处理一步，就在脑海里给丫一拳。 关于工作习惯 自己最受益的工作习惯是做笔记。 最佩服的是会面后最先共享笔记的人。 当日事当日毕能提升工作中的幸福感。 有关人的问题，都不可拖延，不要心存侥幸，认为可以避免直面冲突或对方可以心领神会。越晚着手，问题会恶化的越严重。难听的话必须当面说、尽早说、直接说。 个人行动养成彩排的习惯。打腹稿、做预案。认真准备，就能发现达到一个目标的N种途径，行动中灵活不纠结。 团队作业养成复盘的习惯。不追究具体人责任，着眼于我们学到了什么。 每天琢磨核心数据。问出好问题。 与人面对面交流时不刷手机。 开会时敢于并善于终结无实质意义的对话，直切主题。致力于达成行动共识。 准时参加与别人的约会，不迟到。 每天早中晚三次集中时间段处理社交媒体、邮件等方面的信息。不要随刷随到。这是最节省时间的办法。 购置最好的工作装备。 睁大双眼找个好搭档，和聪明人一起工作。 关于自我成长 早晚你会知道，这个世界上没有别人。你所看到的都是，你自己的认知模式创造的镜像。 与此同时你会知道，这个世界上全是别人。所谓反复追寻的“真我”实在是小到不能再小的东西。 同时知道并接受上述两点，自我成长这件事才真正开始。 最难的在于不断建立更高的标准。为了解决这一问题最有效的方法是，不断结识更好的榜样。 在人际关系中做一个能力型“势利眼”， 向上看、向前看，与比自己优秀的人交往。 既往不恋，不回头，不怀旧，不惋惜。 以真实的、认识的人为榜样，而不是“传说”中的。因为真人会在每天的交往中给你真实的压力。 慎独。守心如镜。 每天独处时问问自己，今天有什么是比前一天做的好的 不做负面表达，负面包括讽刺、抱怨、指责、争论、批评、牢骚、大话、评价议论。凡事从建设性出发。 认真记录并揣摩与别人的交往。 尽可能扩大自己的阅读面。 文科生多阅读点科学著作，理科生不妨研究点文学艺术。阅读是为了理解人。 带徒弟是逼迫个人成长的绝招。 不相信“适当的年龄”这件事。除了生孩子，想做任何事情都不会被年龄限制。 关于机会和陷阱 世界上最大的陷阱，叫做“机会型陷阱”。 评估一下这件事对多少人有利？越是多赢的局面，越可能是个机会，反之如果只有你占尽便宜，那肯定不是机会。 想想这件事是不是很容易做到？有两种事。一种是机灵事：开头就炸，但是越来越没劲。另一种是苦逼事：开头特难，但是越干门槛越高。前者是陷阱，后者是机会。结硬寨、打呆仗是不变的真理，很容易实现的事情，是技巧，不是机会。 看忽悠你干这个事的人跟这事的关系。如果对他在精力上只是业务兼职，在财富上只是锦上添花，而你要付出全部精力，搭上全部身家。那么，要警惕是个陷阱。 周边人赞成与否不重要，但是否出手帮你很重要。一旦开始干，帮你的人越来越多的事，机会。反之，陷阱。 因资源而启动的事，容易翻转为陷阱。因顺势而发生的事，容易找到机会。 推动社会新分工的事，也就是越来越多的人靠这事吃饭养活一家老小的事，机会。在各种裂缝中套利，除了你谁都没好处的事，陷阱。 做成之后，容易被巨无霸们摘果子的事，陷阱。做成之后，自成体系的事，机会。换句话说，南瓜不会结在树上。有命长出来，没命hold住。 就算做成了，也有后遗症的事，陷阱。就算做不成，也长本事长江湖地位的事，机会。 摊在桌上打明牌也能干的事儿，机会。必须遮遮掩掩唯恐别人知道的事儿，陷阱。 你孩子长大了为你骄傲的事，机会。 反之，陷阱。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>思维方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人资料收集]]></title>
    <url>%2F2018%2F08%2F05%2F%E7%94%9F%E6%B4%BB%E8%B5%84%E6%96%99-%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[互联网工具 指数类 百度指数 http://index.baidu.com/v2/index.html#/ 微博指数 https://data.weibo.com/index/ 各种数据指数 http://data.chongbuluo.com/ 企业类 企业信用信息公示系统 http://www.gsxt.gov.cn/index.html 国家统计局 http://data.stats.gov.cn/ 企查查 财报类 上交所http://www.sse.com.cn/ 深交所http://www.szse.cn/ 港交所https://www.hkexnews.hk/ 美国上市公司https://www.sec.gov/ 同花顺财经http://data.10jqka.com.cn/ 分析工具 语义分析系统http://ictclas.nlpir.org/nlpir/ 腾讯文智 https://nlp.qq.com/semantic.cgi#page2 echarts https://echarts.baidu.com/ 在线图片识别文字 https://ocr.wdku.net/ 问卷调查 https://www.wjx.cn/ 视频： 科普-计算机科学速成课 纪录片-设计的艺术 纪录片-小兵小赵 访谈-子夜.大学之殇 月球视频 最后的演讲 性，死亡与生命的意义 统计学：statistics —— CrashCourse 锵锵行天下 蓝色星球 风味人间 成功的原则 youtube视频：Rachel’s English 纪录片-生门 电影-生门 纪录片-人生果实 《人类星球》梦与狂想的王国《尘与雪》《人生七年》《身份的焦虑》 《铁西区》《和凤鸣》《原油》 书： The Non-Designer’s Design Book (4th Edition) 英文原版免费编程书籍 网站： RSS收集网站 知笔墨 微软海底机房摄像头直播 全球免费摄像头直播 设计类网站 漫画-海报 Our the in World 中国知网 统计学可视化 cnki免费下载文献：账号：hqwytsg015 密码：cnki015 北京值得去的地方 纪录片——AlphaGo youtube最受欢迎的频道 写作网站 博客 TED:阅读全世界 阮一峰的个人网站 追求对知识概念和原理进行更合适的描述 《用数据讲故事》作者博客 万维钢的博客 w4lle’s Notes = android技术博客 stormzhang 廖祜秋的博客 数据分析类网站 Kaggle 统计之都 纪杨的网站数据分析笔记 蓝鲸的网站分析笔记 Cloga的互联网笔记 陈老师的天善智能博客文章 秦路-文章 数据可视化网站 一起大数据 数据分析问答 数学公式转换MD格式 信息图制作 简历制作网站 多人协同任务清单 TED 如何掌控你的自由时间 —— 时间=选择 提升自信的技巧 —— 除非你做到了，否则没有人相信你 【TED】科技公司如何控制你的注意力 我从生活和写作中学到了12个真理 - 一个一个写，改初稿， 如果不知道写什么，就写你自己经历的事情 收入如何影响人们的生活方式——世界各国， 收入水平导致的生活条件改变都差不多官方网站 图表的魔力——图表能够让人更快的理解信息 如何利用大数据做出正确的判断-用大量数据去做分析， 去深入了解， 但要想成功， 就需要冒一定的风险 大数据时代：如何避免数据迷信？-不光要依靠大数据， 也要依靠厚数据，让解决问题的方法更加多元化 李开复：人工智能如何拯救人类-ai让我们明白我们为何为人 开启情绪识别的大门-用算法来识别人类情绪 有趣的故事 盗醉猴 植物修炼成精之后还有没有细胞壁？ NBA 感人的比赛或者画面有哪些？ 有没有一部电影让你在深夜中痛哭？ 为什么法海要阻止白素贞和许仙在一起？ What are some amazing pictures one has to see twice to understand? 21世界100部伟大的电影 幽默段子-银教授什么时候有空？也没什么事，就是想占用你一辈子的时间，想和你过过日子。 我这人特别不实在，除了实在想你。 ​​​​ 你这日子一天天过的，没什么两样，都是喜欢我的一天 我把电脑抱在怀里安慰了很久，因为它的系统崩溃了。 ​​​​ 没钱真的会被人看不起。今天叫朋友还我一千块钱，朋友说：“借我一万的人都没找我要，你哪来的脸开口？” 我羞愧无比，暗暗发誓等我有钱了，一定要多借点给他。 总觉得自己过了18岁就能慢慢成熟起来，没想到我每年都是十八岁]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>资料</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫]]></title>
    <url>%2F2018%2F07%2F12%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD-Python%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[爬取英雄联盟-英雄皮肤图片1. 前言最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。 2. 过程分析过程找到皮肤图片链接， 研究规律在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。 打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。 123456789# 英雄1http://ossweb-img.qq.com/images/lol/web201310/skin/small266000.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small266001.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small266002.jpg# 英雄2http://ossweb-img.qq.com/images/lol/web201310/skin/small103000.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small103001.jpghttp://ossweb-img.qq.com/images/lol/web201310/skin/small103002.jp 从以上的链接中，我们可以知道英雄皮肤的链接规律为：1&quot;http://ossweb-img.qq.com/images/lol/web201310/skin/small&quot; + &quot;英雄代号&quot; + &quot;0&quot; + &quot;01-10&quot; 找到每个英雄对应的数字代号那么我们需要解决的问题就变成了到每个英雄对应的代号是多少？ 通过搜索，我们发现每个英雄对应的代号存在champion.js文件中 从Headers中， 我们可以看到champion.js 对应的url为：1http://lol.qq.com/biz/hero/champion.js 我们通过正则表达式， 把js中对应的英雄代号提取出来。 通过以上把链接拼凑起来，我们就可以把链接对应的图片皮肤下载到本地了。 3. 代码1234567891011121314151617181920212223242526272829import requestsimport reimport jsonimport urlliburl = &quot;http://lol.qq.com/biz/hero/champion.js&quot;hd =&#123;&apos;User-Agent&apos;:&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0&quot;&#125;data = requests.get(url,headers = hd).contentdatas = data.decode()pat = &apos;&quot;keys&quot;:(.*?),&quot;data&quot;&apos;imglist = re.findall(pat,datas)datass = json.loads(imglist[0])for i in datass: try: for j in range(12): try: num = str(j) # print(num) if len(num) == 1: hero_num = &quot;00&quot; + num elif len(num) ==2: hero_num = &quot;0&quot; + num numstr = i + hero_num urls = &apos;http://ossweb-img.qq.com/images/lol/web201310/skin/big&apos;+ numstr +&apos;.jpg&apos; localfile = &quot;E:/张宇个人文件/英雄联盟/&quot; + str(i) + str(num) + &quot;.jpg&quot; urllib.request.urlretrieve(urls, filename = localfile) except Exception as err: pass except Exception as err: pass 爬取王者荣耀-英雄图片代码12345678910111213141516171819202122232425262728# 用python爬取王者荣耀皮肤import requestsimport reimport urlliburl = &quot;http://pvp.qq.com/web201605/herolist.shtml&quot;hd =&#123;&apos;User-Agent&apos;:&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0&quot;&#125;data = requests.get(url,headers = hd)pat = &apos;a href=&quot;herodetail/(.*?).shtml&apos;imglist = re.compile(pat, re.S).findall(data.text)for i in imglist: # print(i) try: for j in [1,2,3,4,5,6]: try: numstr = str(i)+&apos;/&apos; +str(i)+&apos;-mobileskin-&apos;+ str(j) # print(numstr) urls = &apos;https://game.gtimg.cn/images/yxzj/img201606/heroimg/&apos;+numstr+&apos;.jpg&apos; print(urls) localfile = &quot;E:/张宇个人文件/官网图片/&quot; + str(i)+ str(j)+ &quot;.jpg&quot; urllib.request.urlretrieve(urls, filename = localfile) except Exception as err: pass except Exception as err: pass 爬取网站美女图片代码构建用户代理池1234567891011121314# 这里可以随意加多个浏览器uapools = [ &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)&quot;, &quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)&quot;, &quot;Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko&quot;, &quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 920)&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0.2) Gecko/20100101 Firefox/6.0.2&quot;, &quot;Opera/9.80 (Windows NT 6.1; WOW64) Presto/2.12.388 Version/12.12&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0 Safari/537.36 OPR/15.0&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.57 Safari/537.17&quot;, &quot;Mozilla/5.0 (X11; CrOS armv7l 3428.193.0) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.126 Safari/537.22&quot;, &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2&quot;, &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/533.9 (KHTML, like Gecko) Maxthon/3.0 Safari/533.9&quot;,] 爬取并下载图片12345678910111213141516171819202122232425import reimport requestsimport urllib.request# uapools 如上所示for ua in uapools: hd =&#123;&apos;User-Agent&apos;:ua&#125; i = uapools.index(ua) # 限制爬取页数， 我们爬取前10页 if i &gt; 10: break try: url = &quot;http://www.iyuanqi.com/home/funimg/fun_list/m/Home/cp_uid/all/sort/30hot/p/&quot;+str(i)+&quot;.html&quot; data = requests.get(url, headers = hd) pat = &apos;class=&quot;lazy-img&quot; src=&quot;(.*?)&quot; data-original=&quot;&apos; imglist = re.compile(pat, re.S).findall(data.text) for j in range(0, len(imglist)): try: thisimg = imglist[j] thisimgurl = thisimg localfile = &quot;E:/张宇个人文件/网络图片/&quot; + str(i) + str(j) + &quot;.jpg&quot; urllib.request.urlretrieve(thisimgurl, filename = localfile) except Exception as err: pass except Exception as err: pass 爬取天善课程数据表存储到MYSQL前言天善智能是一个商业智能与大数据在线社区，有很多很好的学习课程。我们用爬虫来爬取网站的所有课程并存储到MYSQL数据库中， 以便于进一步的分析。 用python在MYSQL中创建名为zhanhyu的数据库 用python连接MYSQL数据库 1234567import pymysql# 因为本地mysql没有设置密码， 所以没有加password参数db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306)# 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句cursor = db.cursor() 创建一个新的数据库， 名字叫做zhangyu 12# cursor.execute 执行真正的sql语句, DEFAULT 指定默认值cursor.execute(&quot;CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8&quot;) 在zhangyu库中创建tianshan2_datas的数据表 指定在zhangyu这个数据库中运行 12db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db=&apos;zhangyu&apos;)cursor = db.cursor() 用sql语句创建名为tianshan2_datas的表 12345sql = &apos;CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))&apos;curosr.exectute(sql)db.close() 爬取天善智能网站的数据12345678910111213141516171819202122232425262728import reimport requestsfor i in range(1,5): # 观察天善课程链接， 找出规律 thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1) # 用requests库抓取数据 hd =&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;&#125; data = requests.get(thisurl, headers = hd) #用正则表达式进行解析 title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos; price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos; numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos; title = re.compile(title_pat, re.S).findall(data.text) if(len(title)&gt;0): title = title[0] else: continue price = re.compile(price_pat, re.S).findall(data.text) if(len(price)&gt;0): price = price[0] else: price = &apos;免费&apos; numb = re.compile(numb_pat, re.S).findall(data.text) if(len(numb)&gt;0): numb = numb[0] else: numb = &apos;缺失&apos; 将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中1234567891011con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)cursor = con.cursor()sql = &apos;insert into tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;try: cursor.execute(sql, (title, price, numb)) con.commit()except: con.rollback()con.close() 这样，我们就成功的把爬取的数据保存到mysql数据库中，方便我们查询使用。 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import pymysql# 因为本地mysql没有设置密码， 所以没有加password参数db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306)# 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句cursor = db.cursor()# cursor.execute 执行真正的sql语句, DEFAULT 指定默认值cursor.execute(&quot;CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8&quot;)db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db=&apos;zhangyu&apos;)cursor = db.cursor()sql = &apos;CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))&apos;cursor.execute(sql)db.close()import reimport pymysqlimport requestsfor i in range(0,284): thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1) hd =&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;&#125; data = requests.get(thisurl, headers = hd) title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos; price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos; numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos; title = re.compile(title_pat, re.S).findall(data.text) if(len(title)&gt;0): title = title[0] else: continue price = re.compile(price_pat, re.S).findall(data.text) if(len(price)&gt;0): price = price[0] else: price = &apos;免费&apos; numb = re.compile(numb_pat, re.S).findall(data.text) if(len(numb)&gt;0): numb = numb[0] else: numb = &apos;缺失&apos; con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;) cursor = con.cursor() sql = &apos;insert into tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos; try: cursor.execute(sql, (title, price, numb)) con.commit() except: con.rollback() con.close()]]></content>
      <categories>
        <category>数据分析技能</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刻意练习]]></title>
    <url>%2F2018%2F04%2F16%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E5%A5%BD%E5%A5%BD%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1. 什么是刻意练习 刻意练习是一个在已经有明确方法论的行业内， 个人通过制定一系列明确的目标， 不断进行刚好超出他们能力范围的练习， 并通过检验反馈不断地对练习进行调整， 从而创建有效的知识晶体， 保存在长时记忆中， 以便以后遇到问题及时响应。 2. 刻意练习背后的原理是什么 利用身体偏爱稳定的倾向，进行刚好超出能力范围的练习我们人类的身体天生偏爱稳定性， 我们的身体通过各种各样的反馈机制来保持身体各项指标的稳定性。当身体系统长时间的感受到压力，原来的平衡再无法保持时， 身体便会开始响应那些变化，让那些变化更加容易， 进而达到重新的平衡。但在过长的时间内过分的逼迫自己， 可能导致倦怠和低效。 例如：对于跑步锻炼来说， 如果你短时间剧烈的运动，导致身体中的能量与氧气下降， 身体就会通过心跳加速以提高氧气供给，并将储存在不同部位的能量拿来给肌肉供给，以达到平衡状态。只要体育锻炼并未让身体平衡机制无法正常运转，就很难引起身体上的生理变化。 因此， 你需要足够努力的锻炼并保持足够长的时间，才能让身体形成新的平衡。要想要改变不断地进行下去， 你就需要不断地加码：跑的更远，更快，负重跑等。 一旦你不给自己在跑步方面施加压力， 你将停止改进的脚步，停留在新的平衡内。 但如果你一上来玩命的跑， 可能只让自己受伤。 同理，对大脑进行长时间的锻炼， 大脑也会以各种不同的方式来重新布置神经元之间的连接，以达到快速地相应。 为了创建有效的知识晶体 知识晶体就是我们思考某件事物时心理所创建的知识结构。 刻意练习的目的之一就是创建有效的知识晶体。 信息预先存在这些晶体中，并长时间保存在记忆之中，当生活中遇到类似的情况可快速地进行响应。 行业内的杰出人物正式由于他们经过多年的积累，针对行业中可能遇到的不同局面，创建了高度复杂和精密的知识晶体。反过来这些知识晶体让他们更好地在一系列事物中找到规律，更好地理解信息，指定计划，高效的学习。 比如： 你听到‘猫’这个词就会想到毛茸茸可爱的猫，它的样子，叫声等具体的内容。你在生活中对‘猫’这个词创建了包括图像， 气味，声音等一系列的晶体结构。 同理，我们要想更好地创建对某一动物的知识晶体，最好的方法就是花一点点的时间来了解它们，摸摸它的毛发，和它玩耍，并且细心地观察它的一举一动。 3. 如何在一个行业中进行刻意练习 找到一位好的导师 如果可以的话， 找到一个好的导师能够让自己的练习事半功倍。 好的导师能够了解什么样的行为会带来进步，能带来及时的反馈。 找行业中的大牛 我们在现实中很难找到一个好的导师， 但我们在互联网中可以很容易找到行业中的大牛。 我们首先确定大牛的指标都有哪些， 然后调查思考谁符合这些指标，算的上是真正的大牛。 在数据分析行业， 称为大牛的特征有：有多年的行业积累， 有大厂的工作经历。 有较大的行业影响力， 愿意传播教授 技能。 通过搜索，我们可以知道：数据挖掘与数据分析博主-邓凯是数据分析里的大牛， 他在数据分析行业工作多年， 并在京东这样的大厂担任数据负责人， 微信公众号有数十万粉丝，现在成立了爱数圈这样的学习团体。 观察大牛都做了什么 观察他们是做了什么让他们如此的杰出，运用了哪些方法让他们如此的卓越。 不断的通过工作业务磨练自己的数据分析思维，建立了良好的互联网分析能力。 他不断地写数据分析的相关文章，总结输出，让自己不断扩大影响力。这些方法途径，也是自己在进行技能学习时可以学习借鉴的方法。 学会分解目标 找到一种适合自己的练习方法，并将漫长的目标分解成一个一个的小目标，每次练习都只专注于这一个目标，当达到目标时， 给自己一个小小的奖赏 最重要的是盯紧自己的目标。 找到自己的练习规律 保证自己在短的时间内能够集中全部的注意力去练习。 一旦自己发现自己不能够保持专注力，就停下来休息。 经过自己这段时间的统计发现，自己能够保持专注学习的时间为一个小时， 超过一个小时自己就看不进去了。 这个时候，自己停下来放松10分钟再看，效果会好的多。 在工作中需要必要的反馈 给自己设计某种必要的反馈， 让自己能够随着时间的推移， 不断的纠正错误和精进技巧。 如何创建反馈， 我觉得可以通过写作来给自己提供反馈，通过输出来倒逼输入， 在写作中发现自己的问题， 比如自己在写这篇读书笔记时就发现自己有很多的概念没有理解。 创建自己对于这个技能的知识晶体 将工作中的项目经验和学到的知识相结合，构成强大的晶体结构。培养自己能够遇到问题迅速的响应能力。多培养自己遇到问题的解决思路。 隐形知识 寻求建议 当遇到停滞阶段时， 稍微给自己加强练习的强度，找出到底是在哪里让你停滞不前， 然后尝试换一种方法专门针对这个缺点来进行练习，或向大牛寻求建议。 自己的打字速度现在停滞不前 在练习的过程中保持动机 给自己制定一个专门的时间点来进行练习，并想办法把干扰你的事物控制到最小。坚定自己可以通过刻意练习可以进步的信念。有可能的话， 加入一个社区进行学习比自己单独学习更容易坚持 比如：把手机调静音，去图书馆学习防止网络对自己的影响。 保持充足的睡眠，加入一个数据分析的圈子进行学习。 保证错误是低风险的。这样自己才能敢于犯错。 练习， 试错， 反馈，修正 应用 当自己在进行学习时， 自己总是会想到刻意练习里的一个观点， 就是在学习过程中必须脱离自己的舒适区，让学习的内容稍微难一点， 这样的学习才会让自己进步。 每当这样想， 自己就不会抵触学习的过程了， 也让自己能够长久的坚持。 –2018-12-08 刻意练习区别与其他练习的特征是什么 有定义明确的特定目标把大目标分解成每一个小目标，制定计划，在达成每一个小目标的过程中，纠正自己的行为方式，解决面临的问题。 具有专注的练习状态尽力保持专注，集中精力，不会走神 练习包含反馈你必须知道自己做的对不对，如果不对，又错在哪里。 走出舒适区 刻意练习的原则专注、反馈、纠正、足够的重复次数 延伸： TED演讲： 《how to get better at the things you care about》 刻意练习的本质-阳志平公众号：心智工具箱网站：http://www.yangzhiping.com/ 论文：the role of Deliberate Practice in the Acquisition of Expert Performance 阅读《好好学习》 如何写反思日记： 什么是反思反思的实质是对假设进行校正做事的顺序：做出假设——采取行动——产生结果反思的顺序： 观察结果——研究原先的假设——反思校正假设 反思的作用 发现知识误区——跳跃性假设 没有通过深入思考就得出结论，比如：遇到大牛就躲闪一旁。 跳跃性假设帮我们选择了思考路径。而缺乏深入思考的过程，又让我们进一步失去了发现解决问题的方法。 如何解决：要深入思考如何深入思考：通过提问来放慢思考速度 提什么问题 今天我做得不好的事情是什么？ 我当时是怎么考虑的？ 如果我重新来做会有哪些改进？ 促进已有知识产生新知识 在反思的时候主动的进行知识的联想和联结，将生活中其他经历和经验串联起来， 重新认识和审视自己过往经历，能够将自己分散的生活经验进行重新组织， 从而产生新的知识。 如何做 我过去还遇到过这样的事情吗？ 我还听过有其他人经历的同样的事情吗？ 有什么相关的方法可以应用到这件事情中吗 检验学习到的新知识是否用了起来 对标管理：提前设定一个标准， 然后每天反思， 与之比较寻找差距 培养反思的额方法 从小事反思，深入突破 把生活案例化处理 培养记反思日记的习惯 每日反思问题： 今天我做得不好的事情是什么？ 我当时是怎么考虑的， 身体是怎么反应的？ 如果我重新来做会有哪些改进？ 我过去还遇到过这样的事情吗？ 我还听过有其他人经历同样的事情吗？ 有什么相关的方法可以应用到这种事情中吗？ 我今天没有有效控制自己的事情是什么？ 我今天在心理上感觉很好的2件事情是什么？ 我今天学到的新技能时什么？ 我离我的职业目标还差哪些技能？]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《刻意学习》读书笔记]]></title>
    <url>%2F2018%2F02%2F17%2F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E5%88%BB%E6%84%8F%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%20%2F</url>
    <content type="text"><![CDATA[如果要对一个话题展开连续的深入思考，我的思维就很容易中断。造成此现象的原因是， 我把大量的时间花在微博、公众号和各路社交媒体上。以为自己走在时代的最前言，其实没有想到这种碎片化的输入对于构建完整的思考体系而言，简直是致命伤害。 但是写作，尤其是写长文，并且时以分析论理风格的长文，可以强迫我将思路呈现在纸上，从而有了目标，可进行自我剖析。这是一个非常有效的思维训练方法。 你必须先遵守才能谈自由与灵活。而事情的残酷在于，灵活性往往最容易出现在半途而废的时候，有些人明明是做不到，却说是为了灵活性和自由，从而心安理得地放弃。 每个人都是自己生活轨迹的制定者，每个人成长的主旋律都在自己手中，要做的事情必须独立承担，任何评价都无法代替我们要面对的事情。 0-300天：感受到“我要做的”和“我能做的”之间的差距， 厘清当前的处境。在这个阶段，每个人的特性会全面暴露。我们会发现自己有那么多不懂的东西，越深入就很发现越多不懂，内心一片灰暗；然后就想偷懒，想放水，想交差，甚至会产生退缩的念头，感觉这样做没有意义。 300-600天： 基于结构构建。缺什么补什么，有困难解决困难，直接硬上， 用时间换空间，用耐心换进步。抵御“放弃”的诱惑，有时候你会感到无趣，但拼的就是坚持。 同时，在初始阶段基本稳定后，开始加载任务。标准： 在原有任务能保持每天做到位并有所进步的基础上，仍然有足够多的心智和力量完成更多的任务。 600-1000天：解决三个问题：1. 路径依赖问题。 2. 思维惯性问题。 3. 自我摧毁问题。 对于一本书， 你能消化多少，不是由采取的方法决定，而是由你自身“消化系统”的能力决定，而这个“消化系统”， 就是学以致用的能力。 习惯就是每天都做，如何你哪一天不做这件事了， 就不再是习惯了。 自己想明白最宝贵，哪怕书上早写了。 对于写作的一个观点： 我写我心，我写我情，我写我世界。 对我而言，写作是用来整理自己的世界，当你把自己梳理好以后，你写的文章也会变得清晰明了，容易理解。而我们的写作，也就顺理成章地变成了一种对我们内心世界的推演。于是你会得到一些结论，而这些结论正是你身体力行、复盘总结、升华提炼后的结果。写作的意义在于，你自己想明白的，就是你的。书上的只是书上的，终究不是你的。 自己想明白的，是从你的体系中萌芽生长出来的；而从书中看到的，非常容易停留在做个笔记画个线，自以为懂了的层面。 只有从原理级别、行动层面、复盘角度综合学习并且全面吸收而掌握的知识、技能，才能真正成为我们所需要的武器。 行动是一个“主动发起、投入资源、外界交互、内部梳理、产出结果”的过程。 当我们说行动的时候，要主动承担一些责任，投入资源。这代表了，一方面我们要与外部世界进行交互，另一方面又要把自己的内心建设好，还有最重要的是，要产出一些结果。 从外部来看，思考和犹豫纠结的区别就在于你有没有出活，有没有输出，有没有行动。 如果在一段时间里， 你做出了决策并有所行动，那这就不算犹豫。如果在这段时间内，你只是“思考”，却没有任何实质的行动，那这可能就只是一种纯粹的犹豫。 持续行动的意思就是将行动延续下去、无间隔、连续不断地行动。 第一：当我们说自己每天要做什么，那么我们就把这个事情做到了，这就是符合自己的预期。第二：持续行动有一个最基本的节奏就是每天做，做足够长的时间，而且要保持稳定。 现在我们每个人的环境都承载了所有前辈的过去，包括出生的家庭环境、所处的城市，都是前辈逐渐积攒的结果。这是我们无法选择的“默认参数”，我们一出生，身上就带了这些参数，需要背着它不断去优化，走完此生。 对现状感到不满，对未来感到迷茫，压力很大。而且我们往往会把这些现状当成原因，来指导我们的行动。我迷茫，所以我要如何。 但在某种程度上，更多的是结果而不是原因。我们只是在还过去欠下的债而已。过去的某个时刻我们没有全力投入，没有付出更多的心思，没有做更多的事情，尝试更多的可能性。于是，我们就按照默认的配置，来到当下。 当我们一无所有的时候，能选择的也就是每天都行动了。 这是我们唯一能够把握的， 因为唯一相对公平的筹码就是每个人的时间，而我们能做的就是把自己有限的时间投入到某个方面，不断积累，提升形成优势，然后去市场上做交换。我们要把时间持续的、长期稳定地专注在一个点上，并且在这一点上形成自己的优势资源。这其实是一种通过持续行动为自己的成长“复利”的行为。 如果你每天都让自己做一些事情，又保持着进步的势头，慢慢积累就会发现，那些你以为需要技巧才能解决的问题，很多时候根本就不需要技巧了； 那些对我们来说很重要的事情，往往都是复杂系统。 比如我们的能力、身体状况、收入处境、家庭幸福…..这些都需要花费大量时间、长期稳定的投入，才会有效果。就像一个生态系统一样，不能今天种两棵树，明天就指望有片热带雨林。 核心技能是没法通过强及时反馈来构建的，也就是你要做好坐冷板凳的准备。而且你也要相信，在这个过程中是不可能天天有强及时反馈的。如何你能守住这种寂寞，就能拨云见日；受不住的话，就是低水平重复建设了。 反馈从来都是漫长的，成长从来都不是一蹴而就的。 我们内心可能有很多欲望和想法，如果沉下心，踏实干好一件事情，往往就足以打开局面了。 但问题在于，我们往往这也想要，那也想要，相当于同事要解多道难题，但资源不够，精力分散，火力不够猛，自然也就解不出来。于是我们迷茫、纠结、痛苦、忧愁…..进而看各种慰藉心灵的鸡汤故事，告诉你这是生活的正常状态，仍然可以闭着眼睛假装自己很幸福。但是事实上，我们搞不定，我们没得选，我们没办法。我们要成长，就要做好心理准备：在解一类很难的问题时，是要消耗大量资源的。 在持续行动的时候，要做好即使没有任何外界反馈仍然能够继续前行的心理准备。反馈从来都是漫长的，成长从来都不是一蹴而就的。 如果你总是期望外界给予一些东西才能走下去，以一种索取者的身份看待周围的所有人和事，把自己的不如意归结于所有环境，那你可能忽视了自己内心的一片荒芜。相反，如果你的目光往内心看，通过逻辑分析想清楚自己想法的来龙去脉，对于所做的事情，有清晰的认知，包括风险、核心、要点、挑战…..那你会走得非常坚定。而且这个时候，外界的反馈对你来说，只是一个顺带结果而已。 他最想要的是什么，你能给吗？你最想要的是什么，她能给吗？ 把这两个问题想明白，然后就去追吧。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习双拼输入法的心得]]></title>
    <url>%2F2017%2F09%2F17%2F%E7%94%9F%E6%B4%BB%E8%B5%84%E6%96%99-%E5%8F%8C%E6%8B%BC%E8%BE%93%E5%85%A5%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 怎么接触到双拼的？自己第一次接触双拼，是看到李笑来老师的《把时间当朋友》第二章中的“盲打究竟是否值得学会”,里面提到了盲打与双拼帮助他快速进行记录笔记和文字。 于是自己就试着在网上找双拼的学习方法。 2. 什么是双拼？ 维基百科：双拼是汉语拼音输入法的一种编码方案。相对于全拼而言，使用双拼输入汉字时只需输入一个代表声母的字母，一个代表韵母的字母，就可以打出任意一个中文单字了。 理解起来也很简单，比如你要拼写 张 红 这两个字， 用全拼的话可能你得输入 zhang hong， 而用小鹤双拼的话， 你只需要输入vh hs 就可以显示。 v 代表zh , h 代表ang , s代表ong 双拼的语法也有很多种，比如小鹤双拼、自然码双拼、紫光拼音双拼、搜狗拼音双拼、微软拼音双拼、智能ABC双拼。 每种双拼对应的语法也都不一样。 自己学习的是小鹤双拼，语法图是这样的： 在搜狗输入法上点击 设置—— 属性设置 —— 常用 —— 特殊习惯—— 双拼 就可以使用了。 3. 学习的过程刚开始学习小鹤双拼的时候， 自己是完全不习惯的， 因为想要使用小鹤双拼进行文字输入，就得记住每个字母对应的韵母， 自己每输入一个字， 就得想一下这个字的韵母是什么， 对应到按键上的那个字母又是什么。 再去输入，说实话当时输入字的效率低下到令人发指，而且往往记不住，自己只好打印了一张语法表贴在自己的电脑旁， 忘了就在表上找。 好几次忍不住偷偷换成了全拼， 特别是在工作着急的情况下。 就这样别别扭扭用了一周之后， 才发现自己已经能够慢慢不看语法表了。 （这让我都有点怀疑自己的智商，因为网上说基本一周就可以很熟练了）一个月过后自己才做到了输入基本不卡壳，但如果旁边有人一紧张还是会忘掉如何输入了。 现在用了一年多， 自己已经能够无意识的使用双拼了。 如果你现在问我键盘上的字母在双拼中代表哪个韵母，自己可能真的答不上来，但只要自己在键盘上打字，自己就能够无意识的打出来。 4. 学习双拼的优点与缺点( 1 ). 优点 简洁，同样一个词全拼要五六下，双拼只需要两下 感觉节省了时间，更喜欢在键盘上敲字了。 （至于是否真正节省了时间，自己没有做过对比） ( 2 ). 缺点 全拼不会用了， 有时在别人的电脑上输入文字总是很别扭，老出错，总想着把输入法改成双拼 有时大脑短路会想不起来双拼的语法 5. 感悟 任何学习都是不可逆的，当你学了到了一项技能，你就不可能再像从前没学过一样生活。 最可怕的不是自己知道自己不知道，而是不知道自己不知道。 比如自己学习双拼，自己以前根本不知道还有双拼这么一种输入法，就更不会产生要学习这种输入法的冲动。 如何解决自己不知道自己不知道的知识，自己目前能够想到的方法是：多读书，多关注大牛，多了解别人是怎么工作、生活。 有些东西只有自己亲身经历过后才能有所体会，哪怕是坏的体验。 如果只是看别人推荐而不去坚持使用双拼， 我就不能体会到大脑下意识使用双拼输入的快感。当然，也许会出现这种情况， 你付出了时间，付出了精力，而这项技能对你的生活影响并不大。这就需要你前期做一些搜索调查。 延伸到生活上，要是我不来北京生活，不来北京工作，我就没有机会知道来北京到底会面临什么困难，到底对自己的职业发展是否有益。也许最后自己会失败，可那又怎么样，自己的人生自己做主。 学会一项技能，不是只是了解它，而是能够在生活中无意识的使用它 一项技能，只是了解是远远不够的， 你要去不断的磨练，打磨，直到它成为你大脑的一部分。 学会的标准就是：你能否不需要专门思考就能够调用它。 要学习那些你通过短时间学会,就能够一辈子用的上的知识。 6. 延伸 总是听很多的牛人说，写作是非常重要的一项技能，对一个人清晰思考问题是非常有帮助的，然而自己却迟迟没有行动，主要还是觉得自己语言词汇匮乏， 缺乏独立思考，怕自己语无伦次。 其实又想想，写作这东西这就和自己刚开始学习双拼时一样，开始你觉得自己没有可能学会，也许过一段时间你就能够发现自己的进步， 你不去坚持写又怎么能够证明自己一定学不会呢？ 自己认为学习是一个自我验证的过程：你认为自己不可能学会，你就不会坚持去学；你不坚持去学，你就不会有进步， 从而你就不会看到到自己能够学会的结果，也就证明了自己确实学不会。相反， 你认为自己能学会，你就坚持去学，看到自己的进步，最终的确学会了，也证明了自己确实能够学会。 7. 未解决问题 如何运用心智的力量在还没有机会亲身体验的情况下，仅凭心智就可以像真实经历过一样深刻体会？ 如何解决 害怕自己付出了时间，付出了精力，而没有一个好的结果 参考资料： 《把时间当朋友》]]></content>
      <categories>
        <category>生活资料</category>
      </categories>
      <tags>
        <tag>双拼</tag>
      </tags>
  </entry>
</search>
