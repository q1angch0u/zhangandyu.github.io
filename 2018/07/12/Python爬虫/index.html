<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Python爬虫 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="爬取英雄联盟-英雄皮肤图片1. 前言最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。 2. 过程分析过程找到皮肤图片链接， 研究规律在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。  打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。  1234">
<meta name="keywords" content="Python,爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫">
<meta property="og:url" content="https://zhangandyu.github.io/2018/07/12/Python爬虫/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="爬取英雄联盟-英雄皮肤图片1. 前言最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。 2. 过程分析过程找到皮肤图片链接， 研究规律在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。  打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。  1234">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://i.loli.net/2018/07/17/5b4e086d05abd.png">
<meta property="og:image" content="https://i.loli.net/2018/07/17/5b4e09769c56a.png">
<meta property="og:image" content="https://i.loli.net/2018/07/17/5b4e0ac67e187.png">
<meta property="og:image" content="https://i.loli.net/2018/07/17/5b4e0df090d6c.png">
<meta property="og:updated_time" content="2019-01-07T14:42:33.846Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python爬虫">
<meta name="twitter:description" content="爬取英雄联盟-英雄皮肤图片1. 前言最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。 2. 过程分析过程找到皮肤图片链接， 研究规律在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。  打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。  1234">
<meta name="twitter:image" content="https://i.loli.net/2018/07/17/5b4e086d05abd.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zhangandyu.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Python爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/12/Python爬虫/" class="article-date">
  <time datetime="2018-07-11T16:00:00.000Z" itemprop="datePublished">2018-07-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/编程语言/">编程语言</a>►<a class="article-category-link" href="/categories/编程语言/Python/">Python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python爬虫
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="爬取英雄联盟-英雄皮肤图片"><a href="#爬取英雄联盟-英雄皮肤图片" class="headerlink" title="爬取英雄联盟-英雄皮肤图片"></a>爬取英雄联盟-英雄皮肤图片</h1><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。</p>
<h2 id="2-过程"><a href="#2-过程" class="headerlink" title="2. 过程"></a>2. 过程</h2><h3 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h3><h4 id="找到皮肤图片链接，-研究规律"><a href="#找到皮肤图片链接，-研究规律" class="headerlink" title="找到皮肤图片链接， 研究规律"></a>找到皮肤图片链接， 研究规律</h4><p>在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e086d05abd.png" alt="英雄联盟图片"></p>
<p>打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e09769c56a.png" alt="英雄皮肤"><br><img src="https://i.loli.net/2018/07/17/5b4e0ac67e187.png" alt="狐狸皮肤"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 英雄1</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266000.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266001.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266002.jpg</span><br><span class="line"></span><br><span class="line"># 英雄2</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103000.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103001.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103002.jp</span><br></pre></td></tr></table></figure>
<p>从以上的链接中，我们可以知道英雄皮肤的链接规律为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;http://ossweb-img.qq.com/images/lol/web201310/skin/small&quot; + &quot;英雄代号&quot; + &quot;0&quot; + &quot;01-10&quot;</span><br></pre></td></tr></table></figure></p>
<h4 id="找到每个英雄对应的数字代号"><a href="#找到每个英雄对应的数字代号" class="headerlink" title="找到每个英雄对应的数字代号"></a>找到每个英雄对应的数字代号</h4><p>那么我们需要解决的问题就变成了到每个英雄对应的代号是多少？</p>
<p>通过搜索，我们发现每个英雄对应的代号存在champion.js文件中</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e0df090d6c.png" alt="英雄对应的代号"></p>
<p>从Headers中， 我们可以看到champion.js 对应的url为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://lol.qq.com/biz/hero/champion.js</span><br></pre></td></tr></table></figure></p>
<p>我们通过正则表达式， 把js中对应的英雄代号提取出来。</p>
<p>通过以上把链接拼凑起来，我们就可以把链接对应的图片皮肤下载到本地了。</p>
<h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3. 代码"></a>3. 代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import json</span><br><span class="line">import urllib</span><br><span class="line">url = &quot;http://lol.qq.com/biz/hero/champion.js&quot;</span><br><span class="line">hd =&#123;&apos;User-Agent&apos;:&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0&quot;&#125;</span><br><span class="line">data = requests.get(url,headers = hd).content</span><br><span class="line">datas = data.decode()</span><br><span class="line">pat = &apos;&quot;keys&quot;:(.*?),&quot;data&quot;&apos;</span><br><span class="line">imglist = re.findall(pat,datas)</span><br><span class="line">datass = json.loads(imglist[0])</span><br><span class="line">for i in datass:</span><br><span class="line">    try:</span><br><span class="line">        for j in range(12):</span><br><span class="line">            try:</span><br><span class="line">                num = str(j)</span><br><span class="line">                # print(num)</span><br><span class="line">                if len(num) == 1:</span><br><span class="line">                    hero_num = &quot;00&quot; + num</span><br><span class="line">                elif len(num) ==2:</span><br><span class="line">                    hero_num = &quot;0&quot; + num</span><br><span class="line">                numstr = i + hero_num</span><br><span class="line">                urls = &apos;http://ossweb-img.qq.com/images/lol/web201310/skin/big&apos;+ numstr +&apos;.jpg&apos;</span><br><span class="line">                localfile = &quot;E:/张宇个人文件/英雄联盟/&quot; + str(i) + str(num) +  &quot;.jpg&quot;</span><br><span class="line">                urllib.request.urlretrieve(urls, filename = localfile)</span><br><span class="line">            except Exception as err:</span><br><span class="line">                pass</span><br><span class="line">    except Exception as err:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="爬取王者荣耀-英雄图片"><a href="#爬取王者荣耀-英雄图片" class="headerlink" title="爬取王者荣耀-英雄图片"></a>爬取王者荣耀-英雄图片</h1><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 用python爬取王者荣耀皮肤</span><br><span class="line"></span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import urllib</span><br><span class="line"></span><br><span class="line">url = &quot;http://pvp.qq.com/web201605/herolist.shtml&quot;</span><br><span class="line">hd =&#123;&apos;User-Agent&apos;:&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0&quot;&#125;</span><br><span class="line">data = requests.get(url,headers = hd)</span><br><span class="line">pat = &apos;a href=&quot;herodetail/(.*?).shtml&apos;</span><br><span class="line">imglist = re.compile(pat, re.S).findall(data.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in imglist:</span><br><span class="line">    # print(i)</span><br><span class="line">    try:</span><br><span class="line">        for j in [1,2,3,4,5,6]:</span><br><span class="line">            try:</span><br><span class="line">                numstr = str(i)+&apos;/&apos; +str(i)+&apos;-mobileskin-&apos;+ str(j)</span><br><span class="line">                # print(numstr)</span><br><span class="line">                urls = &apos;https://game.gtimg.cn/images/yxzj/img201606/heroimg/&apos;+numstr+&apos;.jpg&apos;</span><br><span class="line">                print(urls)</span><br><span class="line">                localfile = &quot;E:/张宇个人文件/官网图片/&quot; + str(i)+ str(j)+  &quot;.jpg&quot;</span><br><span class="line">                urllib.request.urlretrieve(urls, filename = localfile)</span><br><span class="line">            except Exception as err: </span><br><span class="line">                pass</span><br><span class="line">    except Exception as err:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="爬取网站美女图片"><a href="#爬取网站美女图片" class="headerlink" title="爬取网站美女图片"></a>爬取网站美女图片</h1><h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><h3 id="构建用户代理池"><a href="#构建用户代理池" class="headerlink" title="构建用户代理池"></a>构建用户代理池</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 这里可以随意加多个浏览器</span><br><span class="line">uapools = [</span><br><span class="line">    &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 920)&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0.2) Gecko/20100101 Firefox/6.0.2&quot;,</span><br><span class="line">    &quot;Opera/9.80 (Windows NT 6.1; WOW64) Presto/2.12.388 Version/12.12&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0 Safari/537.36 OPR/15.0&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.57 Safari/537.17&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (X11; CrOS armv7l 3428.193.0) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.126 Safari/537.22&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/533.9 (KHTML, like Gecko) Maxthon/3.0 Safari/533.9&quot;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3 id="爬取并下载图片"><a href="#爬取并下载图片" class="headerlink" title="爬取并下载图片"></a>爬取并下载图片</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import requests</span><br><span class="line">import urllib.request</span><br><span class="line"># uapools 如上所示</span><br><span class="line">for ua in uapools:</span><br><span class="line">    hd =&#123;&apos;User-Agent&apos;:ua&#125;</span><br><span class="line">    i = uapools.index(ua)</span><br><span class="line">    # 限制爬取页数， 我们爬取前10页</span><br><span class="line">    if i &gt; 10:</span><br><span class="line">        break</span><br><span class="line">    try:</span><br><span class="line">        url = &quot;http://www.iyuanqi.com/home/funimg/fun_list/m/Home/cp_uid/all/sort/30hot/p/&quot;+str(i)+&quot;.html&quot;</span><br><span class="line">        data = requests.get(url, headers = hd)</span><br><span class="line">        pat = &apos;class=&quot;lazy-img&quot; src=&quot;(.*?)&quot; data-original=&quot;&apos;</span><br><span class="line">        imglist = re.compile(pat, re.S).findall(data.text)</span><br><span class="line">        for j in range(0, len(imglist)):</span><br><span class="line">            try:</span><br><span class="line">                thisimg = imglist[j]</span><br><span class="line">                thisimgurl = thisimg</span><br><span class="line">                localfile = &quot;E:/张宇个人文件/网络图片/&quot; + str(i) + str(j) + &quot;.jpg&quot;</span><br><span class="line">                urllib.request.urlretrieve(thisimgurl, filename = localfile)</span><br><span class="line">            except Exception as err:</span><br><span class="line">                pass</span><br><span class="line">    except Exception as err:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="爬取天善课程数据表存储到MYSQL"><a href="#爬取天善课程数据表存储到MYSQL" class="headerlink" title="爬取天善课程数据表存储到MYSQL"></a>爬取天善课程数据表存储到MYSQL</h1><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>天善智能是一个商业智能与大数据在线社区，有很多很好的学习课程。我们用爬虫来爬取网站的所有课程并存储到MYSQL数据库中， 以便于进一步的分析。</p>
<h4 id="用python在MYSQL中创建名为zhanhyu的数据库"><a href="#用python在MYSQL中创建名为zhanhyu的数据库" class="headerlink" title="用python在MYSQL中创建名为zhanhyu的数据库"></a>用python在MYSQL中创建名为zhanhyu的数据库</h4><ul>
<li>用python连接MYSQL数据库</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line"># 因为本地mysql没有设置密码， 所以没有加password参数</span><br><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306)</span><br><span class="line"></span><br><span class="line"># 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句</span><br><span class="line">cursor = db.cursor()</span><br></pre></td></tr></table></figure>
<ul>
<li>创建一个新的数据库， 名字叫做zhangyu</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># cursor.execute 执行真正的sql语句, DEFAULT 指定默认值</span><br><span class="line">cursor.execute(&quot;CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="在zhangyu库中创建tianshan2-datas的数据表"><a href="#在zhangyu库中创建tianshan2-datas的数据表" class="headerlink" title="在zhangyu库中创建tianshan2_datas的数据表"></a>在zhangyu库中创建tianshan2_datas的数据表</h4><ul>
<li>指定在zhangyu这个数据库中运行</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306, db=&apos;zhangyu&apos;)</span><br><span class="line">cursor = db.cursor()</span><br></pre></td></tr></table></figure>
<ul>
<li>用sql语句创建名为tianshan2_datas的表</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sql = &apos;CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))&apos;</span><br><span class="line"></span><br><span class="line">curosr.exectute(sql)</span><br><span class="line"></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<h4 id="爬取天善智能网站的数据"><a href="#爬取天善智能网站的数据" class="headerlink" title="爬取天善智能网站的数据"></a>爬取天善智能网站的数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">for i in range(1,5):</span><br><span class="line">    # 观察天善课程链接， 找出规律</span><br><span class="line">    thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1)</span><br><span class="line">    # 用requests库抓取数据</span><br><span class="line">    hd =&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;&#125;</span><br><span class="line">    data = requests.get(thisurl, headers = hd)</span><br><span class="line">    #用正则表达式进行解析</span><br><span class="line">    title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos;</span><br><span class="line">    price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    title = re.compile(title_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(title)&gt;0):</span><br><span class="line">        title = title[0]</span><br><span class="line">    else:</span><br><span class="line">        continue</span><br><span class="line">    price = re.compile(price_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(price)&gt;0):</span><br><span class="line">        price = price[0]</span><br><span class="line">    else:</span><br><span class="line">        price = &apos;免费&apos;</span><br><span class="line">    numb = re.compile(numb_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(numb)&gt;0):</span><br><span class="line">        numb = numb[0]</span><br><span class="line">    else:</span><br><span class="line">        numb = &apos;缺失&apos;</span><br></pre></td></tr></table></figure>
<h4 id="将爬取的数据存储到名为zhangyu数据库的tianshan2-datas表中"><a href="#将爬取的数据存储到名为zhangyu数据库的tianshan2-datas表中" class="headerlink" title="将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中"></a>将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)</span><br><span class="line">cursor = con.cursor()</span><br><span class="line"></span><br><span class="line">sql = &apos;insert into  tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;</span><br><span class="line">try:</span><br><span class="line">    cursor.execute(sql, (title, price, numb))</span><br><span class="line">    con.commit()</span><br><span class="line">except:</span><br><span class="line">    con.rollback()</span><br><span class="line">con.close()</span><br></pre></td></tr></table></figure>
<hr>
<p>这样，我们就成功的把爬取的数据保存到mysql数据库中，方便我们查询使用。</p>
<h4 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line"># 因为本地mysql没有设置密码， 所以没有加password参数</span><br><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306)</span><br><span class="line"></span><br><span class="line"># 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句</span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"># cursor.execute 执行真正的sql语句, DEFAULT 指定默认值</span><br><span class="line">cursor.execute(&quot;CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8&quot;)</span><br><span class="line"></span><br><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306, db=&apos;zhangyu&apos;)</span><br><span class="line">cursor = db.cursor()</span><br><span class="line">sql = &apos;CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))&apos;</span><br><span class="line">cursor.execute(sql)</span><br><span class="line">db.close()</span><br><span class="line"></span><br><span class="line">import re</span><br><span class="line">import pymysql</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">for i in range(0,284):</span><br><span class="line">    thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1)</span><br><span class="line">    hd =&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;&#125;</span><br><span class="line">    data = requests.get(thisurl, headers = hd)</span><br><span class="line">    title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos;</span><br><span class="line">    price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    title = re.compile(title_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(title)&gt;0):</span><br><span class="line">        title = title[0]</span><br><span class="line">    else:</span><br><span class="line">        continue</span><br><span class="line">    price = re.compile(price_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(price)&gt;0):</span><br><span class="line">        price = price[0]</span><br><span class="line">    else:</span><br><span class="line">        price = &apos;免费&apos;</span><br><span class="line">    numb = re.compile(numb_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(numb)&gt;0):</span><br><span class="line">        numb = numb[0]</span><br><span class="line">    else:</span><br><span class="line">        numb = &apos;缺失&apos;</span><br><span class="line">        </span><br><span class="line">    con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)</span><br><span class="line">    cursor = con.cursor()</span><br><span class="line"></span><br><span class="line">    sql = &apos;insert into  tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;</span><br><span class="line">    try:</span><br><span class="line">        cursor.execute(sql, (title, price, numb))</span><br><span class="line">        con.commit()</span><br><span class="line">    except:</span><br><span class="line">        con.rollback()</span><br><span class="line">    con.close()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zhangandyu.github.io/2018/07/12/Python爬虫/" data-id="cjsbyj00b0005ykqk0sv8xope" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/07/25/python基础/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          python基础
        
      </div>
    </a>
  
  
    <a href="/2018/04/16/《刻意练习》读书笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">刻意练习</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/">个人系统</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/写作/">写作</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/投资/">投资</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/逻辑/">逻辑</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/阅读/">阅读</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/各项细分/">各项细分</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/电商分析/">电商分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/统计学/">统计学</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/">编程语言</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/Hive/">Hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/Python/">Python</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/书籍/">书籍</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/写作/">写作</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分析流程/">分析流程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/双拼/">双拼</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/周报/">周报</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习方法/">学习方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/学习系统/">学习系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/情绪/">情绪</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据分析/">数据分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文章构思/">文章构思</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/日记/">日记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/术语/">术语</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/活动分析/">活动分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/生活/">生活</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/统计学/">统计学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网站/">网站</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/视频/">视频</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/读书笔记/">读书笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/路径分析/">路径分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/转载/">转载</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/运营/">运营</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/逻辑/">逻辑</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/阅读系统/">阅读系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试问题/">面试问题</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hive/" style="font-size: 12.5px;">Hive</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/书籍/" style="font-size: 10px;">书籍</a> <a href="/tags/写作/" style="font-size: 10px;">写作</a> <a href="/tags/分析流程/" style="font-size: 17.5px;">分析流程</a> <a href="/tags/双拼/" style="font-size: 10px;">双拼</a> <a href="/tags/周报/" style="font-size: 12.5px;">周报</a> <a href="/tags/学习方法/" style="font-size: 12.5px;">学习方法</a> <a href="/tags/学习系统/" style="font-size: 10px;">学习系统</a> <a href="/tags/情绪/" style="font-size: 10px;">情绪</a> <a href="/tags/数据分析/" style="font-size: 20px;">数据分析</a> <a href="/tags/文章构思/" style="font-size: 10px;">文章构思</a> <a href="/tags/日记/" style="font-size: 10px;">日记</a> <a href="/tags/术语/" style="font-size: 10px;">术语</a> <a href="/tags/活动分析/" style="font-size: 10px;">活动分析</a> <a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a> <a href="/tags/生活/" style="font-size: 10px;">生活</a> <a href="/tags/统计学/" style="font-size: 10px;">统计学</a> <a href="/tags/网站/" style="font-size: 12.5px;">网站</a> <a href="/tags/视频/" style="font-size: 10px;">视频</a> <a href="/tags/读书笔记/" style="font-size: 10px;">读书笔记</a> <a href="/tags/路径分析/" style="font-size: 10px;">路径分析</a> <a href="/tags/转载/" style="font-size: 10px;">转载</a> <a href="/tags/运营/" style="font-size: 10px;">运营</a> <a href="/tags/逻辑/" style="font-size: 10px;">逻辑</a> <a href="/tags/阅读系统/" style="font-size: 10px;">阅读系统</a> <a href="/tags/面试问题/" style="font-size: 10px;">面试问题</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/02/20/关于人生和工作的建议/">关于工作和成长的建议（节选）</a>
          </li>
        
          <li>
            <a href="/2019/02/20/linux学习/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/17/运营/">运营笔记</a>
          </li>
        
          <li>
            <a href="/2019/02/17/报表-临时需求-异常分析/">业务分析——工作报表、临时需求、异常数据排查</a>
          </li>
        
          <li>
            <a href="/2019/02/17/《刻意学习》读书笔记 /">《刻意学习》读书笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>