<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="个人博客"><title>Python爬虫学习 | 怪兽宇的小站</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.1/jquery.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/2.0.4/clipboard.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','127783955','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python爬虫学习</h1><a id="logo" href="/.">怪兽宇的小站</a><p class="description">脚踏实地，仰望星空!</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python爬虫学习</h1><div class="post-meta">2018-07-12<span> | </span><span class="category"><a href="/categories/数据分析技能/">数据分析技能</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 10</span><span class="post-meta-item-text"> 分钟</span></span></span></div><a class="disqus-comment-count" href="/2018/07/12/技能-python爬虫学习/#vcomment"><span class="valine-comment-count" data-xid="/2018/07/12/技能-python爬虫学习/"></span><span> 条评论</span></a><div class="post-content"><h1 id="爬取英雄联盟-英雄皮肤图片"><a href="#爬取英雄联盟-英雄皮肤图片" class="headerlink" title="爬取英雄联盟-英雄皮肤图片"></a>爬取英雄联盟-英雄皮肤图片</h1><ol>
<li><p>前言</p>
<blockquote>
<p>最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。</p>
</blockquote>
</li>
<li><p>过程</p>
</li>
</ol>
<ul>
<li>分析过程<blockquote>
<p>找到皮肤图片链接， 研究规律。</p>
<blockquote>
<p>在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。</p>
</blockquote>
<blockquote>
<p><img src="https://i.loli.net/2018/07/17/5b4e086d05abd.png" alt="英雄联盟图片"></p>
</blockquote>
<p>打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e09769c56a.png" alt="英雄皮肤"></p>
<p><img src="https://i.loli.net/2018/07/17/5b4e0ac67e187.png" alt="狐狸皮肤"></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 英雄1</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266000.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266001.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266002.jpg</span><br><span class="line"></span><br><span class="line"># 英雄2</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103000.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103001.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103002.jp</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>从以上的链接中，我们可以知道英雄皮肤的链接规律为：</p>
</blockquote>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;http://ossweb-img.qq.com/images/lol/web201310/skin/small&quot; + &quot;英雄代号&quot; + &quot;0&quot; + &quot;01-10&quot;</span><br></pre></td></tr></table></figure>
<ul>
<li>找到每个英雄对应的数字代号<blockquote>
<p>那么我们需要解决的问题就变成了到每个英雄对应的代号是多少？</p>
<p>通过搜索，我们发现每个英雄对应的代号存在champion.js文件中</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e0df090d6c.png" alt="英雄对应的代号"></p>
<p>从Headers中， 我们可以看到champion.js 对应的url为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;</span><br><span class="line">&gt;我们通过正则表达式， 把js中对应的英雄代号提取出来。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 通过以上把链接拼凑起来，我们就可以把链接对应的图片皮肤下载到本地了。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">3. 代码</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<p>import requests<br>import re<br>import json<br>import urllib<br>url = “<a href="http://lol.qq.com/biz/hero/champion.js&quot;" target="_blank" rel="noopener">http://lol.qq.com/biz/hero/champion.js&quot;</a><br>hd ={‘User-Agent’:”Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0”}<br>data = requests.get(url,headers = hd).content<br>datas = data.decode()<br>pat = ‘“keys”:(.*?),”data”‘<br>imglist = re.findall(pat,datas)<br>datass = json.loads(imglist[0])<br>for i in datass:<br>    try:<br>        for j in range(12):<br>            try:<br>                num = str(j)</p>
<pre><code>            # print(num)
            if len(num) == 1:
                hero_num = &quot;00&quot; + num
            elif len(num) ==2:
                hero_num = &quot;0&quot; + num
            numstr = i + hero_num
            urls = &apos;http://ossweb-img.qq.com/images/lol/web201310/skin/big&apos;+ numstr +&apos;.jpg&apos;
            localfile = &quot;E:/张宇个人文件/英雄联盟/&quot; + str(i) + str(num) +  &quot;.jpg&quot;
            urllib.request.urlretrieve(urls, filename = localfile)
        except Exception as err:
            pass
except Exception as err:
    pass
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 爬取王者荣耀-英雄图片</span><br><span class="line"></span><br><span class="line">1. 代码</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<h1 id="用python爬取王者荣耀皮肤"><a href="#用python爬取王者荣耀皮肤" class="headerlink" title="用python爬取王者荣耀皮肤"></a>用python爬取王者荣耀皮肤</h1><p>import requests<br>import re<br>import urllib</p>
<p>url = “<a href="http://pvp.qq.com/web201605/herolist.shtml&quot;" target="_blank" rel="noopener">http://pvp.qq.com/web201605/herolist.shtml&quot;</a><br>hd ={‘User-Agent’:”Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0”}<br>data = requests.get(url,headers = hd)<br>pat = ‘a href=”herodetail/(.*?).shtml’<br>imglist = re.compile(pat, re.S).findall(data.text)</p>
<p>for i in imglist:</p>
<pre><code># print(i)
try:
    for j in [1,2,3,4,5,6]:
        try:
            numstr = str(i)+&apos;/&apos; +str(i)+&apos;-mobileskin-&apos;+ str(j)
            # print(numstr)
            urls = &apos;https://game.gtimg.cn/images/yxzj/img201606/heroimg/&apos;+numstr+&apos;.jpg&apos;
            print(urls)
            localfile = &quot;E:/张宇个人文件/官网图片/&quot; + str(i)+ str(j)+  &quot;.jpg&quot;
            urllib.request.urlretrieve(urls, filename = localfile)
        except Exception as err: 
            pass
except Exception as err:
    pass
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">------</span><br><span class="line"></span><br><span class="line"># 爬取网站图片</span><br><span class="line">1. 代码</span><br><span class="line">* 构建用户代理池</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<h1 id="这里可以随意加多个浏览器"><a href="#这里可以随意加多个浏览器" class="headerlink" title="这里可以随意加多个浏览器"></a>这里可以随意加多个浏览器</h1><p>uapools = [<br>    “Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)”,<br>    “Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)”,<br>    “Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko”,<br>    “Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 920)”,<br>    “Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0.2) Gecko/20100101 Firefox/6.0.2”,<br>    “Opera/9.80 (Windows NT 6.1; WOW64) Presto/2.12.388 Version/12.12”,<br>    “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0 Safari/537.36 OPR/15.0”,<br>    “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.57 Safari/537.17”,<br>    “Mozilla/5.0 (X11; CrOS armv7l 3428.193.0) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.126 Safari/537.22”,<br>    “Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2”,<br>    “Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/533.9 (KHTML, like Gecko) Maxthon/3.0 Safari/533.9”,<br>]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2. 爬取并下载图片</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>import re<br>import requests<br>import urllib.request</p>
<h1 id="uapools-如上所示"><a href="#uapools-如上所示" class="headerlink" title="uapools 如上所示"></a>uapools 如上所示</h1><p>for ua in uapools:<br>    hd ={‘User-Agent’:ua}<br>    i = uapools.index(ua)</p>
<pre><code># 限制爬取页数， 我们爬取前10页
if i &gt; 10:
    break
try:
    url = &quot;http://www.iyuanqi.com/home/funimg/fun_list/m/Home/cp_uid/all/sort/30hot/p/&quot;+str(i)+&quot;.html&quot;
    data = requests.get(url, headers = hd)
    pat = &apos;class=&quot;lazy-img&quot; src=&quot;(.*?)&quot; data-original=&quot;&apos;
    imglist = re.compile(pat, re.S).findall(data.text)
    for j in range(0, len(imglist)):
        try:
            thisimg = imglist[j]
            thisimgurl = thisimg
            localfile = &quot;E:/张宇个人文件/网络图片/&quot; + str(i) + str(j) + &quot;.jpg&quot;
            urllib.request.urlretrieve(thisimgurl, filename = localfile)
        except Exception as err:
            pass
except Exception as err:
    pass
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-----------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 爬取天善课程数据表存储到MYSQL</span><br><span class="line"></span><br><span class="line">1. 前言</span><br><span class="line">&gt; 天善智能是一个商业智能与大数据在线社区，有很多很好的学习课程。我们用爬虫来爬取网站的所有课程并存储到MYSQL数据库中， 以便于进一步的分析。</span><br><span class="line"></span><br><span class="line">2. 用python在MYSQL中创建名为zhanhyu的数据库</span><br><span class="line"></span><br><span class="line"> * 用python连接MYSQL数据库</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>import pymysql</p>
<h1 id="因为本地mysql没有设置密码，-所以没有加password参数"><a href="#因为本地mysql没有设置密码，-所以没有加password参数" class="headerlink" title="因为本地mysql没有设置密码， 所以没有加password参数"></a>因为本地mysql没有设置密码， 所以没有加password参数</h1><p>db = pymysql.connect(host = ‘localhost’, user = ‘root’,  port = 3306)</p>
<h1 id="用cursor-方法获取MYSQL的操作游标，-利用游标来执行SQL语句"><a href="#用cursor-方法获取MYSQL的操作游标，-利用游标来执行SQL语句" class="headerlink" title="用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句"></a>用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句</h1><p>cursor = db.cursor()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> * 创建一个新的数据库， 名字叫做zhangyu</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<h1 id="cursor-execute-执行真正的sql语句-DEFAULT-指定默认值"><a href="#cursor-execute-执行真正的sql语句-DEFAULT-指定默认值" class="headerlink" title="cursor.execute 执行真正的sql语句, DEFAULT 指定默认值"></a>cursor.execute 执行真正的sql语句, DEFAULT 指定默认值</h1><p>cursor.execute(“CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8”)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">3.  在zhangyu库中创建tianshan2_datas的数据表</span><br><span class="line"></span><br><span class="line"> * 指定在zhangyu这个数据库中运行</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
<p>db = pymysql.connect(host = ‘localhost’, user = ‘root’,  port = 3306, db=’zhangyu’)<br>cursor = db.cursor()<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* 用sql语句创建名为tianshan2_datas的表</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
<p>sql = ‘CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))’</p>
<p>curosr.exectute(sql)</p>
<p>db.close()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">4. 爬取天善智能网站的数据</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>import re<br>import requests</p>
<p>for i in range(1,5):</p>
<pre><code># 观察天善课程链接， 找出规律
thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1)
# 用requests库抓取数据
hd ={&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;}
data = requests.get(thisurl, headers = hd)
#用正则表达式进行解析
title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos;
price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos;
numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos;
title = re.compile(title_pat, re.S).findall(data.text)
if(len(title)&gt;0):
    title = title[0]
else:
    continue
price = re.compile(price_pat, re.S).findall(data.text)
if(len(price)&gt;0):
    price = price[0]
else:
    price = &apos;免费&apos;
numb = re.compile(numb_pat, re.S).findall(data.text)
if(len(numb)&gt;0):
    numb = numb[0]
else:
    numb = &apos;缺失&apos;
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">5. 将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<pre><code>con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)
cursor = con.cursor()

sql = &apos;insert into  tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;
try:
    cursor.execute(sql, (title, price, numb))
    con.commit()
except:
    con.rollback()
con.close()
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">----</span><br><span class="line">&gt; 这样，我们就成功的把爬取的数据保存到mysql数据库中，方便我们查询使用。</span><br><span class="line"></span><br><span class="line">6. 完整代码</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>import pymysql</p>
<h1 id="因为本地mysql没有设置密码，-所以没有加password参数-1"><a href="#因为本地mysql没有设置密码，-所以没有加password参数-1" class="headerlink" title="因为本地mysql没有设置密码， 所以没有加password参数"></a>因为本地mysql没有设置密码， 所以没有加password参数</h1><p>db = pymysql.connect(host = ‘localhost’, user = ‘root’,  port = 3306)</p>
<h1 id="用cursor-方法获取MYSQL的操作游标，-利用游标来执行SQL语句-1"><a href="#用cursor-方法获取MYSQL的操作游标，-利用游标来执行SQL语句-1" class="headerlink" title="用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句"></a>用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句</h1><p>cursor = db.cursor()</p>
<h1 id="cursor-execute-执行真正的sql语句-DEFAULT-指定默认值-1"><a href="#cursor-execute-执行真正的sql语句-DEFAULT-指定默认值-1" class="headerlink" title="cursor.execute 执行真正的sql语句, DEFAULT 指定默认值"></a>cursor.execute 执行真正的sql语句, DEFAULT 指定默认值</h1><p>cursor.execute(“CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8”)</p>
<p>db = pymysql.connect(host = ‘localhost’, user = ‘root’,  port = 3306, db=’zhangyu’)<br>cursor = db.cursor()<br>sql = ‘CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))’<br>cursor.execute(sql)<br>db.close()</p>
<p>import re<br>import pymysql<br>import requests</p>
<p>for i in range(0,284):<br>    thisurl = “<a href="https://edu.hellobi.com/course/&quot;" target="_blank" rel="noopener">https://edu.hellobi.com/course/&quot;</a> + str(i+1)<br>    hd ={“user-agent”: “Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36”}<br>    data = requests.get(thisurl, headers = hd)<br>    title_pat = ‘<li class="active">(.<em>?)</em></li>‘<br>    price_pat = ‘class=”price-expense”&gt;<sub>￥</sub>(.?)‘<br>    numb_pat = ‘class=”course-view”&gt;(.*?)‘<br>    title = re.compile(title_pat, re.S).findall(data.text)<br>    if(len(title)&gt;0):<br>        title = title[0]<br>    else:<br>        continue<br>    price = re.compile(price_pat, re.S).findall(data.text)<br>    if(len(price)&gt;0):<br>        price = price[0]<br>    else:<br>        price = ‘免费’<br>    numb = re.compile(numb_pat, re.S).findall(data.text)<br>    if(len(numb)&gt;0):<br>        numb = numb[0]<br>    else:<br>        numb = ‘缺失’</p>
<pre><code>con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)
cursor = con.cursor()

sql = &apos;insert into  tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;
try:
    cursor.execute(sql, (title, price, numb))
    con.commit()
except:
    con.rollback()
con.close()
</code></pre><p><code>`</code></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://zhangandyu.github.io/2018/07/12/技能-python爬虫学习/" data-id="ck819938a000bikqkym7j13sm" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACrUlEQVR42u3aQXLbQAwEQP//084DEtIzwK5LqWqeVBIloXkgQABfX/Hx/XD8fc7TO0/f/S6PrxsHHh4e3qHQZ8El//L0ztNFSS7WYwx4eHh413hPAb2f845Jkkp7EfOY8fDw8D6H14bblubv5+Ph4eH9j7xZ6O3r9kw8PDy83+dtgtvf4vNS+2KvBQ8PD+/CFOlzXl+Z7+Hh4eGtp+rtokASxPuvtcsHP0SLh4eHd4GX33DbH83HV++lcJsY8PDw8G7zksFSXsgmt/tNA7f+NTw8PLwLvPw2fSrQWVu2Lfej/S88PDy8ES85aTMGywdj+cXNo8XDw8O7wds3W/PQ8xI8iWRW9OPh4eH9Dq9t1J56P28H10tXeHh4eId47brAe1G7abzO0sAPSDw8PLwLvFm7dpY22nyVtImLjjUeHh7emndqBaotkfNFhDxF/SN+PDw8vKO8zaN+HnqbEtp/fMTj4eHhXeBtNpTOhrIvx4tnBTw8PLyjvM1gfta2aBvEsz4DHh4e3lleUhwnbda22N00Z5PyHQ8PD+8Gb/Zg365StSlk3xzBw8PDu8fLR1ltIbtvW2y6Cnh4eHi3ebNmxGy3K2/mtpfycK8FDw8P77XabBu1LaBdQZi1LR4zHh4eHt5RXs5oS+d9KEkM+cXCw8PDO8vLb8HDG/GFFsbwWQEPDw/vMi+/ud8YibUJJhqA4eHh4R3l1XX36NIkbYv8F4rRFx4eHt4h3nd5JKV220TIE0n+KR4eHt49Xn60ZXE+DNuPwWYpDQ8PD2/DmyWD5NM8AWwuTbF6hYeHh3eUN2s0zEb7eWo5MFrDw8PD+0heO/7ftxWKb+Hh4eF9DG+2LNUubLVrCkW2wcPDw1vzThXH+9bDfvELDw8P7zbvwAN//Df7sNoGBx4eHt5R3h/WHCIWakii1QAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/Python/"><i class="fa fa-tag"></i>Python</a></div><div class="post-nav"><a class="pre" href="/2018/07/25/技能-python基础学习/">python基础学习</a><a class="next" href="/2018/04/23/生活-个人总结-音乐系统/">音乐</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' ? true : false;
var verify = 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'LWPB8jjoMUiH98OUCjulreBj-gzGzoHsz',
  appKey:'YOWrXQ1oP2QTavuCRp2QeRYV',
  placeholder:'　快来留下你的脚印吧',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/">个人系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析技能/">数据分析技能</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析方法/">数据分析方法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活资料/">生活资料</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/">读书笔记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/博客主题/" style="font-size: 15px;">博客主题</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/sql/" style="font-size: 15px;">sql</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/数据分析/" style="font-size: 15px;">数据分析</a> <a href="/tags/统计学/" style="font-size: 15px;">统计学</a> <a href="/tags/改版分析/" style="font-size: 15px;">改版分析</a> <a href="/tags/读书笔记/" style="font-size: 15px;">读书笔记</a> <a href="/tags/思考方法/" style="font-size: 15px;">思考方法</a> <a href="/tags/学习方法/" style="font-size: 15px;">学习方法</a> <a href="/tags/思维方法/" style="font-size: 15px;">思维方法</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/书单/" style="font-size: 15px;">书单</a> <a href="/tags/音乐/" style="font-size: 15px;">音乐</a> <a href="/tags/逻辑/" style="font-size: 15px;">逻辑</a> <a href="/tags/类比/" style="font-size: 15px;">类比</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/博客主题更换/">博客更换主题</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/22/方法-改版分析/">改版分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/07/技能-Hive进阶学习/">Hive 进阶查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/18/技能-Hive基础学习/">Hive 基础查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/30/通用-沟通能力-类比系统/">类比汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/26/方法-常见的分析方法/">常见的分析思维方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/26/方法-常见的分析模型/">常见的分析思维模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/20/生活-个人总结-成长书单/">读书档案</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/20/生活-个人总结-《零秒思考》读书笔记/">如何整理大脑思绪</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/13/生活-个人总结-《好好学习》读书笔记/">反思日记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.ruanyifeng.com/blog/" title="阮一峰的网络日志" target="_blank">阮一峰的网络日志</a><ul></ul><a href="http://www.chinawebanalytics.cn/" title="互联网分析在中国" target="_blank">互联网分析在中国</a><ul></ul><a href="https://www.yangzhiping.com/" title="阳志平的网志" target="_blank">阳志平的网志</a><ul></ul><a href="https://maxoxo.me/" title="maxOS" target="_blank">maxOS</a><ul></ul><a href="https://thelongestway.com/" title="The Longest Way" target="_blank">The Longest Way</a><ul></ul><a href="https://christophrehage.cn/" title="Christoph Rehage" target="_blank">Christoph Rehage</a><ul></ul><a href="https://codechina.org/" title="Tinyfool的中文Blog" target="_blank">Tinyfool的中文Blog</a><ul></ul><a href="http://sunny.blogchina.com/" title="梁宁的专栏" target="_blank">梁宁的专栏</a><ul></ul><a href="https://ayearofreadingtheworld.com/" title="A year of reading the world" target="_blank">A year of reading the world</a><ul></ul><a href="http://www.storytellingwithdata.com/blog/" title="storytelling-data" target="_blank">storytelling-data</a><ul></ul><a href="https://github.com/xiaolai/xiaolai.github.io" title="李笑来作品集##" target="_blank">李笑来作品集##</a><ul></ul><a href="https://etc.usf.edu/lit2go/55/around-the-world-in-80-days/" title="英文有声读物" target="_blank">英文有声读物</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">怪兽宇的小站.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/copycode/js/copycode.js"></script><link rel="stylesheet" type="text/css" href="/copycode/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>