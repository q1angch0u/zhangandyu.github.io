<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="个人博客"><title>Python爬虫 | 怪兽宇的小站</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.1/jquery.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/2.0.4/clipboard.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','127783955','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python爬虫</h1><a id="logo" href="/.">怪兽宇的小站</a><p class="description">脚踏实地，仰望星空!</p></div><div id="nav-menu"><a href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/tool/"><i class="fa fa-yelp"> 工具</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python爬虫</h1><div class="post-content"><h1 id="爬取英雄联盟-英雄皮肤图片"><a href="#爬取英雄联盟-英雄皮肤图片" class="headerlink" title="爬取英雄联盟-英雄皮肤图片"></a>爬取英雄联盟-英雄皮肤图片</h1><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>最近自己在学爬虫， 有天朋友问我能否爬取英雄联盟的皮肤图片到本地，好实现快速浏览，折腾了半个小时，终于成功了。</p>
<h2 id="2-过程"><a href="#2-过程" class="headerlink" title="2. 过程"></a>2. 过程</h2><h3 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h3><h4 id="找到皮肤图片链接，-研究规律"><a href="#找到皮肤图片链接，-研究规律" class="headerlink" title="找到皮肤图片链接， 研究规律"></a>找到皮肤图片链接， 研究规律</h4><p>在抓取图片之前，我们需要分析网址链接的构成， 以便找到其中的规律。</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e086d05abd.png" alt="英雄联盟图片"></p>
<p>打开英雄联盟网站, 点击其中的一个英雄， 我们可以看到一个英雄有1-6个皮肤甚至更多，且我们很容易从每个皮肤链接中找到规律。</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e09769c56a.png" alt="英雄皮肤"><br><img src="https://i.loli.net/2018/07/17/5b4e0ac67e187.png" alt="狐狸皮肤"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 英雄1</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266000.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266001.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small266002.jpg</span><br><span class="line"></span><br><span class="line"># 英雄2</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103000.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103001.jpg</span><br><span class="line">http://ossweb-img.qq.com/images/lol/web201310/skin/small103002.jp</span><br></pre></td></tr></table></figure>
<p>从以上的链接中，我们可以知道英雄皮肤的链接规律为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;http://ossweb-img.qq.com/images/lol/web201310/skin/small&quot; + &quot;英雄代号&quot; + &quot;0&quot; + &quot;01-10&quot;</span><br></pre></td></tr></table></figure></p>
<h4 id="找到每个英雄对应的数字代号"><a href="#找到每个英雄对应的数字代号" class="headerlink" title="找到每个英雄对应的数字代号"></a>找到每个英雄对应的数字代号</h4><p>那么我们需要解决的问题就变成了到每个英雄对应的代号是多少？</p>
<p>通过搜索，我们发现每个英雄对应的代号存在champion.js文件中</p>
<p><img src="https://i.loli.net/2018/07/17/5b4e0df090d6c.png" alt="英雄对应的代号"></p>
<p>从Headers中， 我们可以看到champion.js 对应的url为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://lol.qq.com/biz/hero/champion.js</span><br></pre></td></tr></table></figure></p>
<p>我们通过正则表达式， 把js中对应的英雄代号提取出来。</p>
<p>通过以上把链接拼凑起来，我们就可以把链接对应的图片皮肤下载到本地了。</p>
<h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3. 代码"></a>3. 代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import json</span><br><span class="line">import urllib</span><br><span class="line">url = &quot;http://lol.qq.com/biz/hero/champion.js&quot;</span><br><span class="line">hd =&#123;&apos;User-Agent&apos;:&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0&quot;&#125;</span><br><span class="line">data = requests.get(url,headers = hd).content</span><br><span class="line">datas = data.decode()</span><br><span class="line">pat = &apos;&quot;keys&quot;:(.*?),&quot;data&quot;&apos;</span><br><span class="line">imglist = re.findall(pat,datas)</span><br><span class="line">datass = json.loads(imglist[0])</span><br><span class="line">for i in datass:</span><br><span class="line">    try:</span><br><span class="line">        for j in range(12):</span><br><span class="line">            try:</span><br><span class="line">                num = str(j)</span><br><span class="line">                # print(num)</span><br><span class="line">                if len(num) == 1:</span><br><span class="line">                    hero_num = &quot;00&quot; + num</span><br><span class="line">                elif len(num) ==2:</span><br><span class="line">                    hero_num = &quot;0&quot; + num</span><br><span class="line">                numstr = i + hero_num</span><br><span class="line">                urls = &apos;http://ossweb-img.qq.com/images/lol/web201310/skin/big&apos;+ numstr +&apos;.jpg&apos;</span><br><span class="line">                localfile = &quot;E:/张宇个人文件/英雄联盟/&quot; + str(i) + str(num) +  &quot;.jpg&quot;</span><br><span class="line">                urllib.request.urlretrieve(urls, filename = localfile)</span><br><span class="line">            except Exception as err:</span><br><span class="line">                pass</span><br><span class="line">    except Exception as err:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="爬取王者荣耀-英雄图片"><a href="#爬取王者荣耀-英雄图片" class="headerlink" title="爬取王者荣耀-英雄图片"></a>爬取王者荣耀-英雄图片</h1><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 用python爬取王者荣耀皮肤</span><br><span class="line"></span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import urllib</span><br><span class="line"></span><br><span class="line">url = &quot;http://pvp.qq.com/web201605/herolist.shtml&quot;</span><br><span class="line">hd =&#123;&apos;User-Agent&apos;:&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.802.30 Safari/535.1 SE 2.X MetaSr 1.0&quot;&#125;</span><br><span class="line">data = requests.get(url,headers = hd)</span><br><span class="line">pat = &apos;a href=&quot;herodetail/(.*?).shtml&apos;</span><br><span class="line">imglist = re.compile(pat, re.S).findall(data.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in imglist:</span><br><span class="line">    # print(i)</span><br><span class="line">    try:</span><br><span class="line">        for j in [1,2,3,4,5,6]:</span><br><span class="line">            try:</span><br><span class="line">                numstr = str(i)+&apos;/&apos; +str(i)+&apos;-mobileskin-&apos;+ str(j)</span><br><span class="line">                # print(numstr)</span><br><span class="line">                urls = &apos;https://game.gtimg.cn/images/yxzj/img201606/heroimg/&apos;+numstr+&apos;.jpg&apos;</span><br><span class="line">                print(urls)</span><br><span class="line">                localfile = &quot;E:/张宇个人文件/官网图片/&quot; + str(i)+ str(j)+  &quot;.jpg&quot;</span><br><span class="line">                urllib.request.urlretrieve(urls, filename = localfile)</span><br><span class="line">            except Exception as err: </span><br><span class="line">                pass</span><br><span class="line">    except Exception as err:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="爬取网站美女图片"><a href="#爬取网站美女图片" class="headerlink" title="爬取网站美女图片"></a>爬取网站美女图片</h1><h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><h3 id="构建用户代理池"><a href="#构建用户代理池" class="headerlink" title="构建用户代理池"></a>构建用户代理池</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 这里可以随意加多个浏览器</span><br><span class="line">uapools = [</span><br><span class="line">    &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 920)&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0.2) Gecko/20100101 Firefox/6.0.2&quot;,</span><br><span class="line">    &quot;Opera/9.80 (Windows NT 6.1; WOW64) Presto/2.12.388 Version/12.12&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0 Safari/537.36 OPR/15.0&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.57 Safari/537.17&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (X11; CrOS armv7l 3428.193.0) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.126 Safari/537.22&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2&quot;,</span><br><span class="line">    &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/533.9 (KHTML, like Gecko) Maxthon/3.0 Safari/533.9&quot;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3 id="爬取并下载图片"><a href="#爬取并下载图片" class="headerlink" title="爬取并下载图片"></a>爬取并下载图片</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import requests</span><br><span class="line">import urllib.request</span><br><span class="line"># uapools 如上所示</span><br><span class="line">for ua in uapools:</span><br><span class="line">    hd =&#123;&apos;User-Agent&apos;:ua&#125;</span><br><span class="line">    i = uapools.index(ua)</span><br><span class="line">    # 限制爬取页数， 我们爬取前10页</span><br><span class="line">    if i &gt; 10:</span><br><span class="line">        break</span><br><span class="line">    try:</span><br><span class="line">        url = &quot;http://www.iyuanqi.com/home/funimg/fun_list/m/Home/cp_uid/all/sort/30hot/p/&quot;+str(i)+&quot;.html&quot;</span><br><span class="line">        data = requests.get(url, headers = hd)</span><br><span class="line">        pat = &apos;class=&quot;lazy-img&quot; src=&quot;(.*?)&quot; data-original=&quot;&apos;</span><br><span class="line">        imglist = re.compile(pat, re.S).findall(data.text)</span><br><span class="line">        for j in range(0, len(imglist)):</span><br><span class="line">            try:</span><br><span class="line">                thisimg = imglist[j]</span><br><span class="line">                thisimgurl = thisimg</span><br><span class="line">                localfile = &quot;E:/张宇个人文件/网络图片/&quot; + str(i) + str(j) + &quot;.jpg&quot;</span><br><span class="line">                urllib.request.urlretrieve(thisimgurl, filename = localfile)</span><br><span class="line">            except Exception as err:</span><br><span class="line">                pass</span><br><span class="line">    except Exception as err:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="爬取天善课程数据表存储到MYSQL"><a href="#爬取天善课程数据表存储到MYSQL" class="headerlink" title="爬取天善课程数据表存储到MYSQL"></a>爬取天善课程数据表存储到MYSQL</h1><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>天善智能是一个商业智能与大数据在线社区，有很多很好的学习课程。我们用爬虫来爬取网站的所有课程并存储到MYSQL数据库中， 以便于进一步的分析。</p>
<h4 id="用python在MYSQL中创建名为zhanhyu的数据库"><a href="#用python在MYSQL中创建名为zhanhyu的数据库" class="headerlink" title="用python在MYSQL中创建名为zhanhyu的数据库"></a>用python在MYSQL中创建名为zhanhyu的数据库</h4><ul>
<li>用python连接MYSQL数据库</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line"># 因为本地mysql没有设置密码， 所以没有加password参数</span><br><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306)</span><br><span class="line"></span><br><span class="line"># 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句</span><br><span class="line">cursor = db.cursor()</span><br></pre></td></tr></table></figure>
<ul>
<li>创建一个新的数据库， 名字叫做zhangyu</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># cursor.execute 执行真正的sql语句, DEFAULT 指定默认值</span><br><span class="line">cursor.execute(&quot;CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="在zhangyu库中创建tianshan2-datas的数据表"><a href="#在zhangyu库中创建tianshan2-datas的数据表" class="headerlink" title="在zhangyu库中创建tianshan2_datas的数据表"></a>在zhangyu库中创建tianshan2_datas的数据表</h4><ul>
<li>指定在zhangyu这个数据库中运行</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306, db=&apos;zhangyu&apos;)</span><br><span class="line">cursor = db.cursor()</span><br></pre></td></tr></table></figure>
<ul>
<li>用sql语句创建名为tianshan2_datas的表</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sql = &apos;CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))&apos;</span><br><span class="line"></span><br><span class="line">curosr.exectute(sql)</span><br><span class="line"></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<h4 id="爬取天善智能网站的数据"><a href="#爬取天善智能网站的数据" class="headerlink" title="爬取天善智能网站的数据"></a>爬取天善智能网站的数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">for i in range(1,5):</span><br><span class="line">    # 观察天善课程链接， 找出规律</span><br><span class="line">    thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1)</span><br><span class="line">    # 用requests库抓取数据</span><br><span class="line">    hd =&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;&#125;</span><br><span class="line">    data = requests.get(thisurl, headers = hd)</span><br><span class="line">    #用正则表达式进行解析</span><br><span class="line">    title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos;</span><br><span class="line">    price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    title = re.compile(title_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(title)&gt;0):</span><br><span class="line">        title = title[0]</span><br><span class="line">    else:</span><br><span class="line">        continue</span><br><span class="line">    price = re.compile(price_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(price)&gt;0):</span><br><span class="line">        price = price[0]</span><br><span class="line">    else:</span><br><span class="line">        price = &apos;免费&apos;</span><br><span class="line">    numb = re.compile(numb_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(numb)&gt;0):</span><br><span class="line">        numb = numb[0]</span><br><span class="line">    else:</span><br><span class="line">        numb = &apos;缺失&apos;</span><br></pre></td></tr></table></figure>
<h4 id="将爬取的数据存储到名为zhangyu数据库的tianshan2-datas表中"><a href="#将爬取的数据存储到名为zhangyu数据库的tianshan2-datas表中" class="headerlink" title="将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中"></a>将爬取的数据存储到名为zhangyu数据库的tianshan2_datas表中</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)</span><br><span class="line">cursor = con.cursor()</span><br><span class="line"></span><br><span class="line">sql = &apos;insert into  tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;</span><br><span class="line">try:</span><br><span class="line">    cursor.execute(sql, (title, price, numb))</span><br><span class="line">    con.commit()</span><br><span class="line">except:</span><br><span class="line">    con.rollback()</span><br><span class="line">con.close()</span><br></pre></td></tr></table></figure>
<hr>
<p>这样，我们就成功的把爬取的数据保存到mysql数据库中，方便我们查询使用。</p>
<h4 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line"># 因为本地mysql没有设置密码， 所以没有加password参数</span><br><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306)</span><br><span class="line"></span><br><span class="line"># 用cursor()方法获取MYSQL的操作游标， 利用游标来执行SQL语句</span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"># cursor.execute 执行真正的sql语句, DEFAULT 指定默认值</span><br><span class="line">cursor.execute(&quot;CREATE DATABASE zhangyu DEFAULT CHARACTER SET utf8&quot;)</span><br><span class="line"></span><br><span class="line">db = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;,  port = 3306, db=&apos;zhangyu&apos;)</span><br><span class="line">cursor = db.cursor()</span><br><span class="line">sql = &apos;CREATE TABLE IF NOT EXISTS tianshan2_datas (name VARCHAR(255) NOT NULL, pirce VARCHAR(255) NOT NULL,numbers VARCHAR(255), PRIMARY KEY (name))&apos;</span><br><span class="line">cursor.execute(sql)</span><br><span class="line">db.close()</span><br><span class="line"></span><br><span class="line">import re</span><br><span class="line">import pymysql</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">for i in range(0,284):</span><br><span class="line">    thisurl = &quot;https://edu.hellobi.com/course/&quot; + str(i+1)</span><br><span class="line">    hd =&#123;&quot;user-agent&quot;: &quot;Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Mobile Safari/537.36&quot;&#125;</span><br><span class="line">    data = requests.get(thisurl, headers = hd)</span><br><span class="line">    title_pat = &apos;&lt;li class=&quot;active&quot;&gt;(.*?)&lt;/li&gt;&apos;</span><br><span class="line">    price_pat = &apos;class=&quot;price-expense&quot;&gt;&lt;sub&gt;￥&lt;/sub&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    numb_pat = &apos;class=&quot;course-view&quot;&gt;(.*?)&lt;/span&gt;&apos;</span><br><span class="line">    title = re.compile(title_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(title)&gt;0):</span><br><span class="line">        title = title[0]</span><br><span class="line">    else:</span><br><span class="line">        continue</span><br><span class="line">    price = re.compile(price_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(price)&gt;0):</span><br><span class="line">        price = price[0]</span><br><span class="line">    else:</span><br><span class="line">        price = &apos;免费&apos;</span><br><span class="line">    numb = re.compile(numb_pat, re.S).findall(data.text)</span><br><span class="line">    if(len(numb)&gt;0):</span><br><span class="line">        numb = numb[0]</span><br><span class="line">    else:</span><br><span class="line">        numb = &apos;缺失&apos;</span><br><span class="line">        </span><br><span class="line">    con = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, port = 3306, db = &apos;zhangyu&apos;)</span><br><span class="line">    cursor = con.cursor()</span><br><span class="line"></span><br><span class="line">    sql = &apos;insert into  tianshan2_datas(name, pirce, numbers) values(%s,%s,%s)&apos;</span><br><span class="line">    try:</span><br><span class="line">        cursor.execute(sql, (title, price, numb))</span><br><span class="line">        con.commit()</span><br><span class="line">    except:</span><br><span class="line">        con.rollback()</span><br><span class="line">    con.close()</span><br></pre></td></tr></table></figure>
</div></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' ? true : false;
var verify = 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'LWPB8jjoMUiH98OUCjulreBj-gzGzoHsz',
  appKey:'YOWrXQ1oP2QTavuCRp2QeRYV',
  placeholder:'　快来留下你的脚印吧',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/个人系统/">个人系统</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析技能/">数据分析技能</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析方法/">数据分析方法</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活资料/">生活资料</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书笔记/">读书笔记</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/04/02/技能-Hive中的窗口函数/">Hive 中的窗口函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/20/生活-个人总结-博客主题更换/">博客主题更换</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/03/方法-数据异常分析/">数据异常分析方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/02/生活-个人总结-利用环境来辅助自己的进步/">利用环境来辅助自己进步</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/29/方法-如何用数据说话/">如何用数据说话</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/01/技能-数据分析-培养数据敏感度/">培养数据敏感度</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/22/方法-改版分析/">改版分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/12/方法-常用指标/">搭建业务运营指标</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/07/技能-Hive进阶学习/">Hive 进阶查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/22/方法-营销活动分析/">营销活动分析</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/数据分析/" style="font-size: 15px;">数据分析</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/sql/" style="font-size: 15px;">sql</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/数据敏感度/" style="font-size: 15px;">数据敏感度</a> <a href="/tags/统计学/" style="font-size: 15px;">统计学</a> <a href="/tags/报告/" style="font-size: 15px;">报告</a> <a href="/tags/岗位介绍/" style="font-size: 15px;">岗位介绍</a> <a href="/tags/常用指标/" style="font-size: 15px;">常用指标</a> <a href="/tags/改版分析/" style="font-size: 15px;">改版分析</a> <a href="/tags/异常分析/" style="font-size: 15px;">异常分析</a> <a href="/tags/活动分析/" style="font-size: 15px;">活动分析</a> <a href="/tags/逻辑/" style="font-size: 15px;">逻辑</a> <a href="/tags/学习方法/" style="font-size: 15px;">学习方法</a> <a href="/tags/读书笔记/" style="font-size: 15px;">读书笔记</a> <a href="/tags/思考方法/" style="font-size: 15px;">思考方法</a> <a href="/tags/思维方法/" style="font-size: 15px;">思维方法</a> <a href="/tags/心理/" style="font-size: 15px;">心理</a> <a href="/tags/方法/" style="font-size: 15px;">方法</a> <a href="/tags/博客主题/" style="font-size: 15px;">博客主题</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/书单/" style="font-size: 15px;">书单</a> <a href="/tags/音乐/" style="font-size: 15px;">音乐</a> <a href="/tags/类比/" style="font-size: 15px;">类比</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.ruanyifeng.com/blog/" title="阮一峰的网络日志" target="_blank">阮一峰的网络日志</a><ul></ul><a href="http://www.chinawebanalytics.cn/" title="互联网分析在中国" target="_blank">互联网分析在中国</a><ul></ul><a href="https://www.yangzhiping.com/" title="阳志平的网志" target="_blank">阳志平的网志</a><ul></ul><a href="https://maxoxo.me/" title="maxOS" target="_blank">maxOS</a><ul></ul><a href="https://thelongestway.com/" title="The Longest Way" target="_blank">The Longest Way</a><ul></ul><a href="https://christophrehage.cn/" title="Christoph Rehage" target="_blank">Christoph Rehage</a><ul></ul><a href="https://codechina.org/" title="Tinyfool的中文Blog" target="_blank">Tinyfool的中文Blog</a><ul></ul><a href="http://sunny.blogchina.com/" title="梁宁的专栏" target="_blank">梁宁的专栏</a><ul></ul><a href="https://ayearofreadingtheworld.com/" title="A year of reading the world" target="_blank">A year of reading the world</a><ul></ul><a href="http://www.storytellingwithdata.com/blog/" title="storytelling-data" target="_blank">storytelling-data</a><ul></ul><a href="https://github.com/xiaolai/xiaolai.github.io" title="李笑来网站" target="_blank">李笑来网站</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">怪兽宇的小站.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/love/js/love.js"></script><script type="text/javascript" src="/copycode/js/copycode.js"></script><link rel="stylesheet" type="text/css" href="/copycode/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>